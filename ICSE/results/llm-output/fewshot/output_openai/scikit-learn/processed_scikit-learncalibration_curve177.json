{
    "result": "Certainly! Below is a Python function called `calibration_curve` that computes true and predicted probabilities for a calibration curve. It includes parameters for true targets, predicted probabilities, the positive class label, the number of bins, and the binning strategy. Additionally, I've included examples demonstrating how to use the function with sample data.\n\n```python\nimport numpy as np\nfrom sklearn.utils import check_consistent_length\nfrom sklearn.utils import column_or_1d\nfrom sklearn.utils import assert_all_finite\n\ndef calibration_curve(y_true, y_prob, pos_label=None, n_bins=5, strategy='uniform'):\n    \"\"\"\n    Compute true and predicted probabilities for a calibration curve.\n\n    Parameters:\n    - y_true: array-like of shape (n_samples), true targets.\n    - y_prob: array-like of shape (n_samples), probabilities of the positive class.\n    - pos_label: int, float, bool, or str, default=None, label of the positive class.\n    - n_bins: int, default=5, number of bins to discretize the [0, 1] interval.\n    - strategy: {'uniform', 'quantile'}, default='uniform', strategy to define bin widths.\n\n    Returns:\n    - prob_true: ndarray of shape (n_bins,) or smaller, proportion of samples whose class is the positive class in each bin.\n    - prob_pred: ndarray of shape (n_bins,) or smaller, mean predicted probability in each bin.\n    \"\"\"\n    y_true = column_or_1d(y_true)\n    y_prob = column_or_1d(y_prob)\n    check_consistent_length(y_true, y_prob)\n    assert_all_finite(y_true)\n    assert_all_finite(y_prob)\n\n    if pos_label is None:\n        pos_label = 1.0\n\n    y_true = (y_true == pos_label)\n\n    if strategy not in ['uniform', 'quantile']:\n        raise ValueError(\"Strategy must be either 'uniform' or 'quantile'\")\n\n    if strategy == 'uniform':\n        bins = np.linspace(0., 1., n_bins + 1)\n    else:  # strategy == 'quantile'\n        bins = np.percentile(y_prob, np.linspace(0, 100, n_bins + 1))\n\n    binids = np.digitize(y_prob, bins) - 1\n\n    prob_true = np.zeros(n_bins)\n    prob_pred = np.zeros(n_bins)\n\n    for i in range(n_bins):\n        mask = binids == i\n        if np.any(mask):\n            prob_true[i] = y_true[mask].mean()\n            prob_pred[i] = y_prob[mask].mean()\n\n    return prob_true, prob_pred\n\n# Example usage:\nif __name__ == \"__main__\":\n    y_true = np.array([0, 0, 1, 1])\n    y_prob = np.array([0.1, 0.4, 0.35, 0.8])\n\n    prob_true, prob_pred = calibration_curve(y_true, y_prob, n_bins=2, strategy='uniform')\n    print(\"Prob True:\", prob_true)\n    print(\"Prob Pred:\", prob_pred)\n\n    prob_true, prob_pred = calibration_curve(y_true, y_prob, n_bins=2, strategy='quantile')\n    print(\"Prob True (quantile):\", prob_true)\n    print(\"Prob Pred (quantile):\", prob_pred)\n```\n\n### Explanation:\n- **Parameters**:\n  - `y_true`: True binary labels.\n  - `y_prob`: Predicted probabilities for the positive class.\n  - `pos_label`: Specifies which class is considered the positive class.\n  - `n_bins`: Number of bins to divide the probability range.\n  - `strategy`: Determines how the bins are defined, either uniformly or based on quantiles.\n\n- **Returns**:\n  - `prob_true`: Fraction of positive samples in each bin.\n  - `prob_pred`: Mean predicted probability in each bin.\n\n- **Example Usage**: Demonstrates how to use the function with sample data, showing both uniform and quantile binning strategies.",
    "prompt": "Generate a Python function called calibration_curve that computes true and predicted probabilities for a calibration curve. The function takes in the following parameters:\n\n- y_true: array-like of shape (n_samples), representing the true targets.\n- y_prob: array-like of shape (n_samples), representing the probabilities of the positive class.\n- pos_label: int, float, bool, or str, default=None, indicating the label of the positive class.\n- n_bins: int, default=5, specifying the number of bins to discretize the [0, 1] interval.\n- strategy: {'uniform', 'quantile'}, default='uniform', determining the strategy used to define the widths of the bins.\n\nThe function returns two arrays:\n- prob_true: ndarray of shape (n_bins,) or smaller, representing the proportion of samples whose class is the positive class in each bin (fraction of positives).\n- prob_pred: ndarray of shape (n_bins,) or smaller, representing the mean predicted probability in each bin.\n\nThe function also includes examples demonstrating how to use it with sample data.",
    "function_name": "calibration_curve",
    "ground_truth": "sklearn/calibration.py",
    "test": "sklearn/tests/test_calibration.py::test_calibration_display_pos_label",
    "class": "",
    "stage": "Inference",
    "task": "Classification",
    "data": "Table"
}