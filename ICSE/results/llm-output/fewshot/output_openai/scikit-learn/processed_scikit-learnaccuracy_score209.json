{
    "result": "Certainly! Below is a Python function called `accuracy_score` that calculates the accuracy classification score. It includes parameters for ground truth labels, predicted labels, normalization, and sample weights. Additionally, I've included examples demonstrating how to use the function with different inputs.\n\n```python\nimport numpy as np\n\ndef accuracy_score(y_true, y_pred, normalize=True, sample_weight=None):\n    \"\"\"\n    Calculate the accuracy classification score.\n\n    Args:\n        y_true (array-like): Ground truth (correct) labels.\n        y_pred (array-like): Predicted labels.\n        normalize (bool): If True, return the fraction of correctly classified samples.\n                          If False, return the number of correctly classified samples.\n        sample_weight (array-like, optional): Sample weights. Defaults to None.\n\n    Returns:\n        float or int: Accuracy score. The best performance is 1 with normalize=True\n                      and the number of samples with normalize=False.\n    \"\"\"\n    y_true = np.asarray(y_true)\n    y_pred = np.asarray(y_pred)\n\n    if sample_weight is None:\n        sample_weight = np.ones_like(y_true, dtype=np.float64)\n    else:\n        sample_weight = np.asarray(sample_weight)\n\n    if y_true.shape != y_pred.shape:\n        raise ValueError(\"Shape of y_true and y_pred must be the same.\")\n\n    correct_predictions = (y_true == y_pred)\n    weighted_correct_predictions = sample_weight * correct_predictions\n\n    if normalize:\n        return np.sum(weighted_correct_predictions) / np.sum(sample_weight)\n    else:\n        return np.sum(weighted_correct_predictions)\n\n# Examples\n# Example 1: Basic usage with normalization\ny_true = [0, 1, 2, 3]\ny_pred = [0, 2, 1, 3]\nprint(accuracy_score(y_true, y_pred))  # Output: 0.5\n\n# Example 2: Without normalization\nprint(accuracy_score(y_true, y_pred, normalize=False))  # Output: 2\n\n# Example 3: With sample weights\nsample_weight = [0.5, 1, 1, 0.5]\nprint(accuracy_score(y_true, y_pred, sample_weight=sample_weight))  # Output: 0.5\n\n# Example 4: With sample weights and without normalization\nprint(accuracy_score(y_true, y_pred, normalize=False, sample_weight=sample_weight))  # Output: 2.0\n```\n\nThis function calculates the accuracy by comparing the true labels (`y_true`) with the predicted labels (`y_pred`). It can return either the fraction of correctly classified samples or the count of correctly classified samples, depending on the `normalize` parameter. The `sample_weight` parameter allows for weighted accuracy calculations.",
    "prompt": "Generate a Python function called accuracy_score that calculates the accuracy classification score. The function takes in the following parameters:\n\n- y_true: Ground truth (correct) labels\n- y_pred: Predicted labels\n- normalize: Boolean value indicating whether to return the fraction of correctly classified samples or the number of correctly classified samples\n- sample_weight: Sample weights\n\nThe function returns a float or integer value based on the normalize parameter. The best performance is 1 when normalize is True and the number of samples when normalize is False.\n\nThe function also includes examples demonstrating how to use it with different inputs.",
    "function_name": "accuracy_score",
    "ground_truth": "sklearn/metrics/_classification.py",
    "test": "sklearn/metrics/tests/test_classification.py",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "Classification",
    "data": ""
}