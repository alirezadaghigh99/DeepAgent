{
    "result": "To create a Python function called `hinge_loss` that calculates the average hinge loss for binary or multiclass classification tasks, you can follow the structure and guidelines provided in your request. Here's a possible implementation:\n\n```python\nimport numpy as np\n\ndef hinge_loss(y_true, pred_decision, labels=None, sample_weight=None):\n    \"\"\"\n    Calculate the average hinge loss for binary or multiclass classification tasks.\n\n    Args:\n        y_true (array-like): True target values, encoded as integers (+1 and -1 for binary classification).\n        pred_decision (array-like): Predicted decision values.\n        labels (array-like, optional): All labels for multiclass hinge loss. Defaults to None.\n        sample_weight (array-like, optional): Sample weights. Defaults to None.\n\n    Returns:\n        float: The average hinge loss.\n    \"\"\"\n    y_true = np.asarray(y_true)\n    pred_decision = np.asarray(pred_decision)\n\n    if sample_weight is not None:\n        sample_weight = np.asarray(sample_weight)\n        if sample_weight.shape != y_true.shape:\n            raise ValueError(\"sample_weight and y_true must have the same shape.\")\n\n    if labels is None:\n        labels = np.unique(y_true)\n\n    if len(labels) == 2:\n        # Binary classification\n        y_true = np.where(y_true == labels[0], 1, -1)\n        loss = np.maximum(0, 1 - y_true * pred_decision)\n    else:\n        # Multiclass classification\n        if pred_decision.ndim == 1:\n            raise ValueError(\"pred_decision must be a 2D array for multiclass classification.\")\n        \n        n_samples, n_classes = pred_decision.shape\n        if n_classes != len(labels):\n            raise ValueError(\"Number of columns in pred_decision must match number of labels.\")\n\n        correct_class_scores = pred_decision[np.arange(n_samples), y_true]\n        margins = np.maximum(0, pred_decision - correct_class_scores[:, np.newaxis] + 1)\n        margins[np.arange(n_samples), y_true] = 0\n        loss = np.sum(margins, axis=1)\n\n    if sample_weight is not None:\n        loss *= sample_weight\n\n    return np.mean(loss)\n\n```\n\n### Explanation:\n\n1. **Input Validation**: The function first converts `y_true` and `pred_decision` to NumPy arrays for efficient computation. It also checks if `sample_weight` is provided and ensures it has the same shape as `y_true`.\n\n2. **Label Handling**: If `labels` are not provided, it defaults to the unique values in `y_true`.\n\n3. **Binary Classification**: For binary classification, the function calculates the hinge loss using the formula `max(0, 1 - y_true * pred_decision)`.\n\n4. **Multiclass Classification**: For multiclass classification, it calculates the margins for each class and sums them, excluding the correct class.\n\n5. **Sample Weighting**: If `sample_weight` is provided, it multiplies the loss by the sample weights.\n\n6. **Return**: The function returns the mean of the calculated loss values.\n\nThis implementation handles both binary and multiclass cases and includes error handling for various scenarios.",
    "prompt": "Create a Python function called hinge_loss that calculates the average hinge loss for binary or multiclass classification tasks. The function takes in the following parameters:\n\n- y_true: an array-like object containing the true target values, encoded as integers (+1 and -1 for binary classification).\n- pred_decision: an array-like object containing the predicted decision values.\n- labels: an optional array-like object containing all the labels for multiclass hinge loss.\n- sample_weight: an optional array-like object containing sample weights.\n\nThe function returns the average hinge loss as a float value. The hinge loss is calculated based on the margin between the true and predicted values, and it serves as an upper bound for the number of classification mistakes made by the classifier.\n\nThe function handles both binary and multiclass cases, applying different calculations based on the number of unique labels present in the target values. The implementation includes error handling for different scenarios and utilizes NumPy functions for efficient computation.",
    "function_name": "hinge_loss",
    "ground_truth": "sklearn/metrics/_classification.py",
    "test": "sklearn/metrics/tests/test_classification.py",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "Classificatoin",
    "data": "Table"
}