{
    "result": "To implement the `ndcg_score` function, we need to calculate the Normalized Discounted Cumulative Gain (NDCG) for a set of true labels and predicted scores. The NDCG is a measure of ranking quality, and it is particularly useful in information retrieval and recommendation systems. Here's how you can implement this function in Python:\n\n```python\nimport numpy as np\n\ndef dcg_score(y_true, y_score, k=None, ignore_ties=False):\n    \"\"\"Compute Discounted Cumulative Gain.\"\"\"\n    order = np.argsort(y_score)[::-1]\n    y_true = np.take(y_true, order[:k])\n\n    if not ignore_ties:\n        gains = 2 ** y_true - 1\n    else:\n        gains = y_true\n\n    discounts = np.log2(np.arange(len(y_true)) + 2)\n    return np.sum(gains / discounts)\n\ndef ndcg_score(y_true, y_score, k=None, sample_weight=None, ignore_ties=False):\n    \"\"\"Compute Normalized Discounted Cumulative Gain (NDCG).\"\"\"\n    y_true = np.asarray(y_true)\n    y_score = np.asarray(y_score)\n\n    if sample_weight is None:\n        sample_weight = np.ones(y_true.shape[0])\n    else:\n        sample_weight = np.asarray(sample_weight)\n\n    scores = []\n    for i in range(y_true.shape[0]):\n        actual_dcg = dcg_score(y_true[i], y_score[i], k, ignore_ties)\n        best_dcg = dcg_score(y_true[i], y_true[i], k, ignore_ties)\n        if best_dcg == 0:\n            score = 0.0\n        else:\n            score = actual_dcg / best_dcg\n        scores.append(score * sample_weight[i])\n\n    return np.sum(scores) / np.sum(sample_weight)\n\n# Example usage:\ny_true = np.array([[3, 2, 3, 0, 1, 2]])\ny_score = np.array([[0.1, 0.4, 0.35, 0.8, 0.7, 0.2]])\nprint(ndcg_score(y_true, y_score, k=5))\n```\n\n### Explanation:\n\n1. **DCG Calculation**: The `dcg_score` function computes the Discounted Cumulative Gain (DCG) by sorting the predicted scores, taking the top `k` scores, and applying a logarithmic discount to the true scores.\n\n2. **NDCG Calculation**: The `ndcg_score` function calculates the NDCG by dividing the actual DCG by the ideal DCG (best possible DCG). The ideal DCG is computed by assuming a perfect ranking of the true scores.\n\n3. **Sample Weighting**: If `sample_weight` is provided, it is used to weight the NDCG scores for each sample.\n\n4. **Handling Ties**: The `ignore_ties` parameter allows for efficiency gains by assuming no ties in the predicted scores.\n\nThis implementation provides a flexible way to compute NDCG for multilabel classification or ranking tasks, with options for handling ties and weighting samples.",
    "prompt": "Generate a Python function called ndcg_score that Compute Normalized Discounted Cumulative Gain.\n\n    Sum the true scores ranked in the order induced by the predicted scores,\n    after applying a logarithmic discount. Then divide by the best possible\n    score (Ideal DCG, obtained for a perfect ranking) to obtain a score between\n    0 and 1.\n\n    This ranking metric returns a high value if true labels are ranked high by\n    ``y_score``.\n\n    Parameters\n    ----------\n    y_true : array-like of shape (n_samples, n_labels)\n        True targets of multilabel classification, or true scores of entities\n        to be ranked. Negative values in `y_true` may result in an output\n        that is not between 0 and 1.\n\n    y_score : array-like of shape (n_samples, n_labels)\n        Target scores, can either be probability estimates, confidence values,\n        or non-thresholded measure of decisions (as returned by\n        \"decision_function\" on some classifiers).\n\n    k : int, default=None\n        Only consider the highest k scores in the ranking. If `None`, use all\n        outputs.\n\n    sample_weight : array-like of shape (n_samples,), default=None\n        Sample weights. If `None`, all samples are given the same weight.\n\n    ignore_ties : bool, default=False\n        Assume that there are no ties in y_score (which is likely to be the\n        case if y_score is continuous) for efficiency gains.\n\n    Returns\n    -------\n    normalized_discounted_cumulative_gain : float in [0., 1.]\n        The averaged NDCG scores for all samples.",
    "function_name": "ndcg_score",
    "ground_truth": "sklearn/metrics/_ranking.py",
    "test": "sklearn/metrics/tests/test_ranking.py:test_ndcg_toy_examples",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "",
    "data": "Table"
}