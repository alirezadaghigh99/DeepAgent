{
    "result": "Certainly! Below is a Python function that standardizes a dataset along a specified axis, centering it to the mean and scaling it to unit variance. This function is similar to the `StandardScaler` in scikit-learn.\n\n```python\nimport numpy as np\nfrom scipy import sparse\n\ndef scale(X, axis=0, with_mean=True, with_std=True, copy=True):\n    \"\"\"\n    Standardize a dataset along any axis.\n\n    Center to the mean and component-wise scale to unit variance.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The data to center and scale.\n\n    axis : {0, 1}, default=0\n        Axis used to compute the means and standard deviations along. If 0,\n        independently standardize each feature, otherwise (if 1) standardize\n        each sample.\n\n    with_mean : bool, default=True\n        If True, center the data before scaling.\n\n    with_std : bool, default=True\n        If True, scale the data to unit variance (or equivalently,\n        unit standard deviation).\n\n    copy : bool, default=True\n        If False, try to avoid a copy and scale in place.\n        This is not guaranteed to always work in place; e.g. if the data is\n        a numpy array with an int dtype, a copy will be returned even with\n        copy=False.\n\n    Returns\n    -------\n    X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n        The transformed data.\n    \"\"\"\n    if sparse.issparse(X):\n        raise TypeError(\"Sparse matrices are not supported by this function.\")\n\n    X = np.array(X, copy=copy, dtype=np.float64)\n\n    if with_mean:\n        mean = np.mean(X, axis=axis, keepdims=True)\n        X -= mean\n\n    if with_std:\n        scale = np.std(X, axis=axis, keepdims=True)\n        scale[scale == 0] = 1  # Avoid division by zero\n        X /= scale\n\n    return X\n```\n\n### Key Points:\n- **Axis Parameter**: The `axis` parameter determines whether the standardization is done per feature (axis=0) or per sample (axis=1).\n- **Handling Mean and Standard Deviation**: The function allows you to choose whether to center the data (`with_mean`) and/or scale it to unit variance (`with_std`).\n- **Copy Parameter**: The `copy` parameter controls whether the operation is done in place or a new array is created.\n- **Sparse Matrices**: The function currently does not support sparse matrices, and an error is raised if a sparse matrix is passed. You can extend this functionality if needed.",
    "prompt": "Write a python functoin scale Standardize a dataset along any axis.\n\n    Center to the mean and component wise scale to unit variance.\n\n    Read more in the :ref:`User Guide <preprocessing_scaler>`.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The data to center and scale.\n\n    axis : {0, 1}, default=0\n        Axis used to compute the means and standard deviations along. If 0,\n        independently standardize each feature, otherwise (if 1) standardize\n        each sample.\n\n    with_mean : bool, default=True\n        If True, center the data before scaling.\n\n    with_std : bool, default=True\n        If True, scale the data to unit variance (or equivalently,\n        unit standard deviation).\n\n    copy : bool, default=True\n        If False, try to avoid a copy and scale in place.\n        This is not guaranteed to always work in place; e.g. if the data is\n        a numpy array with an int dtype, a copy will be returned even with\n        copy=False.\n\n    Returns\n    -------\n    X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n        The transformed data.",
    "function_name": "scale",
    "ground_truth": "sklearn/preprocessing/_data.py",
    "test": "sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "",
    "data": ""
}