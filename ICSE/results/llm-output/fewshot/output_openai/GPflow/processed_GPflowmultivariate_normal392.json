{
    "result": "To implement the `multivariate_normal` function as described, you can use TensorFlow to compute the log-density of a multivariate normal distribution. The function will take advantage of the Cholesky decomposition of the covariance matrix for efficient computation. Here's how you can write this function:\n\n```python\nimport tensorflow as tf\nfrom tensorflow_probability import distributions as tfd\nfrom typing import Union\n\ndef multivariate_normal(x: tf.Tensor, mu: tf.Tensor, L: tf.Tensor) -> tf.Tensor:\n    \"\"\"\n    Computes the log-density of a multivariate normal.\n\n    :param x: sample(s) for which we want the density, shape [D, N] or [D]\n    :param mu: mean(s) of the normal distribution, shape [D, N] or [D]\n    :param L: Cholesky decomposition of the covariance matrix, shape [D, D]\n    :return: log densities, shape [N] or scalar\n    \"\"\"\n    # Ensure x and mu are at least 2D\n    x = tf.convert_to_tensor(x)\n    mu = tf.convert_to_tensor(mu)\n    L = tf.convert_to_tensor(L)\n\n    # Compute the precision matrix from the Cholesky factor\n    precision_matrix = tf.linalg.inv(tf.matmul(L, L, transpose_b=True))\n\n    # Create a multivariate normal distribution\n    mvn = tfd.MultivariateNormalTriL(loc=mu, scale_tril=L)\n\n    # Compute the log probability\n    log_prob = mvn.log_prob(x)\n\n    return log_prob\n```\n\n### Explanation:\n- **Inputs**:\n  - `x`: The samples for which you want to compute the log-density. It can be a single sample or multiple samples.\n  - `mu`: The mean of the multivariate normal distribution. It should match the shape of `x`.\n  - `L`: The lower triangular matrix from the Cholesky decomposition of the covariance matrix.\n\n- **Outputs**:\n  - The function returns the log-density of the samples under the specified multivariate normal distribution.\n\n- **TensorFlow Probability**:\n  - The function uses TensorFlow Probability's `MultivariateNormalTriL` to handle the multivariate normal distribution with a lower triangular matrix (Cholesky factor) for the covariance.\n\nThis implementation assumes that the input tensors are compatible in terms of dimensions and broadcasting rules. Adjustments may be needed based on specific use cases or input shapes.",
    "prompt": "\"Write the multivariate_normal function as follow :\n@check_shapes(\n    \"x: [D, broadcast N]\",\n    \"mu: [D, broadcast N]\",\n    \"L: [D, D]\",\n    \"return: [N]\",\n)\ndef multivariate_normal(x: TensorType, mu: TensorType, L: TensorType) -> tf.Tensor:\n    \"\"\"\n    Computes the log-density of a multivariate normal.\n\n    :param x: sample(s) for which we want the density\n    :param mu: mean(s) of the normal distribution\n    :param L: Cholesky decomposition of the covariance matrix\n    :return: log densities\n    \"\"\"",
    "function_name": "multivariate_normal",
    "ground_truth": "gpflow/logdensities.py",
    "test": "tests/gpflow/test_logdensities.py::test_multivariate_normal",
    "class": "",
    "stage": "Model Construction",
    "task": "Prediction",
    "data": "tabular"
}