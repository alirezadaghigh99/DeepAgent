{
    "result": "To create the `vert_align` function as described, we need to handle several tasks: sampling features from a feature map based on vertex positions, handling different interpolation and padding modes, and managing different input types and shapes. Below is a Python implementation of the `vert_align` function:\n\n```python\nimport torch\nimport torch.nn.functional as F\n\ndef vert_align(\n    feats: Union[torch.Tensor, List[torch.Tensor]],\n    verts: Union[torch.Tensor, Any],\n    return_packed: bool = False,\n    interp_mode: str = 'bilinear',\n    padding_mode: str = 'zeros',\n    align_corners: bool = True\n) -> torch.Tensor:\n    \"\"\"\n    Perform vertex alignment or perceptual feature pooling.\n\n    Args:\n        feats (Tensor or List[Tensor]): Image features of shape (N, C, H, W) or a list of such tensors.\n        verts (Tensor or object): Vertex positions of shape (N, V, 3) or an object with verts_padded or points_padded attributes.\n        return_packed (bool): Whether to return packed features. Defaults to False.\n        interp_mode (str): Interpolation mode ('bilinear' or 'nearest'). Defaults to 'bilinear'.\n        padding_mode (str): Padding mode ('zeros', 'reflection', or 'border'). Defaults to 'zeros'.\n        align_corners (bool): Whether to align corners geometrically. Defaults to True.\n\n    Returns:\n        Tensor: Sampled features of shape (N, V, C) or packed representation if return_packed is True.\n    \"\"\"\n    if isinstance(feats, list):\n        # Concatenate features from the list\n        feats = [f.unsqueeze(0) if f.dim() == 3 else f for f in feats]\n        feats = torch.cat(feats, dim=1)\n\n    if not isinstance(feats, torch.Tensor) or feats.dim() != 4:\n        raise ValueError(\"feats must be a tensor of shape (N, C, H, W) or a list of such tensors.\")\n\n    if hasattr(verts, 'verts_padded'):\n        verts = verts.verts_padded()\n    elif hasattr(verts, 'points_padded'):\n        verts = verts.points_padded()\n\n    if not isinstance(verts, torch.Tensor) or verts.dim() != 3 or verts.size(2) != 3:\n        raise ValueError(\"verts must be a tensor of shape (N, V, 3) or have verts_padded or points_padded attributes.\")\n\n    N, C, H, W = feats.shape\n    N_v, V, _ = verts.shape\n\n    if N != N_v:\n        raise ValueError(\"Batch dimensions of feats and verts must match.\")\n\n    # Normalize vertex coordinates to [0, 1] range\n    verts_normalized = (verts[..., :2] + 1) / 2\n    verts_normalized = verts_normalized * torch.tensor([W - 1, H - 1], device=verts.device)\n\n    # Sample features using grid_sample\n    grid = verts_normalized.view(N, V, 1, 2)\n    feats_sampled = F.grid_sample(\n        feats, grid, mode=interp_mode, padding_mode=padding_mode, align_corners=align_corners\n    ).squeeze(2).permute(0, 2, 1)\n\n    if return_packed:\n        feats_sampled = feats_sampled.view(-1, C)\n\n    return feats_sampled\n```\n\n### Key Points:\n- **Input Handling**: The function accepts either a single tensor or a list of tensors for `feats`. It checks and concatenates them if necessary.\n- **Vertex Handling**: The function checks for `verts_padded` or `points_padded` attributes and normalizes the vertex coordinates to the feature map dimensions.\n- **Feature Sampling**: Uses `torch.nn.functional.grid_sample` to sample features based on the vertex positions, supporting different interpolation and padding modes.\n- **Error Handling**: Raises `ValueError` for incorrect input shapes or mismatched batch dimensions.\n- **Output**: Returns sampled features, optionally in a packed format.",
    "prompt": "Create a Python function vert_align that performs \"vertex alignment\" or \"perceptual feature pooling,\" which samples vertex features from a feature map based on vertex positions. The function takes the following parameters:\n\nfeats: A tensor of shape (N, C, H, W) representing image features from which to sample, or a list of such tensors, each with potentially different C, H, or W dimensions.\nverts: A tensor of shape (N, V, 3) representing the (x, y, z) vertex positions, or an object with verts_padded or points_padded attributes. The (x, y) coordinates should be normalized such that (-1, -1) corresponds to the top-left and (1, 1) to the bottom-right of the feature map.\nreturn_packed: A boolean flag indicating whether to return packed features. Defaults to False.\ninterp_mode: A string specifying the interpolation mode ('bilinear' or 'nearest'). Defaults to 'bilinear'.\npadding_mode: A string specifying how to handle vertices outside the [-1, 1] range ('zeros', 'reflection', or 'border'). Defaults to 'zeros'.\nalign_corners: A boolean indicating whether to align corners geometrically. If True, extrema refer to the center points of corner pixels; if False, they refer to the corner points of the input's corner pixels. Defaults to True.\nReturns:\nfeats_sampled: A tensor of shape (N, V, C) giving sampled features for each vertex. If feats is a list, the function returns concatenated features in shape (N, V, sum(C_n)) where C_n = feats[n].shape[1]. If return_packed = True, the features are transformed to a packed representation of shape (sum(V), C).\nError Handling:\nRaise a ValueError if verts does not have the expected shape or attributes.\nRaise a ValueError if feats does not have the expected shape (N, C, H, W) or if the batch dimensions of feats and verts do not match.",
    "function_name": "vert_align",
    "ground_truth": "pytorch3d/ops/vert_align.py",
    "test": "tests/test_vert_align.py",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "",
    "data": "Image"
}