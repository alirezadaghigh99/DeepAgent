{
    "result": "To implement the `get_badge_embeddings` function for the `BADGE` class, we need to consider both multi-class and binary classification scenarios. The function will scale the embeddings based on the predicted class probabilities. For multi-class problems, each embedding is expanded and scaled for each class, while for binary problems, the original embeddings are returned. Here's how you can implement this function:\n\n```python\nimport numpy as np\n\nclass BADGE(EmbeddingBasedQueryStrategy):\n    def __init__(self, num_classes):\n        self.num_classes = num_classes\n\n    def get_badge_embeddings(self, embeddings, proba):\n        \"\"\"\n        Calculate badge embeddings scaled by class probabilities.\n\n        Args:\n            embeddings (np.ndarray): Original embeddings of shape (n_samples, embedding_dim).\n            proba (np.ndarray): Predicted class probabilities of shape (n_samples, num_classes).\n\n        Returns:\n            np.ndarray: Badge embeddings of shape (n_samples, num_classes * embedding_dim) for multi-class\n                        or (n_samples, embedding_dim) for binary classification.\n        \"\"\"\n        n_samples, embedding_dim = embeddings.shape\n\n        if self.num_classes > 2:\n            # Multi-class case\n            badge_embeddings = np.zeros((n_samples, self.num_classes * embedding_dim))\n\n            for i in range(n_samples):\n                for c in range(self.num_classes):\n                    # Calculate the gradient-like embedding for each class\n                    scaled_embedding = embeddings[i] * (proba[i, c] - (c == np.argmax(proba[i])))\n                    badge_embeddings[i, c * embedding_dim:(c + 1) * embedding_dim] = scaled_embedding\n\n        else:\n            # Binary case\n            badge_embeddings = embeddings * (proba[:, 1] - proba[:, 0])[:, np.newaxis]\n\n        return badge_embeddings\n```\n\n### Explanation:\n\n1. **Multi-class Case:**\n   - For each sample, we iterate over each class.\n   - We scale the embedding by the class probability minus the probability of the most likely class (which is subtracted by 1 for the most likely class).\n   - The scaled embeddings for each class are concatenated to form a larger embedding matrix.\n\n2. **Binary Case:**\n   - The embeddings are scaled by the difference between the probabilities of the two classes.\n   - This results in the original embedding shape being preserved.\n\nThis function assumes that `embeddings` is a 2D numpy array of shape `(n_samples, embedding_dim)` and `proba` is a 2D numpy array of shape `(n_samples, num_classes)`. The output is a 2D numpy array where each row corresponds to a scaled embedding.",
    "prompt": "Write a Python function `get_badge_embeddings` for the `BADGE` class. This function should calculate embeddings scaled by class probabilities, enabling the use of the BADGE strategy for batch active learning. The function takes `embeddings` and `proba` (predicted class probabilities) as input and returns the `badge_embeddings`. For multi-class problems, the embeddings are expanded and scaled for each class; for binary problems, the original embeddings are returned.\n\n```python\nclass BADGE(EmbeddingBasedQueryStrategy):\n    def __init__(self, num_classes):\n        self.num_classes = num_classes\n\n    def get_badge_embeddings(self, embeddings, proba):\n``` \n\nThe `get_badge_embeddings` function should generate an embedding matrix where each original embedding is scaled by the negative class probabilities, except for the most likely class, which is scaled differently. For multi-class classification, this scaling is performed for each class, creating a larger embedding matrix. The output is a 2D numpy array where each row corresponds to an embedding.",
    "function_name": "get_badge_embeddings",
    "ground_truth": "small_text/integrations/pytorch/query_strategies/strategies.py",
    "test": "tests/integration/small_text/integrations/pytorch/query_strategies/test_query_strategies.py::QueryStrategiesTest",
    "class": "BADGE",
    "stage": "Text",
    "task": "Classification",
    "data": "Evaluation/metrics"
}