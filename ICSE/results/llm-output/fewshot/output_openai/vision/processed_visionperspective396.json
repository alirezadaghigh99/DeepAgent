{
    "result": "To create a function called `perspective` that performs a perspective transformation on an image, we need to handle both PIL Images and PyTorch Tensors as inputs. The function will also need to compute transformation coefficients and apply the transformation using interpolation. Here's how you can implement this:\n\n```python\nfrom typing import Union, Tuple, Optional\nimport numpy as np\nfrom PIL import Image\nimport torch\nimport torchvision.transforms.functional as F\n\ndef _get_perspective_coeffs(startpoints, endpoints):\n    \"\"\"Compute the coefficients for a perspective transformation.\"\"\"\n    matrix = []\n    for (x0, y0), (x1, y1) in zip(startpoints, endpoints):\n        matrix.append([x0, y0, 1, 0, 0, 0, -x1 * x0, -x1 * y0])\n        matrix.append([0, 0, 0, x0, y0, 1, -y1 * x0, -y1 * y0])\n    A = np.array(matrix, dtype=np.float32)\n    B = np.array(endpoints, dtype=np.float32).reshape(8)\n    res = np.linalg.solve(A, B)\n    return res.tolist()\n\ndef perspective(\n    image: Union[Image.Image, torch.Tensor],\n    startpoints: Tuple[Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int]],\n    endpoints: Tuple[Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int]],\n    interpolation: int = Image.BILINEAR,\n    fill: Optional[Union[int, Tuple[int, int, int]]] = None\n) -> Union[Image.Image, torch.Tensor]:\n    \"\"\"\n    Perform a perspective transformation on an image.\n\n    Args:\n        image (PIL Image or Tensor): The input image.\n        startpoints (tuple): Four corner points of the original image.\n        endpoints (tuple): Four corner points of the transformed image.\n        interpolation (int): Interpolation method. Defaults to BILINEAR.\n        fill (int or tuple, optional): Fill color for areas outside the transformed image.\n\n    Returns:\n        Transformed image as a PIL Image or Tensor.\n    \"\"\"\n    if len(startpoints) != 4 or len(endpoints) != 4:\n        raise ValueError(\"startpoints and endpoints must both contain exactly four points.\")\n\n    coeffs = _get_perspective_coeffs(startpoints, endpoints)\n\n    if isinstance(image, Image.Image):\n        return image.transform(image.size, Image.PERSPECTIVE, coeffs, interpolation, fillcolor=fill)\n    elif isinstance(image, torch.Tensor):\n        if image.ndimension() == 3:\n            image = image.unsqueeze(0)  # Add batch dimension if missing\n        pil_image = F.to_pil_image(image.squeeze(0))\n        transformed_pil = pil_image.transform(pil_image.size, Image.PERSPECTIVE, coeffs, interpolation, fillcolor=fill)\n        return F.to_tensor(transformed_pil).unsqueeze(0)\n    else:\n        raise TypeError(\"Input image must be a PIL Image or a PyTorch Tensor.\")\n\n```\n\n### Explanation:\n\n1. **_get_perspective_coeffs**: This helper function calculates the coefficients needed for the perspective transformation using a system of linear equations.\n\n2. **perspective Function**:\n   - **Input Validation**: Ensures that exactly four corner points are provided for both `startpoints` and `endpoints`.\n   - **Transformation Coefficients**: Uses `_get_perspective_coeffs` to compute the transformation coefficients.\n   - **Image Transformation**: \n     - If the input is a PIL Image, it uses the `transform` method with the calculated coefficients.\n     - If the input is a PyTorch Tensor, it first converts it to a PIL Image, applies the transformation, and then converts it back to a Tensor.\n   - **Error Handling**: Raises a `TypeError` if the input image is neither a PIL Image nor a PyTorch Tensor.\n\nThis function should handle most common use cases for perspective transformations in both PIL and PyTorch environments.",
    "prompt": "Generate a Python function called perspective that performs a perspective transformation on an image. The function should accept an image input, which can be either a PIL Image or a PyTorch Tensor, along with startpoints and endpoints, each consisting of four coordinate pairs representing the corners of the original and transformed images, respectively. It should include an interpolation parameter to specify how pixel values are calculated during the transformation, defaulting to BILINEAR. Additionally, an optional fill parameter should be provided to determine the pixel values for areas outside the transformed image. The function should handle errors gracefully, such as ensuring exactly four corner points are provided for both startpoints and endpoints, and raise appropriate exceptions for invalid inputs. The function should utilize underlying helper functions like _get_perspective_coeffs to compute the necessary transformation coefficients and apply the transformation using appropriate methods based on the input type, returning the transformed image as a PIL Image or Tensor.",
    "function_name": "perspective",
    "ground_truth": "torchvision/transforms/functional.py",
    "test": "test/test_transforms.py::test_randomperspective_fill",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "",
    "data": "image"
}