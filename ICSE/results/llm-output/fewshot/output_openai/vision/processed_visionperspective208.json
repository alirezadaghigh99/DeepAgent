{
    "result": "To create a function that performs a perspective transform on an image, you can use the `torchvision.transforms` module for PyTorch tensors or the `PIL` library for PIL images. Below is a Python function named `perspective` that handles both types of images and applies a perspective transformation based on the provided start and end points.\n\n```python\nimport torch\nfrom torchvision.transforms import functional as F\nfrom torchvision.transforms import InterpolationMode\nfrom PIL import Image\n\ndef perspective(img, startpoints, endpoints, interpolation=InterpolationMode.BILINEAR, fill=0):\n    \"\"\"\n    Perform a perspective transform of the given image.\n\n    Args:\n        img (PIL Image or Tensor): Image to be transformed.\n        startpoints (list of list of ints): List containing four lists of two integers corresponding to four corners\n            [top-left, top-right, bottom-right, bottom-left] of the original image.\n        endpoints (list of list of ints): List containing four lists of two integers corresponding to four corners\n            [top-left, top-right, bottom-right, bottom-left] of the transformed image.\n        interpolation (InterpolationMode): Desired interpolation enum defined by\n            torchvision.transforms.InterpolationMode. Default is InterpolationMode.BILINEAR.\n            If input is Tensor, only InterpolationMode.NEAREST, InterpolationMode.BILINEAR are supported.\n            The corresponding Pillow integer constants, e.g. PIL.Image.BILINEAR are accepted as well.\n        fill (sequence or number, optional): Pixel fill value for the area outside the transformed\n            image. If given a number, the value is used for all bands respectively.\n\n    Returns:\n        PIL Image or Tensor: Transformed Image.\n    \"\"\"\n    if isinstance(img, torch.Tensor):\n        # Handle torch Tensor\n        return F.perspective(img, startpoints, endpoints, interpolation=interpolation, fill=fill)\n    elif isinstance(img, Image.Image):\n        # Handle PIL Image\n        return F.perspective(img, startpoints, endpoints, interpolation=interpolation, fill=fill)\n    else:\n        raise TypeError(\"img should be PIL Image or Tensor. Got {}\".format(type(img)))\n\n# Example usage:\n# img_tensor = torch.rand(3, 256, 256)  # Example tensor image\n# img_pil = Image.open('path_to_image.jpg')  # Example PIL image\n# startpoints = [[0, 0], [255, 0], [255, 255], [0, 255]]\n# endpoints = [[0, 0], [255, 0], [255, 255], [0, 255]]\n# transformed_img_tensor = perspective(img_tensor, startpoints, endpoints)\n# transformed_img_pil = perspective(img_pil, startpoints, endpoints)\n```\n\n### Explanation:\n- **Input Handling**: The function checks if the input image is a `torch.Tensor` or a `PIL.Image`. It applies the appropriate transformation function from `torchvision.transforms.functional`.\n- **Perspective Transformation**: The `F.perspective` function is used to apply the perspective transformation. It requires the start and end points to define how the image should be warped.\n- **Interpolation and Fill**: The function allows specifying the interpolation method and fill value for areas outside the transformed image.\n- **Error Handling**: If the input image is neither a `torch.Tensor` nor a `PIL.Image`, the function raises a `TypeError`.\n\nThis function provides a flexible way to apply perspective transformations to images in both tensor and PIL formats.",
    "prompt": "Generate a Python function called perspective that perform perspective transform of the given image.\n    If the image is torch Tensor, it is expected\n    to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions.\n\n    Args:\n        img (PIL Image or Tensor): Image to be transformed.\n        startpoints (list of list of ints): List containing four lists of two integers corresponding to four corners\n            ``[top-left, top-right, bottom-right, bottom-left]`` of the original image.\n        endpoints (list of list of ints): List containing four lists of two integers corresponding to four corners\n            ``[top-left, top-right, bottom-right, bottom-left]`` of the transformed image.\n        interpolation (InterpolationMode): Desired interpolation enum defined by\n            :class:`torchvision.transforms.InterpolationMode`. Default is ``InterpolationMode.BILINEAR``.\n            If input is Tensor, only ``InterpolationMode.NEAREST``, ``InterpolationMode.BILINEAR`` are supported.\n            The corresponding Pillow integer constants, e.g. ``PIL.Image.BILINEAR`` are accepted as well.\n        fill (sequence or number, optional): Pixel fill value for the area outside the transformed\n            image. If given a number, the value is used for all bands respectively.\n\n    Returns:\n        PIL Image or Tensor: transformed Image.",
    "function_name": "perspective",
    "ground_truth": "torchvision/transforms/functional.py",
    "test": "test/test_transforms.py::test_randomperspective_fill",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "",
    "data": "Image"
}