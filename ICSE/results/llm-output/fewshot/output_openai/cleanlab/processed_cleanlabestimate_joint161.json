{
    "result": "To create the `estimate_joint` function as described, we need to consider the requirements and the logic for estimating the joint distribution of label noise. Below is a Python implementation of the function:\n\n```python\nimport numpy as np\n\ndef estimate_joint(labels, pred_probs, confident_joint=None, multi_label=False):\n    \"\"\"\n    Estimate the joint distribution of label noise P(label=i, true_label=j).\n\n    Args:\n        labels (array-like): Class labels for each example in the dataset.\n        pred_probs (array-like): Model-predicted class probabilities for each example.\n        confident_joint (array-like, optional): Estimated class label error statistics.\n        multi_label (bool): Indicates if the dataset is for multi-label classification.\n\n    Returns:\n        confident_joint_distribution (np.ndarray): Estimated joint distribution of noisy and true labels.\n    \"\"\"\n    labels = np.asarray(labels)\n    pred_probs = np.asarray(pred_probs)\n    num_classes = pred_probs.shape[1]\n\n    if confident_joint is None:\n        confident_joint = np.zeros((num_classes, num_classes), dtype=np.float64)\n        for i, label in enumerate(labels):\n            predicted_label = np.argmax(pred_probs[i])\n            confident_joint[label, predicted_label] += 1\n\n    if multi_label:\n        return _estimate_joint_multilabel(labels, pred_probs, confident_joint)\n\n    # Normalize the confident_joint to get the joint distribution\n    confident_joint_distribution = confident_joint / confident_joint.sum()\n\n    return confident_joint_distribution\n\ndef _estimate_joint_multilabel(labels, pred_probs, confident_joint):\n    \"\"\"\n    Estimate the joint distribution for multi-label classification.\n\n    Args:\n        labels (array-like): Class labels for each example in the dataset.\n        pred_probs (array-like): Model-predicted class probabilities for each example.\n        confident_joint (array-like): Estimated class label error statistics.\n\n    Returns:\n        confident_joint_distribution (np.ndarray): Estimated joint distribution of noisy and true labels.\n    \"\"\"\n    num_classes = pred_probs.shape[1]\n    confident_joint_distribution = np.zeros((num_classes, 2, 2), dtype=np.float64)\n\n    for i in range(num_classes):\n        for j in range(2):\n            for k in range(2):\n                mask = (labels[:, i] == j) & (pred_probs[:, i] > 0.5) == k\n                confident_joint_distribution[i, j, k] = np.sum(mask)\n\n    # Normalize the confident_joint_distribution\n    confident_joint_distribution /= confident_joint_distribution.sum()\n\n    return confident_joint_distribution\n```\n\n### Explanation:\n\n1. **Inputs and Initialization**:\n   - The function takes `labels`, `pred_probs`, `confident_joint`, and `multi_label` as inputs.\n   - If `confident_joint` is not provided, it is initialized as a zero matrix of shape `(num_classes, num_classes)`.\n\n2. **Confident Joint Calculation**:\n   - If `confident_joint` is not provided, it is computed by iterating over each example, determining the predicted label, and updating the `confident_joint` matrix.\n\n3. **Multi-label Handling**:\n   - If `multi_label` is `True`, the function calls `_estimate_joint_multilabel`, which handles the multi-label case by creating a `(K, 2, 2)` matrix.\n\n4. **Normalization**:\n   - The `confident_joint` or `confident_joint_distribution` is normalized to ensure that the sum of the joint distribution is 1.\n\n5. **Return**:\n   - The function returns the `confident_joint_distribution`, which represents the estimated joint distribution of noisy and true labels.",
    "prompt": "Generate a Python function called estimate_joint that estimates the joint distribution of label noise P(label=i, true_label=j) based on the given inputs. The function takes in the following parameters:\n\n- labels: an array or list of class labels for each example in the dataset\n- pred_probs: an array of model-predicted class probabilities for each example in the dataset\n- confident_joint: an optional array of estimated class label error statistics\n- multi_label: a boolean indicating whether the dataset is for regular (multi-class) classification or multi-label classification\n\nThe function returns confident_joint_distribution, an array representing an estimate of the true joint distribution of noisy and true labels. The shape of the array depends on the value of multi_label - it will be (K, K) if multi_label is False, and (K, 2, 2) if multi_label is True. The function ensures that the sum of the joint distribution is 1 and satisfies certain conditions.\n\nThe function internally computes the confident_joint if it is not provided, and calibrates it based on the input labels and pred_probs. If multi_label is True, the function calls _estimate_joint_multilabel to handle multi-label classification.",
    "function_name": "estimate_joint",
    "ground_truth": "cleanlab/count.py",
    "test": "tests/test_filter_count.py",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "",
    "data": "Table"
}