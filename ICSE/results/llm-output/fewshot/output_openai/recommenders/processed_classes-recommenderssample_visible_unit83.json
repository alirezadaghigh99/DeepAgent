{
    "result": "To implement the `sample_visible_units` function for the `RBM` class in TensorFlow, we need to follow the steps outlined in the prompt. Here's how you can write this function:\n\n```python\nimport tensorflow as tf\n\nclass RBM:\n    def __init__(self, possible_ratings, visible_units, hidden_units=500, keep_prob=0.7, init_stdv=0.1, learning_rate=0.004, minibatch_size=100, training_epoch=20, display_epoch=10, sampling_protocol=[50, 70, 80, 90, 100], debug=False, with_metrics=False, seed=42):\n        self.w = tf.Variable(tf.random.normal([visible_units, hidden_units], stddev=init_stdv), name='weights')\n        self.bv = tf.Variable(tf.zeros([visible_units]), name='visible_bias')\n        self.v = None  # This should be set to the original input vector during training or inference\n\n    def multinomial_distribution(self, phi):\n        # Outputs a tensor representing the probability distribution over the visible units\n        return tf.nn.softmax(phi)\n\n    def multinomial_sampling(self, pr):\n        # Outputs a tensor representing sampled values of the visible units\n        return tf.random.categorical(tf.math.log(pr), num_samples=1)\n\n    def sample_visible_units(self, h):\n        # Calculate the linear combination of hidden units and weights, add visible biases\n        phi_v = tf.matmul(h, tf.transpose(self.w)) + self.bv\n        \n        # Calculate the activation probability of the visible units\n        pvh = self.multinomial_distribution(phi_v)\n        \n        # Sample the visible units\n        v_ = self.multinomial_sampling(pvh)\n        \n        # Apply mask to enforce zero values in the reconstructed vector for inactive units\n        if self.v is not None:\n            mask = tf.cast(self.v > 0, dtype=tf.float32)\n            v_ = v_ * mask\n        \n        return pvh, v_\n```\n\n### Explanation:\n1. **Weights and Biases Initialization**: The weights (`self.w`) and visible biases (`self.bv`) are initialized in the constructor. The weights are initialized with a normal distribution, and the biases are initialized to zero.\n\n2. **Multinomial Distribution**: The `multinomial_distribution` method uses the softmax function to convert the linear combination of inputs into a probability distribution.\n\n3. **Multinomial Sampling**: The `multinomial_sampling` method samples from the probability distribution using TensorFlow's `tf.random.categorical`.\n\n4. **Sample Visible Units**: \n   - Compute the linear combination of the hidden units and the transpose of the weights, then add the visible biases.\n   - Calculate the activation probability using the `multinomial_distribution`.\n   - Sample the visible units using `multinomial_sampling`.\n   - Apply a mask to ensure that inactive units in the original input remain zero in the sampled output.\n\nThis implementation assumes that the original input vector (`self.v`) is set appropriately during training or inference. Adjustments may be needed based on the specific use case and data preprocessing steps.",
    "prompt": "prompt = '''\n\"\"Generate a Python function `sample_visible_units` for the class `RBM` that samples the visible units given the hidden units (`h`). This function should return two tensors: the activation probability of the visible units (`pvh`) and the sampled visible units (`v_`). The function involves calculating a linear combination of the hidden units with the transpose of the weights (`self.w`) and the biases of the visible units (`self.bv`), followed by using `multinomial_distribution` to determine the conditional probability `pvh`. The visible units are then sampled using `multinomial_sampling`. A mask is applied to enforce zero values in the reconstructed vector for the inactive units as indicated by the original input (`self.v`). The code should implement in tensorflow\n\nClass structure:\n\n```python\nclass RBM:\n    def __init__(self, possible_ratings, visible_units, hidden_units=500, keep_prob=0.7, init_stdv=0.1, learning_rate=0.004, minibatch_size=100, training_epoch=20, display_epoch=10, sampling_protocol=[50, 70, 80, 90, 100], debug=False, with_metrics=False, seed=42):\n        self.w = None  # weights between visible and hidden units\n        self.bv = None  # biases of the visible units\n        self.v = None  # original input vector\n        pass\n\n    def multinomial_distribution(self, phi):\n        # Outputs a tensor representing the probability distribution over the visible units\n        pass\n\n    def multinomial_sampling(self, pr):\n        # Outputs a tensor representing sampled values of the visible units\n        pass\n\n    def sample_visible_units(self, h):\n        # Implement the function as described in the prompt\n```\"\n```\"\n'''\ncode = get_completion(prompt)",
    "function_name": "sample_visible_unit",
    "ground_truth": "recommenders/models/rbm/rbm.py",
    "test": "tests/unit/recommenders/models/test_rbm.py",
    "class": "RBM",
    "stage": "",
    "task": "Recommendation",
    "data": "Inference"
}