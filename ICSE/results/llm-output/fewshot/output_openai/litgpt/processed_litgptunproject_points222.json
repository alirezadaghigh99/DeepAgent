{
    "result": "Here's a Python function called `unproject_points` that unprojects a 2D point into 3D space, transforming coordinates from the pixel frame to the camera frame. This function takes into account the camera intrinsics and optionally normalizes the point cloud if the depth is represented as the Euclidean ray length from the camera position.\n\n```python\nimport torch\n\ndef unproject_points(\n    point2d: torch.Tensor,\n    depth: torch.Tensor,\n    camera_matrix: torch.Tensor,\n    normalize: bool = False\n) -> torch.Tensor:\n    \"\"\"\n    Unproject a 2D point into 3D space.\n\n    Transform coordinates in the pixel frame to the camera frame.\n\n    Args:\n        point2d: Tensor containing the 2D points to be projected to\n            world coordinates. The shape of the tensor can be :math:`(*, 2)`.\n        depth: Tensor containing the depth value of each 2D\n            point. The tensor shape must be equal to point2d :math:`(*, 1)`.\n        camera_matrix: Tensor containing the intrinsics camera\n            matrix. The tensor shape must be :math:`(*, 3, 3)`.\n        normalize: Whether to normalize the point cloud. This\n            must be set to `True` when the depth is represented as the Euclidean\n            ray length from the camera position.\n\n    Returns:\n        Tensor of (x, y, z) world coordinates with shape :math:`(*, 3)`.\n    \"\"\"\n    # Ensure the inputs are of the correct shape\n    assert point2d.shape[-1] == 2, \"point2d must have shape (*, 2)\"\n    assert depth.shape == point2d.shape[:-1] + (1,), \"depth must have shape (*, 1)\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"camera_matrix must have shape (*, 3, 3)\"\n\n    # Convert 2D points to homogeneous coordinates\n    ones = torch.ones_like(depth)\n    point2d_homogeneous = torch.cat([point2d, ones], dim=-1)\n\n    # Invert the camera matrix\n    camera_matrix_inv = torch.inverse(camera_matrix)\n\n    # Unproject the points\n    point3d_homogeneous = torch.matmul(camera_matrix_inv, point2d_homogeneous.unsqueeze(-1)).squeeze(-1)\n\n    # Scale by depth\n    point3d = point3d_homogeneous * depth\n\n    if normalize:\n        # Normalize the points if required\n        norm = torch.norm(point3d, dim=-1, keepdim=True)\n        point3d = point3d / norm\n\n    return point3d\n\n# Example usage\nif __name__ == \"__main__\":\n    torch.manual_seed(0)\n    x = torch.rand(1, 2)\n    depth = torch.ones(1, 1)\n    K = torch.eye(3)[None]\n    result = unproject_points(x, depth, K)\n    print(result)\n```\n\nThis function first converts the 2D points to homogeneous coordinates, then uses the inverse of the camera matrix to transform these points into the camera frame. It scales the resulting 3D points by the depth values and optionally normalizes them if required.",
    "prompt": "Generate a python function called unproject_points that Unproject a 2d point in 3d.\n\n    Transform coordinates in the pixel frame to the camera frame.\n\n    Args:\n        point2d: tensor containing the 2d to be projected to\n            world coordinates. The shape of the tensor can be :math:`(*, 2)`.\n        depth: tensor containing the depth value of each 2d\n            points. The tensor shape must be equal to point2d :math:`(*, 1)`.\n        camera_matrix: tensor containing the intrinsics camera\n            matrix. The tensor shape must be :math:`(*, 3, 3)`.\n        normalize: whether to normalize the pointcloud. This\n            must be set to `True` when the depth is represented as the Euclidean\n            ray length from the camera position.\n\n    Returns:\n        tensor of (x, y, z) world coordinates with shape :math:`(*, 3)`.\n\n    Example:\n        >>> _ = torch.manual_seed(0)\n        >>> x = torch.rand(1, 2)\n        >>> depth = torch.ones(1, 1)\n        >>> K = torch.eye(3)[None]\n        >>> unproject_points(x, depth, K)\n        tensor([[0.4963, 0.7682, 1.0000]])",
    "function_name": "unproject_points",
    "ground_truth": "kornia/geometry/camera/perspective.py#L39",
    "test": "tests/geometry/camera/test_perspective.py",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "Detection",
    "data": "Image"
}