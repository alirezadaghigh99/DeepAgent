{
    "result": "Here's a Python function `depth_to_normals` that computes surface normals per pixel from a depth image, following the specifications you provided:\n\n```python\nimport torch\n\ndef depth_to_normals(depth: torch.Tensor, camera_matrix: torch.Tensor, normalize_points: bool = False) -> torch.Tensor:\n    \"\"\"\n    Computes the surface normals per pixel from a depth image.\n\n    Args:\n        depth (Tensor): A tensor of shape (B, 1, H, W) containing depth values.\n        camera_matrix (Tensor): A tensor of shape (B, 3, 3) representing the camera intrinsics.\n        normalize_points (bool): Whether to normalize the point cloud.\n\n    Returns:\n        Tensor: A tensor with a normal vector per pixel of shape (B, 3, H, W).\n\n    Raises:\n        TypeError: If `depth` or `camera_matrix` is not a Tensor.\n        ValueError: If `depth` does not have the shape (B, 1, H, W) or `camera_matrix` does not have the shape (B, 3, 3).\n    \"\"\"\n    if not isinstance(depth, torch.Tensor):\n        raise TypeError(\"depth must be a Tensor\")\n    if not isinstance(camera_matrix, torch.Tensor):\n        raise TypeError(\"camera_matrix must be a Tensor\")\n    if depth.ndim != 4 or depth.shape[1] != 1:\n        raise ValueError(\"depth must have the shape (B, 1, H, W)\")\n    if camera_matrix.ndim != 3 or camera_matrix.shape[1:] != (3, 3):\n        raise ValueError(\"camera_matrix must have the shape (B, 3, 3)\")\n\n    B, _, H, W = depth.shape\n\n    # Create a meshgrid for pixel coordinates\n    y, x = torch.meshgrid(torch.arange(H, device=depth.device), torch.arange(W, device=depth.device))\n    y, x = y.float(), x.float()\n\n    # Expand dimensions to match batch size\n    x = x.unsqueeze(0).expand(B, -1, -1)\n    y = y.unsqueeze(0).expand(B, -1, -1)\n\n    # Unpack camera intrinsics\n    fx = camera_matrix[:, 0, 0]\n    fy = camera_matrix[:, 1, 1]\n    cx = camera_matrix[:, 0, 2]\n    cy = camera_matrix[:, 1, 2]\n\n    # Compute 3D points\n    z = depth[:, 0, :, :]\n    x3d = (x - cx.unsqueeze(-1).unsqueeze(-1)) * z / fx.unsqueeze(-1).unsqueeze(-1)\n    y3d = (y - cy.unsqueeze(-1).unsqueeze(-1)) * z / fy.unsqueeze(-1).unsqueeze(-1)\n    points_3d = torch.stack((x3d, y3d, z), dim=1)\n\n    if normalize_points:\n        points_3d = points_3d / torch.norm(points_3d, dim=1, keepdim=True)\n\n    # Compute gradients\n    dzdx = torch.gradient(z, dim=2)[0]\n    dzdy = torch.gradient(z, dim=1)[0]\n\n    # Compute normals\n    normals = torch.stack((-dzdx, -dzdy, torch.ones_like(z)), dim=1)\n    normals = normals / torch.norm(normals, dim=1, keepdim=True)\n\n    return normals\n```\n\n### Explanation:\n- **Input Validation**: The function checks if `depth` and `camera_matrix` are tensors and have the correct shapes.\n- **Meshgrid Creation**: A meshgrid is created for pixel coordinates, which is used to compute the 3D points.\n- **3D Point Calculation**: Using the camera intrinsics, the 3D coordinates are computed from the depth values.\n- **Normalization**: If `normalize_points` is `True`, the 3D points are normalized.\n- **Gradient Calculation**: Gradients of the depth map are computed to estimate the surface normals.\n- **Normal Vector Calculation**: The normal vectors are computed and normalized to unit length.",
    "prompt": "Create a Python function `depth_to_normals` that:\n\n- Computes the surface normals per pixel from a depth image.\n- Accepts the following parameters:\n  - `depth`: A tensor of shape `(B, 1, H, W)` containing depth values.\n  - `camera_matrix`: A tensor of shape `(B, 3, 3)` representing the camera intrinsics.\n  - `normalize_points`: A boolean indicating whether to normalize the point cloud. This is necessary when depth values represent Euclidean distances from the camera position.\n- Returns a tensor with a normal vector per pixel of shape `(B, 3, H, W)`.\n\nErrors:\n- Raises `TypeError` if `depth` or `camera_matrix` is not a Tensor.\n- Raises `ValueError` if `depth` does not have the shape `(B, 1, H, W)` or `camera_matrix` does not have the shape `(B, 3, 3)`.",
    "function_name": "depth_to_normals",
    "ground_truth": "kornia/geometry/depth.py",
    "test": "tests/geometry/test_depth.py::TestDepthToNormals",
    "class": "",
    "stage": "Model Construction",
    "task": "Segmentation",
    "data": "Image"
}