{
    "result": "To calculate the Kullback-Leibler (KL) divergence loss between heatmaps, you can implement a function in PyTorch. The KL divergence is a measure of how one probability distribution diverges from a second, expected probability distribution. Here's how you can implement this function:\n\n```python\nimport torch\nimport torch.nn.functional as F\n\ndef kl_div_loss_2d(pred: torch.Tensor, target: torch.Tensor, reduction: str = 'mean') -> torch.Tensor:\n    \"\"\"\n    Calculate the Kullback-Leibler divergence loss between heatmaps.\n\n    Args:\n        pred (Tensor): The input tensor with shape (B, N, H, W).\n        target (Tensor): The target tensor with shape (B, N, H, W).\n        reduction (str): Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'.\n                         'none': no reduction will be applied,\n                         'mean': the sum of the output will be divided by the number of elements in the output,\n                         'sum': the output will be summed.\n\n    Returns:\n        Tensor: The calculated KL divergence loss.\n    \"\"\"\n    # Ensure the input tensors are in log space\n    pred_log = F.log_softmax(pred, dim=-1)\n    target_log = F.log_softmax(target, dim=-1)\n\n    # Calculate the KL divergence\n    kl_div = F.kl_div(pred_log, target_log, reduction='none')\n\n    # Apply the specified reduction\n    if reduction == 'mean':\n        return kl_div.mean()\n    elif reduction == 'sum':\n        return kl_div.sum()\n    elif reduction == 'none':\n        return kl_div\n    else:\n        raise ValueError(f\"Invalid reduction type: {reduction}. Expected 'none', 'mean', or 'sum'.\")\n\n# Example usage\nif __name__ == \"__main__\":\n    pred = torch.full((1, 1, 2, 4), 0.125)\n    loss = kl_div_loss_2d(pred, pred)\n    print(loss.item())  # Output: 0.0\n```\n\n### Explanation:\n- **Log Softmax**: The `F.log_softmax` function is used to ensure that the input tensors are in log space, which is necessary for computing the KL divergence.\n- **KL Divergence Calculation**: The `F.kl_div` function computes the element-wise KL divergence between the `pred_log` and `target_log`.\n- **Reduction**: The function supports three types of reduction: `'none'`, `'mean'`, and `'sum'`. The `'mean'` reduction divides the sum of the output by the number of elements, while `'sum'` simply sums the output. `'none'` returns the raw KL divergence values without any reduction.",
    "prompt": "Calculate the Kullback-Leibler divergence loss between heatmaps.\n\n    Args:\n        pred: the input tensor with shape :math:`(B, N, H, W)`.\n        target: the target tensor with shape :math:`(B, N, H, W)`.\n        reduction: Specifies the reduction to apply to the\n          output: ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction\n          will be applied, ``'mean'``: the sum of the output will be divided by\n          the number of elements in the output, ``'sum'``: the output will be\n          summed.\n\n    Examples:\n        >>> pred = torch.full((1, 1, 2, 4), 0.125)\n        >>> loss = kl_div_loss_2d(pred, pred)\n        >>> loss.item()\n        0.0",
    "function_name": "kl_div_loss_2d",
    "ground_truth": "kornia/losses/divergence.py",
    "test": "tests/losses/test_divergence.py::TestDivergenceLoss::test_kl_div_loss_2d",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "Segmentation",
    "data": "Image"
}