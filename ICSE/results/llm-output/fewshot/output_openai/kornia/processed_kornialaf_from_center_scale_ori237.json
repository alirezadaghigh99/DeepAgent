{
    "result": "Here's a Python function `laf_from_center_scale_ori` that creates a Local Affine Frame (LAF) from keypoint center, scale, and orientation as you described:\n\n```python\nimport torch\n\ndef laf_from_center_scale_ori(\n    xy: torch.Tensor,\n    scale: Optional[torch.Tensor] = None,\n    ori: Optional[torch.Tensor] = None\n) -> torch.Tensor:\n    \"\"\"\n    Create a Local Affine Frame (LAF) from keypoint center, scale, and orientation.\n\n    Args:\n        xy (Tensor): Tensor of shape (B, N, 2) representing the keypoint centers.\n        scale (Tensor, optional): Tensor of shape (B, N, 1, 1) representing the scale. Defaults to 1.0.\n        ori (Tensor, optional): Tensor of shape (B, N, 1) representing the orientation in radians. Defaults to 0.\n\n    Returns:\n        Tensor: LAF of shape (B, N, 2, 3) representing the Local Affine Frames.\n    \"\"\"\n    # Check the shape of the input tensor xy\n    if xy.ndim != 3 or xy.shape[2] != 2:\n        raise ValueError(\"Input tensor xy must have shape (B, N, 2)\")\n\n    # Initialize device and data type\n    device = xy.device\n    dtype = xy.dtype\n\n    # Calculate batch size B and number of keypoints N\n    B, N, _ = xy.shape\n\n    # Set default scale if not provided\n    if scale is None:\n        scale = torch.ones((B, N, 1, 1), device=device, dtype=dtype)\n\n    # Set default orientation if not provided\n    if ori is None:\n        ori = torch.zeros((B, N, 1), device=device, dtype=dtype)\n\n    # Check the shape of the scale and orientation tensors\n    if scale.shape != (B, N, 1, 1):\n        raise ValueError(\"Scale tensor must have shape (B, N, 1, 1)\")\n    if ori.shape != (B, N, 1):\n        raise ValueError(\"Orientation tensor must have shape (B, N, 1)\")\n\n    # Calculate the rotation matrix based on the orientation\n    cos_ori = torch.cos(ori)\n    sin_ori = torch.sin(ori)\n    rotation_matrix = torch.cat([\n        cos_ori, -sin_ori,\n        sin_ori, cos_ori\n    ], dim=-1).view(B, N, 2, 2)\n\n    # Concatenate the rotation matrix with the keypoint centers\n    laf = torch.cat([rotation_matrix, xy.unsqueeze(-1)], dim=-1)\n\n    # Scale the LAF based on the provided scale\n    laf = laf * scale\n\n    return laf\n```\n\n### Explanation:\n- **Input Validation**: The function first checks the shape of the input tensor `xy` to ensure it is of shape `(B, N, 2)`.\n- **Defaults**: If `scale` or `ori` are not provided, they are set to default values of ones and zeros, respectively, with appropriate shapes.\n- **Rotation Matrix**: The function calculates the rotation matrix using the cosine and sine of the orientation angles.\n- **Concatenation and Scaling**: The rotation matrix is concatenated with the keypoint centers, and the resulting LAF is scaled by the provided scale tensor.\n- **Output**: The function returns the LAF tensor of shape `(B, N, 2, 3)`.",
    "prompt": "Generate a Python function called laf_from_center_scale_ori that creates a Local Affine Frame (LAF) from keypoint center, scale, and orientation. The function takes in a tensor xy of shape (B, N, 2) representing the keypoint centers, an optional tensor scale of shape (B, N, 1, 1) defaulting to 1.0, and an optional tensor ori of shape (B, N, 1) defaulting to 0. \n\nThe function returns a tensor LAF of shape (B, N, 2, 3) representing the Local Affine Frames. The function first checks the shape of the input tensor xy, then initializes the device and data type. It then calculates the batch size B and number of keypoints N. If scale is not provided, it sets it to ones tensor of the appropriate shape. If orientation is not provided, it sets it to zeros tensor of the appropriate shape. \n\nThe function then checks the shape of the scale and orientation tensors, concatenates the rotation matrix based on the orientation with the keypoint centers, and scales the LAF based on the provided scale. Finally, it returns the LAF tensor.",
    "function_name": "laf_from_center_scale_ori",
    "ground_truth": "kornia/feature/laf.py",
    "test": "tests/feature/test_laf.py::TestGetCreateLAF",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "Detection",
    "data": "Image"
}