{
    "result": "Here's a Python function `depth_to_3d` that meets your specifications. This function computes 3D points from depth values using camera intrinsics and includes error handling for input types and shapes:\n\n```python\nimport torch\n\ndef depth_to_3d(depth: torch.Tensor, camera_matrix: torch.Tensor, normalize: bool = False) -> torch.Tensor:\n    \"\"\"\n    Converts depth values to 3D points using camera intrinsics.\n\n    Args:\n        depth (torch.Tensor): Depth tensor of shape (B, 1, H, W).\n        camera_matrix (torch.Tensor): Camera intrinsics tensor of shape (B, 3, 3).\n        normalize (bool): Whether to normalize the 3D points.\n\n    Returns:\n        torch.Tensor: 3D points tensor of shape (B, 3, H, W).\n    \"\"\"\n    # Validate input shapes\n    if depth.ndim != 4 or depth.shape[1] != 1:\n        raise ValueError(\"Depth tensor must have shape (B, 1, H, W).\")\n    if camera_matrix.ndim != 3 or camera_matrix.shape[1:] != (3, 3):\n        raise ValueError(\"Camera matrix must have shape (B, 3, 3).\")\n    if depth.shape[0] != camera_matrix.shape[0]:\n        raise ValueError(\"Batch size of depth and camera matrix must match.\")\n\n    B, _, H, W = depth.shape\n\n    # Create a meshgrid of pixel coordinates\n    y, x = torch.meshgrid(torch.arange(H, device=depth.device), torch.arange(W, device=depth.device))\n    y, x = y.float(), x.float()\n\n    # Expand to batch size\n    x = x.unsqueeze(0).expand(B, -1, -1)\n    y = y.unsqueeze(0).expand(B, -1, -1)\n\n    # Extract camera intrinsics\n    fx = camera_matrix[:, 0, 0]\n    fy = camera_matrix[:, 1, 1]\n    cx = camera_matrix[:, 0, 2]\n    cy = camera_matrix[:, 1, 2]\n\n    # Compute 3D points\n    z = depth[:, 0, :, :]\n    x3d = (x - cx.view(-1, 1, 1)) * z / fx.view(-1, 1, 1)\n    y3d = (y - cy.view(-1, 1, 1)) * z / fy.view(-1, 1, 1)\n    z3d = z\n\n    points_3d = torch.stack((x3d, y3d, z3d), dim=1)\n\n    if normalize:\n        # Normalize the 3D points\n        norm = torch.norm(points_3d, dim=1, keepdim=True)\n        points_3d = points_3d / (norm + 1e-8)\n\n    return points_3d\n```\n\n### Explanation:\n- **Input Validation**: The function checks that the depth tensor has the shape `(B, 1, H, W)` and the camera matrix has the shape `(B, 3, 3)`. It also ensures that the batch sizes match.\n- **Meshgrid Creation**: A meshgrid of pixel coordinates is created for the image dimensions `(H, W)`.\n- **3D Point Calculation**: Using the camera intrinsics, the function calculates the 3D coordinates `(x3d, y3d, z3d)` for each pixel.\n- **Normalization**: If the `normalize` flag is set to `True`, the 3D points are normalized to unit vectors.\n- **Output**: The function returns a tensor of shape `(B, 3, H, W)` containing the 3D points.",
    "prompt": "Generate a Python function called depth_to_3d that takes in a tensor representing depth values per pixel, a tensor containing camera intrinsics, and a boolean flag to normalize points. The function computes a 3D point per pixel based on the depth value and camera intrinsics. The input depth tensor should have a shape of (B, 1, H, W) and the camera_matrix tensor should have a shape of (B, 3, 3). The function returns a tensor with a 3D point per pixel of the same resolution as the input, with a shape of (B, 3, H, W). The function also includes error handling for input types and shapes.",
    "function_name": "depth_to_3d",
    "ground_truth": "kornia/geometry/depth.py",
    "test": "tests/geometry/test_depth.py::TestDepthTo3d::test_shapes_broadcast",
    "class": "",
    "stage": "Model Construction",
    "task": "",
    "data": "Image"
}