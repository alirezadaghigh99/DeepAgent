{
    "result": "To generate a Python function called `random_text_classification_dataset`, we need to break down the task into several steps. We'll use PyTorch and some of its utilities to create a synthetic text classification dataset. Here's how we can approach this:\n\n1. **Import Necessary Libraries**: We'll need PyTorch and some utilities for handling text data.\n\n2. **Define the Function Signature**: The function will take several parameters as described.\n\n3. **Generate Random Text Data**: We'll create random sequences of integers to simulate text data.\n\n4. **Generate Random Labels**: Depending on whether the task is multi-label or single-label, we'll generate appropriate labels.\n\n5. **Ensure All Labels Are Present**: We'll make sure that each class label is represented in the dataset.\n\n6. **Create a Vocabulary**: We'll simulate a vocabulary of a given size.\n\n7. **Return a Custom Dataset Object**: We'll define a simple dataset class to encapsulate the data and return it.\n\nLet's start coding step by step:\n\n### Step 1: Import Necessary Libraries\n\n```python\nimport torch\nfrom torch.utils.data import Dataset\nimport random\n```\n\n### Step 2: Define the Function Signature\n\n```python\ndef random_text_classification_dataset(num_samples, max_length, num_classes, multi_label=False, vocab_size=1000, device='cpu', target_labels=None, dtype=torch.long):\n    pass\n```\n\n### Step 3: Generate Random Text Data\n\n```python\ndef random_text_classification_dataset(num_samples, max_length, num_classes, multi_label=False, vocab_size=1000, device='cpu', target_labels=None, dtype=torch.long):\n    # Generate random text data\n    data = [torch.randint(1, vocab_size, (random.randint(1, max_length),), dtype=dtype, device=device) for _ in range(num_samples)]\n```\n\n### Step 4: Generate Random Labels\n\n```python\n    # Generate random labels\n    if multi_label:\n        labels = [torch.randint(0, 2, (num_classes,), dtype=dtype, device=device) for _ in range(num_samples)]\n    else:\n        labels = [torch.randint(0, num_classes, (1,), dtype=dtype, device=device) for _ in range(num_samples)]\n```\n\n### Step 5: Ensure All Labels Are Present\n\n```python\n    # Ensure all labels are present\n    if not multi_label:\n        for i in range(num_classes):\n            if i not in [label.item() for label in labels]:\n                labels[random.randint(0, num_samples - 1)] = torch.tensor([i], dtype=dtype, device=device)\n    else:\n        for i in range(num_classes):\n            if not any(label[i].item() == 1 for label in labels):\n                labels[random.randint(0, num_samples - 1)][i] = 1\n```\n\n### Step 6: Create a Vocabulary\n\n```python\n    # Create a vocabulary\n    vocabulary = {i: f\"word_{i}\" for i in range(1, vocab_size)}\n```\n\n### Step 7: Return a Custom Dataset Object\n\n```python\n    # Define a simple dataset class\n    class PytorchTextClassificationDataset(Dataset):\n        def __init__(self, data, labels):\n            self.data = data\n            self.labels = labels\n\n        def __len__(self):\n            return len(self.data)\n\n        def __getitem__(self, idx):\n            return self.data[idx], self.labels[idx]\n\n    # Create dataset object\n    dataset = PytorchTextClassificationDataset(data, labels)\n\n    return dataset, vocabulary, multi_label, target_labels\n```\n\n### Complete Function\n\nHere's the complete function:\n\n```python\nimport torch\nfrom torch.utils.data import Dataset\nimport random\n\ndef random_text_classification_dataset(num_samples, max_length, num_classes, multi_label=False, vocab_size=1000, device='cpu', target_labels=None, dtype=torch.long):\n    # Generate random text data\n    data = [torch.randint(1, vocab_size, (random.randint(1, max_length),), dtype=dtype, device=device) for _ in range(num_samples)]\n\n    # Generate random labels\n    if multi_label:\n        labels = [torch.randint(0, 2, (num_classes,), dtype=dtype, device=device) for _ in range(num_samples)]\n    else:\n        labels = [torch.randint(0, num_classes, (1,), dtype=dtype, device=device) for _ in range(num_samples)]\n\n    # Ensure all labels are present\n    if not multi_label:\n        for i in range(num_classes):\n            if i not in [label.item() for label in labels]:\n                labels[random.randint(0, num_samples - 1)] = torch.tensor([i], dtype=dtype, device=device)\n    else:\n        for i in range(num_classes):\n            if not any(label[i].item() == 1 for label in labels):\n                labels[random.randint(0, num_samples - 1)][i] = 1\n\n    # Create a vocabulary\n    vocabulary = {i: f\"word_{i}\" for i in range(1, vocab_size)}\n\n    # Define a simple dataset class\n    class PytorchTextClassificationDataset(Dataset):\n        def __init__(self, data, labels):\n            self.data = data\n            self.labels = labels\n\n        def __len__(self):\n            return len(self.data)\n\n        def __getitem__(self, idx):\n            return self.data[idx], self.labels[idx]\n\n    # Create dataset object\n    dataset = PytorchTextClassificationDataset(data, labels)\n\n    return dataset, vocabulary, multi_label, target_labels\n```\n\nThis function generates a random text classification dataset with the specified parameters and returns a dataset object, vocabulary, multi-label setting, and target labels.",
    "prompt": "Generate a Python function called random_text_classification_dataset that generates a random text classification dataset. The function takes in parameters such as num_samples, max_length, num_classes, multi_label, vocab_size, device, target_labels, and dtype. It returns a PytorchTextClassificationDataset object with the generated dataset, vocabulary, multi_label setting, and target labels. The function ensures that all labels occur in the dataset and handles different scenarios based on the input parameters.",
    "function_name": "random_text_classification_dataset",
    "ground_truth": "tests/utils/datasets.py",
    "test": "tests/unit/small_text/initialization/test_strategies.py::RandomInitializationStratifiedTest",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "Classification",
    "data": "Text"
}