{
    "result": "To implement the `free_energy` function for the `RBM` class, we need to calculate the free energy of the visible units given the hidden units. The free energy \\( F(x) \\) for a Restricted Boltzmann Machine is given by the formula:\n\n\\[ F(x) = -b_v^T x - \\sum_{j} \\log(1 + \\exp(b_h^j + W_j^T x)) \\]\n\nWhere:\n- \\( b_v \\) is the bias of the visible units.\n- \\( b_h \\) is the bias of the hidden units.\n- \\( W \\) is the weight matrix between visible and hidden units.\n- \\( x \\) is the input tensor representing the visible units.\n\nLet's implement this in the `free_energy` function using TensorFlow:\n\n```python\nimport tensorflow as tf\n\nclass RBM:\n    def __init__(self, possible_ratings, visible_units, hidden_units=500, keep_prob=0.7, init_stdv=0.1, learning_rate=0.004, minibatch_size=100, training_epoch=20, display_epoch=10, sampling_protocol=[50, 70, 80, 90, 100], debug=False, with_metrics=False, seed=42):\n        self.bv = tf.Variable(tf.zeros([visible_units]), dtype=tf.float32)  # biases of the visible units\n        self.bh = tf.Variable(tf.zeros([hidden_units]), dtype=tf.float32)  # biases of the hidden units\n        self.w = tf.Variable(tf.random.normal([visible_units, hidden_units], stddev=init_stdv), dtype=tf.float32)  # weights between visible and hidden units\n\n    def free_energy(self, x):\n        # Compute the bias term for visible units\n        vbias_term = tf.reduce_sum(tf.multiply(x, self.bv), axis=1)\n        \n        # Compute the hidden units contribution\n        wx_b = tf.matmul(x, self.w) + self.bh\n        hidden_term = tf.reduce_sum(tf.math.log(1 + tf.exp(wx_b)), axis=1)\n        \n        # Free energy is the negative sum of these terms\n        free_energy = -vbias_term - hidden_term\n        \n        return free_energy\n\n# Example usage:\n# rbm = RBM(possible_ratings=5, visible_units=784)\n# x = tf.random.normal([100, 784])  # Example input\n# energy = rbm.free_energy(x)\n# print(energy)\n```\n\n### Explanation:\n- **Visible Bias Term**: We calculate the contribution of the visible biases by taking the dot product of the input `x` with the visible biases `self.bv` and summing over the batch.\n- **Hidden Term**: We compute the contribution from the hidden units by first calculating the linear combination of inputs and weights plus the hidden biases (`wx_b`). We then apply the `log(1 + exp(...))` function and sum over the hidden units.\n- **Free Energy**: The free energy is the negative sum of the visible bias term and the hidden term.\n\nThis function will return the free energy for each sample in the batch.",
    "prompt": "Generate a Python function `free_energy` for the class `RBM` that calculates the free energy of the visible units given the hidden units in the model. The function should take as input a tensor `x`, which can be either the sampled value of the visible units or the input data. It should compute the free energy by using the biases of the visible units (`self.bv`), the weights between the visible and hidden units (`self.w`), and the biases of the hidden units (`self.bh`). The function should return the free energy as a tf.tensor, calculated as the sum of the bias term.\n\n```python\nclass RBM:\n    def __init__(self, possible_ratings, visible_units, hidden_units=500, keep_prob=0.7, init_stdv=0.1, learning_rate=0.004, minibatch_size=100, training_epoch=20, display_epoch=10, sampling_protocol=[50, 70, 80, 90, 100], debug=False, with_metrics=False, seed=42):\n        self.bv = None  # biases of the visible units\n        self.bh = None  # biases of the hidden units\n        self.w = None  # weights between visible and hidden units\n        pass\n\n    def free_energy(self, x):\n        # Implement the function as described in the prompt\n```",
    "function_name": "free_energy",
    "ground_truth": "recommenders/models/rbm/rbm.py",
    "test": "tests/unit/recommenders/models/test_rbm.py",
    "class": "RBM",
    "stage": "",
    "task": "Recommendation",
    "data": "Training"
}