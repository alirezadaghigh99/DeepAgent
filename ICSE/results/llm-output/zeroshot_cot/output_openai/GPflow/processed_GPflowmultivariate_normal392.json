{
    "result": "To implement the `multivariate_normal` function with the specified shape checks and functionality, we can proceed step by step. We'll use TensorFlow for tensor operations and assume that `@check_shapes` is a decorator that validates the shapes of the inputs and outputs. Here's how you can implement the function:\n\n1. **Import necessary modules**: We'll need TensorFlow for tensor operations.\n\n2. **Define the function**: We'll define the function with the specified signature and docstring.\n\n3. **Compute the log-density**: We'll use the properties of the multivariate normal distribution to compute the log-density.\n\nHere's the step-by-step implementation:\n\n```python\nimport tensorflow as tf\nfrom typing import Any\n\n# Assuming check_shapes is a decorator that checks the shapes of the inputs and outputs\ndef check_shapes(*args: Any, **kwargs: Any) -> Any:\n    def decorator(func: Any) -> Any:\n        def wrapper(*func_args: Any, **func_kwargs: Any) -> Any:\n            # Here you would implement the actual shape checking logic\n            return func(*func_args, **func_kwargs)\n        return wrapper\n    return decorator\n\n@check_shapes(\n    \"x: [D, broadcast N]\",\n    \"mu: [D, broadcast N]\",\n    \"L: [D, D]\",\n    \"return: [N]\",\n)\ndef multivariate_normal(x: tf.Tensor, mu: tf.Tensor, L: tf.Tensor) -> tf.Tensor:\n    \"\"\"\n    Computes the log-density of a multivariate normal.\n\n    :param x: sample(s) for which we want the density\n    :param mu: mean(s) of the normal distribution\n    :param L: Cholesky decomposition of the covariance matrix\n    :return: log densities\n    \"\"\"\n    # Step 1: Compute the difference between x and mu\n    delta = x - mu\n\n    # Step 2: Solve for y in L * y = delta using triangular solve\n    y = tf.linalg.triangular_solve(L, delta, lower=True)\n\n    # Step 3: Compute the quadratic term\n    quadratic_term = tf.reduce_sum(tf.square(y), axis=0)\n\n    # Step 4: Compute the log determinant of L\n    log_det_L = tf.reduce_sum(tf.math.log(tf.linalg.diag_part(L)))\n\n    # Step 5: Compute the log-density\n    D = tf.cast(tf.shape(x)[0], x.dtype)  # Dimension of the distribution\n    log_density = -0.5 * (D * tf.math.log(2.0 * tf.constant(np.pi, dtype=x.dtype)) + 2.0 * log_det_L + quadratic_term)\n\n    return log_density\n```\n\n### Explanation:\n\n- **Step 1**: Compute the difference `delta` between the sample `x` and the mean `mu`.\n\n- **Step 2**: Use `tf.linalg.triangular_solve` to solve the equation \\( L \\cdot y = \\text{delta} \\) for `y`, where `L` is the lower triangular matrix from the Cholesky decomposition.\n\n- **Step 3**: Compute the quadratic term \\( y^T y \\) which is the sum of squares of `y`.\n\n- **Step 4**: Compute the log determinant of `L` using the sum of the logs of its diagonal elements.\n\n- **Step 5**: Compute the log-density using the formula for the log-density of a multivariate normal distribution.\n\nThis implementation assumes that `x` and `mu` are 2D tensors where the first dimension is the dimensionality of the distribution and the second dimension is the number of samples. The function returns a 1D tensor of log densities, one for each sample.",
    "prompt": "\"Write the multivariate_normal function as follow :\n@check_shapes(\n    \"x: [D, broadcast N]\",\n    \"mu: [D, broadcast N]\",\n    \"L: [D, D]\",\n    \"return: [N]\",\n)\ndef multivariate_normal(x: TensorType, mu: TensorType, L: TensorType) -> tf.Tensor:\n    \"\"\"\n    Computes the log-density of a multivariate normal.\n\n    :param x: sample(s) for which we want the density\n    :param mu: mean(s) of the normal distribution\n    :param L: Cholesky decomposition of the covariance matrix\n    :return: log densities\n    \"\"\"",
    "function_name": "multivariate_normal",
    "ground_truth": "gpflow/logdensities.py",
    "test": "tests/gpflow/test_logdensities.py::test_multivariate_normal",
    "class": "",
    "stage": "Model Construction",
    "task": "Prediction",
    "data": "tabular"
}