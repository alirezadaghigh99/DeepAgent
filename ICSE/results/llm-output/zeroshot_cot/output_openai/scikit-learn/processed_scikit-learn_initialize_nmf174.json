{
    "result": "To create the `_initialize_nmf` function, we need to implement different initialization strategies for Non-negative Matrix Factorization (NMF). We'll start by defining the function signature and then implement each initialization method. Here's how we can proceed:\n\n### Step 1: Define the Function Signature\n\nWe'll start by defining the function signature with the required parameters.\n\n```python\nimport numpy as np\nfrom sklearn.utils import check_random_state\nfrom sklearn.decomposition import TruncatedSVD\n\ndef _initialize_nmf(X, n_components, init=None, eps=1e-6, random_state=None):\n    \"\"\"\n    Initialize the matrices W and H for NMF.\n\n    Parameters:\n    - X: array-like of shape (n_samples, n_features)\n    - n_components: int\n    - init: {'random', 'nndsvd', 'nndsvda', 'nndsvdar'}, default=None\n    - eps: float, default=1e-6\n    - random_state: int, RandomState instance or None, default=None\n\n    Returns:\n    - W: array-like of shape (n_samples, n_components)\n    - H: array-like of shape (n_components, n_features)\n    \"\"\"\n    n_samples, n_features = X.shape\n    rng = check_random_state(random_state)\n```\n\n### Step 2: Implement Random Initialization\n\nFor random initialization, we can use a uniform distribution to generate non-negative values.\n\n```python\n    if init == 'random':\n        W = rng.uniform(low=0, high=1, size=(n_samples, n_components))\n        H = rng.uniform(low=0, high=1, size=(n_components, n_features))\n        return W, H\n```\n\n### Step 3: Implement NNDSVD Initialization\n\nNNDSVD (Non-negative Double Singular Value Decomposition) is a popular method for initializing NMF. We'll implement the basic NNDSVD and its variants.\n\n```python\n    def _nndsvd(X, n_components, variant='nndsvd'):\n        svd = TruncatedSVD(n_components=n_components, random_state=random_state)\n        U = svd.fit_transform(X)\n        Sigma = svd.singular_values_\n        V = svd.components_\n\n        W = np.zeros((n_samples, n_components))\n        H = np.zeros((n_components, n_features))\n\n        # First component\n        W[:, 0] = np.sqrt(Sigma[0]) * np.abs(U[:, 0])\n        H[0, :] = np.sqrt(Sigma[0]) * np.abs(V[0, :])\n\n        for j in range(1, n_components):\n            x, y = U[:, j], V[j, :]\n            xp, xn = np.maximum(x, 0), np.maximum(-x, 0)\n            yp, yn = np.maximum(y, 0), np.maximum(-y, 0)\n            xpnorm, xnnorm = np.linalg.norm(xp), np.linalg.norm(xn)\n            ypnorm, ynnorm = np.linalg.norm(yp), np.linalg.norm(yn)\n            m = xpnorm * ypnorm + xnnorm * ynnorm\n\n            if m == 0:\n                W[:, j] = 0\n                H[j, :] = 0\n            else:\n                if xpnorm * ypnorm >= xnnorm * ynnorm:\n                    W[:, j] = np.sqrt(Sigma[j] * m) * xp / xpnorm\n                    H[j, :] = np.sqrt(Sigma[j] * m) * yp / ypnorm\n                else:\n                    W[:, j] = np.sqrt(Sigma[j] * m) * xn / xnnorm\n                    H[j, :] = np.sqrt(Sigma[j] * m) * yn / ynnorm\n\n        if variant == 'nndsvda':\n            W[W < eps] = eps\n            H[H < eps] = eps\n        elif variant == 'nndsvdar':\n            avg = np.mean(X)\n            W[W < eps] = avg\n            H[H < eps] = avg\n\n        return W, H\n\n    if init in {'nndsvd', 'nndsvda', 'nndsvdar'}:\n        return _nndsvd(X, n_components, variant=init)\n```\n\n### Step 4: Handle Default Case\n\nIf `init` is `None`, we can default to one of the initialization methods, such as 'nndsvd'.\n\n```python\n    if init is None:\n        return _nndsvd(X, n_components, variant='nndsvd')\n```\n\n### Step 5: Complete the Function\n\nFinally, we return the initialized matrices `W` and `H`.\n\n```python\n    raise ValueError(f\"Invalid init parameter: got {init}, expected one of \"\n                     \"{'random', 'nndsvd', 'nndsvda', 'nndsvdar', None}\")\n```\n\n### Full Function\n\nHere is the complete `_initialize_nmf` function:\n\n```python\nimport numpy as np\nfrom sklearn.utils import check_random_state\nfrom sklearn.decomposition import TruncatedSVD\n\ndef _initialize_nmf(X, n_components, init=None, eps=1e-6, random_state=None):\n    n_samples, n_features = X.shape\n    rng = check_random_state(random_state)\n\n    if init == 'random':\n        W = rng.uniform(low=0, high=1, size=(n_samples, n_components))\n        H = rng.uniform(low=0, high=1, size=(n_components, n_features))\n        return W, H\n\n    def _nndsvd(X, n_components, variant='nndsvd'):\n        svd = TruncatedSVD(n_components=n_components, random_state=random_state)\n        U = svd.fit_transform(X)\n        Sigma = svd.singular_values_\n        V = svd.components_\n\n        W = np.zeros((n_samples, n_components))\n        H = np.zeros((n_components, n_features))\n\n        W[:, 0] = np.sqrt(Sigma[0]) * np.abs(U[:, 0])\n        H[0, :] = np.sqrt(Sigma[0]) * np.abs(V[0, :])\n\n        for j in range(1, n_components):\n            x, y = U[:, j], V[j, :]\n            xp, xn = np.maximum(x, 0), np.maximum(-x, 0)\n            yp, yn = np.maximum(y, 0), np.maximum(-y, 0)\n            xpnorm, xnnorm = np.linalg.norm(xp), np.linalg.norm(xn)\n            ypnorm, ynnorm = np.linalg.norm(yp), np.linalg.norm(yn)\n            m = xpnorm * ypnorm + xnnorm * ynnorm\n\n            if m == 0:\n                W[:, j] = 0\n                H[j, :] = 0\n            else:\n                if xpnorm * ypnorm >= xnnorm * ynnorm:\n                    W[:, j] = np.sqrt(Sigma[j] * m) * xp / xpnorm\n                    H[j, :] = np.sqrt(Sigma[j] * m) * yp / ypnorm\n                else:\n                    W[:, j] = np.sqrt(Sigma[j] * m) * xn / xnnorm\n                    H[j, :] = np.sqrt(Sigma[j] * m) * yn / ynnorm\n\n        if variant == 'nndsvda':\n            W[W < eps] = eps\n            H[H < eps] = eps\n        elif variant == 'nndsvdar':\n            avg = np.mean(X)\n            W[W < eps] = avg\n            H[H < eps] = avg\n\n        return W, H\n\n    if init in {'nndsvd', 'nndsvda', 'nndsvdar'}:\n        return _nndsvd(X, n_components, variant=init)\n\n    if init is None:\n        return _nndsvd(X, n_components, variant='nndsvd')\n\n    raise ValueError(f\"Invalid init parameter: got {init}, expected one of \"\n                     \"{'random', 'nndsvd', 'nndsvda', 'nndsvdar', None}\")\n```\n\nThis function provides a flexible way to initialize matrices for NMF using different strategies, ensuring that the initial guesses are suitable for the optimization process.",
    "prompt": "Generate a Python function called _initialize_nmf that computes an initial guess for the non-negative rank k matrix approximation for a given data matrix X using Non-negative Matrix Factorization (NMF) initialization algorithms. The function takes the following parameters:\n\n- X: array-like of shape (n_samples, n_features) - The data matrix to be decomposed.\n- n_components: int - The number of components desired in the approximation.\n- init: {'random', 'nndsvd', 'nndsvda', 'nndsvdar'}, default=None - Method used to initialize the procedure.\n- eps: float, default=1e-6 - Truncate all values less than this in the output to zero.\n- random_state: int, RandomState instance or None, default=None - Used for reproducible results.\n\nThe function returns two arrays:\n- W: array-like of shape (n_samples, n_components) - Initial guesses for solving X ~= WH.\n- H: array-like of shape (n_components, n_features) - Initial guesses for solving X ~= WH.\n\nThe function implements different initialization methods based on the 'init' parameter, such as random initialization, NNDSVD initialization, and custom initialization. It also handles cases where the 'init' parameter is set to 'nndsvd', 'nndsvda', or 'nndsvdar'.",
    "function_name": "_initialize_nmf",
    "ground_truth": "sklearn/decomposition/_nmf.py",
    "test": "sklearn/decomposition/tests/test_nmf.py::test_nmf_minibatchnmf_equivalence",
    "class": "",
    "stage": "Model Construction",
    "task": "",
    "data": "Table"
}