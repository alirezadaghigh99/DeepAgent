{
    "result": "To implement the `brier_score_loss` function, we need to follow a structured approach. We'll start by defining the function signature and then implement each part step by step, including input validation, error handling, and the calculation of the Brier score loss. Here's how you can do it:\n\n### Step 1: Define the Function Signature\n\nWe'll start by defining the function signature with the necessary parameters.\n\n```python\ndef brier_score_loss(y_true, y_proba, sample_weight=None, pos_label=1):\n    \"\"\"\n    Calculate the Brier score loss.\n\n    Parameters:\n    - y_true: array-like of shape (n_samples,)\n        True binary labels.\n    - y_proba: array-like of shape (n_samples,)\n        Predicted probabilities for the positive class.\n    - sample_weight: array-like of shape (n_samples,), default=None\n        Sample weights.\n    - pos_label: int or str, default=1\n        The label of the positive class.\n\n    Returns:\n    - float\n        Brier score loss.\n    \"\"\"\n    pass\n```\n\n### Step 2: Input Validation\n\nWe need to ensure that the inputs are valid. This includes checking the types and shapes of `y_true` and `y_proba`, ensuring that `y_proba` values are within the [0, 1] range, and that `y_true` contains only binary labels.\n\n```python\nimport numpy as np\nfrom sklearn.utils import check_consistent_length\nfrom sklearn.utils.validation import column_or_1d\n\ndef brier_score_loss(y_true, y_proba, sample_weight=None, pos_label=1):\n    # Convert inputs to numpy arrays\n    y_true = column_or_1d(y_true)\n    y_proba = column_or_1d(y_proba)\n\n    # Check consistent length\n    check_consistent_length(y_true, y_proba, sample_weight)\n\n    # Check that y_proba is within [0, 1]\n    if np.any((y_proba < 0) | (y_proba > 1)):\n        raise ValueError(\"y_proba values must be within [0, 1].\")\n\n    # Check that y_true is binary\n    unique_labels = np.unique(y_true)\n    if len(unique_labels) > 2:\n        raise ValueError(\"y_true must be binary.\")\n\n    # Map y_true to 0 and 1 if necessary\n    if pos_label not in unique_labels:\n        raise ValueError(f\"pos_label={pos_label} is not a valid label.\")\n    \n    y_true = np.array([1 if label == pos_label else 0 for label in y_true])\n```\n\n### Step 3: Calculate the Brier Score Loss\n\nNow, we can calculate the Brier score loss using the formula for mean squared error, optionally applying sample weights.\n\n```python\n    # Calculate the Brier score loss\n    if sample_weight is not None:\n        sample_weight = np.array(sample_weight)\n        check_consistent_length(y_true, sample_weight)\n        loss = np.average((y_true - y_proba) ** 2, weights=sample_weight)\n    else:\n        loss = np.mean((y_true - y_proba) ** 2)\n\n    return loss\n```\n\n### Step 4: Complete Function\n\nHere's the complete function with all the steps combined:\n\n```python\nimport numpy as np\nfrom sklearn.utils import check_consistent_length\nfrom sklearn.utils.validation import column_or_1d\n\ndef brier_score_loss(y_true, y_proba, sample_weight=None, pos_label=1):\n    \"\"\"\n    Calculate the Brier score loss.\n\n    Parameters:\n    - y_true: array-like of shape (n_samples,)\n        True binary labels.\n    - y_proba: array-like of shape (n_samples,)\n        Predicted probabilities for the positive class.\n    - sample_weight: array-like of shape (n_samples,), default=None\n        Sample weights.\n    - pos_label: int or str, default=1\n        The label of the positive class.\n\n    Returns:\n    - float\n        Brier score loss.\n    \"\"\"\n    # Convert inputs to numpy arrays\n    y_true = column_or_1d(y_true)\n    y_proba = column_or_1d(y_proba)\n\n    # Check consistent length\n    check_consistent_length(y_true, y_proba, sample_weight)\n\n    # Check that y_proba is within [0, 1]\n    if np.any((y_proba < 0) | (y_proba > 1)):\n        raise ValueError(\"y_proba values must be within [0, 1].\")\n\n    # Check that y_true is binary\n    unique_labels = np.unique(y_true)\n    if len(unique_labels) > 2:\n        raise ValueError(\"y_true must be binary.\")\n\n    # Map y_true to 0 and 1 if necessary\n    if pos_label not in unique_labels:\n        raise ValueError(f\"pos_label={pos_label} is not a valid label.\")\n    \n    y_true = np.array([1 if label == pos_label else 0 for label in y_true])\n\n    # Calculate the Brier score loss\n    if sample_weight is not None:\n        sample_weight = np.array(sample_weight)\n        check_consistent_length(y_true, sample_weight)\n        loss = np.average((y_true - y_proba) ** 2, weights=sample_weight)\n    else:\n        loss = np.mean((y_true - y_proba) ** 2)\n\n    return loss\n```\n\nThis function should now correctly calculate the Brier score loss for binary classification problems, with appropriate error handling and input validation.",
    "prompt": "The `brier_score_loss` function calculates the Brier score loss, which measures the mean squared difference between predicted probabilities and actual binary outcomes. The function supports binary classification and includes error handling for deprecated parameters, input type checking, and label consistency. Inputs include the true labels (`y_true`), predicted probabilities (`y_proba`), optional sample weights, and a parameter to define the positive class label (`pos_label`). The output is a float representing the Brier score loss. Errors are raised for incorrect input types, non-binary classification targets, and probability values outside the [0, 1] range.",
    "function_name": "brier_score_loss",
    "ground_truth": "sklearn/metrics/_classification.py",
    "test": "sklearn/metrics/tests/test_classification.py",
    "class": "",
    "stage": "Model Construction",
    "task": "Classification",
    "data": ""
}