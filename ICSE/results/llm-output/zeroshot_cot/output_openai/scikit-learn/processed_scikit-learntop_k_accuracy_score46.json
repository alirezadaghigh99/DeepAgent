{
    "result": "To create the `top_k_accuracy_score` function, we need to follow these steps:\n\n1. **Validate Inputs**: Ensure that the inputs are valid and have the correct shapes.\n2. **Determine Top-k Predictions**: For each sample, determine the top-k predicted classes based on the scores.\n3. **Calculate Correct Predictions**: Compare the true labels with the top-k predictions to determine if the true label is within the top-k predictions.\n4. **Apply Sample Weights**: If sample weights are provided, apply them to the correct predictions.\n5. **Normalize the Result**: Depending on the `normalize` parameter, return either the fraction of correctly classified samples or the count.\n\nLet's implement this step by step:\n\n### Step 1: Validate Inputs\n\nWe need to ensure that `y_true`, `y_score`, and other inputs are in the correct format and shape.\n\n```python\nimport numpy as np\n\ndef top_k_accuracy_score(y_true, y_score, k=1, normalize=True, sample_weight=None, labels=None):\n    # Convert inputs to numpy arrays\n    y_true = np.asarray(y_true)\n    y_score = np.asarray(y_score)\n    \n    # Check if y_score is 1D or 2D\n    if y_score.ndim == 1:\n        y_score = y_score[:, np.newaxis]\n    \n    # Validate the shape of y_score\n    n_samples, n_classes = y_score.shape\n    if y_true.shape[0] != n_samples:\n        raise ValueError(\"The number of samples in y_true and y_score must be the same.\")\n    \n    # Validate k\n    if not (1 <= k <= n_classes):\n        raise ValueError(\"k must be between 1 and the number of classes.\")\n    \n    # Validate sample_weight\n    if sample_weight is not None:\n        sample_weight = np.asarray(sample_weight)\n        if sample_weight.shape[0] != n_samples:\n            raise ValueError(\"sample_weight must have the same number of samples as y_true.\")\n    \n    # Validate labels\n    if labels is not None:\n        labels = np.asarray(labels)\n        if labels.shape[0] != n_classes:\n            raise ValueError(\"labels must have the same number of classes as y_score.\")\n```\n\n### Step 2: Determine Top-k Predictions\n\nFor each sample, we need to find the indices of the top-k scores.\n\n```python\n    # Determine the top-k predictions\n    top_k_preds = np.argsort(y_score, axis=1)[:, -k:]\n```\n\n### Step 3: Calculate Correct Predictions\n\nCheck if the true label is within the top-k predictions.\n\n```python\n    # Check if true labels are in the top-k predictions\n    correct = np.any(top_k_preds == y_true[:, np.newaxis], axis=1)\n```\n\n### Step 4: Apply Sample Weights\n\nIf sample weights are provided, apply them to the correct predictions.\n\n```python\n    # Apply sample weights if provided\n    if sample_weight is not None:\n        correct = correct * sample_weight\n```\n\n### Step 5: Normalize the Result\n\nReturn the fraction or count of correctly classified samples based on the `normalize` parameter.\n\n```python\n    # Calculate the top-k accuracy score\n    if normalize:\n        return np.sum(correct) / n_samples\n    else:\n        return np.sum(correct)\n```\n\n### Complete Function\n\nHere is the complete function with examples and additional information:\n\n```python\ndef top_k_accuracy_score(y_true, y_score, k=1, normalize=True, sample_weight=None, labels=None):\n    \"\"\"\n    Calculate the top-k accuracy score.\n\n    Parameters:\n    - y_true: array-like of shape (n_samples,) representing the true labels.\n    - y_score: array-like of shape (n_samples,) or (n_samples, n_classes) representing the target scores.\n    - k: int, number of most likely outcomes considered to find the correct label.\n    - normalize: bool, whether to return the fraction of correctly classified samples or the number of correctly classified samples.\n    - sample_weight: array-like of shape (n_samples,) representing sample weights.\n    - labels: array-like of shape (n_classes,) representing the list of labels that index the classes in y_score.\n\n    Returns:\n    - float, top-k accuracy score.\n    \"\"\"\n    # Convert inputs to numpy arrays\n    y_true = np.asarray(y_true)\n    y_score = np.asarray(y_score)\n    \n    # Check if y_score is 1D or 2D\n    if y_score.ndim == 1:\n        y_score = y_score[:, np.newaxis]\n    \n    # Validate the shape of y_score\n    n_samples, n_classes = y_score.shape\n    if y_true.shape[0] != n_samples:\n        raise ValueError(\"The number of samples in y_true and y_score must be the same.\")\n    \n    # Validate k\n    if not (1 <= k <= n_classes):\n        raise ValueError(\"k must be between 1 and the number of classes.\")\n    \n    # Validate sample_weight\n    if sample_weight is not None:\n        sample_weight = np.asarray(sample_weight)\n        if sample_weight.shape[0] != n_samples:\n            raise ValueError(\"sample_weight must have the same number of samples as y_true.\")\n    \n    # Validate labels\n    if labels is not None:\n        labels = np.asarray(labels)\n        if labels.shape[0] != n_classes:\n            raise ValueError(\"labels must have the same number of classes as y_score.\")\n    \n    # Determine the top-k predictions\n    top_k_preds = np.argsort(y_score, axis=1)[:, -k:]\n    \n    # Check if true labels are in the top-k predictions\n    correct = np.any(top_k_preds == y_true[:, np.newaxis], axis=1)\n    \n    # Apply sample weights if provided\n    if sample_weight is not None:\n        correct = correct * sample_weight\n    \n    # Calculate the top-k accuracy score\n    if normalize:\n        return np.sum(correct) / n_samples\n    else:\n        return np.sum(correct)\n\n# Example usage\ny_true = np.array([0, 1, 2, 2])\ny_score = np.array([[0.2, 0.3, 0.5],\n                    [0.1, 0.6, 0.3],\n                    [0.3, 0.4, 0.3],\n                    [0.7, 0.2, 0.1]])\nk = 2\nprint(top_k_accuracy_score(y_true, y_score, k))  # Output: 0.75\n```\n\nThis function calculates the top-k accuracy score, which is useful for evaluating models where the top-k predictions are considered.",
    "prompt": "Generate a Python function called top_k_accuracy_score that calculates the top-k accuracy classification score. The function takes in the following parameters:\n\n- y_true: array-like of shape (n_samples,) representing the true labels.\n- y_score: array-like of shape (n_samples,) or (n_samples, n_classes) representing the target scores.\n- k: an integer representing the number of most likely outcomes considered to find the correct label.\n- normalize: a boolean indicating whether to return the fraction of correctly classified samples or the number of correctly classified samples.\n- sample_weight: array-like of shape (n_samples,) representing sample weights.\n- labels: array-like of shape (n_classes,) representing the list of labels that index the classes in y_score.\n\nThe function returns a float value representing the top-k accuracy score. The best performance is 1 with normalize == True and the number of samples with normalize == False. The function also includes examples and additional information about the metric.",
    "function_name": "top_k_accuracy_score",
    "ground_truth": "sklearn/metrics/_ranking.py",
    "test": "sklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_binary",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "Classification",
    "data": "Table"
}