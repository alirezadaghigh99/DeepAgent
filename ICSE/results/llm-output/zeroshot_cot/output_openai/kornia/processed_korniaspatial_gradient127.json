{
    "result": "To create the `spatial_gradient` function, we will break down the task into several steps. We'll start by defining the function signature and then implement the logic for computing the image derivatives using the Sobel operator. We'll also handle the different parameters such as `mode`, `order`, and `normalized`. Finally, we'll provide examples of how to use the function.\n\n### Step 1: Define the Function Signature\n\nWe'll start by defining the function signature with the necessary parameters.\n\n```python\nimport torch\nimport torch.nn.functional as F\n\ndef spatial_gradient(input_image, mode='sobel', order=1, normalized=False):\n    \"\"\"\n    Computes the first-order image derivative in both x and y using a Sobel operator.\n\n    Parameters:\n    - input_image: torch.Tensor of shape (B, C, H, W)\n    - mode: str, either 'sobel' or 'diff'\n    - order: int, the order of the derivatives\n    - normalized: bool, whether the output is normalized\n\n    Returns:\n    - torch.Tensor of shape (B, C, 2, H, W) containing the derivatives\n    \"\"\"\n    # Validate input\n    if mode not in ['sobel', 'diff']:\n        raise ValueError(\"Mode must be either 'sobel' or 'diff'\")\n    if order != 1:\n        raise ValueError(\"Currently, only first-order derivatives are supported\")\n    \n    # Initialize Sobel kernels\n    sobel_x = torch.tensor([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n    sobel_y = torch.tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n    \n    # Normalize kernels if required\n    if normalized:\n        sobel_x /= 8.0\n        sobel_y /= 8.0\n    \n    # Apply Sobel operator\n    B, C, H, W = input_image.shape\n    grad_x = F.conv2d(input_image.view(B * C, 1, H, W), sobel_x, padding=1)\n    grad_y = F.conv2d(input_image.view(B * C, 1, H, W), sobel_y, padding=1)\n    \n    # Reshape to (B, C, 2, H, W)\n    grad_x = grad_x.view(B, C, H, W)\n    grad_y = grad_y.view(B, C, H, W)\n    gradients = torch.stack((grad_x, grad_y), dim=2)\n    \n    return gradients\n```\n\n### Step 2: Implement the 'diff' Mode\n\nFor the 'diff' mode, we will compute simple finite differences instead of using the Sobel operator.\n\n```python\n    if mode == 'diff':\n        # Compute finite differences\n        grad_x = input_image[:, :, :, 1:] - input_image[:, :, :, :-1]\n        grad_y = input_image[:, :, 1:, :] - input_image[:, :, :-1, :]\n        \n        # Pad the gradients to maintain the original size\n        grad_x = F.pad(grad_x, (0, 1, 0, 0))\n        grad_y = F.pad(grad_y, (0, 0, 0, 1))\n        \n        # Reshape to (B, C, 2, H, W)\n        gradients = torch.stack((grad_x, grad_y), dim=2)\n    \n    return gradients\n```\n\n### Step 3: Provide Usage Examples\n\nFinally, let's add some examples to demonstrate how to use the function.\n\n```python\n# Example usage\nif __name__ == \"__main__\":\n    # Create a random input image tensor with shape (B, C, H, W)\n    input_image = torch.rand(1, 1, 5, 5)  # Example with a single-channel image\n\n    # Compute gradients using Sobel operator\n    sobel_gradients = spatial_gradient(input_image, mode='sobel', normalized=True)\n    print(\"Sobel Gradients:\\n\", sobel_gradients)\n\n    # Compute gradients using finite differences\n    diff_gradients = spatial_gradient(input_image, mode='diff')\n    print(\"Finite Difference Gradients:\\n\", diff_gradients)\n```\n\nThis code defines the `spatial_gradient` function, which computes the first-order image derivatives using either the Sobel operator or finite differences, and provides examples of how to use the function.",
    "prompt": "Generate a Python function called spatial_gradient that computes the first-order image derivative in both x and y using a Sobel operator. The function takes in an input image tensor with shape (B, C, H, W), a mode parameter specifying the derivatives modality (either 'sobel' or 'diff'), an order parameter indicating the order of the derivatives, and a normalized parameter determining whether the output is normalized. The function returns the derivatives of the input feature map with shape (B, C, 2, H, W). The function also includes examples demonstrating its usage.",
    "function_name": "spatial_gradient",
    "ground_truth": "kornia/filters/sobel.py",
    "test": "tests/filters/test_sobel.py::TestSpatialGradient",
    "class": "",
    "stage": "Training",
    "task": "",
    "data": "Image"
}