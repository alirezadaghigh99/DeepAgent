{
    "result": "To create the `unproject_points` function, we need to transform 2D pixel coordinates into 3D world coordinates using the camera's intrinsic matrix and the depth information. Here's a step-by-step implementation of the function:\n\n```python\nimport torch\n\ndef unproject_points(point2d: torch.Tensor, depth: torch.Tensor, camera_matrix: torch.Tensor, normalize: bool = False) -> torch.Tensor:\n    \"\"\"\n    Unproject a 2D point into 3D world coordinates using the camera's intrinsic matrix.\n\n    Args:\n        point2d (torch.Tensor): Tensor containing the 2D points to be projected to\n            world coordinates. The shape of the tensor can be :math:`(*, 2)`.\n        depth (torch.Tensor): Tensor containing the depth value of each 2D\n            point. The tensor shape must be equal to point2d :math:`(*, 1)`.\n        camera_matrix (torch.Tensor): Tensor containing the intrinsic camera\n            matrix. The tensor shape must be :math:`(*, 3, 3)`.\n        normalize (bool): Whether to normalize the point cloud. This\n            must be set to `True` when the depth is represented as the Euclidean\n            ray length from the camera position.\n\n    Returns:\n        torch.Tensor: Tensor of (x, y, z) world coordinates with shape :math:`(*, 3)`.\n    \"\"\"\n    # 1. Ensure the input tensors have compatible shapes\n    assert point2d.shape[:-1] == depth.shape[:-1], \"point2d and depth must have compatible shapes\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"camera_matrix must have shape (*, 3, 3)\"\n\n    # 2. Add a homogeneous coordinate to the 2D points\n    ones = torch.ones_like(point2d[..., :1])\n    point2d_homogeneous = torch.cat([point2d, ones], dim=-1)  # shape: (*, 3)\n\n    # 3. Invert the camera matrix to transform from pixel to camera coordinates\n    camera_matrix_inv = torch.inverse(camera_matrix)\n\n    # 4. Compute the 3D points in the camera frame\n    point3d_camera = torch.matmul(camera_matrix_inv, point2d_homogeneous.unsqueeze(-1)).squeeze(-1)  # shape: (*, 3)\n\n    # 5. Scale the 3D points by the depth\n    point3d_world = point3d_camera * depth\n\n    # 6. Normalize the 3D points if required\n    if normalize:\n        point3d_world = point3d_world / point3d_world.norm(dim=-1, keepdim=True)\n\n    # 7. Return the 3D world coordinates\n    return point3d_world\n\n# Example usage\nif __name__ == \"__main__\":\n    torch.manual_seed(0)\n    x = torch.rand(1, 2)\n    depth = torch.ones(1, 1)\n    K = torch.eye(3)[None]\n    result = unproject_points(x, depth, K)\n    print(result)  # Output: tensor([[0.4963, 0.7682, 1.0000]])\n```\n\n### Explanation:\n\n1. **Input Validation**: We ensure that the shapes of `point2d`, `depth`, and `camera_matrix` are compatible for the operations.\n\n2. **Homogeneous Coordinates**: We convert the 2D points into homogeneous coordinates by appending a 1, which is necessary for matrix multiplication with the camera matrix.\n\n3. **Camera Matrix Inversion**: We invert the camera matrix to transform the 2D pixel coordinates into 3D camera coordinates.\n\n4. **3D Point Calculation**: We multiply the inverted camera matrix with the homogeneous 2D points to get the 3D points in the camera frame.\n\n5. **Depth Scaling**: We scale the 3D points by the depth to get the actual 3D world coordinates.\n\n6. **Normalization**: If `normalize` is `True`, we normalize the 3D points to have unit length.\n\n7. **Return**: Finally, we return the 3D world coordinates.",
    "prompt": "Generate a python function called unproject_points that Unproject a 2d point in 3d.\n\n    Transform coordinates in the pixel frame to the camera frame.\n\n    Args:\n        point2d: tensor containing the 2d to be projected to\n            world coordinates. The shape of the tensor can be :math:`(*, 2)`.\n        depth: tensor containing the depth value of each 2d\n            points. The tensor shape must be equal to point2d :math:`(*, 1)`.\n        camera_matrix: tensor containing the intrinsics camera\n            matrix. The tensor shape must be :math:`(*, 3, 3)`.\n        normalize: whether to normalize the pointcloud. This\n            must be set to `True` when the depth is represented as the Euclidean\n            ray length from the camera position.\n\n    Returns:\n        tensor of (x, y, z) world coordinates with shape :math:`(*, 3)`.\n\n    Example:\n        >>> _ = torch.manual_seed(0)\n        >>> x = torch.rand(1, 2)\n        >>> depth = torch.ones(1, 1)\n        >>> K = torch.eye(3)[None]\n        >>> unproject_points(x, depth, K)\n        tensor([[0.4963, 0.7682, 1.0000]])",
    "function_name": "unproject_points",
    "ground_truth": "kornia/geometry/camera/perspective.py#L39",
    "test": "tests/geometry/camera/test_perspective.py",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "Detection",
    "data": "Image"
}