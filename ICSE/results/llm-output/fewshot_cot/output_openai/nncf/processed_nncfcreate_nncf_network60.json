{
    "result": "To create a Python function called `create_nncf_network` that prepares a PyTorch model for compression using a configuration object, we can follow a structured approach similar to the examples provided. Here's a step-by-step implementation:\n\n```python\nfrom typing import Callable, Tuple, Dict, Any\nimport torch\nfrom nncf import NNCFNetwork, nncf_model_input\n\ndef create_nncf_network(\n    model: torch.nn.Module,\n    config: Dict[str, Any],\n    dummy_forward_fn: Callable = None,\n    wrap_inputs_fn: Callable = None,\n    wrap_outputs_fn: Callable = None\n) -> NNCFNetwork:\n    \"\"\"\n    Prepares a PyTorch model for compression using NNCF.\n\n    :param model: The original model with parameters loaded.\n    :param config: Configuration object for compression modifications.\n    :param dummy_forward_fn: Optional function for custom forward pass during graph tracing.\n    :param wrap_inputs_fn: Optional function to wrap model inputs for compression.\n    :param wrap_outputs_fn: Optional function to wrap model outputs for compression.\n\n    :return: A model wrapped by NNCFNetwork, ready for compression.\n    \"\"\"\n    # 1. Validate the input arguments\n    if dummy_forward_fn is not None and wrap_inputs_fn is None:\n        raise ValueError(\"wrap_inputs_fn must be specified if dummy_forward_fn is provided.\")\n\n    # 2. Define a default dummy forward function if not provided\n    if dummy_forward_fn is None:\n        def default_dummy_forward_fn(*args, **kwargs):\n            # Use mock tensors based on config for tracing\n            input_shapes = config.get('input_info', [])\n            mock_inputs = [torch.randn(shape) for shape in input_shapes]\n            return model(*mock_inputs)\n\n        dummy_forward_fn = default_dummy_forward_fn\n\n    # 3. Define a default wrap inputs function if not provided\n    if wrap_inputs_fn is None:\n        def default_wrap_inputs_fn(args, kwargs):\n            # Wrap each tensor in args and kwargs with nncf_model_input\n            wrapped_args = tuple(nncf_model_input(arg) if isinstance(arg, torch.Tensor) else arg for arg in args)\n            wrapped_kwargs = {k: nncf_model_input(v) if isinstance(v, torch.Tensor) else v for k, v in kwargs.items()}\n            return wrapped_args, wrapped_kwargs\n\n        wrap_inputs_fn = default_wrap_inputs_fn\n\n    # 4. Define a default wrap outputs function if not provided\n    if wrap_outputs_fn is None:\n        def default_wrap_outputs_fn(outputs):\n            # Wrap outputs with nncf_model_input if needed\n            if isinstance(outputs, torch.Tensor):\n                return nncf_model_input(outputs)\n            elif isinstance(outputs, (list, tuple)):\n                return type(outputs)(nncf_model_input(o) if isinstance(o, torch.Tensor) else o for o in outputs)\n            elif isinstance(outputs, dict):\n                return {k: nncf_model_input(v) if isinstance(v, torch.Tensor) else v for k, v in outputs.items()}\n            return outputs\n\n        wrap_outputs_fn = default_wrap_outputs_fn\n\n    # 5. Create the NNCFNetwork with the provided or default functions\n    nncf_network = NNCFNetwork(\n        model,\n        config,\n        dummy_forward_fn=dummy_forward_fn,\n        wrap_inputs_fn=wrap_inputs_fn,\n        wrap_outputs_fn=wrap_outputs_fn\n    )\n\n    # 6. Return the NNCF-wrapped model ready for compression\n    return nncf_network\n```\n\n### Explanation:\n1. **Input Validation**: Ensure that if `dummy_forward_fn` is provided, `wrap_inputs_fn` must also be specified.\n2. **Default Functions**: Define default functions for `dummy_forward_fn`, `wrap_inputs_fn`, and `wrap_outputs_fn` if they are not provided by the user.\n3. **NNCFNetwork Creation**: Use the provided or default functions to create an `NNCFNetwork` instance, which wraps the original model and prepares it for compression.\n4. **Return**: The function returns the `NNCFNetwork` instance, ready for further compression operations.",
    "prompt": "Generate a Python function called create_nncf_network that The main function used to produce a model ready for adding compression from an original PyTorch\n    model and a configuration object.\n\n    :param model: The original model. Should have its parameters already loaded from a checkpoint or another\n        source.\n    :param config: A configuration object used to determine the exact compression modifications to be applied\n        to the model\n    :param dummy_forward_fn: if supplied, will be used instead of a *forward* function call to build\n        the internal graph representation via tracing. Specifying this is useful when the original training pipeline\n        has special formats of data loader output or has additional *forward* arguments other than input tensors.\n        Otherwise, the *forward* call of the model during graph tracing will be made with mock tensors according\n        to the shape specified in the config object. The dummy_forward_fn code MUST contain calls to\n        nncf.nncf_model_input\n        functions made with each compressed model input tensor in the underlying model's args/kwargs tuple, and these\n        calls should be exactly the same as in the wrap_inputs_fn function code (see below); if dummy_forward_fn is\n        specified, then wrap_inputs_fn also must be specified.\n    :param wrap_inputs_fn: if supplied, will be used on the module's input arguments during a regular, non-dummy\n        forward call before passing the inputs to the underlying compressed model. This is required if the model's input\n        tensors that are important for compression are not supplied as arguments to the model's forward call directly,\n        but instead are located in a container (such as list), and the model receives the container as an argument.\n        wrap_inputs_fn should take as input two arguments - the tuple of positional arguments to the underlying\n        model's forward call, and a dict of keyword arguments to the same. The function should wrap each tensor among\n        the supplied model's args and kwargs that is important for compression (e.g. quantization) with an\n        nncf.nncf_model_input function, which is a no-operation function and marks the tensors as inputs to be traced\n        by NNCF in the internal graph representation. Output is the tuple of (args, kwargs), where args and kwargs are\n        the same as were supplied in input, but each tensor in the original input. Must be specified if\n        dummy_forward_fn is specified.\n    :param wrap_outputs_fn: Same as `wrap_inputs_fn`, but for marking model outputs with\n\n    :return: A model wrapped by NNCFNetwork, which is ready for adding compression.\"\"\"",
    "function_name": "create_nncf_network",
    "ground_truth": "nncf/torch/model_creation.py",
    "test": "tests/torch/sparsity/movement/test_algo.py::TestControllerCreation",
    "class": "",
    "stage": "Model Construction",
    "task": "",
    "data": ""
}