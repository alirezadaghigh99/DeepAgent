{
    "result": "To create a function called `_compute_tf_loss` that calculates the sigmoid cross-entropy loss using TensorFlow, you can follow a step-by-step approach similar to the examples provided. Here's how you can implement this function:\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras.losses import Loss\n\nclass SigmoidCrossEntropy(Loss):\n    def _compute_tf_loss(self, output, labels):\n        \"\"\"\n        Compute the sigmoid cross-entropy loss between output logits and labels.\n\n        Args:\n            output (tf.Tensor): Logits tensor with shape (batch_size,) or (batch_size, tasks).\n            labels (tf.Tensor): Labels tensor with the same shape as output.\n\n        Returns:\n            tf.Tensor: Tensor of loss values with shape (batch_size,) or (batch_size, tasks).\n        \"\"\"\n        # 1. Ensure that the output and labels have the same shape\n        if output.shape != labels.shape:\n            raise ValueError(\"Output and labels must have the same shape.\")\n\n        # 2. Compute the sigmoid cross-entropy loss\n        loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=output)\n\n        # 3. Return the computed loss\n        return loss\n```\n\n### Step-by-step Explanation:\n\n1. **Import TensorFlow**: Import the necessary TensorFlow module to use its functions and classes.\n\n2. **Define the Class**: Create a class `SigmoidCrossEntropy` that inherits from `Loss`. This allows you to define custom loss functions in a structured way.\n\n3. **Define the Method**: Implement the `_compute_tf_loss` method within the class. This method will compute the sigmoid cross-entropy loss.\n\n4. **Docstring**: Add a docstring to describe the purpose of the method, its arguments, and its return value.\n\n5. **Shape Check**: Ensure that the `output` and `labels` tensors have the same shape. If not, raise a `ValueError`.\n\n6. **Compute Loss**: Use TensorFlow's `tf.nn.sigmoid_cross_entropy_with_logits` function to compute the loss. This function applies the sigmoid activation to the logits and then computes the cross-entropy loss.\n\n7. **Return Loss**: Return the computed loss tensor. The shape of the loss tensor will match the input shape, either `(batch_size,)` or `(batch_size, tasks)`.\n\nThis function will calculate the sigmoid cross-entropy loss for each element in the batch, which is useful for binary classification tasks with one or more outputs per sample.",
    "prompt": "Generate a Python function called `_compute_tf_loss` that calculates the sigmoid cross entropy loss between output logits and labels using TensorFlow. The inputs are tensors of logits and labels with shapes `(batch_size)` or `(batch_size, tasks)`, and the output is a tensor of loss values.\n\n```python\nclass SigmoidCrossEntropy(Loss):\n    def _compute_tf_loss(self, output, labels):\n```",
    "function_name": "_compute_tf_loss",
    "ground_truth": "deepchem/models/losses.py",
    "test": "deepchem/model/tests/test_losses.py",
    "class": "SigmoidCrossEntropy",
    "stage": "",
    "task": "Classification",
    "data": "Training"
}