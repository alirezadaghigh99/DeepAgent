{
    "result": "To implement the `binomial_sampling` function for the `RBM` class, we need to perform binomial sampling using a rejection method. This involves comparing each probability in the input tensor `pr` with a random value sampled from a uniform distribution. The output should be a tensor of the same shape as `pr`, with values of `1` or `0`, indicating whether each hidden unit is active.\n\nHere's how you can implement this function using TensorFlow:\n\n```python\nimport tensorflow as tf\n\nclass RBM:\n    def __init__(self, possible_ratings, visible_units, hidden_units=500, keep_prob=0.7, init_stdv=0.1, learning_rate=0.004, minibatch_size=100, training_epoch=20, display_epoch=10, sampling_protocol=[50, 70, 80, 90, 100], debug=False, with_metrics=False, seed=42):\n        self.seed = seed\n        tf.random.set_seed(self.seed)\n\n    def binomial_sampling(self, pr):\n        \"\"\"\n        Perform binomial sampling of hidden unit activations using a rejection method.\n\n        Args:\n            pr (tf.Tensor): Tensor of shape (N, H) representing the conditional probabilities\n                            of the hidden units being active.\n\n        Returns:\n            tf.Tensor: Tensor of the same shape as `pr` with values of `1` or `0`.\n        \"\"\"\n        # 1. Generate a random tensor of the same shape as `pr` from a uniform distribution [0, 1)\n        random_values = tf.random.uniform(shape=tf.shape(pr), minval=0.0, maxval=1.0, dtype=tf.float32)\n\n        # 2. Compare each probability in `pr` with the corresponding random value\n        #    If the probability is greater than the random value, the hidden unit is active (1)\n        #    Otherwise, it is inactive (0)\n        sampled_activations = tf.cast(pr > random_values, dtype=tf.float32)\n\n        # 3. Return the tensor of sampled activations\n        return sampled_activations\n```\n\n### Explanation:\n\n1. **Random Tensor Generation**: We generate a tensor of random values from a uniform distribution between 0 and 1, with the same shape as the input tensor `pr`. This is done using `tf.random.uniform`.\n\n2. **Comparison for Sampling**: We compare each element of `pr` with the corresponding element in the random tensor. If the probability is greater than the random value, the hidden unit is considered active (represented by `1`), otherwise inactive (represented by `0`).\n\n3. **Output Tensor**: The result is a tensor of the same shape as `pr`, containing `1`s and `0`s, indicating the sampled activations of the hidden units.\n\nThis method effectively performs binomial sampling using a rejection method, where the probability of each hidden unit being active is determined by the corresponding value in `pr`.",
    "prompt": "Generate a Python function `binomial_sampling` for the class `RBM` that performs binomial sampling of hidden unit activations using a rejection method. The function should take as input a tensor `pr`, which represents the conditional probabilities of the hidden units being active, and compare each probability with a random value sampled from a uniform distribution The input is `pr` (tf.Tensor, float32), and the output is a tensor of the same shape with values of `1` or `0`.\n```python\nclass RBM:\n    def __init__(self, possible_ratings, visible_units, hidden_units=500, keep_prob=0.7, init_stdv=0.1, learning_rate=0.004, minibatch_size=100, training_epoch=20, display_epoch=10, sampling_protocol=[50, 70, 80, 90, 100], debug=False, with_metrics=False, seed=42):\n        pass\n\n    def binomial_sampling(self, pr):\n        # Implement the function as described in the prompt\n```",
    "function_name": "binomial_sampling",
    "ground_truth": "recommenders/models/rbm/rbm.py",
    "test": "tests/unit/recommenders/models/test_rbm.py",
    "class": "RBM",
    "stage": "",
    "task": "Recommendation",
    "data": "pre-post process"
}