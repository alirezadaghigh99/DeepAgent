{
    "result": "To create the `vert_align` function, we will follow a step-by-step approach similar to the examples provided. This function will perform \"vertex alignment\" by sampling features from a feature map based on vertex positions. Here's how you can implement it:\n\n```python\nimport torch\nimport torch.nn.functional as F\n\ndef vert_align(\n    feats: Union[torch.Tensor, List[torch.Tensor]],\n    verts: torch.Tensor,\n    return_packed: bool = False,\n    interp_mode: str = 'bilinear',\n    padding_mode: str = 'zeros',\n    align_corners: bool = True\n) -> torch.Tensor:\n    \"\"\"\n    Perform vertex alignment by sampling features from a feature map based on vertex positions.\n\n    Args:\n        feats (Tensor or List[Tensor]): Image features of shape (N, C, H, W) or a list of such tensors.\n        verts (Tensor): Vertex positions of shape (N, V, 3) or an object with verts_padded or points_padded attributes.\n        return_packed (bool): Whether to return packed features. Defaults to False.\n        interp_mode (str): Interpolation mode ('bilinear' or 'nearest'). Defaults to 'bilinear'.\n        padding_mode (str): How to handle vertices outside the [-1, 1] range ('zeros', 'reflection', 'border'). Defaults to 'zeros'.\n        align_corners (bool): Whether to align corners geometrically. Defaults to True.\n\n    Returns:\n        feats_sampled (Tensor): Sampled features of shape (N, V, C) or packed representation if return_packed is True.\n    \"\"\"\n    # 1. Handle the case where feats is a list of tensors\n    if isinstance(feats, list):\n        # Ensure all tensors in the list have the same batch size\n        batch_size = feats[0].shape[0]\n        for f in feats:\n            if f.shape[0] != batch_size:\n                raise ValueError(\"All feature tensors must have the same batch size.\")\n        \n        # Concatenate features along the channel dimension\n        feats = torch.cat(feats, dim=1)\n\n    # 2. Validate the shape of feats and verts\n    if feats.ndim != 4:\n        raise ValueError(\"feats must be a 4D tensor of shape (N, C, H, W).\")\n    if verts.ndim != 3 or verts.shape[2] != 3:\n        raise ValueError(\"verts must be a 3D tensor of shape (N, V, 3).\")\n\n    # 3. Extract the batch size, number of vertices, and feature dimensions\n    N, C, H, W = feats.shape\n    _, V, _ = verts.shape\n\n    # 4. Normalize vertex positions to the range [0, 1] for grid_sample\n    verts_normalized = verts[..., :2]  # Extract (x, y) coordinates\n    verts_normalized = (verts_normalized + 1) / 2  # Normalize to [0, 1]\n\n    # 5. Prepare grid for sampling\n    grid = verts_normalized.view(N, V, 1, 2)  # Reshape to (N, V, 1, 2)\n\n    # 6. Sample features using grid_sample\n    feats_sampled = F.grid_sample(\n        feats, grid, mode=interp_mode, padding_mode=padding_mode, align_corners=align_corners\n    )\n\n    # 7. Reshape sampled features to (N, V, C)\n    feats_sampled = feats_sampled.view(N, C, V).permute(0, 2, 1)\n\n    # 8. Handle return_packed option\n    if return_packed:\n        feats_sampled = feats_sampled.view(-1, C)  # Flatten to (sum(V), C)\n\n    # 9. Return the sampled features\n    return feats_sampled\n```\n\n### Explanation:\n\n1. **Input Handling**: The function first checks if `feats` is a list of tensors and concatenates them along the channel dimension if so. It also validates the shapes of `feats` and `verts`.\n\n2. **Normalization**: The vertex positions are normalized to the range [0, 1] to be compatible with `grid_sample`.\n\n3. **Grid Preparation**: A grid is prepared for sampling, reshaping the vertex positions to match the expected input for `grid_sample`.\n\n4. **Feature Sampling**: The `grid_sample` function is used to sample features from the feature map based on the vertex positions.\n\n5. **Output Reshaping**: The sampled features are reshaped to the desired output shape, and the `return_packed` option is handled by flattening the output if necessary.\n\n6. **Return**: The function returns the sampled features, either in the original shape or packed, based on the `return_packed` flag.",
    "prompt": "Create a Python function vert_align that performs \"vertex alignment\" or \"perceptual feature pooling,\" which samples vertex features from a feature map based on vertex positions. The function takes the following parameters:\n\nfeats: A tensor of shape (N, C, H, W) representing image features from which to sample, or a list of such tensors, each with potentially different C, H, or W dimensions.\nverts: A tensor of shape (N, V, 3) representing the (x, y, z) vertex positions, or an object with verts_padded or points_padded attributes. The (x, y) coordinates should be normalized such that (-1, -1) corresponds to the top-left and (1, 1) to the bottom-right of the feature map.\nreturn_packed: A boolean flag indicating whether to return packed features. Defaults to False.\ninterp_mode: A string specifying the interpolation mode ('bilinear' or 'nearest'). Defaults to 'bilinear'.\npadding_mode: A string specifying how to handle vertices outside the [-1, 1] range ('zeros', 'reflection', or 'border'). Defaults to 'zeros'.\nalign_corners: A boolean indicating whether to align corners geometrically. If True, extrema refer to the center points of corner pixels; if False, they refer to the corner points of the input's corner pixels. Defaults to True.\nReturns:\nfeats_sampled: A tensor of shape (N, V, C) giving sampled features for each vertex. If feats is a list, the function returns concatenated features in shape (N, V, sum(C_n)) where C_n = feats[n].shape[1]. If return_packed = True, the features are transformed to a packed representation of shape (sum(V), C).\nError Handling:\nRaise a ValueError if verts does not have the expected shape or attributes.\nRaise a ValueError if feats does not have the expected shape (N, C, H, W) or if the batch dimensions of feats and verts do not match.",
    "function_name": "vert_align",
    "ground_truth": "pytorch3d/ops/vert_align.py",
    "test": "tests/test_vert_align.py",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "",
    "data": "Image"
}