{
    "result": "To create the `look_at_rotation` function, we will follow a step-by-step approach similar to the examples provided. This function will compute a rotation matrix that transforms world coordinates to view coordinates based on the camera's position, the point it is looking at, and the up direction. Here's how you can implement it:\n\n```python\nimport torch\nfrom typing import Union, Tuple, List\n\ndef look_at_rotation(\n    camera_position: Union[Tuple[float, float, float], List[float], torch.Tensor],\n    at: Union[Tuple[float, float, float], List[float], torch.Tensor],\n    up: Union[Tuple[float, float, float], List[float], torch.Tensor],\n    device: torch.device = torch.device('cpu')\n) -> torch.Tensor:\n    \"\"\"\n    Computes a batched rotation matrix for transforming world coordinates to view coordinates.\n\n    Args:\n        camera_position: The position of the camera in world coordinates.\n        at: The point the camera is looking at.\n        up: The up direction for the camera.\n        device: The device on which to perform computations (e.g., 'cpu' or 'cuda').\n\n    Returns:\n        A batched rotation matrix R of shape (N, 3, 3).\n    \"\"\"\n    # 1. Convert inputs to torch tensors if they are not already\n    camera_position = torch.tensor(camera_position, dtype=torch.float32, device=device)\n    at = torch.tensor(at, dtype=torch.float32, device=device)\n    up = torch.tensor(up, dtype=torch.float32, device=device)\n\n    # 2. Ensure inputs are batched (N, 3)\n    if camera_position.ndim == 1:\n        camera_position = camera_position.unsqueeze(0)\n    if at.ndim == 1:\n        at = at.unsqueeze(0)\n    if up.ndim == 1:\n        up = up.unsqueeze(0)\n\n    # 3. Calculate the z-axis (view direction) and normalize\n    z_axis = at - camera_position\n    z_axis = z_axis / torch.norm(z_axis, dim=1, keepdim=True)\n\n    # 4. Calculate the x-axis (right direction) using cross product and normalize\n    x_axis = torch.cross(up, z_axis, dim=1)\n    x_axis_norm = torch.norm(x_axis, dim=1, keepdim=True)\n    # Handle cases where x-axis is close to zero\n    x_axis = torch.where(x_axis_norm < 1e-6, torch.tensor([1.0, 0.0, 0.0], device=device), x_axis)\n    x_axis = x_axis / torch.norm(x_axis, dim=1, keepdim=True)\n\n    # 5. Calculate the y-axis (up direction) using cross product and normalize\n    y_axis = torch.cross(z_axis, x_axis, dim=1)\n    y_axis = y_axis / torch.norm(y_axis, dim=1, keepdim=True)\n\n    # 6. Concatenate the axes to form the rotation matrix\n    R = torch.stack((x_axis, y_axis, z_axis), dim=-1)\n\n    # 7. Return the transposed rotation matrix\n    return R.transpose(1, 2)\n\n```\n\n### Explanation:\n\n1. **Input Handling**: The function accepts inputs as tuples, lists, or tensors. It converts them to tensors and ensures they are batched (i.e., have a shape of (N, 3)).\n\n2. **Axis Calculation**:\n   - **Z-axis**: Calculated as the normalized vector from the camera position to the point it is looking at.\n   - **X-axis**: Calculated using the cross product of the up vector and the z-axis. It is normalized and checked for near-zero values to avoid numerical instability.\n   - **Y-axis**: Calculated using the cross product of the z-axis and x-axis, ensuring orthogonality.\n\n3. **Matrix Construction**: The x, y, and z axes are concatenated to form the rotation matrix, which is then transposed to match the expected output format.\n\nThis function provides a robust way to compute the view transformation matrix for a camera in 3D space.",
    "prompt": "Generate a Python function called look_at_rotation that takes in the camera_position, at, up vectors, and device type as inputs. The function returns a batched rotation matrix R representing the transformation from world coordinates to view coordinates. The camera_position, at, and up vectors can be 3-element tuples/lists or torch tensors of shape (1, 3) or (N, 3), where N is the batch size. The function normalizes the input vectors, calculates the x, y, and z axes, and handles cases where the x-axis is close to zero. Finally, it concatenates the axes to form the rotation matrix R and returns the transposed matrix.",
    "function_name": "look_at_rotation",
    "ground_truth": "pytorch3d/renderer/cameras.py",
    "test": "tests/test_cameras.py",
    "class": "",
    "stage": "Model Construction",
    "task": "Detection",
    "data": "Image"
}