{
    "result": "To create a function `random_text_classification_dataset` that generates a random text classification dataset, we can follow a structured approach similar to the examples provided. This function will generate random text data and corresponding labels, considering various parameters like the number of samples, maximum text length, number of classes, and more. Here's a step-by-step implementation:\n\n```python\nimport torch\nfrom torch.utils.data import Dataset\nimport random\nimport string\nfrom typing import List, Optional, Union\n\nclass PytorchTextClassificationDataset(Dataset):\n    def __init__(self, data, labels, vocab, multi_label, target_labels):\n        self.data = data\n        self.labels = labels\n        self.vocab = vocab\n        self.multi_label = multi_label\n        self.target_labels = target_labels\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx], self.labels[idx]\n\ndef random_text_classification_dataset(\n    num_samples: int,\n    max_length: int,\n    num_classes: int,\n    multi_label: bool = False,\n    vocab_size: int = 1000,\n    device: Optional[torch.device] = None,\n    target_labels: Optional[List[str]] = None,\n    dtype: torch.dtype = torch.long\n) -> PytorchTextClassificationDataset:\n    \"\"\"\n    Generate a random text classification dataset.\n\n    Args:\n        num_samples (int): Number of samples in the dataset.\n        max_length (int): Maximum length of each text sample.\n        num_classes (int): Number of classes for classification.\n        multi_label (bool): If True, each sample can have multiple labels.\n        vocab_size (int): Size of the vocabulary.\n        device (torch.device, optional): Device to store the dataset.\n        target_labels (List[str], optional): List of target labels.\n        dtype (torch.dtype): Data type for the labels.\n\n    Returns:\n        PytorchTextClassificationDataset: The generated dataset.\n    \"\"\"\n    # 1. Generate a random vocabulary\n    vocab = [''.join(random.choices(string.ascii_lowercase, k=5)) for _ in range(vocab_size)]\n\n    # 2. Generate random text samples\n    data = []\n    for _ in range(num_samples):\n        length = random.randint(1, max_length)\n        sample = random.choices(vocab, k=length)\n        data.append(sample)\n\n    # 3. Generate random labels\n    labels = []\n    for _ in range(num_samples):\n        if multi_label:\n            # Each sample can have multiple labels\n            label = torch.zeros(num_classes, dtype=dtype)\n            num_labels = random.randint(1, num_classes)\n            label_indices = random.sample(range(num_classes), num_labels)\n            label[label_indices] = 1\n        else:\n            # Single label per sample\n            label = torch.tensor(random.randint(0, num_classes - 1), dtype=dtype)\n        labels.append(label)\n\n    # 4. Ensure all labels occur in the dataset\n    if not multi_label:\n        for i in range(num_classes):\n            if i not in labels:\n                labels[random.randint(0, num_samples - 1)] = torch.tensor(i, dtype=dtype)\n\n    # 5. Handle target labels\n    if target_labels is None:\n        target_labels = [f\"Class_{i}\" for i in range(num_classes)]\n\n    # 6. Convert data and labels to tensors\n    data_tensor = [torch.tensor([vocab.index(word) for word in sample], dtype=dtype) for sample in data]\n    labels_tensor = torch.stack(labels)\n\n    # 7. Create the dataset object\n    dataset = PytorchTextClassificationDataset(data_tensor, labels_tensor, vocab, multi_label, target_labels)\n\n    # 8. Move dataset to the specified device\n    if device is not None:\n        dataset.data = [d.to(device) for d in dataset.data]\n        dataset.labels = dataset.labels.to(device)\n\n    return dataset\n```\n\n### Explanation:\n1. **Vocabulary Generation**: A random vocabulary of specified size is created using lowercase letters.\n2. **Text Sample Generation**: Random text samples are generated using the vocabulary, with lengths up to `max_length`.\n3. **Label Generation**: Labels are generated based on whether the dataset is multi-label or single-label.\n4. **Label Coverage**: Ensures that all possible labels are present in the dataset.\n5. **Target Labels**: If not provided, default target labels are generated.\n6. **Tensor Conversion**: Converts data and labels to PyTorch tensors.\n7. **Dataset Creation**: A custom dataset class is used to store the data, labels, and other metadata.\n8. **Device Handling**: Moves data to the specified device if provided.\n\nThis function provides a flexible way to generate synthetic text classification datasets for testing and experimentation.",
    "prompt": "Generate a Python function called random_text_classification_dataset that generates a random text classification dataset. The function takes in parameters such as num_samples, max_length, num_classes, multi_label, vocab_size, device, target_labels, and dtype. It returns a PytorchTextClassificationDataset object with the generated dataset, vocabulary, multi_label setting, and target labels. The function ensures that all labels occur in the dataset and handles different scenarios based on the input parameters.",
    "function_name": "random_text_classification_dataset",
    "ground_truth": "tests/utils/datasets.py",
    "test": "tests/unit/small_text/initialization/test_strategies.py::RandomInitializationStratifiedTest",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "Classification",
    "data": "Text"
}