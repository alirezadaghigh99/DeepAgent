{
    "result": "To implement the `draw_segmentation_masks` function, we need to follow a structured approach similar to the examples provided. Here's a step-by-step implementation:\n\n```python\nimport torch\nimport numpy as np\nfrom typing import Optional, Union, List, Tuple\nimport warnings\n\ndef draw_segmentation_masks(\n    image: torch.Tensor,\n    masks: torch.Tensor,\n    alpha: float = 0.5,\n    colors: Optional[Union[List[Union[str, Tuple[int, int, int]]], str, Tuple[int, int, int]]] = None\n) -> torch.Tensor:\n    \"\"\"\n    Overlays segmentation masks onto an RGB image.\n\n    Args:\n        image (Tensor): Tensor of shape (3, H, W) representing the RGB image.\n        masks (Tensor): Tensor of shape (num_masks, H, W) or (H, W) with boolean values.\n        alpha (float): Transparency level of the masks, between 0 and 1.\n        colors (Optional): Colors for each mask or a single color for all masks.\n\n    Returns:\n        Tensor: Image tensor with masks applied, in the same dtype as the original image.\n    \"\"\"\n    # 1. Validate the image input\n    if not isinstance(image, torch.Tensor):\n        raise TypeError(\"The image must be a PyTorch tensor.\")\n    \n    if image.dtype not in [torch.uint8, torch.float32, torch.float64]:\n        raise ValueError(\"The image tensor's dtype must be uint8 or a floating point.\")\n    \n    if image.ndim != 3 or image.size(0) != 3:\n        raise ValueError(\"The image tensor must have 3 dimensions and be an RGB image (3 channels).\")\n\n    # 2. Validate the masks input\n    if masks.ndim not in [2, 3]:\n        raise ValueError(\"The masks tensor must have 2 or 3 dimensions.\")\n    \n    if masks.dtype != torch.bool:\n        raise ValueError(\"The masks tensor must be of boolean dtype.\")\n    \n    if masks.ndim == 2:\n        masks = masks.unsqueeze(0)  # Convert to (1, H, W) for consistency\n\n    if masks.shape[1:] != image.shape[1:]:\n        raise ValueError(\"The masks tensor's spatial dimensions must match the image tensor.\")\n\n    # 3. Parse colors\n    num_masks = masks.shape[0]\n    colors = _parse_colors(colors, num_objects=num_masks)\n\n    # 4. Prepare the image for mask application\n    original_dtype = image.dtype\n    if original_dtype.is_floating_point:\n        image = (image * 255).to(torch.uint8)\n\n    # 5. Apply each mask with the specified color and alpha\n    for i, mask in enumerate(masks):\n        color = colors[i]\n        color_tensor = torch.tensor(color, dtype=torch.uint8).view(3, 1, 1)\n        mask_rgb = color_tensor * mask.unsqueeze(0)\n        image = torch.where(mask.unsqueeze(0), (1 - alpha) * image + alpha * mask_rgb, image)\n\n    # 6. Convert back to the original dtype if necessary\n    if original_dtype.is_floating_point:\n        image = image.to(original_dtype) / 255\n\n    return image\n\ndef _parse_colors(colors, num_objects):\n    \"\"\"\n    Helper function to parse and generate colors for the masks.\n    \"\"\"\n    if colors is None:\n        # Generate random colors\n        colors = [tuple(np.random.randint(0, 256, size=3)) for _ in range(num_objects)]\n    elif isinstance(colors, (str, tuple)):\n        # Single color for all masks\n        colors = [colors] * num_objects\n    elif isinstance(colors, list):\n        if len(colors) != num_objects:\n            raise ValueError(\"The number of colors must match the number of masks.\")\n    else:\n        raise TypeError(\"Colors must be a list, a single color, or None.\")\n\n    return colors\n```\n\n### Explanation:\n\n1. **Input Validation**: We first check that the `image` is a PyTorch tensor with the correct dtype and dimensions. Similarly, we validate the `masks` tensor to ensure it has the correct shape and dtype.\n\n2. **Color Parsing**: The `_parse_colors` helper function ensures that we have a list of colors matching the number of masks. If no colors are provided, random colors are generated.\n\n3. **Mask Application**: We iterate over each mask, apply the color with the specified transparency (`alpha`), and blend it with the original image.\n\n4. **Output**: The resulting image is returned in the same dtype as the input image, ensuring consistency.\n\nThis implementation handles the overlay of segmentation masks on an RGB image, with proper error handling and flexibility in color specification.",
    "prompt": "Implement a function named `draw_segmentation_masks` that overlays segmentation masks onto an RGB image. The function takes the following inputs: `image`, a PyTorch tensor of shape (3, H, W) representing the RGB image; `masks`, a tensor of shape (num_masks, H, W) or (H, W) with boolean values indicating the mask regions; `alpha`, a float between 0 and 1 that controls the transparency of the masks; and `colors`, which can be a list of colors, a single color, or left as `None` to generate random colors.\n\nThe function raises the following errors to ensure input validity:\n- `TypeError` if the `image` is not a tensor.\n- `ValueError` if the `image` tensor's dtype is neither `uint8` nor a floating point.\n- `ValueError` if the `image` tensor does not have exactly 3 dimensions or if it is not an RGB image (3 channels).\n- `ValueError` if the `masks` tensor does not have 2 or 3 dimensions.\n- `ValueError` if the `masks` tensor is not of boolean dtype.\n- `ValueError` if the `masks` tensor's spatial dimensions do not match the `image` tensor.\n\nThe function handles the application of masks, including overlapping masks, and adjusts the transparency using the `alpha` parameter. The resulting image tensor, with the masks applied, is returned in the same dtype as the original image.",
    "function_name": "draw_segmentation_masks",
    "ground_truth": "torchvision/utils.py",
    "test": "test/test_utils.py::test_draw_segmentation_masks",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "Segmentation",
    "data": "Image"
}