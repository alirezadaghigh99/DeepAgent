{
    "result": "To create a function called `perspective` that performs a perspective transform on a given image, we can follow a step-by-step approach similar to the examples provided. This function will handle both PIL Images and PyTorch Tensors, and it will use the specified start and end points to compute the transformation matrix. Here's how you can implement it:\n\n```python\nimport torch\nfrom torchvision.transforms import InterpolationMode\nfrom torchvision.transforms.functional import perspective as F_perspective\nfrom PIL import Image\n\ndef perspective(img, startpoints, endpoints, interpolation=InterpolationMode.BILINEAR, fill=0):\n    \"\"\"\n    Perform a perspective transform of the given image.\n\n    Args:\n        img (PIL Image or Tensor): Image to be transformed.\n        startpoints (list of list of ints): List containing four lists of two integers corresponding to four corners\n            [top-left, top-right, bottom-right, bottom-left] of the original image.\n        endpoints (list of list of ints): List containing four lists of two integers corresponding to four corners\n            [top-left, top-right, bottom-right, bottom-left] of the transformed image.\n        interpolation (InterpolationMode): Desired interpolation enum defined by\n            torchvision.transforms.InterpolationMode. Default is InterpolationMode.BILINEAR.\n            If input is Tensor, only InterpolationMode.NEAREST, InterpolationMode.BILINEAR are supported.\n            The corresponding Pillow integer constants, e.g. PIL.Image.BILINEAR are accepted as well.\n        fill (sequence or number, optional): Pixel fill value for the area outside the transformed\n            image. If given a number, the value is used for all bands respectively.\n\n    Returns:\n        PIL Image or Tensor: Transformed Image.\n    \"\"\"\n    # 1. Check if the input image is a PIL Image or a Tensor\n    is_pil = isinstance(img, Image.Image)\n\n    # 2. If the image is a Tensor, ensure it has the correct shape\n    if not is_pil and not isinstance(img, torch.Tensor):\n        raise TypeError(\"img should be PIL Image or Tensor. Got {}\".format(type(img)))\n\n    # 3. Perform the perspective transformation using torchvision's functional API\n    transformed_img = F_perspective(img, startpoints, endpoints, interpolation=interpolation, fill=fill)\n\n    # 4. Return the transformed image\n    return transformed_img\n```\n\n### Explanation:\n\n1. **Input Type Check**: The function first checks if the input image is a PIL Image or a PyTorch Tensor. This ensures that the function can handle both types of inputs.\n\n2. **Shape Validation**: If the input is a Tensor, it should have the shape [..., H, W], where ... represents any number of leading dimensions.\n\n3. **Perspective Transformation**: The function uses `torchvision.transforms.functional.perspective` to perform the actual transformation. This function handles both PIL Images and Tensors, applying the specified interpolation and fill values.\n\n4. **Return**: The transformed image is returned, maintaining the same type (PIL Image or Tensor) as the input.\n\nThis implementation leverages the existing functionality in `torchvision` to handle the perspective transformation efficiently and correctly.",
    "prompt": "Generate a Python function called perspective that perform perspective transform of the given image.\n    If the image is torch Tensor, it is expected\n    to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions.\n\n    Args:\n        img (PIL Image or Tensor): Image to be transformed.\n        startpoints (list of list of ints): List containing four lists of two integers corresponding to four corners\n            ``[top-left, top-right, bottom-right, bottom-left]`` of the original image.\n        endpoints (list of list of ints): List containing four lists of two integers corresponding to four corners\n            ``[top-left, top-right, bottom-right, bottom-left]`` of the transformed image.\n        interpolation (InterpolationMode): Desired interpolation enum defined by\n            :class:`torchvision.transforms.InterpolationMode`. Default is ``InterpolationMode.BILINEAR``.\n            If input is Tensor, only ``InterpolationMode.NEAREST``, ``InterpolationMode.BILINEAR`` are supported.\n            The corresponding Pillow integer constants, e.g. ``PIL.Image.BILINEAR`` are accepted as well.\n        fill (sequence or number, optional): Pixel fill value for the area outside the transformed\n            image. If given a number, the value is used for all bands respectively.\n\n    Returns:\n        PIL Image or Tensor: transformed Image.",
    "function_name": "perspective",
    "ground_truth": "torchvision/transforms/functional.py",
    "test": "test/test_transforms.py::test_randomperspective_fill",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "",
    "data": "Image"
}