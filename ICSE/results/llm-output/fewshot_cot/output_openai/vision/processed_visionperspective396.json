{
    "result": "To create a function called `perspective` that performs a perspective transformation on an image, we can follow a structured approach similar to the examples you provided. Here's a step-by-step implementation:\n\n```python\nfrom typing import Union, Tuple, Optional\nfrom PIL import Image\nimport torch\nimport torchvision.transforms.functional as F\nimport numpy as np\n\ndef _get_perspective_coeffs(startpoints, endpoints):\n    \"\"\"\n    Calculate coefficients for a perspective transformation.\n    \"\"\"\n    matrix = []\n    for (x0, y0), (x1, y1) in zip(startpoints, endpoints):\n        matrix.append([x0, y0, 1, 0, 0, 0, -x1 * x0, -x1 * y0])\n        matrix.append([0, 0, 0, x0, y0, 1, -y1 * x0, -y1 * y0])\n\n    A = np.array(matrix, dtype=np.float32)\n    B = np.array(endpoints, dtype=np.float32).reshape(8)\n\n    res = np.linalg.solve(A, B)\n    return res.tolist()\n\ndef perspective(\n    image: Union[Image.Image, torch.Tensor],\n    startpoints: Tuple[Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int]],\n    endpoints: Tuple[Tuple[int, int], Tuple[int, int], Tuple[int, int], Tuple[int, int]],\n    interpolation: int = Image.BILINEAR,\n    fill: Optional[Union[int, Tuple[int, int, int]]] = None\n) -> Union[Image.Image, torch.Tensor]:\n    \"\"\"\n    Perform a perspective transformation on an image.\n\n    Args:\n        image (Union[Image.Image, torch.Tensor]): Input image.\n        startpoints (Tuple[Tuple[int, int], ...]): Four corner points of the original image.\n        endpoints (Tuple[Tuple[int, int], ...]): Four corner points of the transformed image.\n        interpolation (int): Interpolation method. Defaults to BILINEAR.\n        fill (Optional[Union[int, Tuple[int, int, int]]]): Fill color for areas outside the transformed image.\n\n    Returns:\n        Union[Image.Image, torch.Tensor]: Transformed image.\n    \"\"\"\n    # 1. Validate the number of points\n    if len(startpoints) != 4 or len(endpoints) != 4:\n        raise ValueError(\"startpoints and endpoints must both contain exactly four points.\")\n\n    # 2. Compute the perspective transformation coefficients\n    coeffs = _get_perspective_coeffs(startpoints, endpoints)\n\n    # 3. Handle PIL Image input\n    if isinstance(image, Image.Image):\n        return image.transform(\n            image.size, Image.PERSPECTIVE, coeffs, resample=interpolation, fillcolor=fill\n        )\n\n    # 4. Handle PyTorch Tensor input\n    elif isinstance(image, torch.Tensor):\n        # Convert tensor to PIL Image\n        pil_image = F.to_pil_image(image)\n        transformed_image = pil_image.transform(\n            pil_image.size, Image.PERSPECTIVE, coeffs, resample=interpolation, fillcolor=fill\n        )\n        # Convert back to tensor\n        return F.to_tensor(transformed_image)\n\n    else:\n        raise TypeError(\"Input image must be a PIL Image or a PyTorch Tensor.\")\n\n```\n\n### Explanation:\n\n1. **Validation**: The function first checks that exactly four corner points are provided for both `startpoints` and `endpoints`. If not, it raises a `ValueError`.\n\n2. **Coefficient Calculation**: The `_get_perspective_coeffs` helper function calculates the coefficients needed for the perspective transformation using linear algebra.\n\n3. **Image Transformation**:\n   - If the input is a PIL Image, it uses the `transform` method with the calculated coefficients.\n   - If the input is a PyTorch Tensor, it first converts it to a PIL Image, applies the transformation, and then converts it back to a Tensor.\n\n4. **Error Handling**: The function raises a `TypeError` if the input image is neither a PIL Image nor a PyTorch Tensor.\n\nThis implementation provides a flexible and robust way to perform perspective transformations on images, handling both PIL Images and PyTorch Tensors.",
    "prompt": "Generate a Python function called perspective that performs a perspective transformation on an image. The function should accept an image input, which can be either a PIL Image or a PyTorch Tensor, along with startpoints and endpoints, each consisting of four coordinate pairs representing the corners of the original and transformed images, respectively. It should include an interpolation parameter to specify how pixel values are calculated during the transformation, defaulting to BILINEAR. Additionally, an optional fill parameter should be provided to determine the pixel values for areas outside the transformed image. The function should handle errors gracefully, such as ensuring exactly four corner points are provided for both startpoints and endpoints, and raise appropriate exceptions for invalid inputs. The function should utilize underlying helper functions like _get_perspective_coeffs to compute the necessary transformation coefficients and apply the transformation using appropriate methods based on the input type, returning the transformed image as a PIL Image or Tensor.",
    "function_name": "perspective",
    "ground_truth": "torchvision/transforms/functional.py",
    "test": "test/test_transforms.py::test_randomperspective_fill",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "",
    "data": "image"
}