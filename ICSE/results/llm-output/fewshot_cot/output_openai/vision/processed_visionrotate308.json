{
    "result": "To implement the `rotate` function that rotates an image by a specified angle, we can follow a step-by-step approach similar to the examples provided. This function will handle both PIL Images and PyTorch Tensors, and it will include options for interpolation, expansion, center of rotation, and fill value. Here's how you can implement it:\n\n```python\nfrom typing import Optional, Union, Sequence\nimport torch\nfrom torchvision.transforms import InterpolationMode\nfrom PIL import Image\n\ndef rotate(\n    img: Union[Image.Image, torch.Tensor],\n    angle: float,\n    interpolation: InterpolationMode = InterpolationMode.NEAREST,\n    expand: bool = False,\n    center: Optional[Sequence[float]] = None,\n    fill: Optional[Union[float, Sequence[float]]] = None\n) -> Union[Image.Image, torch.Tensor]:\n    \"\"\"\n    Rotate the image by angle.\n\n    Args:\n        img (PIL Image or Tensor): Image to be rotated.\n        angle (float): Rotation angle value in degrees, counter-clockwise.\n        interpolation (InterpolationMode): Desired interpolation mode.\n        expand (bool, optional): If true, expands the output image to hold the entire rotated image.\n        center (sequence, optional): Center of rotation. Default is the center of the image.\n        fill (sequence or number, optional): Pixel fill value for the area outside the transformed image.\n\n    Returns:\n        PIL Image or Tensor: Rotated image.\n    \"\"\"\n    # 1. Check if the input is a PIL Image or a Tensor\n    if isinstance(img, Image.Image):\n        # 2. Use PIL's rotate method for PIL Images\n        return img.rotate(angle, resample=interpolation.value, expand=expand, center=center, fillcolor=fill)\n    elif isinstance(img, torch.Tensor):\n        # 3. Handle Tensor input\n        import torchvision.transforms.functional as F\n\n        # 4. Validate interpolation mode for Tensors\n        if interpolation not in [InterpolationMode.NEAREST, InterpolationMode.BILINEAR]:\n            raise ValueError(\"For Tensor inputs, only NEAREST and BILINEAR interpolation modes are supported.\")\n\n        # 5. Rotate the Tensor using torchvision's functional API\n        return F.rotate(img, angle, interpolation=interpolation, expand=expand, center=center, fill=fill)\n    else:\n        raise TypeError(\"img should be either a PIL Image or a torch Tensor\")\n\n# Example usage:\n# rotated_img = rotate(pil_image, 45, interpolation=InterpolationMode.BILINEAR, expand=True)\n# rotated_tensor = rotate(tensor_image, 45, interpolation=InterpolationMode.BILINEAR, expand=True)\n```\n\n### Explanation:\n\n1. **Input Type Check**: The function first checks if the input image is a PIL Image or a PyTorch Tensor.\n\n2. **PIL Image Handling**: If the input is a PIL Image, it uses the `rotate` method from the PIL library, which directly supports rotation with various options like interpolation, expansion, center, and fill color.\n\n3. **Tensor Handling**: If the input is a PyTorch Tensor, it uses the `rotate` function from `torchvision.transforms.functional`, which supports rotation for Tensors. It also checks that the interpolation mode is either `NEAREST` or `BILINEAR`, as these are the only supported modes for Tensors.\n\n4. **Error Handling**: The function raises a `TypeError` if the input is neither a PIL Image nor a Tensor, ensuring that the function is used correctly.\n\nThis implementation provides a flexible and robust way to rotate images, accommodating both PIL Images and Tensors with various customization options.",
    "prompt": "Write a python function rotate that Rotate the image by angle.\n    If the image is torch Tensor, it is expected\n    to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions.\n\n    Args:\n        img (PIL Image or Tensor): image to be rotated.\n        angle (number): rotation angle value in degrees, counter-clockwise.\n        interpolation (InterpolationMode): Desired interpolation enum defined by\n            :class:`torchvision.transforms.InterpolationMode`. Default is ``InterpolationMode.NEAREST``.\n            If input is Tensor, only ``InterpolationMode.NEAREST``, ``InterpolationMode.BILINEAR`` are supported.\n            The corresponding Pillow integer constants, e.g. ``PIL.Image.BILINEAR`` are accepted as well.\n        expand (bool, optional): Optional expansion flag.\n            If true, expands the output image to make it large enough to hold the entire rotated image.\n            If false or omitted, make the output image the same size as the input image.\n            Note that the expand flag assumes rotation around the center and no translation.\n        center (sequence, optional): Optional center of rotation. Origin is the upper left corner.\n            Default is the center of the image.\n        fill (sequence or number, optional): Pixel fill value for the area outside the transformed\n            image. If given a number, the value is used for all bands respectively. Returns:\n        PIL Image or Tensor: Rotated image.\n\n    if not torch.jit.is_scripting() and not torch.jit.is_tracing():\n        _log_api_usage_once(rotate)\n\n    if isinstance(interpolation, int):\n        interpolation = _interpolation_modes_from_int(interpolation)\n    elif not isinstance(interpolation, InterpolationMode):\n        raise TypeError(\n            \"Argument interpolation should be a InterpolationMode or a corresponding Pillow integer constant\"\n        )\n\n    if not isinstance(angle, (int, float)):\n        raise TypeError(\"Argument angle should be int or float\")\n\n    if center is not None and not isinstance(center, (list, tuple)):\n        raise TypeError(\"Argument center should be a sequence\")",
    "function_name": "rotate",
    "ground_truth": "torchvision/transforms/functional.py",
    "test": "test/test_functional_tensor.py::TestRotate::test_rotate",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "",
    "data": "Image"
}