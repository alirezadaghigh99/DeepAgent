{
    "result": "To create the `draw_bounding_boxes` function as described, we can follow a structured approach similar to the examples provided. Here's a step-by-step implementation:\n\n```python\nimport torch\nfrom typing import List, Optional, Union, Tuple\nfrom PIL import Image, ImageDraw, ImageFont\nimport warnings\nimport torchvision.transforms.functional as F\n\ndef _parse_colors(colors, num_objects):\n    if colors is None:\n        return [\"red\"] * num_objects\n    if isinstance(colors, (str, tuple)):\n        return [colors] * num_objects\n    if isinstance(colors, list):\n        if len(colors) != num_objects:\n            raise ValueError(\"Number of colors must match the number of objects.\")\n        return colors\n    raise TypeError(\"Colors must be a string, tuple, or list of these.\")\n\ndef draw_bounding_boxes(\n    image: torch.Tensor,\n    boxes: torch.Tensor,\n    labels: Optional[List[str]] = None,\n    colors: Optional[Union[List[Union[str, Tuple[int, int, int]]], str, Tuple[int, int, int]]] = None,\n    fill: Optional[bool] = False,\n    width: int = 1,\n    font: Optional[str] = None,\n    font_size: Optional[int] = None,\n) -> torch.Tensor:\n    \"\"\"\n    Draws bounding boxes on a given RGB or grayscale image.\n\n    Args:\n        image (Tensor): Tensor of shape (C, H, W) and dtype uint8 or float.\n        boxes (Tensor): Tensor of size (N, 4) containing bounding boxes in (xmin, ymin, xmax, ymax) format.\n        labels (List[str], optional): Labels for the bounding boxes. Defaults to None.\n        colors (Union[List[Union[str, Tuple[int, int, int]]], str, Tuple[int, int, int]], optional):\n            Colors for each bounding box or a single color for all boxes.\n        fill (bool): Whether to fill the bounding boxes.\n        width (int): Width of the bounding box outline.\n        font (str, optional): Path to a TrueType font. Defaults to None.\n        font_size (int, optional): Font size for labels. Defaults to None.\n\n    Returns:\n        img (Tensor[C, H, W]): Image tensor (dtype=uint8) with bounding boxes drawn.\n    \"\"\"\n    # Error handling\n    if not isinstance(image, torch.Tensor):\n        raise TypeError(\"Image must be a tensor.\")\n    if image.dtype not in [torch.uint8, torch.float32, torch.float64]:\n        raise ValueError(\"Image dtype must be uint8 or float.\")\n    if image.dim() != 3 or image.size(0) not in [1, 3]:\n        raise ValueError(\"Image must have shape (C, H, W) with C=1 or 3.\")\n    if boxes.size(1) != 4:\n        raise ValueError(\"Boxes must have shape (N, 4).\")\n\n    num_boxes = boxes.shape[0]\n    if num_boxes == 0:\n        warnings.warn(\"No bounding boxes provided.\")\n        return image\n\n    if labels is None:\n        labels = [None] * num_boxes\n    elif len(labels) != num_boxes:\n        warnings.warn(\"Number of labels does not match number of boxes.\")\n        labels = [None] * num_boxes\n\n    colors = _parse_colors(colors, num_objects=num_boxes)\n\n    if font is None:\n        if font_size is not None:\n            warnings.warn(\"Argument 'font_size' will be ignored since 'font' is not set.\")\n        txt_font = ImageFont.load_default()\n    else:\n        txt_font = ImageFont.truetype(font=font, size=font_size or 10)\n\n    if image.size(0) == 1:\n        image = torch.tile(image, (3, 1, 1))\n\n    original_dtype = image.dtype\n    if original_dtype.is_floating_point:\n        image = F.to_pil_image(image.mul(255).byte())\n    else:\n        image = F.to_pil_image(image)\n\n    img_boxes = boxes.to(torch.int64).tolist()\n\n    if fill:\n        draw = ImageDraw.Draw(image, \"RGBA\")\n    else:\n        draw = ImageDraw.Draw(image)\n\n    for bbox, color, label in zip(img_boxes, colors, labels):\n        if fill:\n            fill_color = color + (100,)\n            draw.rectangle(bbox, width=width, outline=color, fill=fill_color)\n        else:\n            draw.rectangle(bbox, width=width, outline=color)\n\n        if label is not None:\n            margin = width + 1\n            draw.text((bbox[0] + margin, bbox[1] + margin), label, fill=color, font=txt_font)\n\n    out = F.to_tensor(image)\n    if original_dtype.is_floating_point:\n        out = out.float().div(255)\n\n    return out\n```\n\n### Key Points:\n- **Error Handling**: The function checks for the correct type and shape of the input image and bounding boxes, raising appropriate errors or warnings.\n- **Color Parsing**: A helper function `_parse_colors` ensures that the color input is correctly formatted and matches the number of bounding boxes.\n- **Image Conversion**: The function handles both RGB and grayscale images, converting them to a format suitable for drawing operations.\n- **Drawing**: Uses PIL to draw rectangles and text on the image, with options for filled boxes and custom fonts.\n- **Output**: Returns the modified image as a PyTorch tensor, maintaining the original data type.",
    "prompt": "Create a Python function `draw_bounding_boxes` that draws bounding boxes on a given RGB or grayscale image represented as a PyTorch tensor. The function should accept an image tensor (`image`) of shape `(C, H, W)` and dtype `uint8` or float, a tensor of bounding boxes (`boxes`) in `(xmin, ymin, xmax, ymax)` format, and optional parameters such as labels, colors, fill option, box width, font, and font size. The function should return the image tensor with the bounding boxes drawn on it.\n\n### Error Handling:\n- Raise a `TypeError` if the input `image` is not a tensor.\n- Raise a `ValueError` if the image dtype is not `uint8` or float, if the image dimensions are incorrect, or if the bounding boxes are not in the correct format.\n- Warn if no bounding boxes are provided or if the number of labels does not match the number of boxes.\n\nThe function should support options like filling the bounding boxes with a color, specifying the width of the bounding box edges, and adding labels with custom fonts. The output should be a tensor with the bounding boxes applied, suitable for further processing or visualization.",
    "function_name": "draw_bounding_boxes",
    "ground_truth": "torchvision/utils.py",
    "test": "test/test_utils.py",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "Segmentation",
    "data": "Image"
}