{
    "result": "To implement the `_clamp_bounding_boxes` function, we need to follow a series of steps to ensure that the bounding boxes are clamped within the given canvas size. Here's a step-by-step implementation:\n\n```python\nimport torch\nfrom enum import Enum\n\nclass BoundingBoxFormat(Enum):\n    XYXY = \"xyxy\"\n    XYWH = \"xywh\"\n    CXCYWH = \"cxcywh\"\n\ndef _convert_to_xyxy(bounding_boxes, format):\n    if format == BoundingBoxFormat.XYXY:\n        return bounding_boxes\n    elif format == BoundingBoxFormat.XYWH:\n        x, y, w, h = bounding_boxes.unbind(-1)\n        return torch.stack((x, y, x + w, y + h), dim=-1)\n    elif format == BoundingBoxFormat.CXCYWH:\n        cx, cy, w, h = bounding_boxes.unbind(-1)\n        return torch.stack((cx - w / 2, cy - h / 2, cx + w / 2, cy + h / 2), dim=-1)\n    else:\n        raise ValueError(f\"Unsupported format: {format}\")\n\ndef _convert_from_xyxy(bounding_boxes, format):\n    if format == BoundingBoxFormat.XYXY:\n        return bounding_boxes\n    elif format == BoundingBoxFormat.XYWH:\n        x1, y1, x2, y2 = bounding_boxes.unbind(-1)\n        return torch.stack((x1, y1, x2 - x1, y2 - y1), dim=-1)\n    elif format == BoundingBoxFormat.CXCYWH:\n        x1, y1, x2, y2 = bounding_boxes.unbind(-1)\n        return torch.stack(((x1 + x2) / 2, (y1 + y2) / 2, x2 - x1, y2 - y1), dim=-1)\n    else:\n        raise ValueError(f\"Unsupported format: {format}\")\n\ndef _clamp_bounding_boxes(bounding_boxes, format, canvas_size):\n    \"\"\"\n    Adjusts bounding boxes to fit within a given canvas size.\n\n    Args:\n        bounding_boxes (Tensor): Tensor of bounding boxes.\n        format (BoundingBoxFormat): Format of the bounding boxes.\n        canvas_size (Tuple[int, int]): Size of the canvas as (height, width).\n\n    Returns:\n        Tensor: Clamped bounding boxes in the original format.\n    \"\"\"\n    # 1. Convert bounding boxes to XYXY format for clamping\n    boxes_xyxy = _convert_to_xyxy(bounding_boxes, format)\n\n    # 2. Clamp the coordinates to fit within the canvas size\n    height, width = canvas_size\n    x1, y1, x2, y2 = boxes_xyxy.unbind(-1)\n    x1 = x1.clamp(min=0, max=width)\n    y1 = y1.clamp(min=0, max=height)\n    x2 = x2.clamp(min=0, max=width)\n    y2 = y2.clamp(min=0, max=height)\n    clamped_boxes_xyxy = torch.stack((x1, y1, x2, y2), dim=-1)\n\n    # 3. Convert the clamped boxes back to the original format\n    clamped_boxes = _convert_from_xyxy(clamped_boxes_xyxy, format)\n\n    # 4. Return the clamped bounding boxes\n    return clamped_boxes\n```\n\n### Explanation:\n\n1. **Conversion Functions**: We define helper functions `_convert_to_xyxy` and `_convert_from_xyxy` to convert bounding boxes between different formats. This allows us to perform clamping in a consistent `XYXY` format.\n\n2. **Clamping**: The function `_clamp_bounding_boxes` first converts the bounding boxes to the `XYXY` format. It then clamps the coordinates to ensure they fit within the canvas size. The clamping is done using the `clamp` method, which restricts values to a specified range.\n\n3. **Return to Original Format**: After clamping, the bounding boxes are converted back to their original format before being returned.\n\nThis implementation ensures that the bounding boxes are adjusted to fit within the specified canvas size while maintaining their original format and data type.",
    "prompt": "Implement a function named `_clamp_bounding_boxes` that adjusts bounding boxes to fit within a given canvas size. The function takes three inputs: `bounding_boxes`, a PyTorch tensor representing the bounding boxes; `format`, an enum of type `BoundingBoxFormat`, which can be one of the following: `XYXY`, `XYWH`, or `CXCYWH`; and `canvas_size`, a tuple representing the height and width of the canvas. The function ensures that the bounding boxes do not exceed the canvas boundaries by clamping their coordinates. It first converts the bounding boxes to the `XYXY` format for clamping, then converts them back to their original format before returning them as a PyTorch tensor in the same data type as the input.",
    "function_name": "_clamp_bounding_boxes",
    "ground_truth": "torchvision/transforms/v2/functional/_meta.py",
    "test": "test/test_transforms_v2.py::TestResize::test_bounding_boxes_correctness",
    "class": "",
    "stage": "Inference",
    "task": "",
    "data": "Image"
}