{
    "result": "To create a function `pairwise_distances_chunked` that computes a distance matrix in chunks and optionally applies a reduction function, we can follow a structured approach similar to the examples you provided. Here's a step-by-step implementation:\n\n```python\nimport numpy as np\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn.utils import gen_batches\nfrom typing import Callable, Optional, Any, Tuple, Iterator\n\ndef pairwise_distances_chunked(\n    X: np.ndarray,\n    Y: Optional[np.ndarray] = None,\n    reduce_func: Optional[Callable[[np.ndarray, Tuple[int, int]], Any]] = None,\n    metric: str = 'euclidean',\n    n_jobs: int = 1,\n    working_memory: int = 1024,\n    **kwds\n) -> Iterator:\n    \"\"\"\n    Compute pairwise distances in chunks and optionally apply a reduction function.\n\n    Parameters:\n    - X: np.ndarray\n        An array of shape (n_samples_X, n_features).\n    - Y: np.ndarray, optional\n        An array of shape (n_samples_Y, n_features). If None, Y is assumed to be equal to X.\n    - reduce_func: callable, optional\n        A function to apply to each chunk of the distance matrix.\n    - metric: str, default='euclidean'\n        The distance metric to use.\n    - n_jobs: int, default=1\n        The number of jobs to use for the computation.\n    - working_memory: int, default=1024\n        The amount of memory (in MB) to use for computing the distance matrix.\n    - **kwds: additional keyword arguments\n        Additional arguments to pass to the distance function.\n\n    Yields:\n    - A contiguous slice of the distance matrix, optionally processed by reduce_func.\n    \"\"\"\n    # 1. Determine the number of samples in X and Y\n    n_samples_X = X.shape[0]\n    n_samples_Y = Y.shape[0] if Y is not None else n_samples_X\n\n    # 2. Calculate the size of each chunk based on working_memory\n    chunk_size = int(working_memory * (1024 ** 2) / (n_samples_Y * X.itemsize))\n\n    # 3. Generate batches for processing\n    for chunk_start, chunk_stop in gen_batches(n_samples_X, chunk_size):\n        # 4. Compute the pairwise distances for the current chunk\n        distances = pairwise_distances(X[chunk_start:chunk_stop], Y, metric=metric, n_jobs=n_jobs, **kwds)\n\n        # 5. If a reduction function is provided, apply it to the current chunk\n        if reduce_func is not None:\n            yield reduce_func(distances, (chunk_start, chunk_stop))\n        else:\n            yield distances\n\n# Example usage without reduce_func\nX = np.random.random((1000, 5))\nfor chunk in pairwise_distances_chunked(X, working_memory=1):\n    print(chunk.shape)\n\n# Example usage with reduce_func\ndef reduce_func(dist_chunk, slice_range):\n    # Example: Find indices of neighbors within a radius of 0.5\n    neighbors = [np.where(row < 0.5)[0] for row in dist_chunk]\n    return neighbors\n\nfor neighbors in pairwise_distances_chunked(X, reduce_func=reduce_func, working_memory=1):\n    print(neighbors)\n```\n\n### Explanation:\n\n1. **Parameters**: The function takes in arrays `X` and `Y`, a `reduce_func` for optional processing, a `metric` for distance calculation, `n_jobs` for parallel computation, and `working_memory` to determine chunk size.\n\n2. **Chunk Size Calculation**: The chunk size is determined based on the available working memory and the size of the data.\n\n3. **Batch Generation**: The function uses `gen_batches` to create chunks of data to process.\n\n4. **Distance Calculation**: For each chunk, it calculates the pairwise distances using `pairwise_distances`.\n\n5. **Reduction Function**: If a `reduce_func` is provided, it processes each chunk before yielding.\n\n6. **Yielding Results**: The function yields either the raw distance matrix chunks or the processed results from `reduce_func`.\n\nThis implementation allows for efficient computation of large distance matrices by processing them in manageable chunks, with optional custom processing for each chunk.",
    "prompt": "Generate a Python function called pairwise_distances_chunked that generates a distance matrix chunk by chunk with optional reduction. The function takes in parameters X, Y, reduce_func, metric, n_jobs, working_memory, and additional keyword parameters. It calculates pairwise distances in working_memory-sized chunks and applies reduce_func on each chunk if provided. The function yields a contiguous slice of the distance matrix, optionally processed by reduce_func. The function also includes examples of usage without reduce_func and with reduce_func for retrieving neighbors and average distance within a radius.",
    "function_name": "pairwise_distances_chunked",
    "ground_truth": "sklearn/metrics/pairwise.py",
    "test": "sklearn/metrics/tests/test_pairwise.py::test_pairwise_distances_chunked_reduce_valid",
    "class": "",
    "stage": "Model Construction",
    "task": "",
    "data": "Table"
}