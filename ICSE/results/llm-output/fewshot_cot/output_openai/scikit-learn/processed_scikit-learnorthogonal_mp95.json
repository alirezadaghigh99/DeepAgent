{
    "result": "To implement the Orthogonal Matching Pursuit (OMP) algorithm in Python, we can follow a structured approach similar to the examples you provided. Here's a step-by-step implementation of the `orthogonal_mp` function:\n\n```python\nimport numpy as np\nfrom sklearn.utils import check_array\nfrom sklearn.utils.extmath import safe_sparse_dot\nfrom sklearn.linear_model import orthogonal_mp_gram\n\ndef orthogonal_mp(X, y, n_nonzero_coefs=None, tol=None, precompute='auto', copy_X=True, return_path=False, return_n_iter=False):\n    \"\"\"\n    Orthogonal Matching Pursuit (OMP) algorithm.\n\n    Parameters:\n    - X: array-like of shape (n_samples, n_features)\n    - y: ndarray of shape (n_samples,) or (n_samples, n_targets)\n    - n_nonzero_coefs: int, optional\n        Desired number of non-zero entries in the solution.\n    - tol: float, optional\n        Maximum norm of the residual.\n    - precompute: 'auto', bool or array-like, default='auto'\n        Whether to precompute Gram matrix.\n    - copy_X: bool, default=True\n        Whether to copy X.\n    - return_path: bool, default=False\n        Whether to return the entire path of solutions.\n    - return_n_iter: bool, default=False\n        Whether to return the number of iterations.\n\n    Returns:\n    - coef: ndarray of shape (n_features,) or (n_features, n_targets)\n    - n_iters: int, optional\n        Number of active features across every target.\n    \"\"\"\n    # 1. Validate input data\n    X = check_array(X, copy=copy_X)\n    y = check_array(y, ensure_2d=False)\n\n    # 2. Determine the number of targets\n    if y.ndim == 1:\n        y = y[:, np.newaxis]\n    n_targets = y.shape[1]\n\n    # 3. Initialize variables\n    n_samples, n_features = X.shape\n    coef = np.zeros((n_features, n_targets), dtype=X.dtype)\n    n_iters = []\n\n    # 4. Precompute Gram matrix if needed\n    if precompute is True or (precompute == 'auto' and n_samples > n_features):\n        Gram = safe_sparse_dot(X.T, X)\n        Xy = safe_sparse_dot(X.T, y)\n    else:\n        Gram = None\n        Xy = None\n\n    # 5. Solve OMP for each target\n    for k in range(n_targets):\n        if Gram is not None:\n            coef[:, k], n_iter = orthogonal_mp_gram(Gram, Xy[:, k], n_nonzero_coefs=n_nonzero_coefs, tol=tol, return_path=return_path)\n        else:\n            coef[:, k], n_iter = orthogonal_mp_gram(X, y[:, k], n_nonzero_coefs=n_nonzero_coefs, tol=tol, return_path=return_path)\n\n        if return_n_iter:\n            n_iters.append(n_iter)\n\n    # 6. Return results\n    if return_n_iter:\n        return coef, n_iters\n    return coef\n\n# Example usage\nif __name__ == \"__main__\":\n    # Sample data\n    X = np.random.randn(100, 50)\n    y = np.random.randn(100)\n\n    # Run OMP\n    coef = orthogonal_mp(X, y, n_nonzero_coefs=5)\n    print(\"Coefficients:\", coef)\n```\n\n### Explanation:\n\n1. **Input Validation**: We use `check_array` from `sklearn.utils` to ensure that the input data `X` and `y` are in the correct format.\n\n2. **Precomputation**: Depending on the `precompute` parameter, we may precompute the Gram matrix (`X.T @ X`) and the product `X.T @ y` to speed up the computation.\n\n3. **OMP Solution**: We solve the OMP problem for each target in `y`. If the Gram matrix is precomputed, we use it to solve the problem more efficiently.\n\n4. **Return Options**: The function can return the coefficients, the entire path of solutions, and the number of iterations, depending on the input parameters.\n\nThis implementation provides a basic structure for the OMP algorithm, and you can further optimize or extend it based on specific requirements or constraints.",
    "prompt": "Generate a Python function called orthogonal_mp that implements the Orthogonal Matching Pursuit (OMP) algorithm. The function takes in input parameters X (array-like of shape (n_samples, n_features)) and y (ndarray of shape (n_samples,) or (n_samples, n_targets)), along with optional parameters such as n_nonzero_coefs, tol, precompute, copy_X, return_path, and return_n_iter. \n\nThe function solves n_targets OMP problems by finding the coefficients of the OMP solution based on the input data X and targets y. The OMP problem is defined as finding the coefficients that minimize the residual error subject to constraints on the number of non-zero coefficients or the maximum squared norm of the residual.\n\nThe function returns the coefficients (coef) of the OMP solution as an ndarray of shape (n_features,) or (n_features, n_targets), along with the number of active features across every target (n_iters) if return_n_iter is set to True. Additionally, the function provides options to return the coefficient path and the number of iterations.\n\nThe OMP algorithm is based on the work by Mallat and Zhang in 1993 and Rubinstein, Zibulevsky, and Elad in 2008. The function includes examples demonstrating the usage of orthogonal_mp with sample data.",
    "function_name": "orthogonal_mp",
    "ground_truth": "sklearn/linear_model/_omp.py",
    "test": "sklearn/linear_model/tests/test_omp.py",
    "class": "",
    "stage": "Training",
    "task": "",
    "data": "Table"
}