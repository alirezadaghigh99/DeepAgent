{
    "result": "To implement the `brier_score_loss` function, we can follow a step-by-step approach similar to the examples provided. Here's how you might structure the function:\n\n```python\nimport numpy as np\nfrom sklearn.utils import check_consistent_length, column_or_1d\nfrom sklearn.utils.validation import _deprecate_positional_args\n\n@_deprecate_positional_args\ndef brier_score_loss(y_true, y_proba, *, sample_weight=None, pos_label=None):\n    \"\"\"\n    Compute the Brier score loss.\n\n    The Brier score measures the mean squared difference between predicted probabilities\n    and the actual binary outcomes. It is suitable for binary classification tasks.\n\n    Parameters:\n    - y_true: array-like of shape (n_samples,)\n        True binary labels.\n    - y_proba: array-like of shape (n_samples,)\n        Predicted probabilities of the positive class.\n    - sample_weight: array-like of shape (n_samples,), default=None\n        Sample weights.\n    - pos_label: int or str, default=None\n        The label of the positive class. If None, the positive class is inferred.\n\n    Returns:\n    - score: float\n        Brier score loss.\n    \"\"\"\n    # 1. Ensure y_true and y_proba have consistent lengths\n    check_consistent_length(y_true, y_proba, sample_weight)\n\n    # 2. Convert y_true to a 1D array\n    y_true = column_or_1d(y_true)\n\n    # 3. Determine the positive class label if not provided\n    if pos_label is None:\n        pos_label = 1\n\n    # 4. Check that y_true contains only binary labels\n    unique_labels = np.unique(y_true)\n    if len(unique_labels) > 2:\n        raise ValueError(\"y_true contains more than two unique labels.\")\n\n    # 5. Map y_true to binary values (0 and 1) based on pos_label\n    y_true_binary = np.array(y_true == pos_label, dtype=np.float64)\n\n    # 6. Check that y_proba values are within the [0, 1] range\n    if np.any((y_proba < 0) | (y_proba > 1)):\n        raise ValueError(\"y_proba values must be in the range [0, 1].\")\n\n    # 7. Compute the squared differences between y_true_binary and y_proba\n    squared_diff = (y_true_binary - y_proba) ** 2\n\n    # 8. Apply sample weights if provided\n    if sample_weight is not None:\n        score = np.average(squared_diff, weights=sample_weight)\n    else:\n        score = np.mean(squared_diff)\n\n    # 9. Return the Brier score loss\n    return score\n```\n\n### Explanation of Steps:\n\n1. **Input Consistency**: We first ensure that the lengths of `y_true`, `y_proba`, and `sample_weight` (if provided) are consistent.\n\n2. **1D Conversion**: Convert `y_true` to a 1D array for easier handling.\n\n3. **Positive Label Determination**: If `pos_label` is not provided, we default to 1. This is the label for which probabilities are predicted.\n\n4. **Binary Label Check**: Ensure that `y_true` contains only two unique labels, suitable for binary classification.\n\n5. **Binary Mapping**: Convert `y_true` to binary values (0 and 1) based on the `pos_label`.\n\n6. **Probability Range Check**: Ensure that all `y_proba` values are within the valid probability range [0, 1].\n\n7. **Squared Differences**: Calculate the squared differences between the true binary labels and the predicted probabilities.\n\n8. **Sample Weight Application**: If `sample_weight` is provided, compute a weighted average of the squared differences; otherwise, compute the mean.\n\n9. **Return Score**: Finally, return the computed Brier score loss.",
    "prompt": "The `brier_score_loss` function calculates the Brier score loss, which measures the mean squared difference between predicted probabilities and actual binary outcomes. The function supports binary classification and includes error handling for deprecated parameters, input type checking, and label consistency. Inputs include the true labels (`y_true`), predicted probabilities (`y_proba`), optional sample weights, and a parameter to define the positive class label (`pos_label`). The output is a float representing the Brier score loss. Errors are raised for incorrect input types, non-binary classification targets, and probability values outside the [0, 1] range.",
    "function_name": "brier_score_loss",
    "ground_truth": "sklearn/metrics/_classification.py",
    "test": "sklearn/metrics/tests/test_classification.py",
    "class": "",
    "stage": "Model Construction",
    "task": "Classification",
    "data": ""
}