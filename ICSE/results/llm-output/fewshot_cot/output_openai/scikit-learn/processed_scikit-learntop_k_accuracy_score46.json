{
    "result": "To create a function called `top_k_accuracy_score` that calculates the top-k accuracy classification score, we can follow a step-by-step approach similar to the examples you provided. Here's how you can implement this function:\n\n```python\nimport numpy as np\nfrom sklearn.utils import check_array, check_consistent_length\n\ndef top_k_accuracy_score(y_true, y_score, k=1, normalize=True, sample_weight=None, labels=None):\n    \"\"\"\n    Calculate the top-k accuracy classification score.\n\n    Parameters:\n    - y_true: array-like of shape (n_samples,) representing the true labels.\n    - y_score: array-like of shape (n_samples,) or (n_samples, n_classes) representing the target scores.\n    - k: int, number of most likely outcomes considered to find the correct label.\n    - normalize: bool, whether to return the fraction of correctly classified samples or the number of correctly classified samples.\n    - sample_weight: array-like of shape (n_samples,), sample weights.\n    - labels: array-like of shape (n_classes,), list of labels that index the classes in y_score.\n\n    Returns:\n    - score: float, top-k accuracy score.\n    \"\"\"\n    # 1. Validate input arrays and ensure consistent length\n    y_true = check_array(y_true, ensure_2d=False)\n    y_score = check_array(y_score, ensure_2d=False)\n    check_consistent_length(y_true, y_score)\n\n    # 2. Handle the case where y_score is a 1D array (binary classification)\n    if y_score.ndim == 1:\n        y_score = np.vstack([1 - y_score, y_score]).T\n\n    # 3. If labels are provided, map y_true to indices in labels\n    if labels is not None:\n        label_to_index = {label: idx for idx, label in enumerate(labels)}\n        y_true = np.array([label_to_index[label] for label in y_true])\n\n    # 4. Get the indices of the top-k scores for each sample\n    top_k_indices = np.argsort(y_score, axis=1)[:, -k:]\n\n    # 5. Check if the true label is in the top-k indices for each sample\n    correct = np.any(top_k_indices == y_true[:, np.newaxis], axis=1)\n\n    # 6. Apply sample weights if provided\n    if sample_weight is not None:\n        sample_weight = check_array(sample_weight, ensure_2d=False)\n        check_consistent_length(y_true, sample_weight)\n        correct = correct * sample_weight\n\n    # 7. Calculate the score: either the fraction or the number of correct samples\n    if normalize:\n        score = np.sum(correct) / np.sum(sample_weight) if sample_weight is not None else np.mean(correct)\n    else:\n        score = np.sum(correct)\n\n    return score\n\n# Example usage:\n# y_true = np.array([0, 1, 2, 2])\n# y_score = np.array([[0.2, 0.3, 0.5], [0.1, 0.8, 0.1], [0.6, 0.2, 0.2], [0.3, 0.4, 0.3]])\n# print(top_k_accuracy_score(y_true, y_score, k=2))  # Output: 0.75\n```\n\n### Explanation:\n\n1. **Input Validation**: We use `check_array` and `check_consistent_length` from `sklearn.utils` to ensure that the input arrays are valid and have consistent lengths.\n\n2. **Binary Classification Handling**: If `y_score` is a 1D array, we assume binary classification and convert it to a 2D array with two columns.\n\n3. **Label Mapping**: If `labels` are provided, we map `y_true` to indices corresponding to the labels.\n\n4. **Top-k Indices**: We use `np.argsort` to get the indices of the top-k scores for each sample.\n\n5. **Correct Predictions**: We check if the true label is among the top-k predicted labels.\n\n6. **Sample Weights**: If `sample_weight` is provided, we apply it to the correct predictions.\n\n7. **Score Calculation**: We calculate the score as either the fraction or the number of correctly classified samples, depending on the `normalize` parameter.",
    "prompt": "Generate a Python function called top_k_accuracy_score that calculates the top-k accuracy classification score. The function takes in the following parameters:\n\n- y_true: array-like of shape (n_samples,) representing the true labels.\n- y_score: array-like of shape (n_samples,) or (n_samples, n_classes) representing the target scores.\n- k: an integer representing the number of most likely outcomes considered to find the correct label.\n- normalize: a boolean indicating whether to return the fraction of correctly classified samples or the number of correctly classified samples.\n- sample_weight: array-like of shape (n_samples,) representing sample weights.\n- labels: array-like of shape (n_classes,) representing the list of labels that index the classes in y_score.\n\nThe function returns a float value representing the top-k accuracy score. The best performance is 1 with normalize == True and the number of samples with normalize == False. The function also includes examples and additional information about the metric.",
    "function_name": "top_k_accuracy_score",
    "ground_truth": "sklearn/metrics/_ranking.py",
    "test": "sklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_binary",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "Classification",
    "data": "Table"
}