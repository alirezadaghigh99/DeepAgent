{
    "result": "To create a function that computes a confusion matrix for evaluating the accuracy of a classification, we can follow a step-by-step approach similar to the examples provided. Here's how you can implement the `confusion_matrix` function in Python:\n\n```python\nimport numpy as np\nfrom sklearn.utils.multiclass import unique_labels\n\ndef confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None):\n    \"\"\"\n    Compute confusion matrix to evaluate the accuracy of a classification.\n\n    Parameters\n    ----------\n    y_true : array-like of shape (n_samples,)\n        Ground truth (correct) target values.\n\n    y_pred : array-like of shape (n_samples,)\n        Estimated targets as returned by a classifier.\n\n    labels : array-like of shape (n_classes), default=None\n        List of labels to index the matrix. This may be used to reorder\n        or select a subset of labels.\n        If None is given, those that appear at least once\n        in y_true or y_pred are used in sorted order.\n\n    sample_weight : array-like of shape (n_samples,), default=None\n        Sample weights.\n\n    normalize : {'true', 'pred', 'all'}, default=None\n        Normalizes confusion matrix over the true (rows), predicted (columns)\n        conditions or all the population. If None, confusion matrix will not be\n        normalized.\n\n    Returns\n    -------\n    C : ndarray of shape (n_classes, n_classes)\n        Confusion matrix whose i-th row and j-th\n        column entry indicates the number of\n        samples with true label being i-th class\n        and predicted label being j-th class.\n    \"\"\"\n    # 1. Determine the unique labels in the data\n    if labels is None:\n        labels = unique_labels(y_true, y_pred)\n    else:\n        labels = np.asarray(labels)\n\n    # 2. Create a mapping from label to index\n    label_to_index = {label: i for i, label in enumerate(labels)}\n\n    # 3. Initialize the confusion matrix with zeros\n    n_labels = labels.size\n    cm = np.zeros((n_labels, n_labels), dtype=np.int64)\n\n    # 4. Populate the confusion matrix\n    for true, pred in zip(y_true, y_pred):\n        if true in label_to_index and pred in label_to_index:\n            cm[label_to_index[true], label_to_index[pred]] += 1\n\n    # 5. Apply sample weights if provided\n    if sample_weight is not None:\n        sample_weight = np.asarray(sample_weight)\n        for i, (true, pred) in enumerate(zip(y_true, y_pred)):\n            if true in label_to_index and pred in label_to_index:\n                cm[label_to_index[true], label_to_index[pred]] += sample_weight[i] - 1\n\n    # 6. Normalize the confusion matrix if requested\n    if normalize is not None:\n        with np.errstate(all='ignore'):\n            if normalize == 'true':\n                cm = cm / cm.sum(axis=1, keepdims=True)\n            elif normalize == 'pred':\n                cm = cm / cm.sum(axis=0, keepdims=True)\n            elif normalize == 'all':\n                cm = cm / cm.sum()\n            else:\n                raise ValueError(\"normalize must be one of {'true', 'pred', 'all', None}\")\n\n    return cm\n```\n\n### Explanation:\n\n1. **Determine Unique Labels**: If no specific labels are provided, the function determines the unique labels from `y_true` and `y_pred`.\n\n2. **Mapping Labels to Indices**: A dictionary maps each label to an index, which is used to populate the confusion matrix.\n\n3. **Initialize Confusion Matrix**: A square matrix of zeros is created, with dimensions equal to the number of unique labels.\n\n4. **Populate Confusion Matrix**: The function iterates over `y_true` and `y_pred`, incrementing the appropriate cell in the matrix for each pair of true and predicted labels.\n\n5. **Apply Sample Weights**: If sample weights are provided, they are used to adjust the counts in the confusion matrix.\n\n6. **Normalize the Matrix**: If normalization is requested, the matrix is normalized by the true labels, predicted labels, or the entire matrix, depending on the `normalize` parameter.\n\nThis function provides a comprehensive way to compute and optionally normalize a confusion matrix, which is a fundamental tool for evaluating classification models.",
    "prompt": "Generate a Python function called confusion_matrix that Compute confusion matrix to evaluate the accuracy of a classification.\n\n    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\n    is equal to the number of observations known to be in group :math:`i` and\n    predicted to be in group :math:`j`.\n\n    Thus in binary classification, the count of true negatives is\n    :math:`C_{0,0}`, false negatives is :math:`C_{1,0}`, true positives is\n    :math:`C_{1,1}` and false positives is :math:`C_{0,1}`.\n\n\n    Parameters\n    ----------\n    y_true : array-like of shape (n_samples,)\n        Ground truth (correct) target values.\n\n    y_pred : array-like of shape (n_samples,)\n        Estimated targets as returned by a classifier.\n\n    labels : array-like of shape (n_classes), default=None\n        List of labels to index the matrix. This may be used to reorder\n        or select a subset of labels.\n        If ``None`` is given, those that appear at least once\n        in ``y_true`` or ``y_pred`` are used in sorted order.\n\n    sample_weight : array-like of shape (n_samples,), default=None\n        Sample weights.\n\n        .. versionadded:: 0.18\n\n    normalize : {'true', 'pred', 'all'}, default=None\n        Normalizes confusion matrix over the true (rows), predicted (columns)\n        conditions or all the population. If None, confusion matrix will not be\n        normalized.\n\n    Returns\n    -------\n    C : ndarray of shape (n_classes, n_classes)\n        Confusion matrix whose i-th row and j-th\n        column entry indicates the number of\n        samples with true label being i-th class\n        and predicted label being j-th class.",
    "function_name": "confusion_matrix",
    "ground_truth": "sklearn/metrics/_classification.py",
    "test": "sklearn/metrics/tests/test_classification.py::test_zero_division_nan_no_warning",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "",
    "data": ""
}