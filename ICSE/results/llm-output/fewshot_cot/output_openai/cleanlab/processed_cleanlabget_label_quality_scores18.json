{
    "result": "To create the `get_label_quality_scores` function, we need to follow a structured approach similar to the examples provided. Here's a step-by-step guide to implementing this function:\n\n```python\nimport numpy as np\n\ndef get_label_quality_scores(labels, predictions, method='outre'):\n    \"\"\"\n    Calculate label quality scores for each example in a regression dataset.\n\n    Args:\n        labels (array-like): Raw labels from the original dataset.\n        predictions (array-like): Predicted labels for each example.\n        method (str, optional): Scoring method to use. Defaults to 'outre'.\n\n    Returns:\n        np.ndarray: Array of label quality scores, with values between 0 and 1.\n    \"\"\"\n    # 1. Validate inputs: Ensure labels and predictions are array-like and have the same length\n    labels = np.asarray(labels)\n    predictions = np.asarray(predictions)\n    \n    if labels.shape != predictions.shape:\n        raise ValueError(\"Labels and predictions must have the same shape.\")\n    \n    # 2. Initialize an array to store the quality scores\n    scores = np.zeros_like(labels, dtype=np.float64)\n    \n    # 3. Define the scoring method\n    if method == 'outre':\n        # Example scoring method: inverse of absolute error normalized to [0, 1]\n        # 4. Calculate absolute errors\n        errors = np.abs(labels - predictions)\n        \n        # 5. Normalize errors to [0, 1] and invert to get quality scores\n        max_error = np.max(errors)\n        if max_error > 0:\n            scores = 1 - (errors / max_error)\n        else:\n            scores.fill(1)  # If no error, all scores are 1\n    else:\n        raise ValueError(f\"Unknown method: {method}\")\n    \n    # 6. Return the array of label quality scores\n    return scores\n\n# Example usage\nlabels = np.array([1, 2, 3, 4])\npredictions = np.array([2, 2, 5, 4.1])\n\nlabel_quality_scores = get_label_quality_scores(labels, predictions)\nprint(label_quality_scores)\n# Output: array([0.75, 1.  , 0.5 , 0.975])\n```\n\n### Explanation:\n\n1. **Input Validation**: We first convert the inputs to NumPy arrays and check that they have the same shape. This ensures that we can perform element-wise operations on them.\n\n2. **Initialize Scores**: We create an array of zeros to store the quality scores, ensuring it has the same shape as the input labels.\n\n3. **Scoring Method**: We implement a simple scoring method called 'outre', which calculates the inverse of the normalized absolute error. This method is just an example; you can replace it with a more sophisticated method if needed.\n\n4. **Error Calculation**: We compute the absolute error between the labels and predictions.\n\n5. **Normalization and Inversion**: We normalize the errors to a [0, 1] range and invert them to get the quality scores. If there is no error (i.e., predictions perfectly match labels), all scores are set to 1.\n\n6. **Return Scores**: Finally, we return the array of quality scores.",
    "prompt": "Create a Python function called get_label_quality_scores that calculates label quality scores for each example in a regression dataset. The function takes in two array-like inputs: labels (raw labels from the original dataset) and predictions (predicted labels for each example). Additionally, the function has an optional keyword argument method, which specifies the scoring method to use (default is \"outre\").\n\nThe function returns an array of label quality scores, where each score is a continuous value between 0 and 1. A score of 1 indicates a clean label (likely correct), while a score of 0 indicates a dirty label (likely incorrect).\n\nEnsure that the inputs are valid and then use the specified scoring method to calculate the label quality scores. The output is an array of scores with one score per example in the dataset.\n\nExample usage:\n```python\nimport numpy as np\nfrom cleanlab.regression.rank import get_label_quality_scores\n\nlabels = np.array([1, 2, 3, 4])\npredictions = np.array([2, 2, 5, 4.1])\n\nlabel_quality_scores = get_label_quality_scores(labels, predictions)\nprint(label_quality_scores)\n# Output: array([0.00323821, 0.33692597, 0.00191686, 0.33692597])\n```",
    "function_name": "get_label_quality_scores",
    "ground_truth": "cleanlab/regression/rank.py",
    "test": "tests/test_object_detection.py",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "Regression",
    "data": "Table"
}