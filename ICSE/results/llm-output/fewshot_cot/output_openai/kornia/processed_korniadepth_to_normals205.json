{
    "result": "To create the `depth_to_normals` function, we need to compute surface normals from a depth image using the camera intrinsics. Here's a step-by-step implementation:\n\n```python\nimport torch\n\ndef depth_to_normals(depth, camera_matrix, normalize_points=False):\n    \"\"\"\n    Computes the surface normals per pixel from a depth image.\n\n    Args:\n        depth (torch.Tensor): A tensor of shape (B, 1, H, W) containing depth values.\n        camera_matrix (torch.Tensor): A tensor of shape (B, 3, 3) representing the camera intrinsics.\n        normalize_points (bool): Whether to normalize the point cloud.\n\n    Returns:\n        torch.Tensor: A tensor with a normal vector per pixel of shape (B, 3, H, W).\n\n    Raises:\n        TypeError: If `depth` or `camera_matrix` is not a Tensor.\n        ValueError: If `depth` does not have the shape (B, 1, H, W) or `camera_matrix` does not have the shape (B, 3, 3).\n    \"\"\"\n    # 1. Validate input types\n    if not isinstance(depth, torch.Tensor):\n        raise TypeError(\"depth must be a torch.Tensor\")\n    if not isinstance(camera_matrix, torch.Tensor):\n        raise TypeError(\"camera_matrix must be a torch.Tensor\")\n\n    # 2. Validate input shapes\n    if depth.ndim != 4 or depth.shape[1] != 1:\n        raise ValueError(\"depth must have shape (B, 1, H, W)\")\n    if camera_matrix.ndim != 3 or camera_matrix.shape[1:] != (3, 3):\n        raise ValueError(\"camera_matrix must have shape (B, 3, 3)\")\n\n    B, _, H, W = depth.shape\n\n    # 3. Create a meshgrid for pixel coordinates\n    y, x = torch.meshgrid(torch.arange(H, device=depth.device), torch.arange(W, device=depth.device))\n    y, x = y.float(), x.float()\n\n    # 4. Compute the inverse of the camera matrix\n    camera_matrix_inv = torch.inverse(camera_matrix)\n\n    # 5. Compute 3D points from depth\n    #    - Homogeneous coordinates: (x, y, 1)\n    #    - Multiply by inverse camera matrix and depth\n    points = torch.stack((x, y, torch.ones_like(x)), dim=0).unsqueeze(0).repeat(B, 1, 1, 1)\n    points = points.view(B, 3, -1)  # Reshape to (B, 3, H*W)\n    points = torch.bmm(camera_matrix_inv, points)  # Apply inverse camera matrix\n    points = points.view(B, 3, H, W) * depth  # Scale by depth\n\n    # 6. Normalize points if required\n    if normalize_points:\n        points = points / torch.norm(points, dim=1, keepdim=True)\n\n    # 7. Compute gradients in x and y directions\n    dzdx = torch.nn.functional.pad(points[:, :, :, 1:] - points[:, :, :, :-1], (0, 1))\n    dzdy = torch.nn.functional.pad(points[:, :, 1:, :] - points[:, :, :-1, :], (0, 0, 0, 1))\n\n    # 8. Compute normals using cross product of gradients\n    normals = torch.cross(dzdx, dzdy, dim=1)\n\n    # 9. Normalize the normals\n    normals = normals / torch.norm(normals, dim=1, keepdim=True)\n\n    return normals\n```\n\n### Explanation:\n\n1. **Input Validation**: We first check if the inputs are tensors and have the correct shapes.\n2. **Meshgrid Creation**: We create a meshgrid for pixel coordinates, which will be used to compute 3D points.\n3. **Inverse Camera Matrix**: We compute the inverse of the camera matrix to transform pixel coordinates to camera coordinates.\n4. **3D Points Calculation**: We compute 3D points from the depth image using the inverse camera matrix.\n5. **Normalization**: If `normalize_points` is `True`, we normalize the 3D points.\n6. **Gradient Calculation**: We compute the gradients in the x and y directions to find the surface normals.\n7. **Normal Calculation**: We use the cross product of the gradients to compute the normals.\n8. **Normalization of Normals**: Finally, we normalize the normals to ensure they are unit vectors.",
    "prompt": "Create a Python function `depth_to_normals` that:\n\n- Computes the surface normals per pixel from a depth image.\n- Accepts the following parameters:\n  - `depth`: A tensor of shape `(B, 1, H, W)` containing depth values.\n  - `camera_matrix`: A tensor of shape `(B, 3, 3)` representing the camera intrinsics.\n  - `normalize_points`: A boolean indicating whether to normalize the point cloud. This is necessary when depth values represent Euclidean distances from the camera position.\n- Returns a tensor with a normal vector per pixel of shape `(B, 3, H, W)`.\n\nErrors:\n- Raises `TypeError` if `depth` or `camera_matrix` is not a Tensor.\n- Raises `ValueError` if `depth` does not have the shape `(B, 1, H, W)` or `camera_matrix` does not have the shape `(B, 3, 3)`.",
    "function_name": "depth_to_normals",
    "ground_truth": "kornia/geometry/depth.py",
    "test": "tests/geometry/test_depth.py::TestDepthToNormals",
    "class": "",
    "stage": "Model Construction",
    "task": "Segmentation",
    "data": "Image"
}