{
    "result": "To create the `depth_from_point` function, we need to apply a rigid transformation to the 3D points using the given rotation matrix \\( R \\) and translation vector \\( t \\). The depth of a point in this context is typically the z-coordinate of the transformed point in the camera's coordinate system. Here's how you can implement this function step by step:\n\n```python\nimport torch\n\ndef depth_from_point(R: torch.Tensor, t: torch.Tensor, X: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Return the depth of a point transformed by a rigid transform.\n\n    Args:\n        R: The rotation matrix with shape :math:`(*, 3, 3)`.\n        t: The translation vector with shape :math:`(*, 3, 1)`.\n        X: The 3D points with shape :math:`(*, 3)`.\n\n    Returns:\n        The depth value per point with shape :math:`(*, 1)`.\n    \"\"\"\n    # 1. Ensure the input tensors have compatible shapes\n    if R.shape[-2:] != (3, 3):\n        raise ValueError(\"Rotation matrix R must have shape (*, 3, 3)\")\n    if t.shape[-2:] != (3, 1):\n        raise ValueError(\"Translation vector t must have shape (*, 3, 1)\")\n    if X.shape[-1] != 3:\n        raise ValueError(\"3D points X must have shape (*, 3)\")\n\n    # 2. Apply the rotation to the 3D points\n    rotated_points = torch.matmul(R, X.unsqueeze(-1))  # Shape: (*, 3, 1)\n\n    # 3. Apply the translation to the rotated points\n    transformed_points = rotated_points + t  # Shape: (*, 3, 1)\n\n    # 4. Extract the z-coordinate (depth) from the transformed points\n    depth = transformed_points[..., 2, :]  # Shape: (*, 1)\n\n    # 5. Return the depth values\n    return depth\n```\n\n### Explanation:\n\n1. **Input Validation**: We first check that the input tensors have the expected shapes. The rotation matrix \\( R \\) should be of shape \\((*, 3, 3)\\), the translation vector \\( t \\) should be of shape \\((*, 3, 1)\\), and the 3D points \\( X \\) should be of shape \\((*, 3)\\).\n\n2. **Rotation**: We apply the rotation matrix \\( R \\) to the 3D points \\( X \\). Since \\( X \\) is of shape \\((*, 3)\\), we first unsqueeze it to \\((*, 3, 1)\\) to make it compatible for matrix multiplication with \\( R \\).\n\n3. **Translation**: We add the translation vector \\( t \\) to the rotated points to get the transformed points.\n\n4. **Depth Extraction**: The depth of each point is the z-coordinate of the transformed point, which is the third element in the last dimension of the transformed points.\n\n5. **Return**: Finally, we return the depth values, which have shape \\((*, 1)\\).",
    "prompt": "Write a python function depth_from_point that Return the depth of a point transformed by a rigid transform.\n\n    Args:\n       R: The rotation matrix with shape :math:`(*, 3, 3)`.\n       t: The translation vector with shape :math:`(*, 3, 1)`.\n       X: The 3d points with shape :math:`(*, 3)`.\n\n    Returns:\n       The depth value per point with shape :math:`(*, 1)`.",
    "function_name": "depth_from_point",
    "ground_truth": "kornia/geometry/epipolar/projection.py#L151",
    "test": "tests/geometry/epipolar/test_essential.py::TestMotionFromEssentialChooseSolution",
    "class": "",
    "stage": "Inference",
    "task": "Prediction",
    "data": "Image"
}