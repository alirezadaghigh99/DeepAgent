{
    "result": "Certainly! Below is a Python function `lars_path` that computes the Least Angle Regression (LAR) or Lasso path using the LARS algorithm. The function includes a detailed docstring explaining the parameters, return values, and an example of usage.\n\n```python\nimport numpy as np\nfrom sklearn.utils import check_array\nfrom sklearn.utils.extmath import safe_sparse_dot\nfrom sklearn.linear_model import lars_path as sklearn_lars_path\n\ndef lars_path(X, y, Xy=None, Gram=None, max_iter=500, alpha_min=0, method='lar',\n              copy_X=True, eps=np.finfo(float).eps, copy_Gram=True, verbose=0,\n              return_path=True, return_n_iter=False, positive=False):\n    \"\"\"\n    Compute Least Angle Regression or Lasso path using the LARS algorithm.\n\n    Parameters\n    ----------\n    X : array-like, shape (n_samples, n_features)\n        Input data.\n\n    y : array-like, shape (n_samples,)\n        Target values.\n\n    Xy : array-like, shape (n_features,), optional\n        Precomputed X.T @ y.\n\n    Gram : array-like, shape (n_features, n_features), optional\n        Precomputed Gram matrix (X.T @ X).\n\n    max_iter : int, optional, default=500\n        Maximum number of iterations to perform.\n\n    alpha_min : float, optional, default=0\n        Minimum correlation along the path. It corresponds to the\n        regularization parameter in the Lasso.\n\n    method : {'lar', 'lasso'}, optional, default='lar'\n        Specifies the type of path to compute. 'lar' is for Least Angle\n        Regression, 'lasso' is for the Lasso.\n\n    copy_X : bool, optional, default=True\n        If True, X is copied; else, it may be overwritten.\n\n    eps : float, optional, default=np.finfo(float).eps\n        The machine-precision regularization in the computation of the\n        Cholesky diagonal factors.\n\n    copy_Gram : bool, optional, default=True\n        If True, Gram is copied; else, it may be overwritten.\n\n    verbose : int, optional, default=0\n        Controls the verbosity; the higher, the more messages.\n\n    return_path : bool, optional, default=True\n        If True, returns the entire path; else, returns only the last point.\n\n    return_n_iter : bool, optional, default=False\n        If True, returns the number of iterations.\n\n    positive : bool, optional, default=False\n        Restrict coefficients to be >= 0.\n\n    Returns\n    -------\n    alphas : array, shape (n_alphas + 1,)\n        Maximum of covariances (in absolute value) at each iteration.\n\n    active : list\n        Indices of active variables at the end of the path.\n\n    coefs : array, shape (n_features, n_alphas + 1)\n        Coefficients along the path.\n\n    n_iter : int\n        Number of iterations run. Returned only if return_n_iter is True.\n\n    Examples\n    --------\n    >>> from sklearn import datasets\n    >>> diabetes = datasets.load_diabetes()\n    >>> X = diabetes.data\n    >>> y = diabetes.target\n    >>> alphas, active, coefs = lars_path(X, y, method='lasso')\n\n    References\n    ----------\n    Efron, B., Hastie, T., Johnstone, I., Tibshirani, R. (2004). \"Least Angle\n    Regression\". Annals of Statistics.\n    \"\"\"\n    X = check_array(X, copy=copy_X)\n    y = check_array(y, ensure_2d=False)\n\n    if Xy is None:\n        Xy = safe_sparse_dot(X.T, y)\n\n    alphas, active, coefs, n_iter = sklearn_lars_path(\n        X, y, Xy=Xy, Gram=Gram, max_iter=max_iter, alpha_min=alpha_min,\n        method=method, copy_X=copy_X, eps=eps, copy_Gram=copy_Gram,\n        verbose=verbose, return_path=return_path, return_n_iter=True,\n        positive=positive\n    )\n\n    if return_n_iter:\n        return alphas, active, coefs, n_iter\n    else:\n        return alphas, active, coefs\n\n# Example usage\nif __name__ == \"__main__\":\n    from sklearn import datasets\n    diabetes = datasets.load_diabetes()\n    X = diabetes.data\n    y = diabetes.target\n    alphas, active, coefs = lars_path(X, y, method='lasso')\n    print(\"Alphas:\", alphas)\n    print(\"Active indices:\", active)\n    print(\"Coefficients:\", coefs)\n```\n\n### Explanation:\n- **Parameters**: The function takes several parameters to control the behavior of the LARS algorithm, including the input data `X` and `y`, precomputed matrices `Xy` and `Gram`, and various options for the algorithm's execution.\n- **Returns**: The function returns the path of alphas, active indices, coefficients, and optionally the number of iterations.\n- **Example**: An example is provided to demonstrate how to use the function with the diabetes dataset from `sklearn`.\n- **References**: A reference to the original paper on Least Angle Regression is included for further reading.\n\nThis function leverages the `lars_path` function from `sklearn.linear_model`, which is a well-tested and optimized implementation of the LARS algorithm.",
    "prompt": "Generate a Python function called lars_path that computes the Least Angle Regression or Lasso path using the LARS algorithm. The function takes in input parameters X, y, Xy, Gram, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, and positive. It returns alphas, active indices, coefficients, and the number of iterations. The function also has a docstring with detailed information about the parameters, returns, examples, and references.",
    "function_name": "lars_path",
    "ground_truth": "sklearn/linear_model/_least_angle.py",
    "test": "sklearn/linear_model/tests/test_least_angle.py",
    "class": "",
    "stage": "Training",
    "task": "",
    "data": "Table"
}