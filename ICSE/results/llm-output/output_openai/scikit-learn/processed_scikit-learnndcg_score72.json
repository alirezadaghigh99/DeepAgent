{
    "result": "To compute the Normalized Discounted Cumulative Gain (NDCG), we need to follow these steps:\n\n1. Compute the Discounted Cumulative Gain (DCG) for the predicted scores.\n2. Compute the Ideal Discounted Cumulative Gain (IDCG) for the true scores.\n3. Normalize the DCG by dividing it by the IDCG.\n\nHere's a Python function that implements this:\n\n```python\nimport numpy as np\n\ndef dcg_score(y_true, y_score, k=None, ignore_ties=False):\n    \"\"\"Compute the Discounted Cumulative Gain (DCG) score.\"\"\"\n    order = np.argsort(y_score)[::-1]\n    y_true = np.take(y_true, order[:k])\n\n    if ignore_ties:\n        gains = y_true\n    else:\n        gains = 2 ** y_true - 1\n\n    discounts = np.log2(np.arange(len(y_true)) + 2)\n    return np.sum(gains / discounts)\n\ndef ndcg_score(y_true, y_score, k=None, sample_weight=None, ignore_ties=False):\n    \"\"\"Compute the Normalized Discounted Cumulative Gain (NDCG) score.\"\"\"\n    y_true = np.asarray(y_true)\n    y_score = np.asarray(y_score)\n\n    if sample_weight is None:\n        sample_weight = np.ones(y_true.shape[0])\n    else:\n        sample_weight = np.asarray(sample_weight)\n\n    scores = []\n    for i in range(y_true.shape[0]):\n        actual_dcg = dcg_score(y_true[i], y_score[i], k, ignore_ties)\n        ideal_dcg = dcg_score(y_true[i], y_true[i], k, ignore_ties)\n        if ideal_dcg == 0:\n            score = 0.0\n        else:\n            score = actual_dcg / ideal_dcg\n        scores.append(score * sample_weight[i])\n\n    return np.sum(scores) / np.sum(sample_weight)\n\n# Example usage:\ny_true = np.array([[3, 2, 3, 0, 1, 2]])\ny_score = np.array([[0.5, 0.2, 0.6, 0.4, 0.3, 0.1]])\nprint(ndcg_score(y_true, y_score, k=5))\n```\n\n### Explanation:\n\n- **DCG Calculation**: The `dcg_score` function calculates the DCG by sorting the scores, applying a logarithmic discount, and summing the discounted gains.\n- **NDCG Calculation**: The `ndcg_score` function calculates the NDCG by normalizing the DCG with the ideal DCG (IDCG), which is computed by sorting the true scores in descending order.\n- **Parameters**:\n  - `k`: Limits the number of top scores considered.\n  - `sample_weight`: Allows weighting of samples.\n  - `ignore_ties`: Assumes no ties in `y_score` for efficiency.\n\nThis function should work for multilabel classification tasks and provide a normalized score between 0 and 1.",
    "prompt": "Generate a Python function called ndcg_score that Compute Normalized Discounted Cumulative Gain.\n\n    Sum the true scores ranked in the order induced by the predicted scores,\n    after applying a logarithmic discount. Then divide by the best possible\n    score (Ideal DCG, obtained for a perfect ranking) to obtain a score between\n    0 and 1.\n\n    This ranking metric returns a high value if true labels are ranked high by\n    ``y_score``.\n\n    Parameters\n    ----------\n    y_true : array-like of shape (n_samples, n_labels)\n        True targets of multilabel classification, or true scores of entities\n        to be ranked. Negative values in `y_true` may result in an output\n        that is not between 0 and 1.\n\n    y_score : array-like of shape (n_samples, n_labels)\n        Target scores, can either be probability estimates, confidence values,\n        or non-thresholded measure of decisions (as returned by\n        \"decision_function\" on some classifiers).\n\n    k : int, default=None\n        Only consider the highest k scores in the ranking. If `None`, use all\n        outputs.\n\n    sample_weight : array-like of shape (n_samples,), default=None\n        Sample weights. If `None`, all samples are given the same weight.\n\n    ignore_ties : bool, default=False\n        Assume that there are no ties in y_score (which is likely to be the\n        case if y_score is continuous) for efficiency gains.\n\n    Returns\n    -------\n    normalized_discounted_cumulative_gain : float in [0., 1.]\n        The averaged NDCG scores for all samples.",
    "function_name": "ndcg_score",
    "ground_truth": "sklearn/metrics/_ranking.py",
    "test": "sklearn/metrics/tests/test_ranking.py:test_ndcg_toy_examples",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "",
    "data": "Table"
}