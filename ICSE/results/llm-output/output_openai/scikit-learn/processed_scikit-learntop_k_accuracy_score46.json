{
    "result": "To implement the `top_k_accuracy_score` function, we need to consider the following steps:\n\n1. Validate the input parameters.\n2. Determine the top-k predictions for each sample.\n3. Compare these predictions with the true labels.\n4. Calculate the accuracy based on whether the true label is within the top-k predictions.\n5. Return the result either as a fraction or as a count, depending on the `normalize` parameter.\n\nHere's the implementation of the `top_k_accuracy_score` function:\n\n```python\nimport numpy as np\n\ndef top_k_accuracy_score(y_true, y_score, k=1, normalize=True, sample_weight=None, labels=None):\n    \"\"\"\n    Calculate the top-k accuracy score.\n\n    Parameters:\n    - y_true: array-like of shape (n_samples,) representing the true labels.\n    - y_score: array-like of shape (n_samples, n_classes) representing the target scores.\n    - k: int, number of most likely outcomes considered to find the correct label.\n    - normalize: bool, whether to return the fraction of correctly classified samples or the number of correctly classified samples.\n    - sample_weight: array-like of shape (n_samples,), sample weights.\n    - labels: array-like of shape (n_classes,), list of labels that index the classes in y_score.\n\n    Returns:\n    - float, top-k accuracy score.\n    \"\"\"\n    y_true = np.asarray(y_true)\n    y_score = np.asarray(y_score)\n    \n    if labels is not None:\n        label_to_index = {label: idx for idx, label in enumerate(labels)}\n        y_true = np.array([label_to_index[label] for label in y_true])\n    \n    if y_score.ndim == 1:\n        raise ValueError(\"y_score must be a 2D array with shape (n_samples, n_classes).\")\n    \n    n_samples = y_true.shape[0]\n    \n    # Get the indices of the top-k predictions\n    top_k_indices = np.argsort(y_score, axis=1)[:, -k:]\n    \n    # Check if the true label is in the top-k predictions\n    correct = np.any(top_k_indices == y_true[:, None], axis=1)\n    \n    if sample_weight is not None:\n        sample_weight = np.asarray(sample_weight)\n        if sample_weight.shape[0] != n_samples:\n            raise ValueError(\"sample_weight must have the same length as y_true.\")\n        correct = correct * sample_weight\n    \n    if normalize:\n        return np.sum(correct) / np.sum(sample_weight) if sample_weight is not None else np.mean(correct)\n    else:\n        return np.sum(correct)\n\n# Example usage:\ny_true = [0, 1, 2, 2]\ny_score = [[0.2, 0.3, 0.5],\n           [0.1, 0.6, 0.3],\n           [0.3, 0.4, 0.3],\n           [0.4, 0.4, 0.2]]\nk = 2\nprint(top_k_accuracy_score(y_true, y_score, k))  # Output: 1.0\n\n# Additional information:\n# - The top-k accuracy score is a metric used to evaluate the performance of a classification model.\n# - It considers a prediction to be correct if the true label is among the top-k predicted labels.\n# - This metric is particularly useful in scenarios where multiple predictions are acceptable.\n```\n\n### Explanation:\n\n- **Input Validation**: The function checks if `y_score` is a 2D array and if `sample_weight` has the correct length.\n- **Top-k Predictions**: The function uses `np.argsort` to get the indices of the top-k scores for each sample.\n- **Correct Predictions**: It checks if the true label is within the top-k predictions using `np.any`.\n- **Weighted Accuracy**: If `sample_weight` is provided, it multiplies the correctness by the weights.\n- **Normalization**: The function returns either the fraction of correct predictions or the count, based on the `normalize` parameter.\n\nThis function is useful for evaluating models in multi-class classification tasks where the top-k predictions are considered.",
    "prompt": "Generate a Python function called top_k_accuracy_score that calculates the top-k accuracy classification score. The function takes in the following parameters:\n\n- y_true: array-like of shape (n_samples,) representing the true labels.\n- y_score: array-like of shape (n_samples,) or (n_samples, n_classes) representing the target scores.\n- k: an integer representing the number of most likely outcomes considered to find the correct label.\n- normalize: a boolean indicating whether to return the fraction of correctly classified samples or the number of correctly classified samples.\n- sample_weight: array-like of shape (n_samples,) representing sample weights.\n- labels: array-like of shape (n_classes,) representing the list of labels that index the classes in y_score.\n\nThe function returns a float value representing the top-k accuracy score. The best performance is 1 with normalize == True and the number of samples with normalize == False. The function also includes examples and additional information about the metric.",
    "function_name": "top_k_accuracy_score",
    "ground_truth": "sklearn/metrics/_ranking.py",
    "test": "sklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_binary",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "Classification",
    "data": "Table"
}