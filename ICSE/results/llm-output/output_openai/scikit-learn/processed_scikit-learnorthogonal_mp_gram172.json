{
    "result": "To implement the Orthogonal Matching Pursuit (OMP) algorithm, we need to iteratively select features that best explain the residuals of the target variable. The algorithm stops when either a specified number of non-zero coefficients is reached or the residual norm falls below a given tolerance. Here's how you can implement this in Python:\n\n```python\nimport numpy as np\nfrom numpy.linalg import norm, lstsq\n\ndef orthogonal_mp_gram(X, y, n_nonzero_coefs=None, tol=None, precompute='auto', copy_X=True, return_path=False, return_n_iter=False):\n    X = np.array(X, copy=copy_X)\n    y = np.array(y, copy=False)\n    \n    n_samples, n_features = X.shape\n    \n    if y.ndim == 1:\n        y = y[:, np.newaxis]\n    \n    n_targets = y.shape[1]\n    \n    if n_nonzero_coefs is None:\n        n_nonzero_coefs = max(1, int(0.1 * n_features))\n    \n    if n_nonzero_coefs > n_features:\n        raise ValueError(\"Number of non-zero coefficients cannot exceed the number of features.\")\n    \n    if precompute == 'auto':\n        precompute = n_samples > n_features\n    \n    if precompute:\n        Gram = np.dot(X.T, X)\n        Xy = np.dot(X.T, y)\n    else:\n        Gram = None\n        Xy = None\n    \n    coef = np.zeros((n_features, n_targets))\n    residuals = y.copy()\n    indices = []\n    path = []\n    \n    for k in range(n_nonzero_coefs):\n        if tol is not None and norm(residuals, ord='fro') ** 2 <= tol:\n            break\n        \n        if precompute:\n            correlations = np.dot(X.T, residuals)\n        else:\n            correlations = np.dot(X.T, residuals)\n        \n        if n_targets == 1:\n            correlations = correlations.ravel()\n        \n        best_idx = np.argmax(np.abs(correlations), axis=0)\n        indices.append(best_idx)\n        \n        if precompute:\n            A = Gram[np.ix_(indices, indices)]\n            b = Xy[indices]\n        else:\n            A = np.dot(X[:, indices].T, X[:, indices])\n            b = np.dot(X[:, indices].T, y)\n        \n        coef_subset, _, _, _ = lstsq(A, b, rcond=None)\n        \n        if n_targets == 1:\n            coef[indices] = coef_subset.ravel()\n        else:\n            coef[indices] = coef_subset\n        \n        residuals = y - np.dot(X, coef)\n        \n        if return_path:\n            path.append(coef.copy())\n    \n    if return_path:\n        path = np.array(path)\n    \n    if return_n_iter:\n        if return_path:\n            return coef, path, k + 1\n        else:\n            return coef, k + 1\n    else:\n        if return_path:\n            return coef, path\n        else:\n            return coef\n\n# Example usage:\n# X = np.random.randn(100, 50)\n# y = np.random.randn(100)\n# coef = orthogonal_mp_gram(X, y, n_nonzero_coefs=5)\n```\n\n### Key Points:\n- **Precomputation**: The Gram matrix and the product of `X.T` and `y` are precomputed if `precompute` is set to `True`, which can speed up the algorithm when `n_samples` is large.\n- **Stopping Criteria**: The algorithm stops based on either the number of non-zero coefficients or the residual norm.\n- **Return Options**: The function can return the entire path of coefficients and the number of iterations if specified.\n- **Edge Cases**: The function raises a `ValueError` if the number of non-zero coefficients exceeds the number of features.\n\nThis implementation is efficient and flexible, allowing for various configurations based on the input parameters.",
    "prompt": "Create a Python function `orthogonal_mp_gram` that implements the Orthogonal Matching Pursuit (OMP) algorithm for solving sparse linear regression problems. The function should accept the following parameters:\n- `X`: A 2D array-like of shape `(n_samples, n_features)` representing the input data. Columns should be assumed to have unit norm.\n- `y`: A 1D or 2D array-like of shape `(n_samples,)` or `(n_samples, n_targets)` representing the target values.\n- `n_nonzero_coefs`: An integer specifying the desired number of non-zero coefficients in the solution. If `None`, this defaults to 10% of the number of features.\n- `tol`: A float specifying the maximum squared norm of the residual. If provided, this overrides `n_nonzero_coefs`.\n- `precompute`: A boolean or the string `'auto'` indicating whether to precompute the Gram matrix for faster computation when `n_targets` or `n_samples` is large.\n- `copy_X`: A boolean indicating whether to copy the input matrix `X` (default is `True`).\n- `return_path`: A boolean indicating whether to return the entire coefficient path for each iteration.\n- `return_n_iter`: A boolean indicating whether to return the number of iterations taken for convergence.\n\nThe function should return the coefficients of the OMP solution as a 1D or 2D NumPy array, depending on the input, with an option to return the number of iterations if `return_n_iter` is `True`. Handle edge cases such as when the number of non-zero coefficients exceeds the number of features by raising a `ValueError`. The function should use efficient computation techniques, including the option to precompute the Gram matrix if `precompute` is enabled.",
    "function_name": "orthogonal_mp_gram",
    "ground_truth": "sklearn/linear_model/_omp.py",
    "test": "sklearn/linear_model/tests/test_omp.py",
    "class": "",
    "stage": "Model Construction",
    "task": "Classification",
    "data": "Table"
}