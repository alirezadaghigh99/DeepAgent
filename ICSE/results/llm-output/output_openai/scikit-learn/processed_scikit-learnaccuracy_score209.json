{
    "result": "Certainly! Below is a Python function called `accuracy_score` that calculates the accuracy classification score. It includes parameters for ground truth labels, predicted labels, normalization, and sample weights. Additionally, I've included examples demonstrating how to use the function with different inputs.\n\n```python\ndef accuracy_score(y_true, y_pred, normalize=True, sample_weight=None):\n    \"\"\"\n    Calculate the accuracy classification score.\n\n    Parameters:\n    - y_true: list or array-like of shape (n_samples,) - Ground truth (correct) labels.\n    - y_pred: list or array-like of shape (n_samples,) - Predicted labels.\n    - normalize: bool, default=True - If True, return the fraction of correctly classified samples.\n                 Otherwise, return the number of correctly classified samples.\n    - sample_weight: list or array-like of shape (n_samples,), default=None - Sample weights.\n\n    Returns:\n    - float or int: Accuracy score. The best performance is 1 with normalize=True and the number\n                    of samples with normalize=False.\n    \"\"\"\n    if len(y_true) != len(y_pred):\n        raise ValueError(\"The length of y_true and y_pred must be the same.\")\n\n    if sample_weight is None:\n        sample_weight = [1] * len(y_true)\n\n    if len(sample_weight) != len(y_true):\n        raise ValueError(\"The length of sample_weight must be the same as y_true and y_pred.\")\n\n    correct_predictions = sum(w for yt, yp, w in zip(y_true, y_pred, sample_weight) if yt == yp)\n    total_weight = sum(sample_weight)\n\n    if normalize:\n        return correct_predictions / total_weight\n    else:\n        return correct_predictions\n\n# Examples of usage:\n\n# Example 1: Basic usage without sample weights\ny_true1 = [0, 1, 2, 3]\ny_pred1 = [0, 2, 2, 3]\nprint(accuracy_score(y_true1, y_pred1))  # Output: 0.75\n\n# Example 2: Using sample weights\ny_true2 = [0, 1, 2, 3]\ny_pred2 = [0, 2, 2, 3]\nsample_weight2 = [1, 1, 2, 1]\nprint(accuracy_score(y_true2, y_pred2, sample_weight=sample_weight2))  # Output: 0.8\n\n# Example 3: Without normalization\ny_true3 = [0, 1, 2, 3]\ny_pred3 = [0, 2, 2, 3]\nprint(accuracy_score(y_true3, y_pred3, normalize=False))  # Output: 3\n\n# Example 4: With sample weights and without normalization\ny_true4 = [0, 1, 2, 3]\ny_pred4 = [0, 2, 2, 3]\nsample_weight4 = [1, 1, 2, 1]\nprint(accuracy_score(y_true4, y_pred4, normalize=False, sample_weight=sample_weight4))  # Output: 4\n```\n\nThis function checks for the correct length of input lists and handles optional sample weights. It calculates the number of correct predictions, optionally normalizing by the total weight of samples. The examples demonstrate how to use the function with and without normalization and sample weights.",
    "prompt": "Generate a Python function called accuracy_score that calculates the accuracy classification score. The function takes in the following parameters:\n\n- y_true: Ground truth (correct) labels\n- y_pred: Predicted labels\n- normalize: Boolean value indicating whether to return the fraction of correctly classified samples or the number of correctly classified samples\n- sample_weight: Sample weights\n\nThe function returns a float or integer value based on the normalize parameter. The best performance is 1 when normalize is True and the number of samples when normalize is False.\n\nThe function also includes examples demonstrating how to use it with different inputs.",
    "function_name": "accuracy_score",
    "ground_truth": "sklearn/metrics/_classification.py",
    "test": "sklearn/metrics/tests/test_classification.py",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "Classification",
    "data": ""
}