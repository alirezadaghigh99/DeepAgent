{
    "result": "To create a `perspective` function that performs a perspective transformation on an image, we need to handle both PIL Images and PyTorch Tensors. The function will compute the transformation coefficients using a helper function and apply the transformation using appropriate methods. Here's how you can implement this:\n\n```python\nfrom PIL import Image\nimport numpy as np\nimport torch\nimport torchvision.transforms.functional as F\nfrom torchvision.transforms import InterpolationMode\n\ndef _get_perspective_coeffs(startpoints, endpoints):\n    \"\"\"Calculate coefficients for perspective transformation.\"\"\"\n    matrix = []\n    for (x0, y0), (x1, y1) in zip(startpoints, endpoints):\n        matrix.append([x0, y0, 1, 0, 0, 0, -x1 * x0, -x1 * y0])\n        matrix.append([0, 0, 0, x0, y0, 1, -y1 * x0, -y1 * y0])\n\n    A = np.array(matrix, dtype=np.float32)\n    B = np.array(endpoints, dtype=np.float32).reshape(8)\n\n    res = np.linalg.solve(A, B)\n    return res.reshape(8)\n\ndef perspective(image, startpoints, endpoints, interpolation=InterpolationMode.BILINEAR, fill=None):\n    \"\"\"Apply a perspective transformation to an image.\"\"\"\n    if len(startpoints) != 4 or len(endpoints) != 4:\n        raise ValueError(\"startpoints and endpoints must each contain exactly four points.\")\n\n    if isinstance(image, Image.Image):\n        coeffs = _get_perspective_coeffs(startpoints, endpoints)\n        return image.transform(image.size, Image.PERSPECTIVE, coeffs, interpolation, fillcolor=fill)\n\n    elif isinstance(image, torch.Tensor):\n        if image.ndimension() != 3:\n            raise ValueError(\"Tensor image should be 3-dimensional (C, H, W).\")\n\n        # Convert startpoints and endpoints to tensors\n        startpoints = torch.tensor(startpoints, dtype=torch.float32)\n        endpoints = torch.tensor(endpoints, dtype=torch.float32)\n\n        # Calculate the perspective transform matrix\n        transform_matrix = F._get_perspective_coeffs(startpoints, endpoints)\n\n        # Apply the perspective transformation\n        return F.perspective(image, startpoints, endpoints, interpolation, fill)\n\n    else:\n        raise TypeError(\"Input image must be a PIL Image or a PyTorch Tensor.\")\n\n# Example usage:\n# image = Image.open('path_to_image.jpg')\n# startpoints = [(0, 0), (width, 0), (width, height), (0, height)]\n# endpoints = [(10, 10), (width-10, 20), (width-20, height-10), (20, height-20)]\n# transformed_image = perspective(image, startpoints, endpoints)\n```\n\n### Key Points:\n- **Error Handling**: The function checks if the `startpoints` and `endpoints` contain exactly four points and raises a `ValueError` if not.\n- **Input Types**: The function supports both PIL Images and PyTorch Tensors. It raises a `TypeError` if the input is neither.\n- **Interpolation**: The function uses `InterpolationMode.BILINEAR` by default, but this can be changed by passing a different interpolation mode.\n- **Fill**: The `fill` parameter allows specifying the fill color for areas outside the transformed image.\n- **Transformation Coefficients**: The `_get_perspective_coeffs` function calculates the coefficients needed for the perspective transformation.\n\nThis implementation should cover the basic requirements for performing a perspective transformation on images using both PIL and PyTorch.",
    "prompt": "Generate a Python function called perspective that performs a perspective transformation on an image. The function should accept an image input, which can be either a PIL Image or a PyTorch Tensor, along with startpoints and endpoints, each consisting of four coordinate pairs representing the corners of the original and transformed images, respectively. It should include an interpolation parameter to specify how pixel values are calculated during the transformation, defaulting to BILINEAR. Additionally, an optional fill parameter should be provided to determine the pixel values for areas outside the transformed image. The function should handle errors gracefully, such as ensuring exactly four corner points are provided for both startpoints and endpoints, and raise appropriate exceptions for invalid inputs. The function should utilize underlying helper functions like _get_perspective_coeffs to compute the necessary transformation coefficients and apply the transformation using appropriate methods based on the input type, returning the transformed image as a PIL Image or Tensor.",
    "function_name": "perspective",
    "ground_truth": "torchvision/transforms/functional.py",
    "test": "test/test_transforms.py::test_randomperspective_fill",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "",
    "data": "image"
}