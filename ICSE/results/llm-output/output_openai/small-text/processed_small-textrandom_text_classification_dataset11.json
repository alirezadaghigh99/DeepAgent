{
    "result": "To generate a random text classification dataset in Python, we can use PyTorch and its associated libraries. Below is a function `random_text_classification_dataset` that creates a synthetic dataset for text classification tasks. This function uses PyTorch and assumes you have a basic understanding of how PyTorch datasets work.\n\n```python\nimport torch\nfrom torch.utils.data import Dataset\nimport random\nimport string\n\nclass PytorchTextClassificationDataset(Dataset):\n    def __init__(self, texts, labels, vocab, multi_label, target_labels):\n        self.texts = texts\n        self.labels = labels\n        self.vocab = vocab\n        self.multi_label = multi_label\n        self.target_labels = target_labels\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        return self.texts[idx], self.labels[idx]\n\ndef random_text_classification_dataset(num_samples=1000, max_length=50, num_classes=2, multi_label=False, \n                                       vocab_size=1000, device='cpu', target_labels=None, dtype=torch.long):\n    # Generate a random vocabulary\n    vocab = [''.join(random.choices(string.ascii_lowercase, k=5)) for _ in range(vocab_size)]\n    \n    # Ensure unique vocabulary\n    vocab = list(set(vocab))\n    \n    # Generate random texts\n    texts = []\n    for _ in range(num_samples):\n        text_length = random.randint(1, max_length)\n        text = random.choices(vocab, k=text_length)\n        texts.append(text)\n    \n    # Generate random labels\n    if multi_label:\n        labels = []\n        for _ in range(num_samples):\n            label = torch.zeros(num_classes, dtype=dtype)\n            num_labels = random.randint(1, num_classes)\n            label_indices = random.sample(range(num_classes), num_labels)\n            label[label_indices] = 1\n            labels.append(label)\n    else:\n        labels = [random.randint(0, num_classes - 1) for _ in range(num_samples)]\n        labels = torch.tensor(labels, dtype=dtype)\n    \n    # Ensure all labels occur in the dataset\n    if not multi_label:\n        for i in range(num_classes):\n            if i not in labels:\n                idx = random.randint(0, num_samples - 1)\n                labels[idx] = i\n    \n    # Handle target_labels\n    if target_labels is None:\n        target_labels = [f'class_{i}' for i in range(num_classes)]\n    \n    # Convert texts to indices\n    word_to_index = {word: i for i, word in enumerate(vocab)}\n    texts_indices = [[word_to_index[word] for word in text] for text in texts]\n    \n    # Convert to tensors\n    texts_tensor = [torch.tensor(text, dtype=dtype) for text in texts_indices]\n    \n    # Create dataset\n    dataset = PytorchTextClassificationDataset(texts_tensor, labels, vocab, multi_label, target_labels)\n    \n    return dataset\n\n# Example usage\ndataset = random_text_classification_dataset(num_samples=100, max_length=10, num_classes=3, multi_label=True, vocab_size=50)\nprint(f\"Number of samples: {len(dataset)}\")\nprint(f\"Sample text: {dataset[0][0]}\")\nprint(f\"Sample label: {dataset[0][1]}\")\n```\n\n### Explanation:\n- **Vocabulary**: A random vocabulary of a specified size is generated using lowercase letters.\n- **Texts**: Random texts are generated by sampling words from the vocabulary.\n- **Labels**: Depending on whether the task is multi-label or not, labels are generated. For multi-label, a binary vector is used, while for single-label, a single integer is used.\n- **Ensuring Label Coverage**: The function ensures that all possible labels are present in the dataset.\n- **Target Labels**: If not provided, default target labels are generated.\n- **Dataset Class**: A custom dataset class `PytorchTextClassificationDataset` is defined to handle the data.\n\nThis function should be adjusted based on specific needs, such as different data types or additional preprocessing steps.",
    "prompt": "Generate a Python function called random_text_classification_dataset that generates a random text classification dataset. The function takes in parameters such as num_samples, max_length, num_classes, multi_label, vocab_size, device, target_labels, and dtype. It returns a PytorchTextClassificationDataset object with the generated dataset, vocabulary, multi_label setting, and target labels. The function ensures that all labels occur in the dataset and handles different scenarios based on the input parameters.",
    "function_name": "random_text_classification_dataset",
    "ground_truth": "tests/utils/datasets.py",
    "test": "tests/unit/small_text/initialization/test_strategies.py::RandomInitializationStratifiedTest",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "Classification",
    "data": "Text"
}