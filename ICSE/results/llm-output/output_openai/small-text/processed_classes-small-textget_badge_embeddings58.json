{
    "result": "To implement the `get_badge_embeddings` function for the `BADGE` class, we need to consider both binary and multi-class classification scenarios. The function will scale the embeddings based on the predicted class probabilities. For multi-class problems, each embedding is expanded and scaled for each class, while for binary problems, the original embeddings are returned without expansion.\n\nHere's how you can implement the `get_badge_embeddings` function:\n\n```python\nimport numpy as np\n\nclass BADGE:\n    def __init__(self, num_classes):\n        self.num_classes = num_classes\n\n    def get_badge_embeddings(self, embeddings, proba):\n        \"\"\"\n        Calculate badge embeddings scaled by class probabilities.\n\n        Parameters:\n        - embeddings: np.ndarray of shape (n_samples, embedding_dim)\n        - proba: np.ndarray of shape (n_samples, num_classes)\n\n        Returns:\n        - badge_embeddings: np.ndarray of shape (n_samples, embedding_dim * num_classes)\n        \"\"\"\n        n_samples, embedding_dim = embeddings.shape\n\n        if self.num_classes == 2:\n            # For binary classification, return the original embeddings\n            return embeddings\n\n        # For multi-class classification, expand and scale embeddings\n        badge_embeddings = np.zeros((n_samples, embedding_dim * self.num_classes))\n\n        for i in range(n_samples):\n            for c in range(self.num_classes):\n                # Calculate the gradient-like vector for each class\n                if c == np.argmax(proba[i]):\n                    # For the most likely class, use (1 - p_c)\n                    scale = 1 - proba[i, c]\n                else:\n                    # For other classes, use -p_c\n                    scale = -proba[i, c]\n\n                # Scale the original embedding and place it in the correct position\n                badge_embeddings[i, c * embedding_dim:(c + 1) * embedding_dim] = scale * embeddings[i]\n\n        return badge_embeddings\n\n# Example usage:\n# badge = BADGE(num_classes=3)\n# embeddings = np.array([[0.1, 0.2], [0.3, 0.4]])\n# proba = np.array([[0.7, 0.2, 0.1], [0.1, 0.8, 0.1]])\n# badge_embeddings = badge.get_badge_embeddings(embeddings, proba)\n# print(badge_embeddings)\n```\n\n### Explanation:\n\n1. **Binary Classification**: If the number of classes is 2, the function simply returns the original embeddings. This is because, in binary classification, the expansion isn't necessary, and the original embeddings suffice for the BADGE strategy.\n\n2. **Multi-Class Classification**: For each sample and each class:\n   - If the class is the most likely class (i.e., the class with the highest probability), the embedding is scaled by \\(1 - p_c\\).\n   - For all other classes, the embedding is scaled by \\(-p_c\\).\n   - The scaled embeddings for each class are concatenated to form a larger embedding vector for each sample.\n\nThis approach allows the BADGE strategy to effectively use the uncertainty and diversity of the samples in the active learning process.",
    "prompt": "Write a Python function `get_badge_embeddings` for the `BADGE` class. This function should calculate embeddings scaled by class probabilities, enabling the use of the BADGE strategy for batch active learning. The function takes `embeddings` and `proba` (predicted class probabilities) as input and returns the `badge_embeddings`. For multi-class problems, the embeddings are expanded and scaled for each class; for binary problems, the original embeddings are returned.\n\n```python\nclass BADGE(EmbeddingBasedQueryStrategy):\n    def __init__(self, num_classes):\n        self.num_classes = num_classes\n\n    def get_badge_embeddings(self, embeddings, proba):\n``` \n\nThe `get_badge_embeddings` function should generate an embedding matrix where each original embedding is scaled by the negative class probabilities, except for the most likely class, which is scaled differently. For multi-class classification, this scaling is performed for each class, creating a larger embedding matrix. The output is a 2D numpy array where each row corresponds to an embedding.",
    "function_name": "get_badge_embeddings",
    "ground_truth": "small_text/integrations/pytorch/query_strategies/strategies.py",
    "test": "tests/integration/small_text/integrations/pytorch/query_strategies/test_query_strategies.py::QueryStrategiesTest",
    "class": "BADGE",
    "stage": "Text",
    "task": "Classification",
    "data": "Evaluation/metrics"
}