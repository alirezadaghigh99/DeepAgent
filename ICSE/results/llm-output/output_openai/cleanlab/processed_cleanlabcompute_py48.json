{
    "result": "To create the `compute_py` function, we need to consider the different methods for computing the prior probabilities of true class labels. We'll implement error handling for invalid input shapes and missing parameters, and ensure the output is clipped between 0 and 1. Here's a possible implementation:\n\n```python\nimport numpy as np\n\ndef compute_py(ps, noise_matrix, inverse_noise_matrix, py_method, true_labels_class_counts):\n    \"\"\"\n    Compute the prior probability of true class labels based on observed noisy labels,\n    noise matrices, and inverse noise matrices.\n\n    Parameters:\n    - ps: array-like, shape (K,) or (1, K), observed noisy label distribution.\n    - noise_matrix: array-like, shape (K, K), noise matrix.\n    - inverse_noise_matrix: array-like, shape (K, K), inverse of the noise matrix.\n    - py_method: str, method to compute prior probabilities ('cnt', 'eqn', 'marginal', 'marginal_ps').\n    - true_labels_class_counts: array-like, shape (K,), counts of true class labels.\n\n    Returns:\n    - py: array, shape (K,) or (1, K), prior probability of each true class label.\n    \"\"\"\n    # Validate input shapes\n    K = len(true_labels_class_counts)\n    if ps.shape not in [(K,), (1, K)]:\n        raise ValueError(\"ps must have shape (K,) or (1, K)\")\n    if noise_matrix.shape != (K, K):\n        raise ValueError(\"noise_matrix must have shape (K, K)\")\n    if inverse_noise_matrix.shape != (K, K):\n        raise ValueError(\"inverse_noise_matrix must have shape (K, K)\")\n\n    # Initialize py\n    py = np.zeros(K)\n\n    # Compute py based on the specified method\n    if py_method == 'cnt':\n        # Use true label class counts to compute prior probabilities\n        total_count = np.sum(true_labels_class_counts)\n        if total_count == 0:\n            raise ValueError(\"Sum of true_labels_class_counts must be greater than 0\")\n        py = true_labels_class_counts / total_count\n\n    elif py_method == 'eqn':\n        # Use the equation method: py = inverse_noise_matrix @ ps\n        py = inverse_noise_matrix @ ps\n        py = py.flatten()\n\n    elif py_method == 'marginal':\n        # Use the marginal method: py = noise_matrix.T @ ps\n        py = noise_matrix.T @ ps\n        py = py.flatten()\n\n    elif py_method == 'marginal_ps':\n        # Use the marginal_ps method: py = ps\n        py = ps.flatten()\n\n    else:\n        raise ValueError(\"Invalid py_method. Choose from 'cnt', 'eqn', 'marginal', 'marginal_ps'.\")\n\n    # Clip py to ensure values are between 0 and 1\n    py = np.clip(py, 0, 1)\n\n    return py\n\n# Example usage:\n# ps = np.array([0.2, 0.3, 0.5])\n# noise_matrix = np.array([[0.9, 0.05, 0.05], [0.1, 0.8, 0.1], [0.05, 0.05, 0.9]])\n# inverse_noise_matrix = np.linalg.inv(noise_matrix)\n# true_labels_class_counts = np.array([50, 30, 20])\n# py_method = 'cnt'\n# py = compute_py(ps, noise_matrix, inverse_noise_matrix, py_method, true_labels_class_counts)\n# print(py)\n```\n\nThis function handles different methods for computing the prior probabilities and includes error handling for invalid input shapes and missing parameters. The output is clipped to ensure all values are between 0 and 1.",
    "prompt": "Generate a Python function called compute_py that computes the prior probability of true class labels based on observed noisy labels, noise matrices, and inverse noise matrices. The function takes in parameters ps, noise_matrix, inverse_noise_matrix, py_method, and true_labels_class_counts. The function returns an array py of shape (K,) or (1, K) containing the prior probability of each true class label. The function includes error handling for invalid input shapes and missing parameters, and uses different methods (cnt, eqn, marginal, marginal_ps) to compute the prior probabilities based on the specified py_method. The output array py is clipped to ensure values are between 0 and 1.",
    "function_name": "compute_py",
    "ground_truth": "cleanlab/internal/latent_algebra.py",
    "test": "tests/test_latent_algebra.py",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "",
    "data": "Table"
}