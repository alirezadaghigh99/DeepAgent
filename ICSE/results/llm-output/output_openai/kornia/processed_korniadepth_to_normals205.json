{
    "result": "To create the `depth_to_normals` function, we need to compute the surface normals from a depth image using the camera intrinsics. The process involves converting depth values to 3D points, computing the gradients of these points, and then calculating the cross product to find the normals. Here's how you can implement this in Python using PyTorch:\n\n```python\nimport torch\n\ndef depth_to_normals(depth, camera_matrix, normalize_points=False):\n    # Validate input types\n    if not isinstance(depth, torch.Tensor):\n        raise TypeError(\"depth must be a Tensor\")\n    if not isinstance(camera_matrix, torch.Tensor):\n        raise TypeError(\"camera_matrix must be a Tensor\")\n    \n    # Validate input shapes\n    if depth.ndim != 4 or depth.shape[1] != 1:\n        raise ValueError(\"depth must have shape (B, 1, H, W)\")\n    if camera_matrix.ndim != 3 or camera_matrix.shape[1:] != (3, 3):\n        raise ValueError(\"camera_matrix must have shape (B, 3, 3)\")\n    \n    B, _, H, W = depth.shape\n    \n    # Create a mesh grid for pixel coordinates\n    y, x = torch.meshgrid(torch.arange(H, device=depth.device), torch.arange(W, device=depth.device))\n    y = y.expand(B, -1, -1)\n    x = x.expand(B, -1, -1)\n    \n    # Unpack camera intrinsics\n    fx = camera_matrix[:, 0, 0].view(B, 1, 1)\n    fy = camera_matrix[:, 1, 1].view(B, 1, 1)\n    cx = camera_matrix[:, 0, 2].view(B, 1, 1)\n    cy = camera_matrix[:, 1, 2].view(B, 1, 1)\n    \n    # Convert depth to 3D points\n    z = depth[:, 0, :, :]\n    x3d = (x - cx) * z / fx\n    y3d = (y - cy) * z / fy\n    points_3d = torch.stack((x3d, y3d, z), dim=1)\n    \n    if normalize_points:\n        points_3d = points_3d / torch.norm(points_3d, dim=1, keepdim=True)\n    \n    # Compute gradients\n    dzdx = torch.gradient(z, dim=2)[0]\n    dzdy = torch.gradient(z, dim=1)[0]\n    \n    # Compute normals using cross product\n    normals = torch.cross(\n        torch.stack((torch.ones_like(dzdx), torch.zeros_like(dzdx), dzdx), dim=1),\n        torch.stack((torch.zeros_like(dzdy), torch.ones_like(dzdy), dzdy), dim=1),\n        dim=1\n    )\n    \n    # Normalize the normals\n    normals = normals / torch.norm(normals, dim=1, keepdim=True)\n    \n    return normals\n\n# Example usage:\n# depth = torch.rand(2, 1, 480, 640)  # Example depth tensor\n# camera_matrix = torch.rand(2, 3, 3)  # Example camera intrinsics\n# normals = depth_to_normals(depth, camera_matrix, normalize_points=True)\n```\n\n### Explanation:\n- **Input Validation**: The function checks if the inputs are tensors and have the correct shapes.\n- **Meshgrid Creation**: A meshgrid of pixel coordinates is created to map each pixel to its corresponding 3D point.\n- **3D Point Conversion**: Using the camera intrinsics, the depth values are converted to 3D points.\n- **Gradient Calculation**: The gradients of the depth map are computed to find the changes in depth along the x and y axes.\n- **Normal Calculation**: The cross product of the gradients is used to compute the surface normals.\n- **Normalization**: The normals are normalized to unit vectors.\n\nThis function should work efficiently with PyTorch tensors and can be used in a deep learning pipeline where depth images are processed to compute surface normals.",
    "prompt": "Create a Python function `depth_to_normals` that:\n\n- Computes the surface normals per pixel from a depth image.\n- Accepts the following parameters:\n  - `depth`: A tensor of shape `(B, 1, H, W)` containing depth values.\n  - `camera_matrix`: A tensor of shape `(B, 3, 3)` representing the camera intrinsics.\n  - `normalize_points`: A boolean indicating whether to normalize the point cloud. This is necessary when depth values represent Euclidean distances from the camera position.\n- Returns a tensor with a normal vector per pixel of shape `(B, 3, H, W)`.\n\nErrors:\n- Raises `TypeError` if `depth` or `camera_matrix` is not a Tensor.\n- Raises `ValueError` if `depth` does not have the shape `(B, 1, H, W)` or `camera_matrix` does not have the shape `(B, 3, 3)`.",
    "function_name": "depth_to_normals",
    "ground_truth": "kornia/geometry/depth.py",
    "test": "tests/geometry/test_depth.py::TestDepthToNormals",
    "class": "",
    "stage": "Model Construction",
    "task": "Segmentation",
    "data": "Image"
}