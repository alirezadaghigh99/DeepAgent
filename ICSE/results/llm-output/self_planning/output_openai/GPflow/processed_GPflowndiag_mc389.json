{
    "result": "Here's the complete implementation of the `ndiag_mc` function, following the structured approach you outlined:\n\n```python\nimport tensorflow as tf\nfrom typing import Callable, Iterable, Union, Optional\nfrom gpflow.base import TensorType\n\n@check_shapes(\n    \"Fmu: [N, Din]\",\n    \"Fvar: [N, Din]\",\n    \"Ys.values(): [broadcast N, .]\",\n    \"return: [broadcast n_funs, N, P]\",\n)\ndef ndiag_mc(\n    funcs: Union[Callable[..., tf.Tensor], Iterable[Callable[..., tf.Tensor]]],\n    S: int,\n    Fmu: TensorType,\n    Fvar: TensorType,\n    logspace: bool = False,\n    epsilon: Optional[TensorType] = None,\n    **Ys: TensorType,\n) -> tf.Tensor:\n    \"\"\"\n    Computes N Gaussian expectation integrals of one or more functions\n    using Monte Carlo samples. The Gaussians must be independent.\n\n    `Fmu`, `Fvar`, `Ys` should all have same shape, with overall size `N`.\n\n    :param funcs: the integrand(s):\n        Callable or Iterable of Callables that operates elementwise\n    :param S: number of Monte Carlo sampling points\n    :param Fmu: array/tensor\n    :param Fvar: array/tensor\n    :param logspace: if True, funcs are the log-integrands and this calculates\n        the log-expectation of exp(funcs)\n    :param Ys: arrays/tensors; deterministic arguments to be passed by name\n    :return: shape is the same as that of the first Fmu\n    \"\"\"\n    # Ensure funcs is iterable\n    if not isinstance(funcs, Iterable):\n        funcs = [funcs]\n    \n    n_funs = len(funcs)\n    N, Din = tf.shape(Fmu)[0], tf.shape(Fmu)[1]\n    \n    # Generate epsilon if not provided\n    if epsilon is None:\n        epsilon = tf.random.normal(shape=(S, N, Din))\n    \n    # Generate samples using the reparameterization trick\n    samples = Fmu + tf.sqrt(Fvar) * epsilon  # Shape: [S, N, Din]\n    \n    results = []\n    for func in funcs:\n        # Evaluate the function on the samples\n        func_results = func(samples, **Ys)  # Shape: [S, N, P]\n        \n        if logspace:\n            # If in logspace, exponentiate the results\n            func_results = tf.exp(func_results)\n        \n        # Compute the expectation by averaging over the samples\n        expectation = tf.reduce_mean(func_results, axis=0)  # Shape: [N, P]\n        \n        if logspace:\n            # If in logspace, take the log of the expectation\n            expectation = tf.math.log(expectation)\n        \n        results.append(expectation)\n    \n    # Stack results to get the final output shape: [n_funs, N, P]\n    return tf.stack(results, axis=0)\n```\n\n### Key Points:\n- **Input Validation**: The function checks if `funcs` is iterable and wraps it in a list if not.\n- **Sampling**: Uses the reparameterization trick to generate samples from the Gaussian distribution.\n- **Function Evaluation**: Evaluates each function on the generated samples and handles the `logspace` option.\n- **Expectation Calculation**: Averages the function evaluations over the samples to approximate the expectation.\n- **Output**: Stacks the results to match the expected output shape `[n_funs, N, P]`.\n\nThis implementation is flexible and can handle multiple functions, optional logspace calculations, and optional pre-specified noise samples (`epsilon`).",
    "prompt": "Complete the following function :\n@check_shapes(\n    \"Fmu: [N, Din]\",\n    \"Fvar: [N, Din]\",\n    \"Ys.values(): [broadcast N, .]\",\n    \"return: [broadcast n_funs, N, P]\",\n)\ndef ndiag_mc(\n    funcs: Union[Callable[..., tf.Tensor], Iterable[Callable[..., tf.Tensor]]],\n    S: int,\n    Fmu: TensorType,\n    Fvar: TensorType,\n    logspace: bool = False,\n    epsilon: Optional[TensorType] = None,\n    **Ys: TensorType,\n) -> tf.Tensor:\n    \"\"\"\n    Computes N Gaussian expectation integrals of one or more functions\n    using Monte Carlo samples. The Gaussians must be independent.\n\n    `Fmu`, `Fvar`, `Ys` should all have same shape, with overall size `N`.\n\n    :param funcs: the integrand(s):\n        Callable or Iterable of Callables that operates elementwise\n    :param S: number of Monte Carlo sampling points\n    :param Fmu: array/tensor\n    :param Fvar: array/tensor\n    :param logspace: if True, funcs are the log-integrands and this calculates\n        the log-expectation of exp(funcs)\n    :param Ys: arrays/tensors; deterministic arguments to be passed by name\n    :return: shape is the same as that of the first Fmu\n    \"\"\"",
    "function_name": "ndiag_mc",
    "ground_truth": "gpflow/quadrature/deprecated.py",
    "test": "tests/gpflow/quadrature/test_quadrature.py",
    "class": "",
    "stage": "Model Construction",
    "task": "Prediction",
    "data": "tabular"
}