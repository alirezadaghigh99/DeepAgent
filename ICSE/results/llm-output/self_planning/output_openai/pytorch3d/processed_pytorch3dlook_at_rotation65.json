{
    "result": "Here's the `look_at_rotation` function implemented in Python, following the steps you outlined. This function computes a batched rotation matrix that transforms world coordinates to view coordinates, given the camera position, target point (`at`), and the `up` vector. It handles inputs as either tuples/lists or PyTorch tensors and ensures proper normalization and axis computation.\n\n```python\nimport torch\n\ndef look_at_rotation(camera_position, at, up, device='cpu'):\n    # Convert inputs to torch tensors if they are not already\n    if not isinstance(camera_position, torch.Tensor):\n        camera_position = torch.tensor(camera_position, device=device, dtype=torch.float32)\n    if not isinstance(at, torch.Tensor):\n        at = torch.tensor(at, device=device, dtype=torch.float32)\n    if not isinstance(up, torch.Tensor):\n        up = torch.tensor(up, device=device, dtype=torch.float32)\n\n    # Ensure inputs are 2D tensors\n    if camera_position.dim() == 1:\n        camera_position = camera_position.unsqueeze(0)\n    if at.dim() == 1:\n        at = at.unsqueeze(0)\n    if up.dim() == 1:\n        up = up.unsqueeze(0)\n\n    # Normalize the at and up vectors\n    at = at / at.norm(dim=1, keepdim=True)\n    up = up / up.norm(dim=1, keepdim=True)\n\n    # Calculate the z-axis\n    z_axis = at - camera_position\n    z_axis = z_axis / z_axis.norm(dim=1, keepdim=True)\n\n    # Calculate the x-axis\n    x_axis = torch.cross(up, z_axis)\n    x_axis_norm = x_axis.norm(dim=1, keepdim=True)\n    \n    # Handle cases where the x-axis is close to zero\n    if torch.any(x_axis_norm < 1e-6):\n        # Adjust the up vector slightly\n        up = up + torch.tensor([0.001, 0.001, 0.001], device=device, dtype=torch.float32)\n        x_axis = torch.cross(up, z_axis)\n        x_axis_norm = x_axis.norm(dim=1, keepdim=True)\n    \n    x_axis = x_axis / x_axis_norm\n\n    # Calculate the y-axis\n    y_axis = torch.cross(z_axis, x_axis)\n    y_axis = y_axis / y_axis.norm(dim=1, keepdim=True)\n\n    # Form the rotation matrix\n    R = torch.stack((x_axis, y_axis, z_axis), dim=2)\n\n    # Transpose the rotation matrix\n    R = R.transpose(1, 2)\n\n    return R\n```\n\n### Key Points:\n- **Input Handling:** The function checks if the inputs are already tensors and converts them if necessary. It also ensures that the inputs are 2D tensors, which is important for batch processing.\n- **Normalization:** The `at` and `up` vectors are normalized to ensure they are unit vectors.\n- **Axis Calculation:** The function calculates the `z_axis` as the direction from the camera to the target, the `x_axis` as perpendicular to both `up` and `z_axis`, and the `y_axis` as perpendicular to both `z_axis` and `x_axis`.\n- **Edge Case Handling:** If the `x_axis` is close to zero, the function slightly adjusts the `up` vector to avoid numerical instability.\n- **Matrix Construction:** The rotation matrix is constructed by stacking the axes and then transposing it to switch from world to view coordinates.\n\nThis function should work efficiently for both single and batched inputs, making it versatile for various applications in computer graphics and vision tasks.",
    "prompt": "Generate a Python function called look_at_rotation that takes in the camera_position, at, up vectors, and device type as inputs. The function returns a batched rotation matrix R representing the transformation from world coordinates to view coordinates. The camera_position, at, and up vectors can be 3-element tuples/lists or torch tensors of shape (1, 3) or (N, 3), where N is the batch size. The function normalizes the input vectors, calculates the x, y, and z axes, and handles cases where the x-axis is close to zero. Finally, it concatenates the axes to form the rotation matrix R and returns the transposed matrix.",
    "function_name": "look_at_rotation",
    "ground_truth": "pytorch3d/renderer/cameras.py",
    "test": "tests/test_cameras.py",
    "class": "",
    "stage": "Model Construction",
    "task": "Detection",
    "data": "Image"
}