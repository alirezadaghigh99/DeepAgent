{
    "result": "Here's the `greedy_coreset` function, which implements the greedy coreset selection process as described. This function efficiently selects a subset of data points from a larger dataset based on specified criteria, using either cosine or Euclidean distance metrics. It also supports optional data normalization and batch processing to handle large datasets.\n\n```python\nimport numpy as np\nfrom scipy.spatial.distance import cdist\n\ndef greedy_coreset(x, indices_unlabeled, indices_labeled, n, distance_metric='euclidean', batch_size=None, normalized=False):\n    # Validate inputs\n    if not isinstance(n, int) or n <= 0 or n > len(indices_unlabeled):\n        raise ValueError(\"n must be a positive integer and less than or equal to the number of unlabeled indices.\")\n    if distance_metric not in ['cosine', 'euclidean']:\n        raise ValueError(\"distance_metric must be either 'cosine' or 'euclidean'.\")\n    \n    # Normalize data if required\n    if normalized:\n        x = x / np.linalg.norm(x, axis=1, keepdims=True)\n    \n    # Initialize selected indices list\n    selected_indices = []\n    \n    # Compute initial distances from labeled to unlabeled points\n    unlabeled_data = x[indices_unlabeled]\n    labeled_data = x[indices_labeled]\n    distances = cdist(unlabeled_data, labeled_data, metric=distance_metric)\n    \n    # Greedy selection process\n    for _ in range(n):\n        # Find the index of the unlabeled point farthest from the current coreset\n        if selected_indices:\n            coreset_data = x[selected_indices]\n            new_distances = cdist(unlabeled_data, coreset_data, metric=distance_metric)\n            min_distances = np.minimum(distances.min(axis=1), new_distances.min(axis=1))\n        else:\n            min_distances = distances.min(axis=1)\n        \n        # Select the point with the maximum minimum distance\n        farthest_index = np.argmax(min_distances)\n        selected_indices.append(indices_unlabeled[farthest_index])\n        \n        # Update distances\n        if batch_size:\n            # Process in batches if batch_size is specified\n            for start in range(0, len(unlabeled_data), batch_size):\n                end = start + batch_size\n                batch_distances = cdist(unlabeled_data[start:end], x[selected_indices], metric=distance_metric)\n                distances[start:end] = np.minimum(distances[start:end], batch_distances)\n        else:\n            # Update distances without batching\n            new_distances = cdist(unlabeled_data, x[selected_indices], metric=distance_metric)\n            distances = np.minimum(distances, new_distances)\n    \n    return np.array(selected_indices)\n```\n\n### Key Points:\n- **Input Validation**: Ensures that the inputs are valid, such as checking that `n` is a positive integer and within the range of available unlabeled indices.\n- **Normalization**: If `normalized` is `True`, the function normalizes the data to unit vectors, which is often necessary for cosine distance calculations.\n- **Distance Calculation**: Uses `cdist` from `scipy.spatial.distance` to compute pairwise distances efficiently.\n- **Greedy Selection**: Iteratively selects the point that is farthest from the current set of selected points, updating the list of selected indices.\n- **Batch Processing**: If `batch_size` is specified, the function processes data in batches to manage memory usage, which is crucial for large datasets.\n\nThis function is designed to be efficient and flexible, making it suitable for various applications where a representative subset of data is needed.",
    "prompt": "Generate a Python function called greedy_coreset that computes a greedy coreset over a matrix x with a specified size n. The function takes in the following parameters: x (a numpy array of row-wise vector representations), indices_unlabeled (an array of indices for unlabeled data), indices_labeled (an array of indices for labeled data), n (the size of the coreset), distance_metric (either 'cosine' or 'euclidean' for the distance metric), batch_size (an integer for batch size), and normalized (a boolean indicating if the data should be normalized).\n\nThe function returns an array of indices relative to x.",
    "function_name": "greedy_coreset",
    "ground_truth": "small_text/query_strategies/coresets.py",
    "test": "tests/unit/small_text/query_strategies/test_coresets.py::GreedyCoresetSamplingStrategyNormalizedTest",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "Classification",
    "data": "Text"
}