{
    "result": "To create a function that generates a random text classification dataset, we need to follow the steps outlined in your plan. The function will generate random text samples and labels, ensure all target labels are present, and return a dataset object. Here's the complete implementation:\n\n```python\nimport random\nimport torch\nfrom torchtext.data import Dataset, Example, Field\n\nclass PytorchTextClassificationDataset(Dataset):\n    def __init__(self, examples, fields, vocab, multi_label, target_labels):\n        super().__init__(examples, fields)\n        self.vocab = vocab\n        self.multi_label = multi_label\n        self.target_labels = target_labels\n\ndef random_text_classification_dataset(num_samples, max_length, num_classes, multi_label=False, vocab_size=1000, device='cpu', target_labels=None, dtype=torch.long):\n    # Initialize lists for samples and labels\n    text_samples = []\n    labels = []\n\n    # Generate random text samples and labels\n    for _ in range(num_samples):\n        # Generate a random text sample\n        text_sample = [random.randint(0, vocab_size - 1) for _ in range(random.randint(1, max_length))]\n        text_samples.append(text_sample)\n\n        # Generate random labels\n        if multi_label:\n            label = list(set(random.randint(0, num_classes - 1) for _ in range(random.randint(1, num_classes))))\n        else:\n            label = random.randint(0, num_classes - 1)\n        labels.append(label)\n\n    # Ensure all target labels occur in the dataset\n    if target_labels is not None:\n        for label in target_labels:\n            if label not in labels:\n                # Add a sample with the missing label\n                text_sample = [random.randint(0, vocab_size - 1) for _ in range(random.randint(1, max_length))]\n                text_samples.append(text_sample)\n                if multi_label:\n                    labels.append([label])\n                else:\n                    labels.append(label)\n\n    # Create a vocabulary\n    vocab = {i: f\"word_{i}\" for i in range(vocab_size)}\n\n    # Define fields\n    TEXT = Field(sequential=True, use_vocab=False, pad_token=0, dtype=dtype)\n    LABEL = Field(sequential=multi_label, use_vocab=False, dtype=dtype)\n\n    # Create examples\n    examples = [Example.fromlist([text, label], [('text', TEXT), ('label', LABEL)]) for text, label in zip(text_samples, labels)]\n\n    # Create dataset\n    dataset = PytorchTextClassificationDataset(examples, fields=[('text', TEXT), ('label', LABEL)], vocab=vocab, multi_label=multi_label, target_labels=target_labels)\n\n    return dataset\n\n# Example usage\ndataset = random_text_classification_dataset(\n    num_samples=100,\n    max_length=10,\n    num_classes=5,\n    multi_label=True,\n    vocab_size=50,\n    target_labels=[0, 1, 2, 3, 4]\n)\n\nprint(f\"Number of samples: {len(dataset)}\")\nprint(f\"Vocabulary: {dataset.vocab}\")\nprint(f\"Multi-label: {dataset.multi_label}\")\nprint(f\"Target labels: {dataset.target_labels}\")\n```\n\n### Key Points:\n- **Random Text Samples**: Each text sample is a list of random integers representing word indices.\n- **Labels**: Depending on the `multi_label` flag, labels are either single integers or lists of integers.\n- **Ensuring All Labels**: The function checks if all `target_labels` are present and adds missing ones if necessary.\n- **Vocabulary**: A simple mapping from indices to \"word\" strings is created.\n- **Dataset Object**: The `PytorchTextClassificationDataset` class is used to encapsulate the dataset, including the vocabulary and label settings.\n\nThis implementation should meet the requirements and provide a flexible way to generate random text classification datasets for testing and experimentation.",
    "prompt": "Generate a Python function called random_text_classification_dataset that generates a random text classification dataset. The function takes in parameters such as num_samples, max_length, num_classes, multi_label, vocab_size, device, target_labels, and dtype. It returns a PytorchTextClassificationDataset object with the generated dataset, vocabulary, multi_label setting, and target labels. The function ensures that all labels occur in the dataset and handles different scenarios based on the input parameters.",
    "function_name": "random_text_classification_dataset",
    "ground_truth": "tests/utils/datasets.py",
    "test": "tests/unit/small_text/initialization/test_strategies.py::RandomInitializationStratifiedTest",
    "class": "",
    "stage": "Pre-Post processing",
    "task": "Classification",
    "data": "Text"
}