{
    "result": "Let's implement the `accuracy_score` function based on the provided plan. This function will calculate the accuracy of classification predictions, taking into account optional sample weights and a choice between returning a normalized score or a raw count of correct predictions.\n\nHere's the implementation:\n\n```python\ndef accuracy_score(y_true, y_pred, normalize=True, sample_weight=None):\n    \"\"\"\n    Calculate the accuracy classification score.\n\n    Parameters:\n    - y_true: list or array-like of shape (n_samples,)\n        Ground truth (correct) labels.\n    - y_pred: list or array-like of shape (n_samples,)\n        Predicted labels, as returned by a classifier.\n    - normalize: bool, default=True\n        If True, return the fraction of correctly classified samples.\n        Otherwise, return the number of correctly classified samples.\n    - sample_weight: list or array-like of shape (n_samples,), default=None\n        Sample weights.\n\n    Returns:\n    - score: float or int\n        If normalize is True, return the fraction of correctly classified samples (float).\n        If normalize is False, return the number of correctly classified samples (int).\n    \"\"\"\n    if len(y_true) != len(y_pred):\n        raise ValueError(\"The length of y_true and y_pred must be the same.\")\n\n    # Calculate the number of correct predictions\n    correct_predictions = [yt == yp for yt, yp in zip(y_true, y_pred)]\n\n    if sample_weight is not None:\n        if len(sample_weight) != len(y_true):\n            raise ValueError(\"The length of sample_weight must be the same as y_true and y_pred.\")\n        # Apply sample weights\n        correct_predictions = [w * c for w, c in zip(sample_weight, correct_predictions)]\n\n    # Calculate the score\n    correct_count = sum(correct_predictions)\n    \n    if normalize:\n        total_count = sum(sample_weight) if sample_weight is not None else len(y_true)\n        return correct_count / total_count\n    else:\n        return correct_count\n\n# Examples\ny_true = [0, 1, 2, 2, 1]\ny_pred = [0, 2, 2, 2, 1]\n\n# Example 1: Without sample weights, normalized\nprint(accuracy_score(y_true, y_pred))  # Output: 0.8\n\n# Example 2: Without sample weights, not normalized\nprint(accuracy_score(y_true, y_pred, normalize=False))  # Output: 4\n\n# Example 3: With sample weights, normalized\nsample_weight = [0.5, 1, 1, 1, 0.5]\nprint(accuracy_score(y_true, y_pred, sample_weight=sample_weight))  # Output: 0.75\n\n# Example 4: With sample weights, not normalized\nprint(accuracy_score(y_true, y_pred, normalize=False, sample_weight=sample_weight))  # Output: 3.0\n```\n\n### Explanation:\n1. **Correct Predictions**: We first determine which predictions are correct by comparing `y_true` and `y_pred`.\n2. **Sample Weights**: If `sample_weight` is provided, we apply these weights to the correct predictions.\n3. **Normalization**: If `normalize` is `True`, we return the fraction of correct predictions. Otherwise, we return the raw count.\n4. **Examples**: The examples demonstrate how to use the function with and without sample weights, and with both normalized and non-normalized outputs.",
    "prompt": "Generate a Python function called accuracy_score that calculates the accuracy classification score. The function takes in the following parameters:\n\n- y_true: Ground truth (correct) labels\n- y_pred: Predicted labels\n- normalize: Boolean value indicating whether to return the fraction of correctly classified samples or the number of correctly classified samples\n- sample_weight: Sample weights\n\nThe function returns a float or integer value based on the normalize parameter. The best performance is 1 when normalize is True and the number of samples when normalize is False.\n\nThe function also includes examples demonstrating how to use it with different inputs.",
    "function_name": "accuracy_score",
    "ground_truth": "sklearn/metrics/_classification.py",
    "test": "sklearn/metrics/tests/test_classification.py",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "Classification",
    "data": ""
}