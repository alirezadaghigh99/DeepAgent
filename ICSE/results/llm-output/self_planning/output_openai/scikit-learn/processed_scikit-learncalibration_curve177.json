{
    "result": "Let's focus on implementing the `calibration_curve` function as described in your request. This function will compute the true and predicted probabilities for a calibration curve based on the given parameters. Here's how you can implement it:\n\n```python\nimport numpy as np\nfrom sklearn.utils import check_array\nfrom sklearn.utils import column_or_1d\nfrom sklearn.preprocessing import label_binarize\n\ndef calibration_curve(y_true, y_prob, pos_label=None, n_bins=5, strategy='uniform'):\n    \"\"\"\n    Compute true and predicted probabilities for a calibration curve.\n\n    Parameters\n    ----------\n    y_true : array-like of shape (n_samples,)\n        True targets.\n    y_prob : array-like of shape (n_samples,)\n        Probabilities of the positive class.\n    pos_label : int, float, bool, or str, default=None\n        The label of the positive class.\n    n_bins : int, default=5\n        Number of bins to discretize the [0, 1] interval.\n    strategy : {'uniform', 'quantile'}, default='uniform'\n        Strategy used to define the widths of the bins.\n\n    Returns\n    -------\n    prob_true : ndarray of shape (n_bins,) or smaller\n        Proportion of samples whose class is the positive class in each bin.\n    prob_pred : ndarray of shape (n_bins,) or smaller\n        Mean predicted probability in each bin.\n    \"\"\"\n    y_true = column_or_1d(y_true)\n    y_prob = column_or_1d(y_prob)\n    \n    if pos_label is None:\n        pos_label = 1.0\n\n    y_true = label_binarize(y_true, classes=[pos_label, 1 - pos_label]).ravel()\n\n    if strategy not in ['uniform', 'quantile']:\n        raise ValueError(\"Invalid strategy: '{}'. Strategy must be 'uniform' or 'quantile'.\".format(strategy))\n\n    if strategy == 'uniform':\n        bins = np.linspace(0., 1., n_bins + 1)\n    elif strategy == 'quantile':\n        bins = np.percentile(y_prob, np.linspace(0, 100, n_bins + 1))\n\n    binids = np.digitize(y_prob, bins) - 1\n\n    prob_true = np.zeros(n_bins)\n    prob_pred = np.zeros(n_bins)\n\n    for i in range(n_bins):\n        mask = binids == i\n        if np.any(mask):\n            prob_true[i] = y_true[mask].mean()\n            prob_pred[i] = y_prob[mask].mean()\n\n    return prob_true, prob_pred\n\n# Example usage\nif __name__ == \"__main__\":\n    y_true = np.array([0, 0, 1, 1])\n    y_prob = np.array([0.1, 0.4, 0.35, 0.8])\n    prob_true, prob_pred = calibration_curve(y_true, y_prob, pos_label=1, n_bins=3, strategy='uniform')\n    print(\"True probabilities:\", prob_true)\n    print(\"Predicted probabilities:\", prob_pred)\n```\n\n### Explanation:\n\n1. **Input Validation**: The function first ensures that `y_true` and `y_prob` are 1-dimensional arrays. It also binarizes `y_true` to ensure it only contains binary values (0 and 1).\n\n2. **Binning Strategy**: Depending on the `strategy` parameter, the function creates bins either uniformly or based on quantiles of `y_prob`.\n\n3. **Bin Assignment**: Each probability in `y_prob` is assigned to a bin using `np.digitize`.\n\n4. **Probability Calculation**: For each bin, the function calculates the mean of the true labels (`prob_true`) and the mean of the predicted probabilities (`prob_pred`).\n\n5. **Return Values**: The function returns the arrays `prob_true` and `prob_pred`, which can be used to plot a calibration curve.\n\n### Example Usage:\nThe example at the end demonstrates how to use the function with sample data. You can adjust the `n_bins` and `strategy` parameters to see how they affect the calibration curve.",
    "prompt": "Generate a Python function called calibration_curve that computes true and predicted probabilities for a calibration curve. The function takes in the following parameters:\n\n- y_true: array-like of shape (n_samples), representing the true targets.\n- y_prob: array-like of shape (n_samples), representing the probabilities of the positive class.\n- pos_label: int, float, bool, or str, default=None, indicating the label of the positive class.\n- n_bins: int, default=5, specifying the number of bins to discretize the [0, 1] interval.\n- strategy: {'uniform', 'quantile'}, default='uniform', determining the strategy used to define the widths of the bins.\n\nThe function returns two arrays:\n- prob_true: ndarray of shape (n_bins,) or smaller, representing the proportion of samples whose class is the positive class in each bin (fraction of positives).\n- prob_pred: ndarray of shape (n_bins,) or smaller, representing the mean predicted probability in each bin.\n\nThe function also includes examples demonstrating how to use it with sample data.",
    "function_name": "calibration_curve",
    "ground_truth": "sklearn/calibration.py",
    "test": "sklearn/tests/test_calibration.py::test_calibration_display_pos_label",
    "class": "",
    "stage": "Inference",
    "task": "Classification",
    "data": "Table"
}