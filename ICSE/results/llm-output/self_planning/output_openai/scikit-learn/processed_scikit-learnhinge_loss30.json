{
    "result": "Let's implement the `hinge_loss` function step by step, following the plan you provided. This function will handle both binary and multiclass classification tasks, compute the hinge loss, and return the average hinge loss. We'll use NumPy for efficient computation.\n\n```python\nimport numpy as np\n\ndef hinge_loss(y_true, pred_decision, labels=None, sample_weight=None):\n    \"\"\"\n    Calculate the average hinge loss for binary or multiclass classification tasks.\n\n    Parameters:\n    - y_true: array-like, true target values encoded as integers (+1 and -1 for binary classification).\n    - pred_decision: array-like, predicted decision values.\n    - labels: optional, array-like, all labels for multiclass hinge loss.\n    - sample_weight: optional, array-like, sample weights.\n\n    Returns:\n    - float, average hinge loss.\n    \"\"\"\n    y_true = np.asarray(y_true)\n    pred_decision = np.asarray(pred_decision)\n\n    # Determine if it's binary or multiclass classification\n    unique_labels = np.unique(y_true)\n    if labels is not None:\n        unique_labels = np.asarray(labels)\n    \n    if len(unique_labels) == 2:\n        # Binary classification\n        # Ensure y_true is in the form of +1 and -1\n        if set(unique_labels) != {1, -1}:\n            raise ValueError(\"For binary classification, y_true should contain only +1 and -1.\")\n        \n        # Calculate hinge loss for binary classification\n        losses = np.maximum(0, 1 - y_true * pred_decision)\n    else:\n        # Multiclass classification\n        if labels is None:\n            raise ValueError(\"For multiclass classification, 'labels' parameter must be provided.\")\n        \n        # One-vs-all approach for multiclass hinge loss\n        num_classes = len(unique_labels)\n        losses = []\n        for i, label in enumerate(unique_labels):\n            # Create binary labels for the current class\n            binary_y_true = np.where(y_true == label, 1, -1)\n            # Calculate hinge loss for the current class\n            class_losses = np.maximum(0, 1 - binary_y_true * pred_decision[:, i])\n            losses.append(class_losses)\n        \n        # Stack losses and take the mean across classes\n        losses = np.mean(np.stack(losses, axis=1), axis=1)\n\n    # Apply sample weights if provided\n    if sample_weight is not None:\n        sample_weight = np.asarray(sample_weight)\n        if sample_weight.shape[0] != losses.shape[0]:\n            raise ValueError(\"sample_weight must have the same length as y_true and pred_decision.\")\n        losses *= sample_weight\n\n    # Compute the average hinge loss\n    average_loss = np.mean(losses)\n\n    return average_loss\n\n# Example usage:\n# y_true = np.array([1, -1, 1, -1])\n# pred_decision = np.array([0.8, -0.5, 0.3, -0.2])\n# print(hinge_loss(y_true, pred_decision))\n```\n\n### Explanation:\n\n1. **Input Handling**: Convert `y_true` and `pred_decision` to NumPy arrays for efficient computation.\n\n2. **Classification Type**: Determine if the task is binary or multiclass based on the number of unique labels. For binary classification, ensure `y_true` contains only +1 and -1.\n\n3. **Hinge Loss Calculation**:\n   - **Binary Classification**: Use the formula `max(0, 1 - y_true * pred_decision)`.\n   - **Multiclass Classification**: Use a one-vs-all approach, calculating hinge loss for each class and averaging across classes.\n\n4. **Sample Weights**: If provided, apply sample weights to the hinge loss values.\n\n5. **Average Loss**: Compute and return the average hinge loss.\n\nThis implementation should handle both binary and multiclass classification tasks, providing flexibility and robustness.",
    "prompt": "Create a Python function called hinge_loss that calculates the average hinge loss for binary or multiclass classification tasks. The function takes in the following parameters:\n\n- y_true: an array-like object containing the true target values, encoded as integers (+1 and -1 for binary classification).\n- pred_decision: an array-like object containing the predicted decision values.\n- labels: an optional array-like object containing all the labels for multiclass hinge loss.\n- sample_weight: an optional array-like object containing sample weights.\n\nThe function returns the average hinge loss as a float value. The hinge loss is calculated based on the margin between the true and predicted values, and it serves as an upper bound for the number of classification mistakes made by the classifier.\n\nThe function handles both binary and multiclass cases, applying different calculations based on the number of unique labels present in the target values. The implementation includes error handling for different scenarios and utilizes NumPy functions for efficient computation.",
    "function_name": "hinge_loss",
    "ground_truth": "sklearn/metrics/_classification.py",
    "test": "sklearn/metrics/tests/test_classification.py",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "Classificatoin",
    "data": "Table"
}