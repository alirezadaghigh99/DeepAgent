{
    "result": "Here's the implementation of the `ndcg_score` function based on the structured approach you provided. This function computes the Normalized Discounted Cumulative Gain (NDCG) for multilabel classification tasks:\n\n```python\nimport numpy as np\n\ndef ndcg_score(y_true, y_score, k=None, sample_weight=None, ignore_ties=False):\n    # Ensure inputs are numpy arrays\n    y_true = np.asarray(y_true)\n    y_score = np.asarray(y_score)\n    \n    # Validate k\n    if k is not None and (not isinstance(k, int) or k <= 0):\n        raise ValueError(\"k should be a positive integer or None.\")\n    \n    # Validate sample_weight\n    if sample_weight is not None:\n        sample_weight = np.asarray(sample_weight)\n        if sample_weight.shape[0] != y_true.shape[0]:\n            raise ValueError(\"sample_weight should have the same number of samples as y_true.\")\n    \n    # Function to compute DCG\n    def dcg(scores, k):\n        if k is not None:\n            scores = scores[:k]\n        return np.sum((2**scores - 1) / np.log2(np.arange(2, scores.size + 2)))\n    \n    # Compute NDCG for each sample\n    ndcg_scores = []\n    for true, score in zip(y_true, y_score):\n        # Sort true scores by predicted scores\n        order = np.argsort(score)[::-1]\n        true_sorted_by_score = true[order]\n        \n        # Compute DCG\n        dcg_value = dcg(true_sorted_by_score, k)\n        \n        # Compute IDCG\n        ideal_order = np.argsort(true)[::-1]\n        true_sorted_by_ideal = true[ideal_order]\n        idcg_value = dcg(true_sorted_by_ideal, k)\n        \n        # Compute NDCG\n        if idcg_value == 0:\n            ndcg_scores.append(0.0)\n        else:\n            ndcg_scores.append(dcg_value / idcg_value)\n    \n    # Aggregate results\n    ndcg_scores = np.array(ndcg_scores)\n    if sample_weight is not None:\n        return np.average(ndcg_scores, weights=sample_weight)\n    else:\n        return np.mean(ndcg_scores)\n\n```\n\n### Explanation\n\n- **Input Validation and Preparation:**\n  - The function ensures that `y_true` and `y_score` are numpy arrays for efficient computation.\n  - It checks that `k` is either `None` or a positive integer.\n  - If `sample_weight` is provided, it ensures that it matches the number of samples in `y_true`.\n\n- **DCG Calculation:**\n  - The `dcg` function computes the Discounted Cumulative Gain by applying a logarithmic discount to the true scores sorted by predicted scores.\n\n- **IDCG Calculation:**\n  - The Ideal DCG (IDCG) is computed by sorting the true scores in descending order, representing the best possible ranking.\n\n- **NDCG Calculation:**\n  - The NDCG is the ratio of DCG to IDCG, providing a normalized score between 0 and 1.\n  - The function handles cases where IDCG is zero to prevent division by zero errors.\n\n- **Aggregation:**\n  - If `sample_weight` is provided, the function computes a weighted average of the NDCG scores; otherwise, it computes a simple average.\n\nThis implementation provides a robust and efficient way to compute the NDCG score for multilabel classification tasks, taking into account various parameters and edge cases.",
    "prompt": "Generate a Python function called ndcg_score that Compute Normalized Discounted Cumulative Gain.\n\n    Sum the true scores ranked in the order induced by the predicted scores,\n    after applying a logarithmic discount. Then divide by the best possible\n    score (Ideal DCG, obtained for a perfect ranking) to obtain a score between\n    0 and 1.\n\n    This ranking metric returns a high value if true labels are ranked high by\n    ``y_score``.\n\n    Parameters\n    ----------\n    y_true : array-like of shape (n_samples, n_labels)\n        True targets of multilabel classification, or true scores of entities\n        to be ranked. Negative values in `y_true` may result in an output\n        that is not between 0 and 1.\n\n    y_score : array-like of shape (n_samples, n_labels)\n        Target scores, can either be probability estimates, confidence values,\n        or non-thresholded measure of decisions (as returned by\n        \"decision_function\" on some classifiers).\n\n    k : int, default=None\n        Only consider the highest k scores in the ranking. If `None`, use all\n        outputs.\n\n    sample_weight : array-like of shape (n_samples,), default=None\n        Sample weights. If `None`, all samples are given the same weight.\n\n    ignore_ties : bool, default=False\n        Assume that there are no ties in y_score (which is likely to be the\n        case if y_score is continuous) for efficiency gains.\n\n    Returns\n    -------\n    normalized_discounted_cumulative_gain : float in [0., 1.]\n        The averaged NDCG scores for all samples.",
    "function_name": "ndcg_score",
    "ground_truth": "sklearn/metrics/_ranking.py",
    "test": "sklearn/metrics/tests/test_ranking.py:test_ndcg_toy_examples",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "",
    "data": "Table"
}