{
    "result": "Here's the implementation of the `confusion_matrix` function based on the plan you provided. This function calculates the confusion matrix without relying on external libraries like `sklearn`, and it assumes that the `true` and `pred` arrays have the same length and contain the same set of distinct class labels.\n\n```python\nimport numpy as np\n\ndef confusion_matrix(true, pred):\n    # Step 1: Validate input lengths\n    if len(true) != len(pred):\n        raise ValueError(\"The length of true and pred must be the same.\")\n    \n    # Step 2: Identify unique classes\n    unique_classes = np.unique(true)\n    num_classes = len(unique_classes)\n    \n    # Create a mapping from class label to index\n    class_to_index = {label: index for index, label in enumerate(unique_classes)}\n    \n    # Step 3: Initialize the confusion matrix\n    conf_matrix = np.zeros((num_classes, num_classes), dtype=int)\n    \n    # Step 4: Populate the confusion matrix\n    for t, p in zip(true, pred):\n        true_index = class_to_index[t]\n        pred_index = class_to_index[p]\n        conf_matrix[true_index, pred_index] += 1\n    \n    # Step 5: Return the confusion matrix\n    return conf_matrix\n\n# Example usage:\n# true_labels = np.array([0, 1, 2, 1, 0])\n# pred_labels = np.array([0, 2, 1, 1, 0])\n# print(confusion_matrix(true_labels, pred_labels))\n```\n\n### Explanation\n\n- **Validation:** The function first checks if the lengths of `true` and `pred` are equal. If not, it raises a `ValueError`.\n- **Unique Classes:** It uses `np.unique` to find the distinct class labels, which helps in determining the size of the confusion matrix.\n- **Class Mapping:** A dictionary `class_to_index` is created to map each class label to a corresponding index. This ensures that the confusion matrix is populated correctly even if class labels are not contiguous integers starting from 0.\n- **Matrix Initialization:** A zero matrix of size `K x K` is created, where `K` is the number of unique classes.\n- **Matrix Population:** The function iterates over each pair of true and predicted labels, updating the matrix to reflect the count of each true-predicted pair using the indices from the `class_to_index` mapping.\n- **Return:** Finally, the populated confusion matrix is returned.\n\nThis implementation is efficient and avoids external dependencies, while correctly handling the mapping of class labels to matrix indices.",
    "prompt": "Generate a Python function called confusion_matrix that iImplements a confusion matrix for true labels\n    and predicted labels. true and pred MUST BE the same length\n    and have the same distinct set of class labels represented.\n\n    Results are identical (and similar computation time) to:\n        \"sklearn.metrics.confusion_matrix\"\n\n    However, this function avoids the dependency on sklearn.\n\n    Parameters\n    ----------\n    true : np.ndarray 1d\n      Contains labels.\n      Assumes true and pred contains the same set of distinct labels.\n\n    pred : np.ndarray 1d\n      A discrete vector of noisy labels, i.e. some labels may be erroneous.\n      *Format requirements*: for dataset with K classes, labels must be in {0,1,...,K-1}.\n\n    Returns\n    -------\n    confusion_matrix : np.ndarray (2D)\n      matrix of confusion counts with true on rows and pred on columns",
    "function_name": "confusion_matrix",
    "ground_truth": "cleanlab/internal/util.py",
    "test": "tests/test_util.py",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "Classification",
    "data": "Table"
}