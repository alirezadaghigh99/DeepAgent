{
    "result": "Let's implement the `estimate_joint` function along with the necessary helper functions. We'll focus on the `estimate_joint` function, but I'll also provide a brief outline for the helper functions that are mentioned in the task description.\n\n### Function 4: `estimate_joint`\n\nThis function estimates the joint distribution of label noise \\( P(\\text{label}=i, \\text{true\\_label}=j) \\) based on the given inputs. Here's how you can implement it:\n\n```python\nimport numpy as np\n\ndef estimate_joint(labels, pred_probs, confident_joint=None, multi_label=False):\n    \"\"\"\n    Estimate the joint distribution of label noise P(label=i, true_label=j).\n\n    Parameters:\n    - labels: array-like, shape (n_samples,)\n        Class labels for each example in the dataset.\n    - pred_probs: array-like, shape (n_samples, n_classes)\n        Model-predicted class probabilities for each example in the dataset.\n    - confident_joint: array-like, optional, shape (n_classes, n_classes)\n        Estimated class label error statistics.\n    - multi_label: bool\n        Indicates whether the dataset is for multi-class or multi-label classification.\n\n    Returns:\n    - confident_joint_distribution: array-like\n        An estimate of the true joint distribution of noisy and true labels.\n    \"\"\"\n    n_classes = pred_probs.shape[1]\n\n    # Compute the confident joint if not provided\n    if confident_joint is None:\n        confident_joint = compute_confident_joint(labels, pred_probs, n_classes)\n\n    # Calibrate the confident joint\n    confident_joint = calibrate_confident_joint(confident_joint)\n\n    # Handle multi-label classification\n    if multi_label:\n        confident_joint_distribution = _estimate_joint_multilabel(confident_joint, n_classes)\n    else:\n        confident_joint_distribution = confident_joint / np.sum(confident_joint)\n\n    return confident_joint_distribution\n\ndef compute_confident_joint(labels, pred_probs, n_classes):\n    \"\"\"\n    Compute the confident joint matrix.\n    \"\"\"\n    # Initialize the confident joint matrix\n    confident_joint = np.zeros((n_classes, n_classes))\n\n    # Populate the confident joint matrix\n    for i, label in enumerate(labels):\n        predicted_class = np.argmax(pred_probs[i])\n        confident_joint[label, predicted_class] += 1\n\n    return confident_joint\n\ndef calibrate_confident_joint(confident_joint):\n    \"\"\"\n    Calibrate the confident joint to ensure it sums to 1.\n    \"\"\"\n    # Normalize the confident joint matrix\n    confident_joint = confident_joint / np.sum(confident_joint)\n    return confident_joint\n\ndef _estimate_joint_multilabel(confident_joint, n_classes):\n    \"\"\"\n    Estimate the joint distribution for multi-label classification.\n    \"\"\"\n    # Initialize the joint distribution for multi-label\n    joint_distribution = np.zeros((n_classes, 2, 2))\n\n    # Populate the joint distribution\n    for i in range(n_classes):\n        joint_distribution[i, 0, 0] = confident_joint[i, i]  # True negatives\n        joint_distribution[i, 1, 1] = confident_joint[i, i]  # True positives\n        joint_distribution[i, 0, 1] = np.sum(confident_joint[i, :]) - confident_joint[i, i]  # False positives\n        joint_distribution[i, 1, 0] = np.sum(confident_joint[:, i]) - confident_joint[i, i]  # False negatives\n\n    # Normalize the joint distribution\n    joint_distribution /= np.sum(joint_distribution)\n\n    return joint_distribution\n```\n\n### Explanation\n\n1. **`estimate_joint`**: This is the main function that estimates the joint distribution. It checks if the `confident_joint` is provided; if not, it computes it using `compute_confident_joint`. It then calibrates the joint matrix and handles multi-label classification if needed.\n\n2. **`compute_confident_joint`**: This helper function computes the confident joint matrix by iterating over the labels and predicted probabilities.\n\n3. **`calibrate_confident_joint`**: This function normalizes the confident joint matrix to ensure it sums to 1.\n\n4. **`_estimate_joint_multilabel`**: This function handles the multi-label case by constructing a joint distribution with shape \\((K, 2, 2)\\).\n\nThis implementation provides a basic framework for estimating the joint distribution of label noise. You may need to adjust the logic based on specific requirements or additional constraints.",
    "prompt": "Generate a Python function called estimate_joint that estimates the joint distribution of label noise P(label=i, true_label=j) based on the given inputs. The function takes in the following parameters:\n\n- labels: an array or list of class labels for each example in the dataset\n- pred_probs: an array of model-predicted class probabilities for each example in the dataset\n- confident_joint: an optional array of estimated class label error statistics\n- multi_label: a boolean indicating whether the dataset is for regular (multi-class) classification or multi-label classification\n\nThe function returns confident_joint_distribution, an array representing an estimate of the true joint distribution of noisy and true labels. The shape of the array depends on the value of multi_label - it will be (K, K) if multi_label is False, and (K, 2, 2) if multi_label is True. The function ensures that the sum of the joint distribution is 1 and satisfies certain conditions.\n\nThe function internally computes the confident_joint if it is not provided, and calibrates it based on the input labels and pred_probs. If multi_label is True, the function calls _estimate_joint_multilabel to handle multi-label classification.",
    "function_name": "estimate_joint",
    "ground_truth": "cleanlab/count.py",
    "test": "tests/test_filter_count.py",
    "class": "",
    "stage": "Evaluating&Metrics",
    "task": "",
    "data": "Table"
}