output file:
processed_scikit-learnscale58.json
function:
scale
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler0] FAILED', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler0] FAILED', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler0] FAILED', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler0]', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler0] FAILED', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler0]', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler0] FAILED', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler0]', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler0]', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler0] FAILED', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler0] FAILED', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler0] FAILED', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler0] FAILED', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler0] FAILED', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler0]', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler0] FAILED', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler0]', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler0]', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler0] FAILED', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler0] FAILED', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler0] FAILED', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler0]', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler0]', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler0]', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler0]', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler0]', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler0]', '../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler0] FAILED'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.9.0, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/scikit-learn/scikit-learn
configfile: setup.cfg
plugins: cov-6.0.0
collecting ... collected 120 items

../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-None-scaler0] I: Seeding RNGs with 740100902
PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler0] FAILED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_array-scaler1] SKIPPED

=================================== FAILURES ===================================
__ test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler0] __

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_matrix'>
dtype = <class 'numpy.float32'>, constant = 0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse matrix of type '<class 'numpy.float32'>'
	with 0 stored elements in Compressed Sparse Column format>, dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
__ test_standard_scaler_constant_features[0-float32-False-csc_array-scaler0] ___

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_array'>
dtype = <class 'numpy.float32'>, constant = 0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse array of type '<class 'numpy.float32'>'
	with 0 stored elements in Compressed Sparse Column format>, dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
__ test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler0] __

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_matrix'>
dtype = <class 'numpy.float32'>, constant = 0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse matrix of type '<class 'numpy.float32'>'
	with 0 stored elements in Compressed Sparse Row format>, dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
__ test_standard_scaler_constant_features[0-float32-False-csr_array-scaler0] ___

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_array'>
dtype = <class 'numpy.float32'>, constant = 0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse array of type '<class 'numpy.float32'>'
	with 0 stored elements in Compressed Sparse Row format>, dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
__ test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler0] __

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_matrix'>
dtype = <class 'numpy.float64'>, constant = 0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Column format>, dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
__ test_standard_scaler_constant_features[0-float64-False-csc_array-scaler0] ___

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_array'>
dtype = <class 'numpy.float64'>, constant = 0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse array of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Column format>, dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
__ test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler0] __

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_matrix'>
dtype = <class 'numpy.float64'>, constant = 0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>, dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
__ test_standard_scaler_constant_features[0-float64-False-csr_array-scaler0] ___

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_array'>
dtype = <class 'numpy.float64'>, constant = 0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse array of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>, dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
____ test_standard_scaler_constant_features[1.0-float32-False-None-scaler0] ____

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = None, dtype = <class 'numpy.float32'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
            X_scaled_2 = scale(X, with_mean=scaler.with_mean)
            assert X_scaled_2 is not X  # make sure we did a copy
>           assert_allclose_dense_sparse(X_scaled_2, X)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_testing.py:285: in assert_allclose_dense_sparse
    assert_allclose(x, y, rtol=rtol, atol=atol, err_msg=err_msg)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_testing.py:239: in assert_allclose
    np_assert_allclose(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<function assert_allclose.<locals>.compare at 0x77ec3b1553a0>, array([[0.],
       [0.],
       [0.],
       [0.],
  ...      [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]], dtype=float32))
kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-07, atol=1e-09', 'strict': False, ...}

    @wraps(func)
    def inner(*args, **kwds):
        with self._recreate_cm():
>           return func(*args, **kwds)
E           AssertionError: 
E           Not equal to tolerance rtol=1e-07, atol=1e-09
E           
E           Mismatched elements: 100 / 100 (100%)
E           Max absolute difference among violations: 1.
E           Max relative difference among violations: 1.
E            ACTUAL: array([[0.],
E                  [0.],
E                  [0.],...
E            DESIRED: array([[1.],
E                  [1.],
E                  [1.],...

/usr/local/lib/python3.9/contextlib.py:79: AssertionError
_ test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_matrix'>
dtype = <class 'numpy.float32'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse matrix of type '<class 'numpy.float32'>'
	with 100 stored elements in Compressed Sparse Column format>,
      dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
_ test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler0] __

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_array'>
dtype = <class 'numpy.float32'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse array of type '<class 'numpy.float32'>'
	with 100 stored elements in Compressed Sparse Column format>,
      dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
_ test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_matrix'>
dtype = <class 'numpy.float32'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse matrix of type '<class 'numpy.float32'>'
	with 100 stored elements in Compressed Sparse Row format>, dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
_ test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler0] __

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_array'>
dtype = <class 'numpy.float32'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse array of type '<class 'numpy.float32'>'
	with 100 stored elements in Compressed Sparse Row format>, dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
____ test_standard_scaler_constant_features[1.0-float64-False-None-scaler0] ____

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = None, dtype = <class 'numpy.float64'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
            X_scaled_2 = scale(X, with_mean=scaler.with_mean)
            assert X_scaled_2 is not X  # make sure we did a copy
>           assert_allclose_dense_sparse(X_scaled_2, X)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_testing.py:285: in assert_allclose_dense_sparse
    assert_allclose(x, y, rtol=rtol, atol=atol, err_msg=err_msg)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_testing.py:239: in assert_allclose
    np_assert_allclose(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<function assert_allclose.<locals>.compare at 0x77ec3b0d0af0>, array([[0.],
       [0.],
       [0.],
       [0.],
  ...
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]))
kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-07, atol=1e-09', 'strict': False, ...}

    @wraps(func)
    def inner(*args, **kwds):
        with self._recreate_cm():
>           return func(*args, **kwds)
E           AssertionError: 
E           Not equal to tolerance rtol=1e-07, atol=1e-09
E           
E           Mismatched elements: 100 / 100 (100%)
E           Max absolute difference among violations: 1.
E           Max relative difference among violations: 1.
E            ACTUAL: array([[0.],
E                  [0.],
E                  [0.],...
E            DESIRED: array([[1.],
E                  [1.],
E                  [1.],...

/usr/local/lib/python3.9/contextlib.py:79: AssertionError
_ test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_matrix'>
dtype = <class 'numpy.float64'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse matrix of type '<class 'numpy.float64'>'
	with 100 stored elements in Compressed Sparse Column format>,
      dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
_ test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler0] __

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_array'>
dtype = <class 'numpy.float64'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse array of type '<class 'numpy.float64'>'
	with 100 stored elements in Compressed Sparse Column format>,
      dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
_ test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_matrix'>
dtype = <class 'numpy.float64'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse matrix of type '<class 'numpy.float64'>'
	with 100 stored elements in Compressed Sparse Row format>, dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
_ test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler0] __

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_array'>
dtype = <class 'numpy.float64'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse array of type '<class 'numpy.float64'>'
	with 100 stored elements in Compressed Sparse Row format>, dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
___ test_standard_scaler_constant_features[100.0-float32-False-None-scaler0] ___

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = None, dtype = <class 'numpy.float32'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
            X_scaled_2 = scale(X, with_mean=scaler.with_mean)
            assert X_scaled_2 is not X  # make sure we did a copy
>           assert_allclose_dense_sparse(X_scaled_2, X)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_testing.py:285: in assert_allclose_dense_sparse
    assert_allclose(x, y, rtol=rtol, atol=atol, err_msg=err_msg)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_testing.py:239: in assert_allclose
    np_assert_allclose(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<function assert_allclose.<locals>.compare at 0x77ec36f05280>, array([[0.],
       [0.],
       [0.],
       [0.],
  ...     [100.],
       [100.],
       [100.],
       [100.],
       [100.],
       [100.],
       [100.]], dtype=float32))
kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-07, atol=1e-09', 'strict': False, ...}

    @wraps(func)
    def inner(*args, **kwds):
        with self._recreate_cm():
>           return func(*args, **kwds)
E           AssertionError: 
E           Not equal to tolerance rtol=1e-07, atol=1e-09
E           
E           Mismatched elements: 100 / 100 (100%)
E           Max absolute difference among violations: 100.
E           Max relative difference among violations: 1.
E            ACTUAL: array([[0.],
E                  [0.],
E                  [0.],...
E            DESIRED: array([[100.],
E                  [100.],
E                  [100.],...

/usr/local/lib/python3.9/contextlib.py:79: AssertionError
_ test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_matrix'>
dtype = <class 'numpy.float32'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse matrix of type '<class 'numpy.float32'>'
	with 100 stored elements in Compressed Sparse Column format>,
      dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
_ test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_array'>
dtype = <class 'numpy.float32'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse array of type '<class 'numpy.float32'>'
	with 100 stored elements in Compressed Sparse Column format>,
      dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
_ test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_matrix'>
dtype = <class 'numpy.float32'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse matrix of type '<class 'numpy.float32'>'
	with 100 stored elements in Compressed Sparse Row format>, dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
_ test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_array'>
dtype = <class 'numpy.float32'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse array of type '<class 'numpy.float32'>'
	with 100 stored elements in Compressed Sparse Row format>, dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
___ test_standard_scaler_constant_features[100.0-float64-False-None-scaler0] ___

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = None, dtype = <class 'numpy.float64'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
            X_scaled_2 = scale(X, with_mean=scaler.with_mean)
            assert X_scaled_2 is not X  # make sure we did a copy
>           assert_allclose_dense_sparse(X_scaled_2, X)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_testing.py:285: in assert_allclose_dense_sparse
    assert_allclose(x, y, rtol=rtol, atol=atol, err_msg=err_msg)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_testing.py:239: in assert_allclose
    np_assert_allclose(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<function assert_allclose.<locals>.compare at 0x77ec4dfff4c0>, array([[0.],
       [0.],
       [0.],
       [0.],
  ...     [100.],
       [100.],
       [100.],
       [100.],
       [100.],
       [100.],
       [100.],
       [100.]]))
kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-07, atol=1e-09', 'strict': False, ...}

    @wraps(func)
    def inner(*args, **kwds):
        with self._recreate_cm():
>           return func(*args, **kwds)
E           AssertionError: 
E           Not equal to tolerance rtol=1e-07, atol=1e-09
E           
E           Mismatched elements: 100 / 100 (100%)
E           Max absolute difference among violations: 100.
E           Max relative difference among violations: 1.
E            ACTUAL: array([[0.],
E                  [0.],
E                  [0.],...
E            DESIRED: array([[100.],
E                  [100.],
E                  [100.],...

/usr/local/lib/python3.9/contextlib.py:79: AssertionError
_ test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_matrix'>
dtype = <class 'numpy.float64'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse matrix of type '<class 'numpy.float64'>'
	with 100 stored elements in Compressed Sparse Column format>,
      dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
_ test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_array'>
dtype = <class 'numpy.float64'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse array of type '<class 'numpy.float64'>'
	with 100 stored elements in Compressed Sparse Column format>,
      dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
_ test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_matrix'>
dtype = <class 'numpy.float64'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse matrix of type '<class 'numpy.float64'>'
	with 100 stored elements in Compressed Sparse Row format>, dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
_ test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_array'>
dtype = <class 'numpy.float64'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:24: in scale
    mean = np.mean(X, axis=axis, keepdims=True)
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:115: in _mean
    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

arr = array(<100x1 sparse array of type '<class 'numpy.float64'>'
	with 100 stored elements in Compressed Sparse Row format>, dtype=object)
axis = (0,), keepdims = True, where = True

    def _count_reduce_items(arr, axis, keepdims=False, where=True):
        # fast-path for the default case
        if where is True:
            # no boolean mask given, calculate items according to axis
            if axis is None:
                axis = tuple(range(arr.ndim))
            elif not isinstance(axis, tuple):
                axis = (axis,)
            items = 1
            for ax in axis:
>               items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
E               numpy.exceptions.AxisError: axis 0 is out of bounds for array of dimension 0

/local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/lib/python3.9/site-packages/numpy/_core/_methods.py:86: AxisError
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler0]
FAILED ../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler0]
================== 28 failed, 62 passed, 30 skipped in 2.72s ===================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.9.0, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/scikit-learn/scikit-learn
configfile: setup.cfg
plugins: cov-6.0.0
collecting ... collected 120 items

../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-None-scaler0] I: Seeding RNGs with 1307574999
PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_array-scaler1] SKIPPED

======================== 90 passed, 30 skipped in 0.61s ========================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.9.0, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/scikit-learn/scikit-learn
configfile: setup.cfg
plugins: cov-6.0.0
collecting ... collected 120 items

../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-None-scaler0] I: Seeding RNGs with 335068866
PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler1] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-None-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-None-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_array-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_matrix-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_matrix-scaler1] SKIPPED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_array-scaler0] PASSED
../../../../../../local/data0/moved_data/publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_array-scaler1] SKIPPED

======================== 90 passed, 30 skipped in 0.63s ========================
