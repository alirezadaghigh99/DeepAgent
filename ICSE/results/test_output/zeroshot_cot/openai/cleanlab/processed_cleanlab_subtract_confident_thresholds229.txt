output file:
processed_cleanlab_subtract_confident_thresholds229.json
function:
_subtract_confident_thresholds
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test__subtract_confident_thresholds', '../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func1] FAILED', '../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func1]', '../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test__subtract_confident_thresholds FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func0]'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/cleanlab/cleanlab/venv/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase(PosixPath('/home/aliredaq/Desktop/ICSE/src/tester/.hypothesis/examples'))
rootdir: /local/data0/moved_data/publishablew/cleanlab/cleanlab
configfile: pyproject.toml
plugins: hypothesis-6.124.1
collecting ... collected 36 items

../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_get_normalized_margin_for_each_label PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_get_self_confidence_for_each_label PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_rank_by_parameter_error PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func0] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func1] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func2] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func0] FAILED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func1] FAILED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func2] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test__subtract_confident_thresholds FAILED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-self_confidence] Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-normalized_margin] Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-confidence_weighted_entropy] Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-self_confidence] Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-normalized_margin] Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-confidence_weighted_entropy] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-self_confidence] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-normalized_margin] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-confidence_weighted_entropy] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-self_confidence] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-normalized_margin] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-confidence_weighted_entropy] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-self_confidence] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-normalized_margin] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-confidence_weighted_entropy] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-self_confidence] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-normalized_margin] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-confidence_weighted_entropy] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_weight_ensemble_members_by_parameter_error Weighting scheme for ensemble: not_a_real_method
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_custom_weights Weighting scheme for ensemble: custom
Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_empty_custom_weights_error Weighting scheme for ensemble: custom
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_wrong_length_custom_weights_error Weighting scheme for ensemble: custom
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_wrong_weight_ensemble_members_by_for_custom_weights_error PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_pred_probs_list_parameter_error PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_unsupported_method_for_adjust_pred_probs PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_find_top_issues PASSED

=================================== FAILURES ===================================
_ test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func0] _

scoring_method_func = ('self_confidence', <function get_self_confidence_for_each_label at 0x7cf981f2cea0>)
adjust_pred_probs = True

    @pytest.mark.parametrize(
        "scoring_method_func",
        [
            ("self_confidence", rank.get_self_confidence_for_each_label),
            ("normalized_margin", rank.get_normalized_margin_for_each_label),
            ("confidence_weighted_entropy", rank.get_confidence_weighted_entropy_for_each_label),
        ],
    )
    @pytest.mark.parametrize("adjust_pred_probs", [False, True])
    def test_order_label_issues_using_scoring_func_ranking(scoring_method_func, adjust_pred_probs):
        # test all scoring methods with the scoring function
    
        method, scoring_func = scoring_method_func
    
        # check if method supports adjust_pred_probs
        # do not run the test below if the method does not support adjust_pred_probs
        # confidence_weighted_entropy scoring method does not support adjust_pred_probs
        if not (adjust_pred_probs == True and method == "confidence_weighted_entropy"):
            indices = np.arange(len(data["label_errors_mask"]))[
                data["label_errors_mask"]
            ]  # indices of label issues
    
            label_issues_indices = rank.order_label_issues(
                label_issues_mask=data["label_errors_mask"],
                labels=data["labels"],
                pred_probs=data["pred_probs"],
                rank_by=method,
                rank_by_kwargs={"adjust_pred_probs": adjust_pred_probs},
            )
    
            # test scoring function with scoring method passed as arg
            scores = rank.get_label_quality_scores(
                data["labels"],
                data["pred_probs"],
                method=method,
                adjust_pred_probs=adjust_pred_probs,
            )
            scores = scores[data["label_errors_mask"]]
            score_idx = sorted(list(zip(scores, indices)), key=lambda y: y[0])  # sort indices by score
            label_issues_indices2 = [z[1] for z in score_idx]
>           assert all(
                label_issues_indices == label_issues_indices2
            ), f"Test failed with scoring method: {method}"
E           AssertionError: Test failed with scoring method: self_confidence
E           assert False
E            +  where False = all(array([ 67, 1...66,  64,  55]) == [10, 27, 32, 33, 45, 58, ...]
E               
E               Full diff:
E               + array([ 67, 141, 123, 105,  83,  70, 151,  59,  58, 159,  10,  33,  32,
E               +         45,  27, 115, 134,  20,   2,  40,  76,  77,  31,  78,  79, 132,
E               +         39, 150,  46, 131,  66,  64,  55])
E               - [
E               -     10,...
E               
E               ...Full output truncated (33 lines hidden), use '-vv' to show)

/local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py:178: AssertionError
_ test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func1] _

scoring_method_func = ('normalized_margin', <function get_normalized_margin_for_each_label at 0x7cf981f2cf40>)
adjust_pred_probs = True

    @pytest.mark.parametrize(
        "scoring_method_func",
        [
            ("self_confidence", rank.get_self_confidence_for_each_label),
            ("normalized_margin", rank.get_normalized_margin_for_each_label),
            ("confidence_weighted_entropy", rank.get_confidence_weighted_entropy_for_each_label),
        ],
    )
    @pytest.mark.parametrize("adjust_pred_probs", [False, True])
    def test_order_label_issues_using_scoring_func_ranking(scoring_method_func, adjust_pred_probs):
        # test all scoring methods with the scoring function
    
        method, scoring_func = scoring_method_func
    
        # check if method supports adjust_pred_probs
        # do not run the test below if the method does not support adjust_pred_probs
        # confidence_weighted_entropy scoring method does not support adjust_pred_probs
        if not (adjust_pred_probs == True and method == "confidence_weighted_entropy"):
            indices = np.arange(len(data["label_errors_mask"]))[
                data["label_errors_mask"]
            ]  # indices of label issues
    
            label_issues_indices = rank.order_label_issues(
                label_issues_mask=data["label_errors_mask"],
                labels=data["labels"],
                pred_probs=data["pred_probs"],
                rank_by=method,
                rank_by_kwargs={"adjust_pred_probs": adjust_pred_probs},
            )
    
            # test scoring function with scoring method passed as arg
            scores = rank.get_label_quality_scores(
                data["labels"],
                data["pred_probs"],
                method=method,
                adjust_pred_probs=adjust_pred_probs,
            )
            scores = scores[data["label_errors_mask"]]
            score_idx = sorted(list(zip(scores, indices)), key=lambda y: y[0])  # sort indices by score
            label_issues_indices2 = [z[1] for z in score_idx]
>           assert all(
                label_issues_indices == label_issues_indices2
            ), f"Test failed with scoring method: {method}"
E           AssertionError: Test failed with scoring method: normalized_margin
E           assert False
E            +  where False = all(array([141, 1...66,  64,  55]) == [83, 105, 123... 58, 115, ...]
E               
E               Full diff:
E               + array([141, 123, 105,  83,  58, 115, 134,   2,  67,  20,  32, 151,  79,
E               +         70, 159,  40,  31,  59,  78,  27, 132,  45,  77,  33,  39,  46,
E               +         76,  10, 150, 131,  66,  64,  55])
E               - [
E               -     83,...
E               
E               ...Full output truncated (33 lines hidden), use '-vv' to show)

/local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py:178: AssertionError
_____________________ test__subtract_confident_thresholds ______________________

    def test__subtract_confident_thresholds():
        labels = data["labels"]
        pred_probs = data["pred_probs"]
    
        # subtract confident class thresholds and renormalize
        pred_probs_adj = _subtract_confident_thresholds(labels, pred_probs)
    
>       assert (pred_probs_adj > 0).all()  # all pred_prob are positive numbers
E       assert False
E        +  where False = <built-in method all of numpy.ndarray object at 0x7cf8c7d6aa90>()
E        +    where <built-in method all of numpy.ndarray object at 0x7cf8c7d6aa90> = array([[6.33785535e-01, 1.06269960e-02, 3.55587469e-01],\n       [8.14719475e-01, 1.85280525e-01, 0.00000000e+00],\n       [9.58047773e-01, 0.00000000e+00, 4.19522270e-02],\n       [7.61350529e-01, 0.00000000e+00, 2.38649471e-01],\n       [8.90888823e-01, 0.00000000e+00, 1.09111177e-01],\n       [8.51755932e-01, 0.00000000e+00, 1.48244068e-01],\n       [8.03348696e-01, 1.96651304e-01, 0.00000000e+00],\n       [8.38133428e-01, 0.00000000e+00, 1.61866572e-01],\n       [9.33156575e-01, 3.70526347e-02, 2.97907907e-02],\n       [7.71459062e-01, 1.88100046e-01, 4.04408924e-02],\n       [4.73188380e-01, 5.26811620e-01, 0.00000000e+00],\n       [6.60952047e-01, 1.24157329e-01, 2.14890624e-01],\n       [8.43551971e-01, 0.00000000e+00, 1.56448029e-01],\n       [8.98940215e-01, 1.01059785e-01, 0.00000000e+00],\n       [7.38982450e-01, 2.60211429e-01, 8.06121514e-04],\n       [8.22035658e-01, 1.77964342e-01, 0.00000000e+00],\n       [8.71379999e-01, 1.28620001e-01, 0.00000000e+00],\n       [6.94412012e-01, 3.05587988e-01, 0.00000000e+00],\n       [6.40735318e-01, 3.59264682e-01, 0.00000000e+00],\n       [6.42060784e-01, 0.00000000e+00, 3.57939216e-01],\n       [9.32795767e-01, 3.96437480e-02, 2.75604849e-02],\n ...,\n       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n       [4.86374387e-01, 0.00000000e+00, 5.13625613e-01],\n       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n       [1.45595689e-01, 0.00000000e+00, 8.54404311e-01],\n       [4.68353621e-01, 0.00000000e+00, 5.31646379e-01],\n       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n       [3.33947962e-01, 0.00000000e+00, 6.66052038e-01],\n       [7.12081672e-02, 1.46733033e-03, 9.27324503e-01],\n       [0.00000000e+00, 2.37971658e-01, 7.62028342e-01],\n       [3.11890139e-01, 0.00000000e+00, 6.88109861e-01],\n       [0.00000000e+00, 3.66776831e-01, 6.33223169e-01],\n       [1.72573513e-01, 1.69587339e-01, 6.57839148e-01],\n       [0.00000000e+00, 1.56514564e-01, 8.43485436e-01],\n       [0.00000000e+00, 9.57947099e-01, 4.20529007e-02],\n       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n       [6.19950719e-01, 0.00000000e+00, 3.80049281e-01],\n       [3.24890732e-01, 2.23459760e-01, 4.51649508e-01],\n       [6.15924967e-01, 0.00000000e+00, 3.84075033e-01],\n       [1.17024905e-02, 0.00000000e+00, 9.88297510e-01],\n       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n       [0.00000000e+00, 1.75971751e-01, 8.24028249e-01]]) > 0.all

/local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py:203: AssertionError
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func0]
FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func1]
FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test__subtract_confident_thresholds
========================= 3 failed, 33 passed in 1.61s =========================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/cleanlab/cleanlab/venv/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase(PosixPath('/home/aliredaq/Desktop/ICSE/src/tester/.hypothesis/examples'))
rootdir: /local/data0/moved_data/publishablew/cleanlab/cleanlab
configfile: pyproject.toml
plugins: hypothesis-6.124.1
collecting ... collected 36 items

../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_get_normalized_margin_for_each_label PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_get_self_confidence_for_each_label PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_rank_by_parameter_error PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func0] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func1] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func2] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func0] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func1] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func2] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test__subtract_confident_thresholds PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-self_confidence] Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-normalized_margin] Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-confidence_weighted_entropy] Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-self_confidence] Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-normalized_margin] Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-confidence_weighted_entropy] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-self_confidence] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-normalized_margin] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-confidence_weighted_entropy] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-self_confidence] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-normalized_margin] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-confidence_weighted_entropy] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-self_confidence] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-normalized_margin] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-confidence_weighted_entropy] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-self_confidence] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-normalized_margin] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-confidence_weighted_entropy] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_weight_ensemble_members_by_parameter_error Weighting scheme for ensemble: not_a_real_method
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_custom_weights Weighting scheme for ensemble: custom
Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_empty_custom_weights_error Weighting scheme for ensemble: custom
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_wrong_length_custom_weights_error Weighting scheme for ensemble: custom
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_wrong_weight_ensemble_members_by_for_custom_weights_error PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_pred_probs_list_parameter_error PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_unsupported_method_for_adjust_pred_probs PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_find_top_issues PASSED

============================== 36 passed in 1.59s ==============================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/cleanlab/cleanlab/venv/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase(PosixPath('/home/aliredaq/Desktop/ICSE/src/tester/.hypothesis/examples'))
rootdir: /local/data0/moved_data/publishablew/cleanlab/cleanlab
configfile: pyproject.toml
plugins: hypothesis-6.124.1
collecting ... collected 36 items

../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_get_normalized_margin_for_each_label PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_get_self_confidence_for_each_label PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_rank_by_parameter_error PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func0] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func1] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func2] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func0] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func1] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func2] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test__subtract_confident_thresholds PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-self_confidence] Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-normalized_margin] Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-confidence_weighted_entropy] Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-self_confidence] Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-normalized_margin] Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-confidence_weighted_entropy] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-self_confidence] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-normalized_margin] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-confidence_weighted_entropy] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-self_confidence] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-normalized_margin] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-confidence_weighted_entropy] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-self_confidence] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-normalized_margin] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-confidence_weighted_entropy] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-self_confidence] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-normalized_margin] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-confidence_weighted_entropy] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_weight_ensemble_members_by_parameter_error Weighting scheme for ensemble: not_a_real_method
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_custom_weights Weighting scheme for ensemble: custom
Weighting scheme for ensemble: uniform
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_empty_custom_weights_error Weighting scheme for ensemble: custom
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_wrong_length_custom_weights_error Weighting scheme for ensemble: custom
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_wrong_weight_ensemble_members_by_for_custom_weights_error PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_pred_probs_list_parameter_error PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_unsupported_method_for_adjust_pred_probs PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_rank.py::test_find_top_issues PASSED

============================== 36 passed in 7.86s ==============================
