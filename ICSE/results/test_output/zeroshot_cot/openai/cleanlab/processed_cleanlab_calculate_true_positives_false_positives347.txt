output file:
processed_cleanlab_calculate_true_positives_false_positives347.json
function:
_calculate_true_positives_false_positives
Error Cases:
Exception ignored in: <function Pool.__del__ at 0x7f744f80bba0>
Traceback (most recent call last):
  File "/usr/lib/python3.11/multiprocessing/pool.py", line 271, in __del__
    self._change_notifier.put(None)
  File "/usr/lib/python3.11/multiprocessing/queues.py", line 377, in put
    self._writer.send_bytes(obj)
  File "/usr/lib/python3.11/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.11/multiprocessing/connection.py", line 427, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.11/multiprocessing/connection.py", line 384, in _send
    n = write(self._handle, buf)
        ^^^^^^^^^^^^^^^^^^^^^^^^
OSError: [Errno 9] Bad file descriptor

Pass or Failed: 0

Related Failed Test Cases:
{'../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_metrics[class_names1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues_overlapping_labels[False]', '../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives[False] FAILED', '../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_metrics[None]', '../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives[True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives[False]', '../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_metrics[None] FAILED', '../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues_overlapping_labels[True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues_overlapping_labels[True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_metrics[class_names1]', '../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_confusion_matrix FAILED', '../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_return_issues_ranked_by_scores FAILED', '../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues_overlapping_labels[False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues', 'FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_return_issues_ranked_by_scores', 'FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives_high_threshold', 'FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_confusion_matrix', '../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives_high_threshold FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives[True]'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/cleanlab/cleanlab/venv/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase(PosixPath('/home/aliredaq/Desktop/ICSE/src/tester/.hypothesis/examples'))
rootdir: /local/data0/moved_data/publishablew/cleanlab/cleanlab
configfile: pyproject.toml
plugins: hypothesis-6.124.1
collecting ... collected 50 items

../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_label_quality_scores Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_label_quality_scores_custom_weights[agg_weights0] Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_label_quality_scores_custom_weights[agg_weights1] Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_label_quality_scores_custom_weights[agg_weights2] Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_issues_from_scores Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_min_pred_prob PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_valid_score PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_valid_subtype_score_params PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_aggregation_weights PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_softmin1d PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_softmax PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_bbox_xyxy_to_xywh Wrong bbox shape 5
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_prune_by_threshold[True] Pruning 44 predictions out of 44 using threshold==1.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
Pruning 0 predictions out of 44 using threshold==0.6. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
Pruning 0 predictions out of 44 using threshold==0.5. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_prune_by_threshold[False] Pruning 0 predictions out of 44 using threshold==0.6. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
Pruning 0 predictions out of 44 using threshold==0.5. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_similarity_matrix PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_compute_label_quality_scores Pruning 33 predictions out of 44 using threshold==0.99. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
Pruning 0 predictions out of 44 using threshold==0.96. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_overlooked_score_shifts_in_correct_direction PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_badloc_score_shifts_in_correct_direction PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_badloc_scores_indexed_correctly PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_score_shifts_in_correct_direction PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues FAILED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_separate_prediction PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_return_issues_ranked_by_scores FAILED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_bad_input_find_label_issues_internal Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues_per_box PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_object_counts_per_image PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_bounding_box_size_distribution PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_class_label_distribution PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_sorted_bbox_count_idxs PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_plot_class_size_distributions PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_plot_class_distribution PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_visualize PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_has_labels_overlap PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_overlap_labels[True] Pruning 0 predictions out of 5 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_overlap_labels[False] Pruning 0 predictions out of 5 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_only_overlap_labels[True] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_only_overlap_labels[False] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues_overlapping_labels[True] FAILED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues_overlapping_labels[False] FAILED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_badloc_low_probability_threshold PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_overlooked_high_probability_threshold PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_high_probability_threshold PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_invalid_method_raises_value_error PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives[True] FAILED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives[False] FAILED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives_high_threshold FAILED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_metrics[None] FAILED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_metrics[class_names1] FAILED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_confusion_matrix FAILED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_areas_across_boxes PASSED

=================================== FAILURES ===================================
____________________________ test_find_label_issues ____________________________
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/lib/python3.11/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
                    ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/multiprocessing/pool.py", line 51, in starmapstar
    return list(itertools.starmap(args[0], args[1]))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py", line 202, in _calculate_true_positives_false_positives
    from .temp import _calculate_true_positives_false_positives
ImportError: cannot import name '_calculate_true_positives_false_positives' from 'cleanlab.object_detection.temp' (/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/temp.py)
"""

The above exception was the direct cause of the following exception:

    def test_find_label_issues():
        auxiliary_inputs = _get_valid_inputs_for_compute_scores(ALPHA, labels, predictions)
        test_inputs = _get_valid_inputs_for_compute_scores_per_image(
            alpha=ALPHA, label=labels[0], prediction=predictions[0]
        )
    
        assert (test_inputs["pred_label_probs"] == auxiliary_inputs[0]["pred_label_probs"]).all()
>       per_class_scores = _get_per_class_ap(labels, predictions)

/local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py:445: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py:269: in _get_per_class_ap
    ap_per_class = _calculate_ap_per_class(labels, predictions, iou_threshold=threshold)
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py:166: in _calculate_ap_per_class
    tpfp = pool.starmap(_calculate_true_positives_false_positives, zip(pred_bboxes, lab_bboxes, [iou_threshold for _ in range(num_images)]))
/usr/lib/python3.11/multiprocessing/pool.py:375: in starmap
    return self._map_async(func, iterable, starmapstar, chunksize).get()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <multiprocessing.pool.MapResult object at 0x7f73f69bedd0>, timeout = None

    def get(self, timeout=None):
        self.wait(timeout)
        if not self.ready():
            raise TimeoutError
        if self._success:
            return self._value
        else:
>           raise self._value
E           ImportError: cannot import name '_calculate_true_positives_false_positives' from 'cleanlab.object_detection.temp' (/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/temp.py)

/usr/lib/python3.11/multiprocessing/pool.py:774: ImportError
_____________________ test_return_issues_ranked_by_scores ______________________
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/lib/python3.11/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
                    ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/multiprocessing/pool.py", line 51, in starmapstar
    return list(itertools.starmap(args[0], args[1]))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py", line 202, in _calculate_true_positives_false_positives
    from .temp import _calculate_true_positives_false_positives
ImportError: cannot import name '_calculate_true_positives_false_positives' from 'cleanlab.object_detection.temp' (/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/temp.py)
"""

The above exception was the direct cause of the following exception:

    def test_return_issues_ranked_by_scores():
>       label_issue_idx = find_label_issues(labels, predictions, return_indices_ranked_by_score=True)

/local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py:579: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py:66: in find_label_issues
    is_issue = _find_label_issues(labels, predictions, scoring_method=scoring_method, return_indices_ranked_by_score=return_indices_ranked_by_score, overlapping_label_check=overlapping_label_check)
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py:73: in _find_label_issues
    per_class_scores = _get_per_class_ap(labels, predictions)
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py:269: in _get_per_class_ap
    ap_per_class = _calculate_ap_per_class(labels, predictions, iou_threshold=threshold)
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py:166: in _calculate_ap_per_class
    tpfp = pool.starmap(_calculate_true_positives_false_positives, zip(pred_bboxes, lab_bboxes, [iou_threshold for _ in range(num_images)]))
/usr/lib/python3.11/multiprocessing/pool.py:375: in starmap
    return self._map_async(func, iterable, starmapstar, chunksize).get()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <multiprocessing.pool.MapResult object at 0x7f744f0bda90>, timeout = None

    def get(self, timeout=None):
        self.wait(timeout)
        if not self.ready():
            raise TimeoutError
        if self._success:
            return self._value
        else:
>           raise self._value
E           ImportError: cannot import name '_calculate_true_positives_false_positives' from 'cleanlab.object_detection.temp' (/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/temp.py)

/usr/lib/python3.11/multiprocessing/pool.py:774: ImportError
_______________ test_find_label_issues_overlapping_labels[True] ________________

overlapping_label_check = True

    @pytest.mark.parametrize("overlapping_label_check", [True, False])
    def test_find_label_issues_overlapping_labels(overlapping_label_check):
        bboxes = np.array(
            [
                [359.0, 146.0, 472.0, 360.0],
                [340.0, 22.0, 494.0, 323.0],
                [472.0, 173.0, 508.0, 221.0],
                [486.0, 183.0, 517.0, 218.0],
                [359.0, 144.0, 470.0, 358.0],
                [340.0, 22.0, 494.0, 323.0],
            ]
        )
        label_classes = np.array([0, 1, 1, 1, 1, 1])
        perfect_pred = [[], []]
        for i in range(0, len(label_classes)):
            perfect_pred[label_classes[i]].append(list(bboxes[i]) + [0.95])
        prediction = [np.array(p) for p in perfect_pred]
        prediction = np.array(prediction, dtype=object)
        label = {"bboxes": bboxes, "labels": label_classes}
>       is_issue = find_label_issues(
            [label], [prediction], overlapping_label_check=overlapping_label_check
        )[0]

/local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py:846: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py:66: in find_label_issues
    is_issue = _find_label_issues(labels, predictions, scoring_method=scoring_method, return_indices_ranked_by_score=return_indices_ranked_by_score, overlapping_label_check=overlapping_label_check)
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py:73: in _find_label_issues
    per_class_scores = _get_per_class_ap(labels, predictions)
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py:269: in _get_per_class_ap
    ap_per_class = _calculate_ap_per_class(labels, predictions, iou_threshold=threshold)
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py:168: in _calculate_ap_per_class
    tpfp = [_calculate_true_positives_false_positives(pred_bboxes[0], lab_bboxes[0], iou_threshold)]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_bboxes = array([[359.  , 146.  , 472.  , 360.  ,   0.95]])
lab_bboxes = array([[359., 146., 472., 360.]]), iou_threshold = 0.5
return_false_negative = False

    def _calculate_true_positives_false_positives(pred_bboxes: np.ndarray, lab_bboxes: np.ndarray, iou_threshold: Optional[float]=0.5, return_false_negative: bool=False) -> Union[Tuple[np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray, np.ndarray]]:
>       from .temp import _calculate_true_positives_false_positives
E       ImportError: cannot import name '_calculate_true_positives_false_positives' from 'cleanlab.object_detection.temp' (/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/temp.py)

/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py:202: ImportError
_______________ test_find_label_issues_overlapping_labels[False] _______________

overlapping_label_check = False

    @pytest.mark.parametrize("overlapping_label_check", [True, False])
    def test_find_label_issues_overlapping_labels(overlapping_label_check):
        bboxes = np.array(
            [
                [359.0, 146.0, 472.0, 360.0],
                [340.0, 22.0, 494.0, 323.0],
                [472.0, 173.0, 508.0, 221.0],
                [486.0, 183.0, 517.0, 218.0],
                [359.0, 144.0, 470.0, 358.0],
                [340.0, 22.0, 494.0, 323.0],
            ]
        )
        label_classes = np.array([0, 1, 1, 1, 1, 1])
        perfect_pred = [[], []]
        for i in range(0, len(label_classes)):
            perfect_pred[label_classes[i]].append(list(bboxes[i]) + [0.95])
        prediction = [np.array(p) for p in perfect_pred]
        prediction = np.array(prediction, dtype=object)
        label = {"bboxes": bboxes, "labels": label_classes}
>       is_issue = find_label_issues(
            [label], [prediction], overlapping_label_check=overlapping_label_check
        )[0]

/local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py:846: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py:66: in find_label_issues
    is_issue = _find_label_issues(labels, predictions, scoring_method=scoring_method, return_indices_ranked_by_score=return_indices_ranked_by_score, overlapping_label_check=overlapping_label_check)
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py:73: in _find_label_issues
    per_class_scores = _get_per_class_ap(labels, predictions)
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py:269: in _get_per_class_ap
    ap_per_class = _calculate_ap_per_class(labels, predictions, iou_threshold=threshold)
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py:168: in _calculate_ap_per_class
    tpfp = [_calculate_true_positives_false_positives(pred_bboxes[0], lab_bboxes[0], iou_threshold)]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_bboxes = array([[359.  , 146.  , 472.  , 360.  ,   0.95]])
lab_bboxes = array([[359., 146., 472., 360.]]), iou_threshold = 0.5
return_false_negative = False

    def _calculate_true_positives_false_positives(pred_bboxes: np.ndarray, lab_bboxes: np.ndarray, iou_threshold: Optional[float]=0.5, return_false_negative: bool=False) -> Union[Tuple[np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray, np.ndarray]]:
>       from .temp import _calculate_true_positives_false_positives
E       ImportError: cannot import name '_calculate_true_positives_false_positives' from 'cleanlab.object_detection.temp' (/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/temp.py)

/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py:202: ImportError
_____________ test_calculate_true_positives_false_positives[True] ______________
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/lib/python3.11/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
                    ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/multiprocessing/pool.py", line 51, in starmapstar
    return list(itertools.starmap(args[0], args[1]))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py", line 202, in _calculate_true_positives_false_positives
    from .temp import _calculate_true_positives_false_positives
ImportError: cannot import name '_calculate_true_positives_false_positives' from 'cleanlab.object_detection.temp' (/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/temp.py)
"""

The above exception was the direct cause of the following exception:

return_false_negative = True

    @pytest.mark.parametrize("return_false_negative", [True, False])
    def test_calculate_true_positives_false_positives(return_false_negative):
        num_classes = len(predictions[0])
        num_images = len(predictions)
        pool = Pool(1)
        iou_threshold = 0.5
        counter_dict = defaultdict(Counter)
    
        for class_num in range(num_classes):
            pred_bboxes, lab_bboxes = _filter_by_class(labels, predictions, class_num)
>           tpfp = pool.starmap(
                _calculate_true_positives_false_positives,
                zip(
                    pred_bboxes,
                    lab_bboxes,
                    [iou_threshold for _ in range(num_images)],
                    [return_false_negative for _ in range(num_images)],
                ),
            )

/local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py:931: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.11/multiprocessing/pool.py:375: in starmap
    return self._map_async(func, iterable, starmapstar, chunksize).get()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <multiprocessing.pool.MapResult object at 0x7f74493c8510>, timeout = None

    def get(self, timeout=None):
        self.wait(timeout)
        if not self.ready():
            raise TimeoutError
        if self._success:
            return self._value
        else:
>           raise self._value
E           ImportError: cannot import name '_calculate_true_positives_false_positives' from 'cleanlab.object_detection.temp' (/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/temp.py)

/usr/lib/python3.11/multiprocessing/pool.py:774: ImportError
_____________ test_calculate_true_positives_false_positives[False] _____________
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/lib/python3.11/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
                    ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/multiprocessing/pool.py", line 51, in starmapstar
    return list(itertools.starmap(args[0], args[1]))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py", line 202, in _calculate_true_positives_false_positives
    from .temp import _calculate_true_positives_false_positives
ImportError: cannot import name '_calculate_true_positives_false_positives' from 'cleanlab.object_detection.temp' (/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/temp.py)
"""

The above exception was the direct cause of the following exception:

return_false_negative = False

    @pytest.mark.parametrize("return_false_negative", [True, False])
    def test_calculate_true_positives_false_positives(return_false_negative):
        num_classes = len(predictions[0])
        num_images = len(predictions)
        pool = Pool(1)
        iou_threshold = 0.5
        counter_dict = defaultdict(Counter)
    
        for class_num in range(num_classes):
            pred_bboxes, lab_bboxes = _filter_by_class(labels, predictions, class_num)
>           tpfp = pool.starmap(
                _calculate_true_positives_false_positives,
                zip(
                    pred_bboxes,
                    lab_bboxes,
                    [iou_threshold for _ in range(num_images)],
                    [return_false_negative for _ in range(num_images)],
                ),
            )

/local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py:931: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.11/multiprocessing/pool.py:375: in starmap
    return self._map_async(func, iterable, starmapstar, chunksize).get()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <multiprocessing.pool.MapResult object at 0x7f74493de0d0>, timeout = None

    def get(self, timeout=None):
        self.wait(timeout)
        if not self.ready():
            raise TimeoutError
        if self._success:
            return self._value
        else:
>           raise self._value
E           ImportError: cannot import name '_calculate_true_positives_false_positives' from 'cleanlab.object_detection.temp' (/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/temp.py)

/usr/lib/python3.11/multiprocessing/pool.py:774: ImportError
_________ test_calculate_true_positives_false_positives_high_threshold _________

    def test_calculate_true_positives_false_positives_high_threshold():
        pred_bboxes = np.array([[1, 1, 5, 5]])
        lab_bboxes = np.array([[1, 1, 6, 6], [3, 3, 8, 8]])
        iou_threshold = 1.0
        (
            true_positives,
            false_positives,
            false_negatives,
>       ) = _calculate_true_positives_false_positives(
            pred_bboxes, lab_bboxes, iou_threshold=iou_threshold, return_false_negative=True
        )

/local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py:991: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred_bboxes = array([[1, 1, 5, 5]])
lab_bboxes = array([[1, 1, 6, 6],
       [3, 3, 8, 8]]), iou_threshold = 1.0
return_false_negative = True

    def _calculate_true_positives_false_positives(pred_bboxes: np.ndarray, lab_bboxes: np.ndarray, iou_threshold: Optional[float]=0.5, return_false_negative: bool=False) -> Union[Tuple[np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray, np.ndarray]]:
>       from .temp import _calculate_true_positives_false_positives
E       ImportError: cannot import name '_calculate_true_positives_false_positives' from 'cleanlab.object_detection.temp' (/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/temp.py)

/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py:202: ImportError
_________________________ test_per_class_metrics[None] _________________________
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/lib/python3.11/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
                    ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/multiprocessing/pool.py", line 51, in starmapstar
    return list(itertools.starmap(args[0], args[1]))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py", line 202, in _calculate_true_positives_false_positives
    from .temp import _calculate_true_positives_false_positives
ImportError: cannot import name '_calculate_true_positives_false_positives' from 'cleanlab.object_detection.temp' (/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/temp.py)
"""

The above exception was the direct cause of the following exception:

class_names = None

    @pytest.mark.parametrize("class_names", [None, class_names])
    def test_per_class_metrics(class_names):
>       per_class_metrics = calculate_per_class_metrics(labels, predictions, class_names=class_names)

/local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py:999: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/summary.py:645: in calculate_per_class_metrics
    avg_metrics = get_average_per_class_confusion_matrix(
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/summary.py:589: in get_average_per_class_confusion_matrix
    results_dict = _get_per_class_confusion_matrix_dict_(
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/summary.py:498: in _get_per_class_confusion_matrix_dict_
    tpfpfn = pool.starmap(
/usr/lib/python3.11/multiprocessing/pool.py:375: in starmap
    return self._map_async(func, iterable, starmapstar, chunksize).get()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <multiprocessing.pool.MapResult object at 0x7f744d6edd10>, timeout = None

    def get(self, timeout=None):
        self.wait(timeout)
        if not self.ready():
            raise TimeoutError
        if self._success:
            return self._value
        else:
>           raise self._value
E           ImportError: cannot import name '_calculate_true_positives_false_positives' from 'cleanlab.object_detection.temp' (/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/temp.py)

/usr/lib/python3.11/multiprocessing/pool.py:774: ImportError
_____________________ test_per_class_metrics[class_names1] _____________________
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/lib/python3.11/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
                    ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/multiprocessing/pool.py", line 51, in starmapstar
    return list(itertools.starmap(args[0], args[1]))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py", line 202, in _calculate_true_positives_false_positives
    from .temp import _calculate_true_positives_false_positives
ImportError: cannot import name '_calculate_true_positives_false_positives' from 'cleanlab.object_detection.temp' (/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/temp.py)
"""

The above exception was the direct cause of the following exception:

class_names = {'0': 'a', '1': 'b', '2': 'c', '3': 'd', ...}

    @pytest.mark.parametrize("class_names", [None, class_names])
    def test_per_class_metrics(class_names):
>       per_class_metrics = calculate_per_class_metrics(labels, predictions, class_names=class_names)

/local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py:999: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/summary.py:645: in calculate_per_class_metrics
    avg_metrics = get_average_per_class_confusion_matrix(
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/summary.py:589: in get_average_per_class_confusion_matrix
    results_dict = _get_per_class_confusion_matrix_dict_(
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/summary.py:498: in _get_per_class_confusion_matrix_dict_
    tpfpfn = pool.starmap(
/usr/lib/python3.11/multiprocessing/pool.py:375: in starmap
    return self._map_async(func, iterable, starmapstar, chunksize).get()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <multiprocessing.pool.MapResult object at 0x7f744d759350>, timeout = None

    def get(self, timeout=None):
        self.wait(timeout)
        if not self.ready():
            raise TimeoutError
        if self._success:
            return self._value
        else:
>           raise self._value
E           ImportError: cannot import name '_calculate_true_positives_false_positives' from 'cleanlab.object_detection.temp' (/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/temp.py)

/usr/lib/python3.11/multiprocessing/pool.py:774: ImportError
_______________________ test_per_class_confusion_matrix ________________________
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/lib/python3.11/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
                    ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/multiprocessing/pool.py", line 51, in starmapstar
    return list(itertools.starmap(args[0], args[1]))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/filter.py", line 202, in _calculate_true_positives_false_positives
    from .temp import _calculate_true_positives_false_positives
ImportError: cannot import name '_calculate_true_positives_false_positives' from 'cleanlab.object_detection.temp' (/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/temp.py)
"""

The above exception was the direct cause of the following exception:

    def test_per_class_confusion_matrix():
>       per_class_confusion_matrix = get_average_per_class_confusion_matrix(labels, predictions)

/local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py:1010: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/summary.py:589: in get_average_per_class_confusion_matrix
    results_dict = _get_per_class_confusion_matrix_dict_(
/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/summary.py:498: in _get_per_class_confusion_matrix_dict_
    tpfpfn = pool.starmap(
/usr/lib/python3.11/multiprocessing/pool.py:375: in starmap
    return self._map_async(func, iterable, starmapstar, chunksize).get()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <multiprocessing.pool.MapResult object at 0x7f744d715d90>, timeout = None

    def get(self, timeout=None):
        self.wait(timeout)
        if not self.ready():
            raise TimeoutError
        if self._success:
            return self._value
        else:
>           raise self._value
E           ImportError: cannot import name '_calculate_true_positives_false_positives' from 'cleanlab.object_detection.temp' (/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/temp.py)

/usr/lib/python3.11/multiprocessing/pool.py:774: ImportError
=============================== warnings summary ===============================
tests/test_object_detection.py::test_visualize
  /local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/summary.py:433: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
    fig, ax = plt.subplots(frameon=False, figsize=figsize)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues
FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_return_issues_ranked_by_scores
FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues_overlapping_labels[True]
FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues_overlapping_labels[False]
FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives[True]
FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives[False]
FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives_high_threshold
FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_metrics[None]
FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_metrics[class_names1]
FAILED ../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_confusion_matrix
=================== 10 failed, 40 passed, 1 warning in 2.26s ===================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/cleanlab/cleanlab/venv/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase(PosixPath('/home/aliredaq/Desktop/ICSE/src/tester/.hypothesis/examples'))
rootdir: /local/data0/moved_data/publishablew/cleanlab/cleanlab
configfile: pyproject.toml
plugins: hypothesis-6.124.1
collecting ... collected 50 items

../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_label_quality_scores Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_label_quality_scores_custom_weights[agg_weights0] Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_label_quality_scores_custom_weights[agg_weights1] Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_label_quality_scores_custom_weights[agg_weights2] Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_issues_from_scores Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_min_pred_prob PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_valid_score PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_valid_subtype_score_params PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_aggregation_weights PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_softmin1d PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_softmax PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_bbox_xyxy_to_xywh Wrong bbox shape 5
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_prune_by_threshold[True] Pruning 44 predictions out of 44 using threshold==1.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
Pruning 0 predictions out of 44 using threshold==0.6. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
Pruning 0 predictions out of 44 using threshold==0.5. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_prune_by_threshold[False] Pruning 0 predictions out of 44 using threshold==0.6. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
Pruning 0 predictions out of 44 using threshold==0.5. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_similarity_matrix PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_compute_label_quality_scores Pruning 33 predictions out of 44 using threshold==0.99. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
Pruning 0 predictions out of 44 using threshold==0.96. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_overlooked_score_shifts_in_correct_direction PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_badloc_score_shifts_in_correct_direction PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_badloc_scores_indexed_correctly PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_score_shifts_in_correct_direction PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_separate_prediction PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_return_issues_ranked_by_scores Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_bad_input_find_label_issues_internal Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues_per_box PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_object_counts_per_image PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_bounding_box_size_distribution PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_class_label_distribution PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_sorted_bbox_count_idxs PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_plot_class_size_distributions PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_plot_class_distribution PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_visualize PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_has_labels_overlap PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_overlap_labels[True] Pruning 0 predictions out of 5 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_overlap_labels[False] Pruning 0 predictions out of 5 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_only_overlap_labels[True] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_only_overlap_labels[False] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues_overlapping_labels[True] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues_overlapping_labels[False] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_badloc_low_probability_threshold PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_overlooked_high_probability_threshold PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_high_probability_threshold PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_invalid_method_raises_value_error PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives[True] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives[False] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives_high_threshold PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_metrics[None] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_metrics[class_names1] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_confusion_matrix PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_areas_across_boxes PASSED

=============================== warnings summary ===============================
tests/test_object_detection.py::test_visualize
  /local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/summary.py:433: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
    fig, ax = plt.subplots(frameon=False, figsize=figsize)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================== 50 passed, 1 warning in 2.64s =========================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/cleanlab/cleanlab/venv/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase(PosixPath('/home/aliredaq/Desktop/ICSE/src/tester/.hypothesis/examples'))
rootdir: /local/data0/moved_data/publishablew/cleanlab/cleanlab
configfile: pyproject.toml
plugins: hypothesis-6.124.1
collecting ... collected 50 items

../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_label_quality_scores Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_label_quality_scores_custom_weights[agg_weights0] Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_label_quality_scores_custom_weights[agg_weights1] Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_label_quality_scores_custom_weights[agg_weights2] Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_issues_from_scores Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_min_pred_prob PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_valid_score PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_valid_subtype_score_params PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_aggregation_weights PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_softmin1d PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_softmax PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_bbox_xyxy_to_xywh Wrong bbox shape 5
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_prune_by_threshold[True] Pruning 44 predictions out of 44 using threshold==1.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
Pruning 0 predictions out of 44 using threshold==0.6. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
Pruning 0 predictions out of 44 using threshold==0.5. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_prune_by_threshold[False] Pruning 0 predictions out of 44 using threshold==0.6. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
Pruning 0 predictions out of 44 using threshold==0.5. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_similarity_matrix PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_compute_label_quality_scores Pruning 33 predictions out of 44 using threshold==0.99. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
Pruning 0 predictions out of 44 using threshold==0.96. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_overlooked_score_shifts_in_correct_direction PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_badloc_score_shifts_in_correct_direction PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_badloc_scores_indexed_correctly PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_score_shifts_in_correct_direction PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_separate_prediction PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_return_issues_ranked_by_scores Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_bad_input_find_label_issues_internal Pruning 0 predictions out of 44 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues_per_box PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_object_counts_per_image PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_bounding_box_size_distribution PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_class_label_distribution PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_get_sorted_bbox_count_idxs PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_plot_class_size_distributions PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_plot_class_distribution PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_visualize PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_has_labels_overlap PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_overlap_labels[True] Pruning 0 predictions out of 5 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_overlap_labels[False] Pruning 0 predictions out of 5 using threshold==0.0. These predictions are no longer considered as potential candidates for identifying label issues as their similarity with the given labels is no longer considered.
PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_only_overlap_labels[True] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_only_overlap_labels[False] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues_overlapping_labels[True] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_find_label_issues_overlapping_labels[False] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_badloc_low_probability_threshold PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_overlooked_high_probability_threshold PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_swap_high_probability_threshold PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_invalid_method_raises_value_error PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives[True] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives[False] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_true_positives_false_positives_high_threshold PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_metrics[None] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_metrics[class_names1] PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_per_class_confusion_matrix PASSED
../../../../../../local/data0/moved_data/publishablew/cleanlab/cleanlab/tests/test_object_detection.py::test_calculate_areas_across_boxes PASSED

=============================== warnings summary ===============================
tests/test_object_detection.py::test_visualize
  /local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/object_detection/summary.py:433: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
    fig, ax = plt.subplots(frameon=False, figsize=figsize)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================== 50 passed, 1 warning in 2.60s =========================
