output file:
processed_pytorch3dcorresponding_points_alignment304.json
function:
corresponding_points_alignment
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestCorrespondingPointsAlignment::test_corresponding_points_alignment FAILED', 'FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_init_transformation', '../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_init_transformation FAILED', 'FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh', 'FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestCorrespondingPointsAlignment::test_corresponding_points_alignment', '../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh FAILED'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.8.5, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/pytorch3d/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/pytorch3d
collecting ... collected 4 items

../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh FAILED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs FAILED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_init_transformation FAILED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestCorrespondingPointsAlignment::test_corresponding_points_alignment FAILED

=================================== FAILURES ===================================
______________________ TestICP.test_compare_with_trimesh _______________________

self = <tests.test_points_alignment.TestICP testMethod=test_compare_with_trimesh>

    def test_compare_with_trimesh(self):
        """
        Compares the outputs of `iterative_closest_point` with the results
        of `trimesh.registration.icp` from the `trimesh` python package:
        https://github.com/mikedh/trimesh
    
        We have run `trimesh.registration.icp` on several random problems
        with different point cloud sizes. The results of trimesh, together with
        the randomly generated input clouds are loaded in the constructor of
        this class and this test compares the loaded results to our runs.
        """
        for n_points_X in (10, 20, 50, 100):
            for n_points_Y in (10, 20, 50, 100):
>               self._compare_with_trimesh(n_points_X=n_points_X, n_points_Y=n_points_Y)

/local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:283: in _compare_with_trimesh
    ) = points_alignment.iterative_closest_point(
/local/data0/moved_data/pytorch3d/pytorch3d/ops/points_alignment.py:103: in iterative_closest_point
    R, T, s = corresponding_points_alignment(Xt_init, Xt_nn_points, weights=mask_X, estimate_scale=estimate_scale, allow_reflection=allow_reflection)
/local/data0/moved_data/pytorch3d/pytorch3d/ops/points_alignment.py:131: in corresponding_points_alignment
    return corresponding_points_alignment(X, Y, weights, estimate_scale, allow_reflection, eps)
/local/data0/moved_data/pytorch3d/pytorch3d/ops/temp.py:20: in corresponding_points_alignment
    weights_sum = np.sum(weights, axis=1, keepdims=True)
<__array_function__ internals>:200: in sum
    ???
/local/data0/moved_data/pytorch3d/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2324: in sum
    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')
ufunc = <ufunc 'add'>, method = 'sum', axis = 1, dtype = None, out = None
kwargs = {'initial': <no value>, 'keepdims': True, 'where': <no value>}
passkwargs = {'keepdims': True}
reduction = <built-in method sum of Tensor object at 0x7133e175b1d0>

    def _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs):
        passkwargs = {k: v for k, v in kwargs.items()
                      if v is not np._NoValue}
    
        if type(obj) is not mu.ndarray:
            try:
                reduction = getattr(obj, method)
            except AttributeError:
                pass
            else:
                # This branch is needed for reductions like any which don't
                # support a dtype.
                if dtype is not None:
                    return reduction(axis=axis, dtype=dtype, out=out, **passkwargs)
                else:
>                   return reduction(axis=axis, out=out, **passkwargs)
E                   TypeError: sum() received an invalid combination of arguments - got (keepdims=bool, axis=int, out=NoneType, ), but expected one of:
E                    * (*, torch.dtype dtype = None)
E                    * (tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None)
E                    * (tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None)

/local/data0/moved_data/pytorch3d/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:84: TypeError
______________________ TestICP.test_heterogeneous_inputs _______________________

self = <tests.test_points_alignment.TestICP testMethod=test_heterogeneous_inputs>
batch_size = 7

    def test_heterogeneous_inputs(self, batch_size=7):
        """
        Tests whether we get the same result when running ICP on
        a set of randomly-sized Pointclouds and on their padded versions.
        """
    
        torch.manual_seed(4)
        device = torch.device("cuda:0")
    
        for estimate_scale in (True, False):
            for max_n_points in (10, 30, 100):
                # initialize ground truth point clouds
                X_pcl, Y_pcl = [
                    TestCorrespondingPointsAlignment.init_point_cloud(
                        batch_size=batch_size,
                        n_points=max_n_points,
                        dim=3,
                        device=device,
                        use_pointclouds=True,
                        random_pcl_size=True,
                    )
                    for _ in range(2)
                ]
    
                # get the padded versions and their num of points
                X_padded = X_pcl.points_padded()
                Y_padded = Y_pcl.points_padded()
                n_points_X = X_pcl.num_points_per_cloud()
                n_points_Y = Y_pcl.num_points_per_cloud()
    
                # run icp with Pointlouds inputs
                (
                    _,
                    _,
                    Xt_pcl,
                    (R_pcl, T_pcl, s_pcl),
                    _,
>               ) = points_alignment.iterative_closest_point(
                    X_pcl,
                    Y_pcl,
                    estimate_scale=estimate_scale,
                    allow_reflection=False,
                    verbose=False,
                    max_iterations=100,
                )

/local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/pytorch3d/pytorch3d/ops/points_alignment.py:103: in iterative_closest_point
    R, T, s = corresponding_points_alignment(Xt_init, Xt_nn_points, weights=mask_X, estimate_scale=estimate_scale, allow_reflection=allow_reflection)
/local/data0/moved_data/pytorch3d/pytorch3d/ops/points_alignment.py:131: in corresponding_points_alignment
    return corresponding_points_alignment(X, Y, weights, estimate_scale, allow_reflection, eps)
/local/data0/moved_data/pytorch3d/pytorch3d/ops/temp.py:20: in corresponding_points_alignment
    weights_sum = np.sum(weights, axis=1, keepdims=True)
<__array_function__ internals>:200: in sum
    ???
/local/data0/moved_data/pytorch3d/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2324: in sum
    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 0., 0., 0., 0.],
        [1., 1., 1., 1., 1... 0., 0.],
        [1., 1., 1., 1., 1., 1., 0., 0., 0.],
        [1., 1., 1., 1., 0., 0., 0., 0., 0.]], device='cuda:0')
ufunc = <ufunc 'add'>, method = 'sum', axis = 1, dtype = None, out = None
kwargs = {'initial': <no value>, 'keepdims': True, 'where': <no value>}
passkwargs = {'keepdims': True}
reduction = <built-in method sum of Tensor object at 0x7133abdf8f40>

    def _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs):
        passkwargs = {k: v for k, v in kwargs.items()
                      if v is not np._NoValue}
    
        if type(obj) is not mu.ndarray:
            try:
                reduction = getattr(obj, method)
            except AttributeError:
                pass
            else:
                # This branch is needed for reductions like any which don't
                # support a dtype.
                if dtype is not None:
                    return reduction(axis=axis, dtype=dtype, out=out, **passkwargs)
                else:
>                   return reduction(axis=axis, out=out, **passkwargs)
E                   TypeError: sum() received an invalid combination of arguments - got (keepdims=bool, axis=int, out=NoneType, ), but expected one of:
E                    * (*, torch.dtype dtype = None)
E                    * (tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None)
E                    * (tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None)

/local/data0/moved_data/pytorch3d/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:84: TypeError
_______________________ TestICP.test_init_transformation _______________________

self = <tests.test_points_alignment.TestICP testMethod=test_init_transformation>
batch_size = 10

    def test_init_transformation(self, batch_size=10):
        """
        First runs a full ICP on a random problem. Then takes a given point
        in the history of ICP iteration transformations, initializes
        a second run of ICP with this transformation and checks whether
        both runs ended with the same solution.
        """
    
        device = torch.device("cuda:0")
    
        for dim in (2, 3, 11):
            for n_points_X in (30, 100):
                for n_points_Y in (30, 100):
                    # initialize ground truth point clouds
                    X, Y = [
                        TestCorrespondingPointsAlignment.init_point_cloud(
                            batch_size=batch_size,
                            n_points=n_points,
                            dim=dim,
                            device=device,
                            use_pointclouds=False,
                            random_pcl_size=True,
                        )
                        for n_points in (n_points_X, n_points_Y)
                    ]
    
                    # run full icp
                    (
                        converged,
                        _,
                        Xt,
                        (R, T, s),
                        t_hist,
>                   ) = points_alignment.iterative_closest_point(
                        X,
                        Y,
                        estimate_scale=False,
                        allow_reflection=False,
                        verbose=False,
                        max_iterations=100,
                    )

/local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/pytorch3d/pytorch3d/ops/points_alignment.py:103: in iterative_closest_point
    R, T, s = corresponding_points_alignment(Xt_init, Xt_nn_points, weights=mask_X, estimate_scale=estimate_scale, allow_reflection=allow_reflection)
/local/data0/moved_data/pytorch3d/pytorch3d/ops/points_alignment.py:131: in corresponding_points_alignment
    return corresponding_points_alignment(X, Y, weights, estimate_scale, allow_reflection, eps)
/local/data0/moved_data/pytorch3d/pytorch3d/ops/temp.py:20: in corresponding_points_alignment
    weights_sum = np.sum(weights, axis=1, keepdims=True)
<__array_function__ internals>:200: in sum
    ???
/local/data0/moved_data/pytorch3d/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2324: in sum
    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., ...1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')
ufunc = <ufunc 'add'>, method = 'sum', axis = 1, dtype = None, out = None
kwargs = {'initial': <no value>, 'keepdims': True, 'where': <no value>}
passkwargs = {'keepdims': True}
reduction = <built-in method sum of Tensor object at 0x713426b57cc0>

    def _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs):
        passkwargs = {k: v for k, v in kwargs.items()
                      if v is not np._NoValue}
    
        if type(obj) is not mu.ndarray:
            try:
                reduction = getattr(obj, method)
            except AttributeError:
                pass
            else:
                # This branch is needed for reductions like any which don't
                # support a dtype.
                if dtype is not None:
                    return reduction(axis=axis, dtype=dtype, out=out, **passkwargs)
                else:
>                   return reduction(axis=axis, out=out, **passkwargs)
E                   TypeError: sum() received an invalid combination of arguments - got (keepdims=bool, axis=int, out=NoneType, ), but expected one of:
E                    * (*, torch.dtype dtype = None)
E                    * (tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None)
E                    * (tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None)

/local/data0/moved_data/pytorch3d/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:84: TypeError
_____ TestCorrespondingPointsAlignment.test_corresponding_points_alignment _____

self = <tests.test_points_alignment.TestCorrespondingPointsAlignment testMethod=test_corresponding_points_alignment>
batch_size = 10

    def test_corresponding_points_alignment(self, batch_size=10):
        """
        Tests whether we can estimate a rigid/similarity motion between
        a randomly initialized point cloud and its randomly transformed version.
    
        The tests are done for all possible combinations
        of the following boolean flags:
            - estimate_scale ... Estimate also a scaling component of
                                 the transformation.
            - reflect ... The ground truth orthonormal part of the generated
                         transformation is a reflection (det==-1).
            - allow_reflection ... If True, the orthonormal matrix of the
                                  estimated transformation is allowed to be
                                  a reflection (det==-1).
            - use_pointclouds ... If True, passes the Pointclouds objects
                                  to corresponding_points_alignment.
        """
        # run this for several different point cloud sizes
        for n_points in (100, 3, 2, 1):
            # run this for several different dimensionalities
            for dim in range(2, 10):
                # switches whether we should use the Pointclouds inputs
                use_point_clouds_cases = (
                    (True, False) if dim == 3 and n_points > 3 else (False,)
                )
                for random_weights in (False, True):
                    for use_pointclouds in use_point_clouds_cases:
                        for estimate_scale in (False, True):
                            for reflect in (False, True):
                                for allow_reflection in (False, True):
>                                   self._test_single_corresponding_points_alignment(
                                        batch_size=10,
                                        n_points=n_points,
                                        dim=dim,
                                        use_pointclouds=use_pointclouds,
                                        estimate_scale=estimate_scale,
                                        reflect=reflect,
                                        allow_reflection=allow_reflection,
                                        random_weights=random_weights,
                                    )

/local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:519: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:592: in _test_single_corresponding_points_alignment
    R_est, T_est, s_est = points_alignment.corresponding_points_alignment(
/local/data0/moved_data/pytorch3d/pytorch3d/ops/points_alignment.py:131: in corresponding_points_alignment
    return corresponding_points_alignment(X, Y, weights, estimate_scale, allow_reflection, eps)
/local/data0/moved_data/pytorch3d/pytorch3d/ops/temp.py:22: in corresponding_points_alignment
    centroid_X = np.sum(X * weights[:, :, np.newaxis], axis=1)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = tensor([[[ 0.1940,  2.1614],
         [-0.1721,  0.8491],
         [-1.9244,  0.6530],
         ...,
         [ 0.5997...         ...,
         [-1.0390, -0.0940],
         [ 0.3311,  0.6411],
         [-0.0195,  0.5738]]], device='cuda:0')
dtype = None

    def __array__(self, dtype=None):
        if has_torch_function_unary(self):
            return handle_torch_function(Tensor.__array__, (self,), self, dtype=dtype)
        if dtype is None:
>           return self.numpy()
E           TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.

/local/data0/moved_data/pytorch3d/venv/lib/python3.8/site-packages/torch/_tensor.py:1083: TypeError
=============================== warnings summary ===============================
tests/test_points_alignment.py::TestICP::test_compare_with_trimesh
tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
tests/test_points_alignment.py::TestICP::test_init_transformation
  /local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
    self.trimesh_results = torch.load(trimesh_results_path)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_init_transformation
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestCorrespondingPointsAlignment::test_corresponding_points_alignment
======================== 4 failed, 3 warnings in 1.46s =========================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.8.5, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/pytorch3d/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/pytorch3d
collecting ... collected 4 items

../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh PASSED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs FAILED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_init_transformation PASSED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestCorrespondingPointsAlignment::test_corresponding_points_alignment PASSED

=================================== FAILURES ===================================
______________________ TestICP.test_heterogeneous_inputs _______________________

self = <tests.test_points_alignment.TestICP testMethod=test_heterogeneous_inputs>
batch_size = 7

    def test_heterogeneous_inputs(self, batch_size=7):
        """
        Tests whether we get the same result when running ICP on
        a set of randomly-sized Pointclouds and on their padded versions.
        """
    
        torch.manual_seed(4)
        device = torch.device("cuda:0")
    
        for estimate_scale in (True, False):
            for max_n_points in (10, 30, 100):
                # initialize ground truth point clouds
                X_pcl, Y_pcl = [
                    TestCorrespondingPointsAlignment.init_point_cloud(
                        batch_size=batch_size,
                        n_points=max_n_points,
                        dim=3,
                        device=device,
                        use_pointclouds=True,
                        random_pcl_size=True,
                    )
                    for _ in range(2)
                ]
    
                # get the padded versions and their num of points
                X_padded = X_pcl.points_padded()
                Y_padded = Y_pcl.points_padded()
                n_points_X = X_pcl.num_points_per_cloud()
                n_points_Y = Y_pcl.num_points_per_cloud()
    
                # run icp with Pointlouds inputs
                (
                    _,
                    _,
                    Xt_pcl,
                    (R_pcl, T_pcl, s_pcl),
                    _,
                ) = points_alignment.iterative_closest_point(
                    X_pcl,
                    Y_pcl,
                    estimate_scale=estimate_scale,
                    allow_reflection=False,
                    verbose=False,
                    max_iterations=100,
                )
                Xt_pcl = Xt_pcl.points_padded()
    
                # run icp with tensor inputs on each element
                # of the batch separately
                icp_results = [
                    points_alignment.iterative_closest_point(
                        X_[None, :n_X, :],
                        Y_[None, :n_Y, :],
                        estimate_scale=estimate_scale,
                        allow_reflection=False,
                        verbose=False,
                        max_iterations=100,
                    )
                    for X_, Y_, n_X, n_Y in zip(
                        X_padded, Y_padded, n_points_X, n_points_Y
                    )
                ]
    
                # parse out the transformation results
                R, T, s = [
                    torch.cat([x.RTs[i] for x in icp_results], dim=0) for i in range(3)
                ]
    
                # check that both sets of transforms are the same
                atol = 1e-5
>               self.assertClose(R_pcl, R, atol=atol)

/local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:233: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/pytorch3d/tests/common_testing.py:209: in assertClose
    self.fail(err)
E   AssertionError: Not close. Max diff 1.4095808267593384. Max relative diff 9.08298397064209 Shape (7, 3, 3). At (4, 0, 0).
=============================== warnings summary ===============================
tests/test_points_alignment.py::TestICP::test_compare_with_trimesh
tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
tests/test_points_alignment.py::TestICP::test_init_transformation
  /local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
    self.trimesh_results = torch.load(trimesh_results_path)

tests/test_points_alignment.py::TestCorrespondingPointsAlignment::test_corresponding_points_alignment
  /local/data0/moved_data/pytorch3d/pytorch3d/ops/points_alignment.py:324: UserWarning: The size of one of the point clouds is <= dim+1. corresponding_points_alignment cannot return a unique rotation.
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
=================== 1 failed, 3 passed, 4 warnings in 2.88s ====================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.8.5, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/pytorch3d/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/pytorch3d
collecting ... collected 4 items

../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh PASSED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs FAILED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_init_transformation PASSED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestCorrespondingPointsAlignment::test_corresponding_points_alignment PASSED

=================================== FAILURES ===================================
______________________ TestICP.test_heterogeneous_inputs _______________________

self = <tests.test_points_alignment.TestICP testMethod=test_heterogeneous_inputs>
batch_size = 7

    def test_heterogeneous_inputs(self, batch_size=7):
        """
        Tests whether we get the same result when running ICP on
        a set of randomly-sized Pointclouds and on their padded versions.
        """
    
        torch.manual_seed(4)
        device = torch.device("cuda:0")
    
        for estimate_scale in (True, False):
            for max_n_points in (10, 30, 100):
                # initialize ground truth point clouds
                X_pcl, Y_pcl = [
                    TestCorrespondingPointsAlignment.init_point_cloud(
                        batch_size=batch_size,
                        n_points=max_n_points,
                        dim=3,
                        device=device,
                        use_pointclouds=True,
                        random_pcl_size=True,
                    )
                    for _ in range(2)
                ]
    
                # get the padded versions and their num of points
                X_padded = X_pcl.points_padded()
                Y_padded = Y_pcl.points_padded()
                n_points_X = X_pcl.num_points_per_cloud()
                n_points_Y = Y_pcl.num_points_per_cloud()
    
                # run icp with Pointlouds inputs
                (
                    _,
                    _,
                    Xt_pcl,
                    (R_pcl, T_pcl, s_pcl),
                    _,
                ) = points_alignment.iterative_closest_point(
                    X_pcl,
                    Y_pcl,
                    estimate_scale=estimate_scale,
                    allow_reflection=False,
                    verbose=False,
                    max_iterations=100,
                )
                Xt_pcl = Xt_pcl.points_padded()
    
                # run icp with tensor inputs on each element
                # of the batch separately
                icp_results = [
                    points_alignment.iterative_closest_point(
                        X_[None, :n_X, :],
                        Y_[None, :n_Y, :],
                        estimate_scale=estimate_scale,
                        allow_reflection=False,
                        verbose=False,
                        max_iterations=100,
                    )
                    for X_, Y_, n_X, n_Y in zip(
                        X_padded, Y_padded, n_points_X, n_points_Y
                    )
                ]
    
                # parse out the transformation results
                R, T, s = [
                    torch.cat([x.RTs[i] for x in icp_results], dim=0) for i in range(3)
                ]
    
                # check that both sets of transforms are the same
                atol = 1e-5
>               self.assertClose(R_pcl, R, atol=atol)

/local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:233: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/pytorch3d/tests/common_testing.py:209: in assertClose
    self.fail(err)
E   AssertionError: Not close. Max diff 1.4095808267593384. Max relative diff 9.08298397064209 Shape (7, 3, 3). At (4, 0, 0).
=============================== warnings summary ===============================
tests/test_points_alignment.py::TestICP::test_compare_with_trimesh
tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
tests/test_points_alignment.py::TestICP::test_init_transformation
  /local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
    self.trimesh_results = torch.load(trimesh_results_path)

tests/test_points_alignment.py::TestCorrespondingPointsAlignment::test_corresponding_points_alignment
  /local/data0/moved_data/pytorch3d/pytorch3d/ops/points_alignment.py:324: UserWarning: The size of one of the point clouds is <= dim+1. corresponding_points_alignment cannot return a unique rotation.
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
=================== 1 failed, 3 passed, 4 warnings in 3.02s ====================
