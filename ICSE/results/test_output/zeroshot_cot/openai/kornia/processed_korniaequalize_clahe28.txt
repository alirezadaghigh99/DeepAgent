output file:
processed_korniaequalize_clahe28.json
function:
equalize_clahe
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] FAILED'}

All Test Cases On Generated code:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'onnxrt', 'inductor', 'openxla', 'jit', 'cudagraphs', 'tvm', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 25 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[0-1.0-grid0-ValueError-Invalid input tensor, it is empty.] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_type PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_jit[cpu-float32] SKIPPED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_module PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] FAILED

=================================== FAILURES ===================================
___________________ TestEqualization.test_smoke[cpu-float32] ___________________

self = <test_equalization.TestEqualization object at 0x7c37f290d720>
device = device(type='cpu'), dtype = torch.float32

    def test_smoke(self, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[3.0931e-01, 7.4665e-01, 8.8804e-01, 8.4283e-01, 8.9896e-01,
           5.1275e-01, 7.1151e-03, 6.8289e-01, ...508e-01, 3.2808e-01, 6.0821e-01, 1.4440e-01,
           4.4226e-01, 1.3720e-01, 9.0829e-01, 1.4362e-02, 5.5947e-01]]]])
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        if not isinstance(input, torch.Tensor):
            raise TypeError('input must be a torch.Tensor.')
        if input.min() < 0 or input.max() > 1:
            raise ValueError('input tensor values must be in the range [0, 1].')
        *batch_dims, C, H, W = input.shape
        input_reshaped = input.view(-1, C, H, W)
>       output = torch.stack([_apply_clahe(img, clip_limit, grid_size, slow_and_differentiable) for img in input_reshaped])
E       TypeError: expected Tensor as element 0 in argument 0, but got NoneType

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:24: TypeError
____________ TestEqualization.test_cardinality[cpu-float32-None-1] _____________

self = <test_equalization.TestEqualization object at 0x7c37f290dbd0>, B = None
C = 1, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.1482, 0.0977, 0.4005, 0.2296, 0.2487, 0.9608, 0.1437, 0.1306,
           0.6160, 0.9059, 0.0280, 0.2406, ...         0.4101, 0.1084, 0.9004, 0.9984, 0.1098, 0.9537, 0.2683, 0.3069,
           0.0159, 0.3838, 0.2113, 0.4412]]]])
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        if not isinstance(input, torch.Tensor):
            raise TypeError('input must be a torch.Tensor.')
        if input.min() < 0 or input.max() > 1:
            raise ValueError('input tensor values must be in the range [0, 1].')
        *batch_dims, C, H, W = input.shape
        input_reshaped = input.view(-1, C, H, W)
>       output = torch.stack([_apply_clahe(img, clip_limit, grid_size, slow_and_differentiable) for img in input_reshaped])
E       TypeError: expected Tensor as element 0 in argument 0, but got NoneType

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:24: TypeError
____________ TestEqualization.test_cardinality[cpu-float32-None-3] _____________

self = <test_equalization.TestEqualization object at 0x7c37f290db10>, B = None
C = 3, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.9101, 0.8180, 0.1650, 0.2738, 0.4830, 0.2141, 0.6065, 0.8038,
           0.3530, 0.5394, 0.9468, 0.6498, ...         0.6248, 0.1943, 0.5925, 0.4164, 0.3582, 0.3133, 0.1975, 0.8516,
           0.3703, 0.3816, 0.8034, 0.8453]]]])
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        if not isinstance(input, torch.Tensor):
            raise TypeError('input must be a torch.Tensor.')
        if input.min() < 0 or input.max() > 1:
            raise ValueError('input tensor values must be in the range [0, 1].')
        *batch_dims, C, H, W = input.shape
        input_reshaped = input.view(-1, C, H, W)
>       output = torch.stack([_apply_clahe(img, clip_limit, grid_size, slow_and_differentiable) for img in input_reshaped])
E       TypeError: expected Tensor as element 0 in argument 0, but got NoneType

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:24: TypeError
______________ TestEqualization.test_cardinality[cpu-float32-1-1] ______________

self = <test_equalization.TestEqualization object at 0x7c37f290df90>, B = 1
C = 1, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.9758, 0.5707, 0.2716, 0.5683, 0.4041, 0.3002, 0.8723, 0.6298,
           0.4863, 0.6279, 0.9549, 0.0555, ...         0.1292, 0.3954, 0.6960, 0.4193, 0.0410, 0.6549, 0.6492, 0.3423,
           0.0211, 0.3299, 0.1269, 0.9275]]]])
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        if not isinstance(input, torch.Tensor):
            raise TypeError('input must be a torch.Tensor.')
        if input.min() < 0 or input.max() > 1:
            raise ValueError('input tensor values must be in the range [0, 1].')
        *batch_dims, C, H, W = input.shape
        input_reshaped = input.view(-1, C, H, W)
>       output = torch.stack([_apply_clahe(img, clip_limit, grid_size, slow_and_differentiable) for img in input_reshaped])
E       TypeError: expected Tensor as element 0 in argument 0, but got NoneType

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:24: TypeError
______________ TestEqualization.test_cardinality[cpu-float32-1-3] ______________

self = <test_equalization.TestEqualization object at 0x7c37f290e050>, B = 1
C = 3, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.6293, 0.3404, 0.9979, 0.0368, 0.0712, 0.4352, 0.9717, 0.5339,
           0.0069, 0.2529, 0.6198, 0.4159, ...         0.4175, 0.5619, 0.0273, 0.3340, 0.4950, 0.0865, 0.1932, 0.3884,
           0.4661, 0.5442, 0.4720, 0.5492]]]])
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        if not isinstance(input, torch.Tensor):
            raise TypeError('input must be a torch.Tensor.')
        if input.min() < 0 or input.max() > 1:
            raise ValueError('input tensor values must be in the range [0, 1].')
        *batch_dims, C, H, W = input.shape
        input_reshaped = input.view(-1, C, H, W)
>       output = torch.stack([_apply_clahe(img, clip_limit, grid_size, slow_and_differentiable) for img in input_reshaped])
E       TypeError: expected Tensor as element 0 in argument 0, but got NoneType

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:24: TypeError
______________ TestEqualization.test_cardinality[cpu-float32-4-1] ______________

self = <test_equalization.TestEqualization object at 0x7c37f290e110>, B = 4
C = 1, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[2.8929e-01, 6.0153e-01, 6.0446e-02, 3.2971e-01, 7.9217e-01,
           5.7078e-01, 5.3071e-01, 7.9188e-01, ...021e-01, 8.1958e-01, 8.1038e-01, 3.8078e-01,
           4.2925e-01, 3.1158e-01, 5.1977e-02, 4.0875e-01, 6.4999e-01]]]])
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        if not isinstance(input, torch.Tensor):
            raise TypeError('input must be a torch.Tensor.')
        if input.min() < 0 or input.max() > 1:
            raise ValueError('input tensor values must be in the range [0, 1].')
        *batch_dims, C, H, W = input.shape
        input_reshaped = input.view(-1, C, H, W)
>       output = torch.stack([_apply_clahe(img, clip_limit, grid_size, slow_and_differentiable) for img in input_reshaped])
E       TypeError: expected Tensor as element 0 in argument 0, but got NoneType

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:24: TypeError
______________ TestEqualization.test_cardinality[cpu-float32-4-3] ______________

self = <test_equalization.TestEqualization object at 0x7c37f290e1d0>, B = 4
C = 3, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.3349, 0.5570, 0.9849,  ..., 0.3731, 0.7488, 0.6683],
          [0.8351, 0.5800, 0.0525,  ..., 0.5040, 0.6...90, 0.2738, 0.4542,  ..., 0.9980, 0.4556, 0.9958],
          [0.8222, 0.3742, 0.0471,  ..., 0.6595, 0.4129, 0.5804]]]])
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        if not isinstance(input, torch.Tensor):
            raise TypeError('input must be a torch.Tensor.')
        if input.min() < 0 or input.max() > 1:
            raise ValueError('input tensor values must be in the range [0, 1].')
        *batch_dims, C, H, W = input.shape
        input_reshaped = input.view(-1, C, H, W)
>       output = torch.stack([_apply_clahe(img, clip_limit, grid_size, slow_and_differentiable) for img in input_reshaped])
E       TypeError: expected Tensor as element 0 in argument 0, but got NoneType

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:24: TypeError
_________ TestEqualization.test_optional_params[cpu-float32-0.0-None] __________

self = <test_equalization.TestEqualization object at 0x7c37f290e560>, clip = 0.0
grid = None, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("clip, grid", [(0.0, None), (None, (2, 2)), (2.0, (2, 2))])
    def test_optional_params(self, clip, grid, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
        if clip is None:
            res = enhance.equalize_clahe(img, grid_size=grid)
        elif grid is None:
>           res = enhance.equalize_clahe(img, clip_limit=clip)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:39: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.4682, 0.8927, 0.5913, 0.2500, 0.1357, 0.9055, 0.2991, 0.8843,
           0.5030, 0.6029, 0.5592, 0.1135, ...         0.2910, 0.4391, 0.2781, 0.7307, 0.9283, 0.1131, 0.0824, 0.5579,
           0.2980, 0.7639, 0.2575, 0.2677]]]])
clip_limit = 0.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        if not isinstance(input, torch.Tensor):
            raise TypeError('input must be a torch.Tensor.')
        if input.min() < 0 or input.max() > 1:
            raise ValueError('input tensor values must be in the range [0, 1].')
        *batch_dims, C, H, W = input.shape
        input_reshaped = input.view(-1, C, H, W)
>       output = torch.stack([_apply_clahe(img, clip_limit, grid_size, slow_and_differentiable) for img in input_reshaped])
E       TypeError: expected Tensor as element 0 in argument 0, but got NoneType

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:24: TypeError
________ TestEqualization.test_optional_params[cpu-float32-None-grid1] _________

self = <test_equalization.TestEqualization object at 0x7c37f290e4a0>
clip = None, grid = (2, 2), device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("clip, grid", [(0.0, None), (None, (2, 2)), (2.0, (2, 2))])
    def test_optional_params(self, clip, grid, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
        if clip is None:
>           res = enhance.equalize_clahe(img, grid_size=grid)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.0691, 0.8316, 0.4935, 0.3984, 0.3770, 0.3053, 0.7149, 0.4245,
           0.2875, 0.8462, 0.3735, 0.9141, ...         0.7492, 0.9385, 0.6850, 0.1339, 0.8572, 0.0253, 0.1875, 0.2938,
           0.2427, 0.0767, 0.1675, 0.8198]]]])
clip_limit = 40.0, grid_size = (2, 2), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        if not isinstance(input, torch.Tensor):
            raise TypeError('input must be a torch.Tensor.')
        if input.min() < 0 or input.max() > 1:
            raise ValueError('input tensor values must be in the range [0, 1].')
        *batch_dims, C, H, W = input.shape
        input_reshaped = input.view(-1, C, H, W)
>       output = torch.stack([_apply_clahe(img, clip_limit, grid_size, slow_and_differentiable) for img in input_reshaped])
E       TypeError: expected Tensor as element 0 in argument 0, but got NoneType

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:24: TypeError
_________ TestEqualization.test_optional_params[cpu-float32-2.0-grid2] _________

self = <test_equalization.TestEqualization object at 0x7c37f290e800>, clip = 2.0
grid = (2, 2), device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("clip, grid", [(0.0, None), (None, (2, 2)), (2.0, (2, 2))])
    def test_optional_params(self, clip, grid, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
        if clip is None:
            res = enhance.equalize_clahe(img, grid_size=grid)
        elif grid is None:
            res = enhance.equalize_clahe(img, clip_limit=clip)
        else:
>           res = enhance.equalize_clahe(img, clip, grid)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.0132, 0.7953, 0.5944, 0.8346, 0.7601, 0.5224, 0.8642, 0.5072,
           0.3585, 0.8579, 0.3902, 0.3732, ...         0.9133, 0.2126, 0.4968, 0.6906, 0.3813, 0.3363, 0.8011, 0.7493,
           0.6952, 0.6235, 0.7648, 0.8749]]]])
clip_limit = 2.0, grid_size = (2, 2), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        if not isinstance(input, torch.Tensor):
            raise TypeError('input must be a torch.Tensor.')
        if input.min() < 0 or input.max() > 1:
            raise ValueError('input tensor values must be in the range [0, 1].')
        *batch_dims, C, H, W = input.shape
        input_reshaped = input.view(-1, C, H, W)
>       output = torch.stack([_apply_clahe(img, clip_limit, grid_size, slow_and_differentiable) for img in input_reshaped])
E       TypeError: expected Tensor as element 0 in argument 0, but got NoneType

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:24: TypeError
_ TestEqualization.test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] _

self = <test_equalization.TestEqualization object at 0x7c37f290ec50>, B = 1
clip = 1, grid = (2, 2), exception_type = <class 'TypeError'>
expected_error_msg = 'Input clip_limit type is not float. Got'

    @pytest.mark.parametrize(
        "B, clip, grid, exception_type, expected_error_msg",
        [
            (0, 1.0, (2, 2), ValueError, "Invalid input tensor, it is empty."),  # from perform_keep_shape_image
            (1, 1, (2, 2), TypeError, "Input clip_limit type is not float. Got"),
            (1, 2.0, 2, TypeError, "Input grid_size type is not Tuple. Got"),
            (1, 2.0, (2, 2, 2), TypeError, "Input grid_size is not a Tuple with 2 elements. Got 3"),
            (1, 2.0, (2, 2.0), TypeError, "Input grid_size type is not valid, must be a Tuple[int, int]"),
            (1, 2.0, (2, 0), ValueError, "Input grid_size elements must be positive. Got"),
        ],
    )
    def test_exception(self, B, clip, grid, exception_type, expected_error_msg):
        C, H, W = 1, 10, 20
        img = torch.rand(B, C, H, W)
        with pytest.raises(exception_type) as errinfo:
            enhance.equalize_clahe(img, clip, grid)
>       assert expected_error_msg in str(errinfo)
E       assert 'Input clip_limit type is not float. Got' in "<ExceptionInfo TypeError('clip_limit must be a float.') tblen=4>"
E        +  where "<ExceptionInfo TypeError('clip_limit must be a float.') tblen=4>" = str(<ExceptionInfo TypeError('clip_limit must be a float.') tblen=4>)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:61: AssertionError
_ TestEqualization.test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] _

self = <test_equalization.TestEqualization object at 0x7c37f290d5a0>, B = 1
clip = 2.0, grid = 2, exception_type = <class 'TypeError'>
expected_error_msg = 'Input grid_size type is not Tuple. Got'

    @pytest.mark.parametrize(
        "B, clip, grid, exception_type, expected_error_msg",
        [
            (0, 1.0, (2, 2), ValueError, "Invalid input tensor, it is empty."),  # from perform_keep_shape_image
            (1, 1, (2, 2), TypeError, "Input clip_limit type is not float. Got"),
            (1, 2.0, 2, TypeError, "Input grid_size type is not Tuple. Got"),
            (1, 2.0, (2, 2, 2), TypeError, "Input grid_size is not a Tuple with 2 elements. Got 3"),
            (1, 2.0, (2, 2.0), TypeError, "Input grid_size type is not valid, must be a Tuple[int, int]"),
            (1, 2.0, (2, 0), ValueError, "Input grid_size elements must be positive. Got"),
        ],
    )
    def test_exception(self, B, clip, grid, exception_type, expected_error_msg):
        C, H, W = 1, 10, 20
        img = torch.rand(B, C, H, W)
        with pytest.raises(exception_type) as errinfo:
            enhance.equalize_clahe(img, clip, grid)
>       assert expected_error_msg in str(errinfo)
E       assert 'Input grid_size type is not Tuple. Got' in "<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>"
E        +  where "<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>" = str(<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:61: AssertionError
_ TestEqualization.test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] _

self = <test_equalization.TestEqualization object at 0x7c37f290ee60>, B = 1
clip = 2.0, grid = (2, 2, 2), exception_type = <class 'TypeError'>
expected_error_msg = 'Input grid_size is not a Tuple with 2 elements. Got 3'

    @pytest.mark.parametrize(
        "B, clip, grid, exception_type, expected_error_msg",
        [
            (0, 1.0, (2, 2), ValueError, "Invalid input tensor, it is empty."),  # from perform_keep_shape_image
            (1, 1, (2, 2), TypeError, "Input clip_limit type is not float. Got"),
            (1, 2.0, 2, TypeError, "Input grid_size type is not Tuple. Got"),
            (1, 2.0, (2, 2, 2), TypeError, "Input grid_size is not a Tuple with 2 elements. Got 3"),
            (1, 2.0, (2, 2.0), TypeError, "Input grid_size type is not valid, must be a Tuple[int, int]"),
            (1, 2.0, (2, 0), ValueError, "Input grid_size elements must be positive. Got"),
        ],
    )
    def test_exception(self, B, clip, grid, exception_type, expected_error_msg):
        C, H, W = 1, 10, 20
        img = torch.rand(B, C, H, W)
        with pytest.raises(exception_type) as errinfo:
            enhance.equalize_clahe(img, clip, grid)
>       assert expected_error_msg in str(errinfo)
E       assert 'Input grid_size is not a Tuple with 2 elements. Got 3' in "<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>"
E        +  where "<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>" = str(<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:61: AssertionError
_ TestEqualization.test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] _

self = <test_equalization.TestEqualization object at 0x7c37f290ef20>, B = 1
clip = 2.0, grid = (2, 2.0), exception_type = <class 'TypeError'>
expected_error_msg = 'Input grid_size type is not valid, must be a Tuple[int, int]'

    @pytest.mark.parametrize(
        "B, clip, grid, exception_type, expected_error_msg",
        [
            (0, 1.0, (2, 2), ValueError, "Invalid input tensor, it is empty."),  # from perform_keep_shape_image
            (1, 1, (2, 2), TypeError, "Input clip_limit type is not float. Got"),
            (1, 2.0, 2, TypeError, "Input grid_size type is not Tuple. Got"),
            (1, 2.0, (2, 2, 2), TypeError, "Input grid_size is not a Tuple with 2 elements. Got 3"),
            (1, 2.0, (2, 2.0), TypeError, "Input grid_size type is not valid, must be a Tuple[int, int]"),
            (1, 2.0, (2, 0), ValueError, "Input grid_size elements must be positive. Got"),
        ],
    )
    def test_exception(self, B, clip, grid, exception_type, expected_error_msg):
        C, H, W = 1, 10, 20
        img = torch.rand(B, C, H, W)
        with pytest.raises(exception_type) as errinfo:
            enhance.equalize_clahe(img, clip, grid)
>       assert expected_error_msg in str(errinfo)
E       assert 'Input grid_size type is not valid, must be a Tuple[int, int]' in "<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>"
E        +  where "<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>" = str(<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:61: AssertionError
_ TestEqualization.test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] _

self = <test_equalization.TestEqualization object at 0x7c37f290efe0>, B = 1
clip = 2.0, grid = (2, 0), exception_type = <class 'ValueError'>
expected_error_msg = 'Input grid_size elements must be positive. Got'

    @pytest.mark.parametrize(
        "B, clip, grid, exception_type, expected_error_msg",
        [
            (0, 1.0, (2, 2), ValueError, "Invalid input tensor, it is empty."),  # from perform_keep_shape_image
            (1, 1, (2, 2), TypeError, "Input clip_limit type is not float. Got"),
            (1, 2.0, 2, TypeError, "Input grid_size type is not Tuple. Got"),
            (1, 2.0, (2, 2, 2), TypeError, "Input grid_size is not a Tuple with 2 elements. Got 3"),
            (1, 2.0, (2, 2.0), TypeError, "Input grid_size type is not valid, must be a Tuple[int, int]"),
            (1, 2.0, (2, 0), ValueError, "Input grid_size elements must be positive. Got"),
        ],
    )
    def test_exception(self, B, clip, grid, exception_type, expected_error_msg):
        C, H, W = 1, 10, 20
        img = torch.rand(B, C, H, W)
        with pytest.raises(exception_type) as errinfo:
            enhance.equalize_clahe(img, clip, grid)
>       assert expected_error_msg in str(errinfo)
E       assert 'Input grid_size elements must be positive. Got' in "<ExceptionInfo ValueError('All elements of grid_size must be positive.') tblen=4>"
E        +  where "<ExceptionInfo ValueError('All elements of grid_size must be positive.') tblen=4>" = str(<ExceptionInfo ValueError('All elements of grid_size must be positive.') tblen=4>)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:61: AssertionError
______________ TestEqualization.test_exception_tensor_dims[dims0] ______________

self = <test_equalization.TestEqualization object at 0x7c37f290f1f0>
dims = (1, 1, 1, 1, 1)

    @pytest.mark.parametrize("dims", [(1, 1, 1, 1, 1), (1, 1)])
    def test_exception_tensor_dims(self, dims):
        img = torch.rand(dims)
        with pytest.raises(ValueError):
>           enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.9975]]]]), clip_limit = 40.0, grid_size = (8, 8)
slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        if not isinstance(input, torch.Tensor):
            raise TypeError('input must be a torch.Tensor.')
        if input.min() < 0 or input.max() > 1:
            raise ValueError('input tensor values must be in the range [0, 1].')
        *batch_dims, C, H, W = input.shape
        input_reshaped = input.view(-1, C, H, W)
>       output = torch.stack([_apply_clahe(img, clip_limit, grid_size, slow_and_differentiable) for img in input_reshaped])
E       TypeError: expected Tensor as element 0 in argument 0, but got NoneType

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:24: TypeError
______________ TestEqualization.test_exception_tensor_dims[dims1] ______________

self = <test_equalization.TestEqualization object at 0x7c37f290f2b0>
dims = (1, 1)

    @pytest.mark.parametrize("dims", [(1, 1, 1, 1, 1), (1, 1)])
    def test_exception_tensor_dims(self, dims):
        img = torch.rand(dims)
        with pytest.raises(ValueError):
>           enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.8323]]]]), clip_limit = 40.0, grid_size = (8, 8)
slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        if not isinstance(input, torch.Tensor):
            raise TypeError('input must be a torch.Tensor.')
        if input.min() < 0 or input.max() > 1:
            raise ValueError('input tensor values must be in the range [0, 1].')
        *batch_dims, C, H, W = input.shape
        input_reshaped = input.view(-1, C, H, W)
>       output = torch.stack([_apply_clahe(img, clip_limit, grid_size, slow_and_differentiable) for img in input_reshaped])
E       TypeError: expected Tensor as element 0 in argument 0, but got NoneType

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:24: TypeError
_____________________ TestEqualization.test_gradcheck[cpu] _____________________

self = <test_equalization.TestEqualization object at 0x7c37f290f7c0>
device = device(type='cpu')

    def test_gradcheck(self, device):
        torch.random.manual_seed(4)
        bs, channels, height, width = 1, 1, 11, 11
        inputs = torch.rand(bs, channels, height, width, device=device, dtype=torch.float64)
    
        def grad_rot(data, a, b, c):
            rot = rotate(data, torch.tensor(30.0, dtype=data.dtype, device=device))
            return enhance.equalize_clahe(rot, a, b, c)
    
>       self.gradcheck(grad_rot, (inputs, 40.0, (2, 2), True), nondet_tol=1e-4)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2074: in _gradcheck_helper
    func_out = func(*tupled_inputs)
/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:80: in grad_rot
    return enhance.equalize_clahe(rot, a, b, c)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.0000, 0.0000, 0.1003, 0.2967, 0.6151, 0.3659, 0.2140, 0.2394,
           0.4072, 0.0181, 0.0000],
       ...7, 0.7032, 0.4179,
           0.1644, 0.0000, 0.0000]]]], dtype=torch.float64,
       grad_fn=<GridSampler2DBackward0>)
clip_limit = 40.0, grid_size = (2, 2), slow_and_differentiable = True

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        if not isinstance(input, torch.Tensor):
            raise TypeError('input must be a torch.Tensor.')
        if input.min() < 0 or input.max() > 1:
            raise ValueError('input tensor values must be in the range [0, 1].')
        *batch_dims, C, H, W = input.shape
        input_reshaped = input.view(-1, C, H, W)
>       output = torch.stack([_apply_clahe(img, clip_limit, grid_size, slow_and_differentiable) for img in input_reshaped])
E       TypeError: expected Tensor as element 0 in argument 0, but got NoneType

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:24: TypeError
____________________ TestEqualization.test_he[cpu-float32] _____________________

self = <test_equalization.TestEqualization object at 0x7c37f2938040>
img = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ...         0.4211, 0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895,
           0.8421, 0.8947, 0.9474, 1.0000]]]])

    def test_he(self, img):
        # should be similar to enhance.equalize but slower. Similar because the lut is computed in a different way.
        clip_limit: float = 0.0
        grid_size: Tuple = (1, 1)
>       res = enhance.equalize_clahe(img, clip_limit=clip_limit, grid_size=grid_size)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ...         0.4211, 0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895,
           0.8421, 0.8947, 0.9474, 1.0000]]]])
clip_limit = 0.0, grid_size = (1, 1), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        if not isinstance(input, torch.Tensor):
            raise TypeError('input must be a torch.Tensor.')
        if input.min() < 0 or input.max() > 1:
            raise ValueError('input tensor values must be in the range [0, 1].')
        *batch_dims, C, H, W = input.shape
        input_reshaped = input.view(-1, C, H, W)
>       output = torch.stack([_apply_clahe(img, clip_limit, grid_size, slow_and_differentiable) for img in input_reshaped])
E       TypeError: expected Tensor as element 0 in argument 0, but got NoneType

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:24: TypeError
____________________ TestEqualization.test_ahe[cpu-float32] ____________________

self = <test_equalization.TestEqualization object at 0x7c37f29383a0>
img = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ...         0.4211, 0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895,
           0.8421, 0.8947, 0.9474, 1.0000]]]])

    def test_ahe(self, img):
        clip_limit: float = 0.0
        grid_size: Tuple = (8, 8)
>       res = enhance.equalize_clahe(img, clip_limit=clip_limit, grid_size=grid_size)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ...         0.4211, 0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895,
           0.8421, 0.8947, 0.9474, 1.0000]]]])
clip_limit = 0.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        if not isinstance(input, torch.Tensor):
            raise TypeError('input must be a torch.Tensor.')
        if input.min() < 0 or input.max() > 1:
            raise ValueError('input tensor values must be in the range [0, 1].')
        *batch_dims, C, H, W = input.shape
        input_reshaped = input.view(-1, C, H, W)
>       output = torch.stack([_apply_clahe(img, clip_limit, grid_size, slow_and_differentiable) for img in input_reshaped])
E       TypeError: expected Tensor as element 0 in argument 0, but got NoneType

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:24: TypeError
___________________ TestEqualization.test_clahe[cpu-float32] ___________________

self = <test_equalization.TestEqualization object at 0x7c37f2938700>
img = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ...         0.4211, 0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895,
           0.8421, 0.8947, 0.9474, 1.0000]]]])

    def test_clahe(self, img):
        clip_limit: float = 2.0
        grid_size: Tuple = (8, 8)
>       res = enhance.equalize_clahe(img, clip_limit=clip_limit, grid_size=grid_size)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ...         0.4211, 0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895,
           0.8421, 0.8947, 0.9474, 1.0000]]]])
clip_limit = 2.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        if not isinstance(input, torch.Tensor):
            raise TypeError('input must be a torch.Tensor.')
        if input.min() < 0 or input.max() > 1:
            raise ValueError('input tensor values must be in the range [0, 1].')
        *batch_dims, C, H, W = input.shape
        input_reshaped = input.view(-1, C, H, W)
>       output = torch.stack([_apply_clahe(img, clip_limit, grid_size, slow_and_differentiable) for img in input_reshaped])
E       TypeError: expected Tensor as element 0 in argument 0, but got NoneType

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:24: TypeError
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32]
=================== 21 failed, 3 passed, 1 skipped in 0.52s ====================


Final Test Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'openxla', 'cudagraphs', 'tvm', 'jit', 'onnxrt', 'inductor', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 25 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[0-1.0-grid0-ValueError-Invalid input tensor, it is empty.] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_type PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_jit[cpu-float32] SKIPPED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_module PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] PASSED

======================== 24 passed, 1 skipped in 0.24s =========================


Initial Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'inductor', 'cudagraphs', 'onnxrt', 'tvm', 'openxla', 'jit', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 25 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[0-1.0-grid0-ValueError-Invalid input tensor, it is empty.] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_type PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_jit[cpu-float32] SKIPPED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_module PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] PASSED

======================== 24 passed, 1 skipped in 0.23s =========================
