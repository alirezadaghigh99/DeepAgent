output file:
processed_kornia_compute_tiles364.json
function:
_compute_tiles
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] FAILED'}

All Test Cases On Generated code:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'tvm', 'cudagraphs', 'onnxrt', 'openxla', 'inductor', 'jit', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 25 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[0-1.0-grid0-ValueError-Invalid input tensor, it is empty.] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_type PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_jit[cpu-float32] SKIPPED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_module PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] FAILED

=================================== FAILURES ===================================
___________________ TestEqualization.test_smoke[cpu-float32] ___________________

self = <test_equalization.TestEqualization object at 0x747c9dd29750>
device = device(type='cpu'), dtype = torch.float32

    def test_smoke(self, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:247: in equalize_clahe
    interp_tiles: torch.Tensor = _compute_interpolation_tiles(img_padded, tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

padded_imgs = tensor([[[[0.0967, 0.0951, 0.4516, 0.9566, 0.4991, 0.5404, 0.6595, 0.6280,
           0.6952, 0.8355, 0.2794, 0.6767, ... 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])
tile_size = (3, 3)

    def _compute_interpolation_tiles(padded_imgs: torch.Tensor, tile_size: Tuple[int, int]) -> torch.Tensor:
        """Compute interpolation tiles on a properly padded set of images.
    
        Note that images must be padded. So, the tile_size (TH, TW) * grid_size (GH, GW) = image_size (H, W)
    
        Args:
            padded_imgs: batch of 2D images with shape (B, C, H, W) already padded to extract tiles
                                        of size (TH, TW).
            tile_size: shape of the current tiles (TH, TW).
    
        Returns:
            tensor with the interpolation tiles (B, 2GH, 2GW, C, TH/2, TW/2).
        """
        if padded_imgs.dim() != 4:
            raise AssertionError('Images Tensor must be 4D.')
        if padded_imgs.shape[-2] % tile_size[0] != 0:
            raise AssertionError('Images are not correctly padded.')
        if padded_imgs.shape[-1] % tile_size[1] != 0:
            raise AssertionError('Images are not correctly padded.')
        interp_kernel_vert: int = tile_size[0] // 2
        interp_kernel_horz: int = tile_size[1] // 2
        c: int = padded_imgs.shape[-3]
        interp_tiles: torch.Tensor = padded_imgs.unfold(1, c, c).unfold(2, interp_kernel_vert, interp_kernel_vert).unfold(3, interp_kernel_horz, interp_kernel_horz).squeeze(1).contiguous()
        if interp_tiles.shape[-3] != c:
            raise AssertionError
        if interp_tiles.shape[-2] != tile_size[0] / 2:
>           raise AssertionError
E           AssertionError

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:76: AssertionError
____________ TestEqualization.test_cardinality[cpu-float32-None-1] _____________

self = <test_equalization.TestEqualization object at 0x747c9dd29c00>, B = None
C = 1, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:247: in equalize_clahe
    interp_tiles: torch.Tensor = _compute_interpolation_tiles(img_padded, tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

padded_imgs = tensor([[[[8.1170e-01, 7.3857e-01, 5.2617e-01, 9.9101e-01, 1.7697e-01,
           5.5733e-01, 2.5031e-01, 4.4425e-01, ...000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]])
tile_size = (3, 3)

    def _compute_interpolation_tiles(padded_imgs: torch.Tensor, tile_size: Tuple[int, int]) -> torch.Tensor:
        """Compute interpolation tiles on a properly padded set of images.
    
        Note that images must be padded. So, the tile_size (TH, TW) * grid_size (GH, GW) = image_size (H, W)
    
        Args:
            padded_imgs: batch of 2D images with shape (B, C, H, W) already padded to extract tiles
                                        of size (TH, TW).
            tile_size: shape of the current tiles (TH, TW).
    
        Returns:
            tensor with the interpolation tiles (B, 2GH, 2GW, C, TH/2, TW/2).
        """
        if padded_imgs.dim() != 4:
            raise AssertionError('Images Tensor must be 4D.')
        if padded_imgs.shape[-2] % tile_size[0] != 0:
            raise AssertionError('Images are not correctly padded.')
        if padded_imgs.shape[-1] % tile_size[1] != 0:
            raise AssertionError('Images are not correctly padded.')
        interp_kernel_vert: int = tile_size[0] // 2
        interp_kernel_horz: int = tile_size[1] // 2
        c: int = padded_imgs.shape[-3]
        interp_tiles: torch.Tensor = padded_imgs.unfold(1, c, c).unfold(2, interp_kernel_vert, interp_kernel_vert).unfold(3, interp_kernel_horz, interp_kernel_horz).squeeze(1).contiguous()
        if interp_tiles.shape[-3] != c:
            raise AssertionError
        if interp_tiles.shape[-2] != tile_size[0] / 2:
>           raise AssertionError
E           AssertionError

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:76: AssertionError
____________ TestEqualization.test_cardinality[cpu-float32-None-3] _____________

self = <test_equalization.TestEqualization object at 0x747c9dd29b40>, B = None
C = 3, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:247: in equalize_clahe
    interp_tiles: torch.Tensor = _compute_interpolation_tiles(img_padded, tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

padded_imgs = tensor([[[[0.9748, 0.9617, 0.7823,  ..., 0.0000, 0.0000, 0.0000],
          [0.1796, 0.7281, 0.1950,  ..., 0.0000, 0.0...00, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]])
tile_size = (3, 3)

    def _compute_interpolation_tiles(padded_imgs: torch.Tensor, tile_size: Tuple[int, int]) -> torch.Tensor:
        """Compute interpolation tiles on a properly padded set of images.
    
        Note that images must be padded. So, the tile_size (TH, TW) * grid_size (GH, GW) = image_size (H, W)
    
        Args:
            padded_imgs: batch of 2D images with shape (B, C, H, W) already padded to extract tiles
                                        of size (TH, TW).
            tile_size: shape of the current tiles (TH, TW).
    
        Returns:
            tensor with the interpolation tiles (B, 2GH, 2GW, C, TH/2, TW/2).
        """
        if padded_imgs.dim() != 4:
            raise AssertionError('Images Tensor must be 4D.')
        if padded_imgs.shape[-2] % tile_size[0] != 0:
            raise AssertionError('Images are not correctly padded.')
        if padded_imgs.shape[-1] % tile_size[1] != 0:
            raise AssertionError('Images are not correctly padded.')
        interp_kernel_vert: int = tile_size[0] // 2
        interp_kernel_horz: int = tile_size[1] // 2
        c: int = padded_imgs.shape[-3]
        interp_tiles: torch.Tensor = padded_imgs.unfold(1, c, c).unfold(2, interp_kernel_vert, interp_kernel_vert).unfold(3, interp_kernel_horz, interp_kernel_horz).squeeze(1).contiguous()
        if interp_tiles.shape[-3] != c:
            raise AssertionError
        if interp_tiles.shape[-2] != tile_size[0] / 2:
>           raise AssertionError
E           AssertionError

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:76: AssertionError
______________ TestEqualization.test_cardinality[cpu-float32-1-1] ______________

self = <test_equalization.TestEqualization object at 0x747c9dd29fc0>, B = 1
C = 1, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:247: in equalize_clahe
    interp_tiles: torch.Tensor = _compute_interpolation_tiles(img_padded, tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

padded_imgs = tensor([[[[0.4395, 0.9658, 0.9355, 0.7872, 0.9963, 0.8645, 0.3705, 0.6269,
           0.2492, 0.7462, 0.1139, 0.8656, ... 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])
tile_size = (3, 3)

    def _compute_interpolation_tiles(padded_imgs: torch.Tensor, tile_size: Tuple[int, int]) -> torch.Tensor:
        """Compute interpolation tiles on a properly padded set of images.
    
        Note that images must be padded. So, the tile_size (TH, TW) * grid_size (GH, GW) = image_size (H, W)
    
        Args:
            padded_imgs: batch of 2D images with shape (B, C, H, W) already padded to extract tiles
                                        of size (TH, TW).
            tile_size: shape of the current tiles (TH, TW).
    
        Returns:
            tensor with the interpolation tiles (B, 2GH, 2GW, C, TH/2, TW/2).
        """
        if padded_imgs.dim() != 4:
            raise AssertionError('Images Tensor must be 4D.')
        if padded_imgs.shape[-2] % tile_size[0] != 0:
            raise AssertionError('Images are not correctly padded.')
        if padded_imgs.shape[-1] % tile_size[1] != 0:
            raise AssertionError('Images are not correctly padded.')
        interp_kernel_vert: int = tile_size[0] // 2
        interp_kernel_horz: int = tile_size[1] // 2
        c: int = padded_imgs.shape[-3]
        interp_tiles: torch.Tensor = padded_imgs.unfold(1, c, c).unfold(2, interp_kernel_vert, interp_kernel_vert).unfold(3, interp_kernel_horz, interp_kernel_horz).squeeze(1).contiguous()
        if interp_tiles.shape[-3] != c:
            raise AssertionError
        if interp_tiles.shape[-2] != tile_size[0] / 2:
>           raise AssertionError
E           AssertionError

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:76: AssertionError
______________ TestEqualization.test_cardinality[cpu-float32-1-3] ______________

self = <test_equalization.TestEqualization object at 0x747c9dd2a080>, B = 1
C = 3, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:247: in equalize_clahe
    interp_tiles: torch.Tensor = _compute_interpolation_tiles(img_padded, tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

padded_imgs = tensor([[[[0.4353, 0.1998, 0.7405,  ..., 0.0000, 0.0000, 0.0000],
          [0.6407, 0.1819, 0.8220,  ..., 0.0000, 0.0...00, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]])
tile_size = (3, 3)

    def _compute_interpolation_tiles(padded_imgs: torch.Tensor, tile_size: Tuple[int, int]) -> torch.Tensor:
        """Compute interpolation tiles on a properly padded set of images.
    
        Note that images must be padded. So, the tile_size (TH, TW) * grid_size (GH, GW) = image_size (H, W)
    
        Args:
            padded_imgs: batch of 2D images with shape (B, C, H, W) already padded to extract tiles
                                        of size (TH, TW).
            tile_size: shape of the current tiles (TH, TW).
    
        Returns:
            tensor with the interpolation tiles (B, 2GH, 2GW, C, TH/2, TW/2).
        """
        if padded_imgs.dim() != 4:
            raise AssertionError('Images Tensor must be 4D.')
        if padded_imgs.shape[-2] % tile_size[0] != 0:
            raise AssertionError('Images are not correctly padded.')
        if padded_imgs.shape[-1] % tile_size[1] != 0:
            raise AssertionError('Images are not correctly padded.')
        interp_kernel_vert: int = tile_size[0] // 2
        interp_kernel_horz: int = tile_size[1] // 2
        c: int = padded_imgs.shape[-3]
        interp_tiles: torch.Tensor = padded_imgs.unfold(1, c, c).unfold(2, interp_kernel_vert, interp_kernel_vert).unfold(3, interp_kernel_horz, interp_kernel_horz).squeeze(1).contiguous()
        if interp_tiles.shape[-3] != c:
            raise AssertionError
        if interp_tiles.shape[-2] != tile_size[0] / 2:
>           raise AssertionError
E           AssertionError

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:76: AssertionError
______________ TestEqualization.test_cardinality[cpu-float32-4-1] ______________

self = <test_equalization.TestEqualization object at 0x747c9dd2a140>, B = 4
C = 1, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:247: in equalize_clahe
    interp_tiles: torch.Tensor = _compute_interpolation_tiles(img_padded, tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

padded_imgs = tensor([[[[0.2115, 0.2204, 0.0742,  ..., 0.0000, 0.0000, 0.0000],
          [0.7554, 0.8567, 0.2036,  ..., 0.0000, 0.0...00, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]])
tile_size = (3, 3)

    def _compute_interpolation_tiles(padded_imgs: torch.Tensor, tile_size: Tuple[int, int]) -> torch.Tensor:
        """Compute interpolation tiles on a properly padded set of images.
    
        Note that images must be padded. So, the tile_size (TH, TW) * grid_size (GH, GW) = image_size (H, W)
    
        Args:
            padded_imgs: batch of 2D images with shape (B, C, H, W) already padded to extract tiles
                                        of size (TH, TW).
            tile_size: shape of the current tiles (TH, TW).
    
        Returns:
            tensor with the interpolation tiles (B, 2GH, 2GW, C, TH/2, TW/2).
        """
        if padded_imgs.dim() != 4:
            raise AssertionError('Images Tensor must be 4D.')
        if padded_imgs.shape[-2] % tile_size[0] != 0:
            raise AssertionError('Images are not correctly padded.')
        if padded_imgs.shape[-1] % tile_size[1] != 0:
            raise AssertionError('Images are not correctly padded.')
        interp_kernel_vert: int = tile_size[0] // 2
        interp_kernel_horz: int = tile_size[1] // 2
        c: int = padded_imgs.shape[-3]
        interp_tiles: torch.Tensor = padded_imgs.unfold(1, c, c).unfold(2, interp_kernel_vert, interp_kernel_vert).unfold(3, interp_kernel_horz, interp_kernel_horz).squeeze(1).contiguous()
        if interp_tiles.shape[-3] != c:
            raise AssertionError
        if interp_tiles.shape[-2] != tile_size[0] / 2:
>           raise AssertionError
E           AssertionError

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:76: AssertionError
______________ TestEqualization.test_cardinality[cpu-float32-4-3] ______________

self = <test_equalization.TestEqualization object at 0x747c9dd2a200>, B = 4
C = 3, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:247: in equalize_clahe
    interp_tiles: torch.Tensor = _compute_interpolation_tiles(img_padded, tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

padded_imgs = tensor([[[[0.8823, 0.1120, 0.5539,  ..., 0.0000, 0.0000, 0.0000],
          [0.0701, 0.3515, 0.9999,  ..., 0.0000, 0.0...00, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]])
tile_size = (3, 3)

    def _compute_interpolation_tiles(padded_imgs: torch.Tensor, tile_size: Tuple[int, int]) -> torch.Tensor:
        """Compute interpolation tiles on a properly padded set of images.
    
        Note that images must be padded. So, the tile_size (TH, TW) * grid_size (GH, GW) = image_size (H, W)
    
        Args:
            padded_imgs: batch of 2D images with shape (B, C, H, W) already padded to extract tiles
                                        of size (TH, TW).
            tile_size: shape of the current tiles (TH, TW).
    
        Returns:
            tensor with the interpolation tiles (B, 2GH, 2GW, C, TH/2, TW/2).
        """
        if padded_imgs.dim() != 4:
            raise AssertionError('Images Tensor must be 4D.')
        if padded_imgs.shape[-2] % tile_size[0] != 0:
            raise AssertionError('Images are not correctly padded.')
        if padded_imgs.shape[-1] % tile_size[1] != 0:
            raise AssertionError('Images are not correctly padded.')
        interp_kernel_vert: int = tile_size[0] // 2
        interp_kernel_horz: int = tile_size[1] // 2
        c: int = padded_imgs.shape[-3]
        interp_tiles: torch.Tensor = padded_imgs.unfold(1, c, c).unfold(2, interp_kernel_vert, interp_kernel_vert).unfold(3, interp_kernel_horz, interp_kernel_horz).squeeze(1).contiguous()
        if interp_tiles.shape[-3] != c:
            raise AssertionError
        if interp_tiles.shape[-2] != tile_size[0] / 2:
>           raise AssertionError
E           AssertionError

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:76: AssertionError
_________ TestEqualization.test_optional_params[cpu-float32-0.0-None] __________

self = <test_equalization.TestEqualization object at 0x747c9dd2a590>, clip = 0.0
grid = None, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("clip, grid", [(0.0, None), (None, (2, 2)), (2.0, (2, 2))])
    def test_optional_params(self, clip, grid, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
        if clip is None:
            res = enhance.equalize_clahe(img, grid_size=grid)
        elif grid is None:
>           res = enhance.equalize_clahe(img, clip_limit=clip)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:39: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:247: in equalize_clahe
    interp_tiles: torch.Tensor = _compute_interpolation_tiles(img_padded, tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

padded_imgs = tensor([[[[6.2995e-02, 1.0586e-01, 6.7904e-01, 4.5163e-01, 1.7991e-01,
           1.8414e-01, 8.0206e-01, 7.9104e-01, ...000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]])
tile_size = (3, 3)

    def _compute_interpolation_tiles(padded_imgs: torch.Tensor, tile_size: Tuple[int, int]) -> torch.Tensor:
        """Compute interpolation tiles on a properly padded set of images.
    
        Note that images must be padded. So, the tile_size (TH, TW) * grid_size (GH, GW) = image_size (H, W)
    
        Args:
            padded_imgs: batch of 2D images with shape (B, C, H, W) already padded to extract tiles
                                        of size (TH, TW).
            tile_size: shape of the current tiles (TH, TW).
    
        Returns:
            tensor with the interpolation tiles (B, 2GH, 2GW, C, TH/2, TW/2).
        """
        if padded_imgs.dim() != 4:
            raise AssertionError('Images Tensor must be 4D.')
        if padded_imgs.shape[-2] % tile_size[0] != 0:
            raise AssertionError('Images are not correctly padded.')
        if padded_imgs.shape[-1] % tile_size[1] != 0:
            raise AssertionError('Images are not correctly padded.')
        interp_kernel_vert: int = tile_size[0] // 2
        interp_kernel_horz: int = tile_size[1] // 2
        c: int = padded_imgs.shape[-3]
        interp_tiles: torch.Tensor = padded_imgs.unfold(1, c, c).unfold(2, interp_kernel_vert, interp_kernel_vert).unfold(3, interp_kernel_horz, interp_kernel_horz).squeeze(1).contiguous()
        if interp_tiles.shape[-3] != c:
            raise AssertionError
        if interp_tiles.shape[-2] != tile_size[0] / 2:
>           raise AssertionError
E           AssertionError

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:76: AssertionError
________ TestEqualization.test_optional_params[cpu-float32-None-grid1] _________

self = <test_equalization.TestEqualization object at 0x747c9dd2a4d0>
clip = None, grid = (2, 2), device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("clip, grid", [(0.0, None), (None, (2, 2)), (2.0, (2, 2))])
    def test_optional_params(self, clip, grid, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
        if clip is None:
>           res = enhance.equalize_clahe(img, grid_size=grid)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[7.9978e-01, 5.9276e-02, 2.2857e-01, 2.1877e-01, 3.6981e-01,
             4.3697e-01, 5.9010e-01, 4.1914e-...+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
             0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]]]])
num_bins = 256, clip = 40.0, diff = False

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
_________ TestEqualization.test_optional_params[cpu-float32-2.0-grid2] _________

self = <test_equalization.TestEqualization object at 0x747c9dd2a830>, clip = 2.0
grid = (2, 2), device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("clip, grid", [(0.0, None), (None, (2, 2)), (2.0, (2, 2))])
    def test_optional_params(self, clip, grid, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
        if clip is None:
            res = enhance.equalize_clahe(img, grid_size=grid)
        elif grid is None:
            res = enhance.equalize_clahe(img, clip_limit=clip)
        else:
>           res = enhance.equalize_clahe(img, clip, grid)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[0.8700, 0.0857, 0.9469, 0.9803, 0.2748, 0.6807, 0.4871, 0.3720,
             0.4850, 0.9428],
           ....0000],
            [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
             0.0000, 0.0000]]]]]])
num_bins = 256, clip = 2.0, diff = False

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
______________ TestEqualization.test_exception_tensor_dims[dims0] ______________

self = <test_equalization.TestEqualization object at 0x747c9dd2b220>
dims = (1, 1, 1, 1, 1)

    @pytest.mark.parametrize("dims", [(1, 1, 1, 1, 1), (1, 1)])
    def test_exception_tensor_dims(self, dims):
        img = torch.rand(dims)
        with pytest.raises(ValueError):
>           enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:247: in equalize_clahe
    interp_tiles: torch.Tensor = _compute_interpolation_tiles(img_padded, tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

padded_imgs = tensor([[[[0.6440, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000,...0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])
tile_size = (1, 1)

    def _compute_interpolation_tiles(padded_imgs: torch.Tensor, tile_size: Tuple[int, int]) -> torch.Tensor:
        """Compute interpolation tiles on a properly padded set of images.
    
        Note that images must be padded. So, the tile_size (TH, TW) * grid_size (GH, GW) = image_size (H, W)
    
        Args:
            padded_imgs: batch of 2D images with shape (B, C, H, W) already padded to extract tiles
                                        of size (TH, TW).
            tile_size: shape of the current tiles (TH, TW).
    
        Returns:
            tensor with the interpolation tiles (B, 2GH, 2GW, C, TH/2, TW/2).
        """
        if padded_imgs.dim() != 4:
            raise AssertionError('Images Tensor must be 4D.')
        if padded_imgs.shape[-2] % tile_size[0] != 0:
            raise AssertionError('Images are not correctly padded.')
        if padded_imgs.shape[-1] % tile_size[1] != 0:
            raise AssertionError('Images are not correctly padded.')
        interp_kernel_vert: int = tile_size[0] // 2
        interp_kernel_horz: int = tile_size[1] // 2
        c: int = padded_imgs.shape[-3]
>       interp_tiles: torch.Tensor = padded_imgs.unfold(1, c, c).unfold(2, interp_kernel_vert, interp_kernel_vert).unfold(3, interp_kernel_horz, interp_kernel_horz).squeeze(1).contiguous()
E       RuntimeError: step is 0 but must be > 0

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:72: RuntimeError
______________ TestEqualization.test_exception_tensor_dims[dims1] ______________

self = <test_equalization.TestEqualization object at 0x747c9dd2b2e0>
dims = (1, 1)

    @pytest.mark.parametrize("dims", [(1, 1, 1, 1, 1), (1, 1)])
    def test_exception_tensor_dims(self, dims):
        img = torch.rand(dims)
        with pytest.raises(ValueError):
>           enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:247: in equalize_clahe
    interp_tiles: torch.Tensor = _compute_interpolation_tiles(img_padded, tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

padded_imgs = tensor([[[[0.4559, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000,...0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])
tile_size = (1, 1)

    def _compute_interpolation_tiles(padded_imgs: torch.Tensor, tile_size: Tuple[int, int]) -> torch.Tensor:
        """Compute interpolation tiles on a properly padded set of images.
    
        Note that images must be padded. So, the tile_size (TH, TW) * grid_size (GH, GW) = image_size (H, W)
    
        Args:
            padded_imgs: batch of 2D images with shape (B, C, H, W) already padded to extract tiles
                                        of size (TH, TW).
            tile_size: shape of the current tiles (TH, TW).
    
        Returns:
            tensor with the interpolation tiles (B, 2GH, 2GW, C, TH/2, TW/2).
        """
        if padded_imgs.dim() != 4:
            raise AssertionError('Images Tensor must be 4D.')
        if padded_imgs.shape[-2] % tile_size[0] != 0:
            raise AssertionError('Images are not correctly padded.')
        if padded_imgs.shape[-1] % tile_size[1] != 0:
            raise AssertionError('Images are not correctly padded.')
        interp_kernel_vert: int = tile_size[0] // 2
        interp_kernel_horz: int = tile_size[1] // 2
        c: int = padded_imgs.shape[-3]
>       interp_tiles: torch.Tensor = padded_imgs.unfold(1, c, c).unfold(2, interp_kernel_vert, interp_kernel_vert).unfold(3, interp_kernel_horz, interp_kernel_horz).squeeze(1).contiguous()
E       RuntimeError: step is 0 but must be > 0

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:72: RuntimeError
_____________________ TestEqualization.test_gradcheck[cpu] _____________________

self = <test_equalization.TestEqualization object at 0x747c9dd2b7f0>
device = device(type='cpu')

    def test_gradcheck(self, device):
        torch.random.manual_seed(4)
        bs, channels, height, width = 1, 1, 11, 11
        inputs = torch.rand(bs, channels, height, width, device=device, dtype=torch.float64)
    
        def grad_rot(data, a, b, c):
            rot = rotate(data, torch.tensor(30.0, dtype=data.dtype, device=device))
            return enhance.equalize_clahe(rot, a, b, c)
    
>       self.gradcheck(grad_rot, (inputs, 40.0, (2, 2), True), nondet_tol=1e-4)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2074: in _gradcheck_helper
    func_out = func(*tupled_inputs)
/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:80: in grad_rot
    return enhance.equalize_clahe(rot, a, b, c)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:247: in equalize_clahe
    interp_tiles: torch.Tensor = _compute_interpolation_tiles(img_padded, tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

padded_imgs = tensor([[[[0.0000, 0.0000, 0.1003, 0.2967, 0.6151, 0.3659, 0.2140, 0.2394,
           0.4072, 0.0181, 0.0000, 0.0000, ...      0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],
       dtype=torch.float64, grad_fn=<ConstantPadNdBackward0>)
tile_size = (7, 7)

    def _compute_interpolation_tiles(padded_imgs: torch.Tensor, tile_size: Tuple[int, int]) -> torch.Tensor:
        """Compute interpolation tiles on a properly padded set of images.
    
        Note that images must be padded. So, the tile_size (TH, TW) * grid_size (GH, GW) = image_size (H, W)
    
        Args:
            padded_imgs: batch of 2D images with shape (B, C, H, W) already padded to extract tiles
                                        of size (TH, TW).
            tile_size: shape of the current tiles (TH, TW).
    
        Returns:
            tensor with the interpolation tiles (B, 2GH, 2GW, C, TH/2, TW/2).
        """
        if padded_imgs.dim() != 4:
            raise AssertionError('Images Tensor must be 4D.')
        if padded_imgs.shape[-2] % tile_size[0] != 0:
            raise AssertionError('Images are not correctly padded.')
        if padded_imgs.shape[-1] % tile_size[1] != 0:
            raise AssertionError('Images are not correctly padded.')
        interp_kernel_vert: int = tile_size[0] // 2
        interp_kernel_horz: int = tile_size[1] // 2
        c: int = padded_imgs.shape[-3]
        interp_tiles: torch.Tensor = padded_imgs.unfold(1, c, c).unfold(2, interp_kernel_vert, interp_kernel_vert).unfold(3, interp_kernel_horz, interp_kernel_horz).squeeze(1).contiguous()
        if interp_tiles.shape[-3] != c:
            raise AssertionError
        if interp_tiles.shape[-2] != tile_size[0] / 2:
>           raise AssertionError
E           AssertionError

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:76: AssertionError
____________________ TestEqualization.test_ahe[cpu-float32] ____________________

self = <test_equalization.TestEqualization object at 0x747c9dd503d0>
img = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ...         0.4211, 0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895,
           0.8421, 0.8947, 0.9474, 1.0000]]]])

    def test_ahe(self, img):
        clip_limit: float = 0.0
        grid_size: Tuple = (8, 8)
>       res = enhance.equalize_clahe(img, clip_limit=clip_limit, grid_size=grid_size)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:247: in equalize_clahe
    interp_tiles: torch.Tensor = _compute_interpolation_tiles(img_padded, tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

padded_imgs = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ... 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])
tile_size = (3, 3)

    def _compute_interpolation_tiles(padded_imgs: torch.Tensor, tile_size: Tuple[int, int]) -> torch.Tensor:
        """Compute interpolation tiles on a properly padded set of images.
    
        Note that images must be padded. So, the tile_size (TH, TW) * grid_size (GH, GW) = image_size (H, W)
    
        Args:
            padded_imgs: batch of 2D images with shape (B, C, H, W) already padded to extract tiles
                                        of size (TH, TW).
            tile_size: shape of the current tiles (TH, TW).
    
        Returns:
            tensor with the interpolation tiles (B, 2GH, 2GW, C, TH/2, TW/2).
        """
        if padded_imgs.dim() != 4:
            raise AssertionError('Images Tensor must be 4D.')
        if padded_imgs.shape[-2] % tile_size[0] != 0:
            raise AssertionError('Images are not correctly padded.')
        if padded_imgs.shape[-1] % tile_size[1] != 0:
            raise AssertionError('Images are not correctly padded.')
        interp_kernel_vert: int = tile_size[0] // 2
        interp_kernel_horz: int = tile_size[1] // 2
        c: int = padded_imgs.shape[-3]
        interp_tiles: torch.Tensor = padded_imgs.unfold(1, c, c).unfold(2, interp_kernel_vert, interp_kernel_vert).unfold(3, interp_kernel_horz, interp_kernel_horz).squeeze(1).contiguous()
        if interp_tiles.shape[-3] != c:
            raise AssertionError
        if interp_tiles.shape[-2] != tile_size[0] / 2:
>           raise AssertionError
E           AssertionError

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:76: AssertionError
___________________ TestEqualization.test_clahe[cpu-float32] ___________________

self = <test_equalization.TestEqualization object at 0x747c9dd50730>
img = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ...         0.4211, 0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895,
           0.8421, 0.8947, 0.9474, 1.0000]]]])

    def test_clahe(self, img):
        clip_limit: float = 2.0
        grid_size: Tuple = (8, 8)
>       res = enhance.equalize_clahe(img, clip_limit=clip_limit, grid_size=grid_size)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:247: in equalize_clahe
    interp_tiles: torch.Tensor = _compute_interpolation_tiles(img_padded, tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

padded_imgs = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ... 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])
tile_size = (3, 3)

    def _compute_interpolation_tiles(padded_imgs: torch.Tensor, tile_size: Tuple[int, int]) -> torch.Tensor:
        """Compute interpolation tiles on a properly padded set of images.
    
        Note that images must be padded. So, the tile_size (TH, TW) * grid_size (GH, GW) = image_size (H, W)
    
        Args:
            padded_imgs: batch of 2D images with shape (B, C, H, W) already padded to extract tiles
                                        of size (TH, TW).
            tile_size: shape of the current tiles (TH, TW).
    
        Returns:
            tensor with the interpolation tiles (B, 2GH, 2GW, C, TH/2, TW/2).
        """
        if padded_imgs.dim() != 4:
            raise AssertionError('Images Tensor must be 4D.')
        if padded_imgs.shape[-2] % tile_size[0] != 0:
            raise AssertionError('Images are not correctly padded.')
        if padded_imgs.shape[-1] % tile_size[1] != 0:
            raise AssertionError('Images are not correctly padded.')
        interp_kernel_vert: int = tile_size[0] // 2
        interp_kernel_horz: int = tile_size[1] // 2
        c: int = padded_imgs.shape[-3]
        interp_tiles: torch.Tensor = padded_imgs.unfold(1, c, c).unfold(2, interp_kernel_vert, interp_kernel_vert).unfold(3, interp_kernel_horz, interp_kernel_horz).squeeze(1).contiguous()
        if interp_tiles.shape[-3] != c:
            raise AssertionError
        if interp_tiles.shape[-2] != tile_size[0] / 2:
>           raise AssertionError
E           AssertionError

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:76: AssertionError
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32]
=================== 15 failed, 9 passed, 1 skipped in 0.54s ====================


Final Test Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'cudagraphs', 'tvm', 'onnxrt', 'openxla', 'jit', 'inductor', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 25 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[0-1.0-grid0-ValueError-Invalid input tensor, it is empty.] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_type PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_jit[cpu-float32] SKIPPED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_module PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] PASSED

======================== 24 passed, 1 skipped in 0.24s =========================


Initial Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'onnxrt', 'cudagraphs', 'jit', 'tvm', 'openxla', None, 'inductor'}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 25 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[0-1.0-grid0-ValueError-Invalid input tensor, it is empty.] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_type PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_jit[cpu-float32] SKIPPED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_module PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] PASSED

======================== 24 passed, 1 skipped in 0.24s =========================
