output file:
processed_korniabinary_focal_loss_with_logits79.json
function:
binary_focal_loss_with_logits
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] FAILED'}

All Test Cases On Generated code:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'openxla', 'jit', 'tvm', 'inductor', 'onnxrt', 'cudagraphs', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 59 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] FAILED

=================================== FAILURES ===================================
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32--100-none] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2915ff0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
ignore_index = -100

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1447, 0.8232],
         [0.7764, 0.6121],
         [0.6544, 0.0592]],

        [[0.4801, 0.8520],
         [0.9509, 0.2691],
         [0.4242, 0.0411]]])
target = tensor([[[0.0616, 0.5595],
         [0.1226, 0.2105],
         [0.9024, 0.6183]],

        [[0.0159, 0.2669],
         [0.9163, 0.8127],
         [0.9644, 0.2720]]])
alpha = None, gamma = 0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32--100-mean] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2915e10>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
ignore_index = -100

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6767, 0.6558],
         [0.9901, 0.1526],
         [0.7563, 0.9625]],

        [[0.1094, 0.6472],
         [0.8251, 0.4989],
         [0.2522, 0.5686]]])
target = tensor([[[0.3957, 0.4936],
         [0.8526, 0.9760],
         [0.1951, 0.1415]],

        [[0.8425, 0.5108],
         [0.3388, 0.3152],
         [0.7454, 0.3878]]])
alpha = None, gamma = 0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32--100-sum] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2916290>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
ignore_index = -100

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8924, 0.6585],
         [0.3283, 0.8941],
         [0.4723, 0.3390]],

        [[0.7996, 0.8589],
         [0.6233, 0.2194],
         [0.5639, 0.4185]]])
target = tensor([[[0.9118, 0.5459],
         [0.4910, 0.7506],
         [0.9239, 0.4776]],

        [[0.9649, 0.6887],
         [0.5383, 0.4145],
         [0.0193, 0.6148]]])
alpha = None, gamma = 0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32-None-none] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2916350>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
ignore_index = None

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3080, 0.8895],
         [0.5608, 0.9529],
         [0.1184, 0.5686]],

        [[0.5935, 0.9683],
         [0.0968, 0.4518],
         [0.4684, 0.1495]]])
target = tensor([[[0.8060, 0.9236],
         [0.0290, 0.8733],
         [0.6259, 0.9950]],

        [[0.8520, 0.5660],
         [0.7798, 0.9185],
         [0.0475, 0.2726]]])
alpha = None, gamma = 0, reduction = 'none', pos_weight = None, weight = None
ignore_index = None

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32-None-mean] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2916410>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
ignore_index = None

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6074, 0.0954],
         [0.3380, 0.7825],
         [0.3592, 0.8416]],

        [[0.4400, 0.5502],
         [0.4926, 0.4029],
         [0.0099, 0.9204]]])
target = tensor([[[0.8673, 0.7008],
         [0.5917, 0.7235],
         [0.3213, 0.7858]],

        [[0.7365, 0.1905],
         [0.0386, 0.3442],
         [0.5853, 0.1159]]])
alpha = None, gamma = 0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = None

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32-None-sum] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b29164d0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
ignore_index = None

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7215, 0.9130],
         [0.0775, 0.9809],
         [0.1276, 0.3187]],

        [[0.2104, 0.5706],
         [0.4284, 0.2809],
         [0.6124, 0.1328]]])
target = tensor([[[0.9998, 0.3581],
         [0.7621, 0.8102],
         [0.8910, 0.9752]],

        [[0.4790, 0.5852],
         [0.0833, 0.2587],
         [0.1644, 0.8530]]])
alpha = None, gamma = 0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = None

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2916890>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    def test_value_same_as_torch_bce_loss_pos_weight_weight(self, device, dtype, reduction):
        num_classes = 3
        logits = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
        labels = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
    
        pos_weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
        weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, pos_weight=pos_weight, weight=weight
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4933, 0.2972],
         [0.5694, 0.1032],
         [0.4085, 0.3240]],

        [[0.7682, 0.1531],
         [0.7232, 0.1301],
         [0.0213, 0.4007]]])
target = tensor([[[0.1914, 0.9712],
         [0.9959, 0.8136],
         [0.3511, 0.9901]],

        [[0.4643, 0.2738],
         [0.7642, 0.9437],
         [0.3388, 0.2160]]])
alpha = None, gamma = 0, reduction = 'none'
pos_weight = tensor([[0.7561],
        [0.1386],
        [0.8061]])
weight = tensor([[0.4454],
        [0.0619],
        [0.0512]])
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b29167d0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    def test_value_same_as_torch_bce_loss_pos_weight_weight(self, device, dtype, reduction):
        num_classes = 3
        logits = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
        labels = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
    
        pos_weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
        weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, pos_weight=pos_weight, weight=weight
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3044, 0.7273],
         [0.9358, 0.9113],
         [0.7039, 0.8829]],

        [[0.9315, 0.4757],
         [0.8927, 0.7325],
         [0.2506, 0.6458]]])
target = tensor([[[0.3316, 0.1861],
         [0.6420, 0.2279],
         [0.6129, 0.0739]],

        [[0.0313, 0.6125],
         [0.0879, 0.0734],
         [0.0223, 0.4488]]])
alpha = None, gamma = 0, reduction = 'mean'
pos_weight = tensor([[0.0658],
        [0.8653],
        [0.1985]])
weight = tensor([[0.7892],
        [0.7107],
        [0.9614]])
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2916ad0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    def test_value_same_as_torch_bce_loss_pos_weight_weight(self, device, dtype, reduction):
        num_classes = 3
        logits = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
        labels = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
    
        pos_weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
        weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, pos_weight=pos_weight, weight=weight
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8633, 0.3204],
         [0.7220, 0.6833],
         [0.4156, 0.1497]],

        [[0.8053, 0.8546],
         [0.9565, 0.8415],
         [0.4454, 0.4869]]])
target = tensor([[[0.4252, 0.2432],
         [0.6738, 0.6312],
         [0.2487, 0.2163]],

        [[0.0570, 0.9723],
         [0.0333, 0.4086],
         [0.4690, 0.5552]]])
alpha = None, gamma = 0, reduction = 'sum'
pos_weight = tensor([[0.4286],
        [0.9873],
        [0.4529]])
weight = tensor([[0.9910],
        [0.4051],
        [0.5126]])
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b29171c0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = None, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1824, 0.6086],
         [0.5132, 0.1771],
         [0.6028, 0.5576]],

        [[0.6249, 0.2962],
         [0.0390, 0.5520],
         [0.4874, 0.2029]]])
target = tensor([[[0.2883, 0.7631],
         [0.9795, 0.8483],
         [0.8424, 0.5772]],

        [[0.0182, 0.1548],
         [0.2533, 0.3713],
         [0.6487, 0.4828]]])
alpha = None, gamma = 0.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2916f20>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = None, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2076, 0.3950],
         [0.4997, 0.0775],
         [0.7262, 0.8714]],

        [[0.8428, 0.9943],
         [0.1902, 0.0071],
         [0.0302, 0.7631]]])
target = tensor([[[0.7196, 0.7375],
         [0.7007, 0.6887],
         [0.5578, 0.8631]],

        [[0.6063, 0.4060],
         [0.1705, 0.4190],
         [0.9754, 0.3720]]])
alpha = None, gamma = 0.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2916fe0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = None, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6105, 0.1830],
         [0.0198, 0.1284],
         [0.6401, 0.7656]],

        [[0.3972, 0.6081],
         [0.3604, 0.3759],
         [0.0255, 0.5197]]])
target = tensor([[[0.6750, 0.3511],
         [0.3468, 0.0151],
         [0.5250, 0.8272]],

        [[0.9163, 0.4303],
         [0.5570, 0.7087],
         [0.1034, 0.7509]]])
alpha = None, gamma = 0.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b29170a0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.2, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6560, 0.2311],
         [0.2285, 0.9734],
         [0.9079, 0.3543]],

        [[0.1867, 0.2708],
         [0.7605, 0.3235],
         [0.4448, 0.6801]]])
target = tensor([[[0.6806, 0.2015],
         [0.2202, 0.4074],
         [0.0351, 0.2242]],

        [[0.2767, 0.4097],
         [0.9962, 0.6747],
         [0.2514, 0.7756]]])
alpha = 0.2, gamma = 0.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2917160>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.2, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1264, 0.0675],
         [0.5863, 0.5966],
         [0.2423, 0.4048]],

        [[0.1349, 0.4144],
         [0.7491, 0.9710],
         [0.3228, 0.9647]]])
target = tensor([[[0.7268, 0.1083],
         [0.0180, 0.1985],
         [0.3058, 0.9803]],

        [[0.5004, 0.9842],
         [0.5288, 0.6691],
         [0.7662, 0.3278]]])
alpha = 0.2, gamma = 0.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2916e60>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.2, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4037, 0.0035],
         [0.8417, 0.8517],
         [0.2120, 0.6801]],

        [[0.9884, 0.5505],
         [0.4394, 0.0579],
         [0.0449, 0.8666]]])
target = tensor([[[0.4827, 0.3951],
         [0.6372, 0.1388],
         [0.7043, 0.9560]],

        [[0.6087, 0.7051],
         [0.9952, 0.2516],
         [0.8622, 0.7933]]])
alpha = 0.2, gamma = 0.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2917c70>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.5, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1547, 0.3304],
         [0.4173, 0.9635],
         [0.2990, 0.4648]],

        [[0.9928, 0.9527],
         [0.6415, 0.6489],
         [0.5286, 0.6211]]])
target = tensor([[[0.2376, 0.7125],
         [0.4940, 0.1742],
         [0.6561, 0.8176]],

        [[0.3156, 0.1141],
         [0.5279, 0.0551],
         [0.9837, 0.0070]]])
alpha = 0.5, gamma = 0.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2917d30>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.5, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0855, 0.6727],
         [0.7991, 0.9459],
         [0.4357, 0.9918]],

        [[0.4062, 0.7161],
         [0.5972, 0.6335],
         [0.3360, 0.5826]]])
target = tensor([[[0.7865, 0.6462],
         [0.4239, 0.9439],
         [0.3657, 0.9173]],

        [[0.5759, 0.2107],
         [0.4280, 0.4256],
         [0.8516, 0.4454]]])
alpha = 0.5, gamma = 0.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2917df0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.5, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1416, 0.8448],
         [0.1428, 0.5744],
         [0.3293, 0.2465]],

        [[0.0585, 0.4317],
         [0.5763, 0.5101],
         [0.5553, 0.6066]]])
target = tensor([[[0.4120, 0.3016],
         [0.5005, 0.4715],
         [0.5945, 0.6833]],

        [[0.7649, 0.4588],
         [0.3118, 0.4934],
         [0.8905, 0.6185]]])
alpha = 0.5, gamma = 0.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2917eb0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = None, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6080, 0.1430],
         [0.7628, 0.8336],
         [0.0230, 0.3428]],

        [[0.9818, 0.3567],
         [0.8801, 0.2259],
         [0.8485, 0.7581]]])
target = tensor([[[0.0060, 0.0871],
         [0.1245, 0.5687],
         [0.3435, 0.4853]],

        [[0.2286, 0.1717],
         [0.3119, 0.7608],
         [0.4793, 0.0249]]])
alpha = None, gamma = 1.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2917f70>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = None, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5170, 0.5313],
         [0.6658, 0.8151],
         [0.7691, 0.9565]],

        [[0.1818, 0.4114],
         [0.1934, 0.5999],
         [0.5371, 0.2347]]])
target = tensor([[[0.1836, 0.9034],
         [0.7779, 0.5631],
         [0.3553, 0.2708]],

        [[0.3819, 0.0948],
         [0.1185, 0.8713],
         [0.5933, 0.8063]]])
alpha = None, gamma = 1.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2948070>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = None, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9718, 0.1361],
         [0.5772, 0.7314],
         [0.2127, 0.2912]],

        [[0.4493, 0.4361],
         [0.8125, 0.8159],
         [0.1598, 0.0307]]])
target = tensor([[[0.6744, 0.1269],
         [0.9856, 0.2658],
         [0.5577, 0.6521]],

        [[0.1540, 0.8425],
         [0.3202, 0.0516],
         [0.2627, 0.2730]]])
alpha = None, gamma = 1.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2948130>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.2, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7596, 0.7367],
         [0.9273, 0.2714],
         [0.3259, 0.9706]],

        [[0.3566, 0.4817],
         [0.1599, 0.8309],
         [0.9500, 0.1373]]])
target = tensor([[[0.2015, 0.0364],
         [0.1346, 0.9258],
         [0.3246, 0.3421]],

        [[0.2530, 0.2217],
         [0.3368, 0.2205],
         [0.2400, 0.5705]]])
alpha = 0.2, gamma = 1.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b29481f0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.2, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7514, 0.3961],
         [0.0427, 0.9776],
         [0.2374, 0.1713]],

        [[0.1382, 0.5480],
         [0.0799, 0.0726],
         [0.0148, 0.4353]]])
target = tensor([[[0.6646, 0.5366],
         [0.9295, 0.5270],
         [0.9851, 0.3519]],

        [[0.4575, 0.9862],
         [0.4269, 0.3873],
         [0.3535, 0.9601]]])
alpha = 0.2, gamma = 1.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b29482b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.2, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[1.8617e-01, 2.0626e-01],
         [7.0096e-01, 7.9140e-01],
         [6.3259e-01, 1.8183e-01]],

        [[5.7160e-01, 7.9483e-04],
         [2.9141e-01, 9.6111e-01],
         [9.4523e-01, 8.3459e-01]]])
target = tensor([[[0.9392, 0.5536],
         [0.9518, 0.0877],
         [0.3427, 0.3481]],

        [[0.3165, 0.4408],
         [0.7602, 0.1821],
         [0.1251, 0.5869]]])
alpha = 0.2, gamma = 1.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2948370>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.5, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7915, 0.7739],
         [0.3261, 0.0401],
         [0.4780, 0.2483]],

        [[0.6506, 0.0132],
         [0.9068, 0.9023],
         [0.6754, 0.3496]]])
target = tensor([[[0.2549, 0.0814],
         [0.1570, 0.0533],
         [0.7618, 0.3335]],

        [[0.2426, 0.5916],
         [0.0949, 0.4175],
         [0.4279, 0.0474]]])
alpha = 0.5, gamma = 1.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2948430>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.5, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7128, 0.7441],
         [0.3939, 0.3638],
         [0.5535, 0.0800]],

        [[0.8498, 0.4355],
         [0.6834, 0.0696],
         [0.4845, 0.4531]]])
target = tensor([[[0.0825, 0.3604],
         [0.6503, 0.0237],
         [0.3862, 0.6849]],

        [[0.9276, 0.3787],
         [0.0990, 0.7265],
         [0.4431, 0.7184]]])
alpha = 0.5, gamma = 1.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b29484f0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.5, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6374, 0.7781],
         [0.1582, 0.7162],
         [0.9158, 0.6837]],

        [[0.8370, 0.0804],
         [0.5160, 0.8890],
         [0.2166, 0.1642]]])
target = tensor([[[0.3946, 0.1148],
         [0.1000, 0.0692],
         [0.8062, 0.6800]],

        [[0.0313, 0.6239],
         [0.0902, 0.7644],
         [0.3151, 0.1487]]])
alpha = 0.5, gamma = 1.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b29485b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = None, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6698, 0.6298],
         [0.3332, 0.8631],
         [0.0814, 0.4924]],

        [[0.7813, 0.6124],
         [0.1424, 0.9828],
         [0.7388, 0.6209]]])
target = tensor([[[0.9465, 0.5188],
         [0.8405, 0.5569],
         [0.8761, 0.0477]],

        [[0.8658, 0.2651],
         [0.7301, 0.4922],
         [0.3917, 0.3789]]])
alpha = None, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2948670>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = None, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[9.2758e-01, 3.5753e-01],
         [1.5060e-01, 5.2470e-01],
         [3.7646e-01, 2.0967e-01]],

        [[2.6210e-01, 6.7051e-01],
         [6.6196e-01, 5.8395e-01],
         [8.8048e-04, 4.4768e-01]]])
target = tensor([[[0.5394, 0.6581],
         [0.9583, 0.9607],
         [0.7329, 0.0636]],

        [[0.7111, 0.3882],
         [0.8003, 0.8797],
         [0.1398, 0.2863]]])
alpha = None, gamma = 2.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2948730>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = None, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9495, 0.9602],
         [0.8317, 0.2276],
         [0.5710, 0.9481]],

        [[0.8121, 0.5687],
         [0.7268, 0.9566],
         [0.3748, 0.4265]]])
target = tensor([[[0.9879, 0.1906],
         [0.3514, 0.0817],
         [0.9024, 0.9655]],

        [[0.9246, 0.0141],
         [0.5050, 0.3791],
         [0.9062, 0.7358]]])
alpha = None, gamma = 2.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b29487f0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.2, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5484, 0.6053],
         [0.9682, 0.3478],
         [0.2551, 0.1722]],

        [[0.8472, 0.4757],
         [0.8127, 0.4023],
         [0.9251, 0.0122]]])
target = tensor([[[0.9817, 0.7054],
         [0.3106, 0.2417],
         [0.4718, 0.6881]],

        [[0.1824, 0.4792],
         [0.7006, 0.3744],
         [0.7504, 0.5832]]])
alpha = 0.2, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b29488b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.2, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5834, 0.6516],
         [0.4669, 0.2737],
         [0.9249, 0.3445]],

        [[0.0310, 0.0420],
         [0.3317, 0.2989],
         [0.8361, 0.1216]]])
target = tensor([[[0.8007, 0.1172],
         [0.4027, 0.4024],
         [0.9986, 0.5402]],

        [[0.4081, 0.3986],
         [0.8242, 0.7561],
         [0.9657, 0.0792]]])
alpha = 0.2, gamma = 2.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2948970>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.2, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1676, 0.7239],
         [0.5898, 0.1105],
         [0.6776, 0.6491]],

        [[0.3922, 0.9857],
         [0.6270, 0.8241],
         [0.7550, 0.5615]]])
target = tensor([[[0.4850, 0.6218],
         [0.2128, 0.7624],
         [0.9118, 0.6897]],

        [[0.5462, 0.0375],
         [0.2832, 0.8097],
         [0.6670, 0.7056]]])
alpha = 0.2, gamma = 2.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2948a30>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.5, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2057, 0.9818],
         [0.7986, 0.9738],
         [0.1962, 0.5026]],

        [[0.1186, 0.3298],
         [0.9524, 0.5360],
         [0.6642, 0.3062]]])
target = tensor([[[0.2480, 0.9229],
         [0.3403, 0.3313],
         [0.8017, 0.0036]],

        [[0.8475, 0.9012],
         [0.7500, 0.9914],
         [0.5390, 0.8203]]])
alpha = 0.5, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2948af0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.5, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6734, 0.8474],
         [0.2530, 0.6746],
         [0.1185, 0.2101]],

        [[0.9428, 0.5656],
         [0.5865, 0.1410],
         [0.2667, 0.8707]]])
target = tensor([[[0.0117, 0.7891],
         [0.3384, 0.5097],
         [0.0753, 0.8622]],

        [[0.3292, 0.6767],
         [0.7278, 0.4427],
         [0.8668, 0.3480]]])
alpha = 0.5, gamma = 2.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2948bb0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.5, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5670, 0.9687],
         [0.2785, 0.6434],
         [0.3595, 0.7292]],

        [[0.1958, 0.1335],
         [0.1476, 0.8105],
         [0.7795, 0.0319]]])
target = tensor([[[0.6456, 0.4786],
         [0.1115, 0.5051],
         [0.4581, 0.1443]],

        [[0.2230, 0.4873],
         [0.0537, 0.5901],
         [0.4512, 0.1475]]])
alpha = 0.5, gamma = 2.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b29491b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = None, weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6381, 0.2393],
         [0.7051, 0.9205],
         [0.8219, 0.6256]],

        [[0.0296, 0.3839],
         [0.2424, 0.0470],
         [0.1946, 0.6158]]])
target = tensor([[[0.1235, 0.1606],
         [0.3418, 0.7003],
         [0.9733, 0.5734]],

        [[0.2938, 0.8661],
         [0.8994, 0.7650],
         [0.1059, 0.0852]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b29490f0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = None, weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7981, 0.2102],
         [0.3309, 0.4486],
         [0.6755, 0.6725]],

        [[0.1196, 0.2224],
         [0.3751, 0.3547],
         [0.8226, 0.0833]]])
target = tensor([[[0.2317, 0.5819],
         [0.2851, 0.8082],
         [0.9671, 0.4377]],

        [[0.1093, 0.1079],
         [0.6152, 0.0340],
         [0.0486, 0.6648]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2948fd0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = None, weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0918, 0.1567],
         [0.7627, 0.6871],
         [0.7318, 0.7383]],

        [[0.5128, 0.3949],
         [0.5473, 0.1912],
         [0.2928, 0.1555]]])
target = tensor([[[0.1410, 0.6612],
         [0.7594, 0.6095],
         [0.1724, 0.8039]],

        [[0.2453, 0.9816],
         [0.2649, 0.7529],
         [0.2319, 0.1157]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b29496c0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = tensor([1., 2., 5.]), weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3953, 0.5920],
         [0.9602, 0.9838],
         [0.9264, 0.0721]],

        [[0.8531, 0.6911],
         [0.3689, 0.9032],
         [0.4981, 0.2568]]])
target = tensor([[[0.4979, 0.3528],
         [0.4900, 0.5629],
         [0.8734, 0.9102]],

        [[0.4660, 0.7647],
         [0.1923, 0.0595],
         [0.5463, 0.3696]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = tensor([1., 2., 5.])
weight = None, ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2949780>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = tensor([1., 2., 5.]), weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8383, 0.9120],
         [0.9993, 0.7634],
         [0.6624, 0.1223]],

        [[0.3998, 0.4991],
         [0.3274, 0.9912],
         [0.3944, 0.5574]]])
target = tensor([[[0.9925, 0.9531],
         [0.3430, 0.8364],
         [0.8125, 0.1015]],

        [[0.0170, 0.5702],
         [0.9983, 0.7704],
         [0.5971, 0.1225]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = tensor([1., 2., 5.])
weight = None, ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2949840>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = tensor([1., 2., 5.]), weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5108, 0.4080],
         [0.6005, 0.4338],
         [0.3702, 0.7632]],

        [[0.8045, 0.3060],
         [0.5982, 0.5246],
         [0.5023, 0.3488]]])
target = tensor([[[0.8123, 0.6096],
         [0.1660, 0.5761],
         [0.9720, 0.3687]],

        [[0.2902, 0.9311],
         [0.0517, 0.6554],
         [0.4712, 0.9785]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = tensor([1., 2., 5.])
weight = None, ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2949900>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4108, 0.1962],
         [0.7086, 0.8068],
         [0.3486, 0.0935]],

        [[0.9338, 0.5035],
         [0.7406, 0.3149],
         [0.5696, 0.5395]]])
target = tensor([[[0.6222, 0.6440],
         [0.5619, 0.2742],
         [0.2971, 0.3866]],

        [[0.4981, 0.1143],
         [0.2008, 0.7210],
         [0.6927, 0.4574]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b29499c0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1161, 0.1864],
         [0.8455, 0.6853],
         [0.8906, 0.3910]],

        [[0.8551, 0.4557],
         [0.0138, 0.3906],
         [0.2056, 0.7605]]])
target = tensor([[[0.9635, 0.4787],
         [0.3270, 0.2208],
         [0.9295, 0.0658]],

        [[0.6322, 0.5358],
         [0.7650, 0.8864],
         [0.7731, 0.9104]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2949a80>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5351, 0.9921],
         [0.5500, 0.5075],
         [0.2414, 0.6918]],

        [[0.6104, 0.0331],
         [0.8469, 0.0996],
         [0.4658, 0.5411]]])
target = tensor([[[0.0593, 0.5859],
         [0.9655, 0.4149],
         [0.7869, 0.3093]],

        [[0.5618, 0.7588],
         [0.4582, 0.0157],
         [0.9120, 0.5718]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2949b40>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9581, 0.7377],
         [0.4153, 0.7798],
         [0.1279, 0.2940]],

        [[0.8897, 0.0374],
         [0.6039, 0.5404],
         [0.0992, 0.8674]]])
target = tensor([[[0.6015, 0.5768],
         [0.7823, 0.1164],
         [0.6913, 0.1906]],

        [[0.6031, 0.6621],
         [0.5432, 0.4283],
         [0.2623, 0.1700]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2949c00>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7818, 0.3410],
         [0.5578, 0.4781],
         [0.7510, 0.2971]],

        [[0.6833, 0.7070],
         [0.3628, 0.3752],
         [0.7232, 0.3522]]])
target = tensor([[[0.6019, 0.3251],
         [0.8696, 0.6783],
         [0.9534, 0.1991]],

        [[0.1270, 0.1104],
         [0.2587, 0.8291],
         [0.8733, 0.1712]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2949cc0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3556, 0.8108],
         [0.6065, 0.1582],
         [0.0293, 0.7127]],

        [[0.7563, 0.6346],
         [0.8395, 0.7446],
         [0.0773, 0.4880]]])
target = tensor([[[0.6568, 0.8028],
         [0.3204, 0.7436],
         [0.4681, 0.2338]],

        [[0.4921, 0.6065],
         [0.8465, 0.3555],
         [0.8668, 0.8462]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32--100-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b294a140>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), ignore_index = -100

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4827, 0.3728],
         [0.3114, 0.1240],
         [0.8559, 0.5352]],

        [[0.2548, 0.7502],
         [0.3696, 0.5745],
         [0.8133, 0.2190]]])
target = tensor([[[ 7.0257e-01,  6.2407e-01],
         [ 6.8405e-01, -1.0000e+02],
         [ 7.0508e-01, -1.0000e+02]],

        [[ 7.4236e-01, -1.0000e+02],
         [ 8.1496e-02, -1.0000e+02],
         [-1.0000e+02,  5.0742e-02]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2949ff0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), ignore_index = -100

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1402, 0.3792],
         [0.9282, 0.7657],
         [0.7423, 0.8636]],

        [[0.1777, 0.0471],
         [0.3632, 0.7378],
         [0.2360, 0.8977]]])
target = tensor([[[-100.0000, -100.0000],
         [-100.0000, -100.0000],
         [   0.6287, -100.0000]],

        [[-100.0000, -100.0000],
         [-100.0000,    0.3434],
         [   0.8653,    0.9011]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b294a470>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), ignore_index = -100

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4929, 0.7040],
         [0.3104, 0.7656],
         [0.2659, 0.7482]],

        [[0.5569, 0.3884],
         [0.6445, 0.0061],
         [0.0912, 0.9331]]])
target = tensor([[[-100.0000,    0.3251],
         [-100.0000,    0.3619],
         [-100.0000, -100.0000]],

        [[-100.0000,    0.2267],
         [   0.2850, -100.0000],
         [   0.3777,    0.7767]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32-255-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b294a530>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), ignore_index = 255

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9089, 0.3691],
         [0.8020, 0.8540],
         [0.0463, 0.4345]],

        [[0.7558, 0.3346],
         [0.7641, 0.2348],
         [0.3767, 0.9447]]])
target = tensor([[[255.0000,   0.7457],
         [  0.7492,   0.7694],
         [255.0000,   0.7009]],

        [[  0.5858, 255.0000],
         [  0.3490, 255.0000],
         [255.0000,   0.8572]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None, weight = None
ignore_index = 255

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b294a5f0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), ignore_index = 255

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0293, 0.8900],
         [0.6640, 0.3227],
         [0.1223, 0.9264]],

        [[0.8969, 0.9161],
         [0.9573, 0.7654],
         [0.7247, 0.7730]]])
target = tensor([[[  0.6510,   0.7270],
         [  0.7293, 255.0000],
         [255.0000, 255.0000]],

        [[  0.3642, 255.0000],
         [255.0000, 255.0000],
         [  0.9137, 255.0000]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None, weight = None
ignore_index = 255

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b294a6b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), ignore_index = 255

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5568, 0.2488],
         [0.8572, 0.4470],
         [0.9711, 0.8288]],

        [[0.1746, 0.0518],
         [0.4354, 0.6062],
         [0.2241, 0.2703]]])
target = tensor([[[2.5500e+02, 4.8196e-04],
         [1.4394e-01, 1.8598e-01],
         [3.8794e-01, 2.5500e+02]],

        [[4.3057e-01, 2.5500e+02],
         [3.1805e-01, 3.5406e-01],
         [7.9931e-01, 8.5653e-01]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None, weight = None
ignore_index = 255

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_______ TestBinaryFocalLossWithLogits.test_dynamo[cpu-float32-inductor] ________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b294aa40>
device = device(type='cpu'), dtype = torch.float32
torch_optimizer = functools.partial(<function compile at 0x75458bd172e0>, backend='inductor')

    def test_dynamo(self, device, dtype, torch_optimizer):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        op = kornia.losses.binary_focal_loss_with_logits
        op_optimized = torch_optimizer(op)
    
        args = (0.25, 2.0)
>       actual = op_optimized(logits, labels, *args)

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:89: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:465: in _fn
    return fn(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6576, 0.4217],
         [0.1726, 0.4159],
         [0.2375, 0.6846]],

        [[0.5491, 0.1880],
         [0.7866, 0.7832],
         [0.5813, 0.2543]]])
target = tensor([[[0.9352, 0.8152],
         [0.9574, 0.8341],
         [0.0075, 0.6320]],

        [[0.7400, 0.5836],
         [0.6170, 0.1653],
         [0.4516, 0.5288]]])
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
______________ TestBinaryFocalLossWithLogits.test_gradcheck[cpu] _______________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b294ace0>
device = device(type='cpu')

    def test_gradcheck(self, device):
        logits = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
        labels = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
    
        args = (0.25, 2.0)
        op = kornia.losses.binary_focal_loss_with_logits
>       self.gradcheck(op, (logits, labels, *args))

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:99: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2074: in _gradcheck_helper
    func_out = func(*tupled_inputs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3421, 0.0651],
         [0.2456, 0.1041],
         [0.0549, 0.8153]],

        [[0.4537, 0.7324],
         [0.6859, 0.7822],
         [0.0458, 0.8556]]], dtype=torch.float64, requires_grad=True)
target = tensor([[[0.9255, 0.4602],
         [0.5113, 0.2797],
         [0.6193, 0.3888]],

        [[0.7023, 0.6025],
         [0.7843, 0.3653],
         [0.7217, 0.1742]]], dtype=torch.float64, requires_grad=True)
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
________ TestBinaryFocalLossWithLogits.test_gradcheck_ignore_index[cpu] ________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b294af80>
device = device(type='cpu')

    def test_gradcheck_ignore_index(self, device):
        logits = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
        labels = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
        ignore = torch.rand(2, 3, 2, device=device) > 0.8
        labels[ignore] = -100
    
        args = (0.25, 2.0)
        op = kornia.losses.binary_focal_loss_with_logits
>       self.gradcheck(op, (logits, labels, *args), requires_grad=[True, False, False, False])

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2074: in _gradcheck_helper
    func_out = func(*tupled_inputs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8332, 0.4407],
         [0.5401, 0.5057],
         [0.3053, 0.2495]],

        [[0.4186, 0.7546],
         [0.0988, 0.5584],
         [0.5838, 0.3701]]], dtype=torch.float64, requires_grad=True)
target = tensor([[[   0.4804,    0.5640],
         [   0.4731, -100.0000],
         [   0.5491, -100.0000]],

        [[   0.3491, -100.0000],
         [-100.0000, -100.0000],
         [   0.7080,    0.3807]]], dtype=torch.float64)
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
____________ TestBinaryFocalLossWithLogits.test_module[cpu-float32] ____________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b2948df0>
device = device(type='cpu'), dtype = torch.float32

    def test_module(self, device, dtype):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        args = (0.25, 2.0)
        op = kornia.losses.binary_focal_loss_with_logits
        op_module = kornia.losses.BinaryFocalLossWithLogits(*args)
>       self.assert_close(op_module(logits, labels), op(logits, labels, *args))

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:261: in forward
    return binary_focal_loss_with_logits(pred, target, self.alpha, self.gamma, self.reduction, self.pos_weight, self.weight, self.ignore_index)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3975, 0.8633],
         [0.3753, 0.0508],
         [0.2538, 0.3951]],

        [[0.7405, 0.9952],
         [0.8649, 0.7241],
         [0.4694, 0.2882]]])
target = tensor([[[0.7545, 0.4119],
         [0.0146, 0.1428],
         [0.7670, 0.2832]],

        [[0.5056, 0.5895],
         [0.7764, 0.6934],
         [0.8589, 0.1525]]])
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
______ TestBinaryFocalLossWithLogits.test_numeric_stability[cpu-float32] _______

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7544b294b370>
device = device(type='cpu'), dtype = torch.float32

    def test_numeric_stability(self, device, dtype):
        logits = torch.tensor([[100.0, -100]], dtype=dtype, device=device)
        labels = torch.tensor([[1.0, 0.0]], dtype=dtype, device=device)
    
        args = (0.25, 2.0)
>       actual = kornia.losses.binary_focal_loss_with_logits(logits, labels, *args)

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[ 100., -100.]]), target = tensor([[1., 0.]]), alpha = 0.25
gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32]
============================== 59 failed in 0.87s ==============================


Final Test Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'inductor', 'openxla', 'tvm', 'onnxrt', 'cudagraphs', 'jit', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 59 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] PASSED

============================== 59 passed in 2.09s ==============================


Initial Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'tvm', 'jit', 'cudagraphs', 'onnxrt', 'inductor', 'openxla', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 59 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] PASSED

============================== 59 passed in 2.10s ==============================
