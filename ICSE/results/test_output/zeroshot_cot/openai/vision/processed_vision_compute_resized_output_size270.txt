output file:
processed_vision_compute_resized_output_size270.json
function:
_compute_resized_output_size
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-28-28] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-29-35] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-35-29] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-28-34] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-34-28]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-27-27] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-34-28] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-29-35] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-27-27]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-28-28] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-28-34] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-28-28] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-29-35] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-35-29] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-35-29]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-28-34]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-34-28]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-28-34]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-27-27]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-34-28]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-35-29]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-27-27]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-35-29]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-29-35]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-29-35] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-35-29] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-35-29]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-34-28] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-27-27]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-28-34]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-28-28]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-34-28] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-35-29] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-27-27] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-34-28]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-28-28] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-35-29] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-28-34] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-34-28]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-34-28] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-28-34] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-34-28] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-28-28] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-28-34] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-27-27] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-27-27] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-34-28]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-27-27] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-35-29] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-27-27] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-35-29]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-29-35]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-28-28] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-28-34] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-29-35]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-35-29]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-28-28] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-28-28]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-27-27] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-29-35]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-34-28] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-28-28]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-35-29]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-34-28] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-28-34] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-28-34]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-28-28] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-29-35] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-29-35]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-29-35]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-29-35]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-27-27] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-28-34]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-28-28]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-34-28]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-35-29] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-34-28] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-27-27]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-29-35] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-35-29]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-29-35]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-34-28]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-34-28] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-28-28] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-34-28]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-35-29]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-27-27]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-35-29] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-28-28]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-35-29]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-28-28]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-27-27]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-34-28]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-29-35]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-28-28] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-28-28]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-28-34]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-28-34] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-35-29]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-27-27]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-29-35]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-28-34]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-35-29] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-28-28] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-29-35] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-27-27] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-34-28]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-28-34]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-28-34]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-29-35] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-29-35]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-29-35] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-28-28]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-27-27] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-28-34]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-29-35] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-28-34]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-27-27] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-34-28] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-35-29] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-29-35] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-28-34] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-28-34] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-35-29]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-29-35]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-34-28]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-28-28]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-34-28] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-28-34] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-27-27]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-27-27]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-28-34]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-28-28] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-28-28]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-29-35] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-28-28]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-35-29] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-27-27]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-28-28]', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-28-34] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-34-28] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-27-27] FAILED', '../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-35-29] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-27-27]'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/vision/vision/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/vision/vision
configfile: pytest.ini
plugins: mock-3.14.0
collecting ... collected 108 items

../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-35-29] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-35-29] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-35-29] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-35-29] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-35-29] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-35-29] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-35-29] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-35-29] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-35-29] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-35-29] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-35-29] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-35-29] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-35-29] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-35-29] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-35-29] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-35-29] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-35-29] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-28-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-27-27] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-28-34] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-29-35] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-34-28] FAILED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-35-29] FAILED

=================================== FAILURES ===================================
__________________________ test_resize[None-22-28-28] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-22-27-27] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-22-28-34] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-22-29-35] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-22-34-28] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-22-35-29] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-27-28-28] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-27-27-27] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-27-28-34] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-27-29-35] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-27-34-28] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-27-35-29] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-28-28-28] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-28-27-27] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-28-28-34] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-28-29-35] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-28-34-28] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-28-35-29] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-36-28-28] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-36-27-27] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-36-28-34] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-36-29-35] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-36-34-28] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[None-36-35-29] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[None-osize4-28-28] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[None-osize4-27-27] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[None-osize4-28-34] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[None-osize4-29-35] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[None-osize4-34-28] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[None-osize4-35-29] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[None-osize5-28-28] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[None-osize5-27-27] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[None-osize5-28-34] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[None-osize5-29-35] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[None-osize5-34-28] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[None-osize5-35-29] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-22-28-28] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-22-27-27] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-22-28-34] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-22-29-35] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-22-34-28] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-22-35-29] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-27-28-28] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-27-27-27] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-27-28-34] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-27-29-35] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-27-34-28] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-27-35-29] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-28-28-28] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-28-27-27] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-28-28-34] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-28-29-35] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-28-34-28] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-28-35-29] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-36-28-28] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-36-27-27] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-36-28-34] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-36-29-35] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-36-34-28] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
___________________________ test_resize[37-36-35-29] ___________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
_________________________ test_resize[37-osize4-28-28] _________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
_________________________ test_resize[37-osize4-27-27] _________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
_________________________ test_resize[37-osize4-28-34] _________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
_________________________ test_resize[37-osize4-29-35] _________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
_________________________ test_resize[37-osize4-34-28] _________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
_________________________ test_resize[37-osize4-35-29] _________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
_________________________ test_resize[37-osize5-28-28] _________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
_________________________ test_resize[37-osize5-27-27] _________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
_________________________ test_resize[37-osize5-28-34] _________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
_________________________ test_resize[37-osize5-29-35] _________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
_________________________ test_resize[37-osize5-34-28] _________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
_________________________ test_resize[37-osize5-35-29] _________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-22-28-28] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-22-27-27] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-22-28-34] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-22-29-35] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-22-34-28] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-22-35-29] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-27-28-28] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-27-27-27] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-27-28-34] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-27-29-35] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-27-34-28] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-27-35-29] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-28-28-28] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-28-27-27] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-28-28-34] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-28-29-35] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-28-34-28] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-28-35-29] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-36-28-28] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-36-27-27] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-36-28-34] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-36-29-35] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-36-34-28] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
__________________________ test_resize[1000-36-35-29] __________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[1000-osize4-28-28] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[1000-osize4-27-27] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[1000-osize4-28-34] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[1000-osize4-29-35] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[1000-osize4-34-28] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[1000-osize4-35-29] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[1000-osize5-28-28] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[1000-osize5-27-27] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[1000-osize5-28-34] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[1000-osize5-29-35] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[1000-osize5-34-28] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
________________________ test_resize[1000-osize5-35-29] ________________________
/local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py:370: in test_resize
    result = t(img)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/transforms.py:354: in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:373: in resize
    output_size = _compute_resized_output_size((image_height, image_width), size, max_size)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/functional.py:283: in _compute_resized_output_size
    return _compute_resized_output_size(image_size, size, max_size, allow_size_none)
/local/data0/moved_data/publishablew/vision/vision/torchvision/transforms/temp.py:27: in _compute_resized_output_size
    raise ValueError('size must be an int, a list/tuple of two ints, or None.')
E   ValueError: size must be an int, a list/tuple of two ints, or None.
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-35-29]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-35-29]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-35-29]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-35-29]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-35-29]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-35-29]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-35-29]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-35-29]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-35-29]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-35-29]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-35-29]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-35-29]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-35-29]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-35-29]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-35-29]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-35-29]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-35-29]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-28-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-27-27]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-28-34]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-29-35]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-34-28]
FAILED ../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-35-29]
============================= 108 failed in 12.39s =============================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/vision/vision/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/vision/vision
configfile: pytest.ini
plugins: mock-3.14.0
collecting ... collected 108 items

../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-35-29] PASSED

============================= 108 passed in 0.46s ==============================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/vision/vision/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/vision/vision
configfile: pytest.ini
plugins: mock-3.14.0
collecting ... collected 108 items

../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-22-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-27-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-28-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-36-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize4-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[None-osize5-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-22-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-27-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-28-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-36-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize4-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[37-osize5-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-22-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-27-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-28-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-36-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize4-35-29] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-28-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-27-27] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-28-34] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-29-35] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-34-28] PASSED
../../../../../../local/data0/moved_data/publishablew/vision/vision/test/test_transforms.py::test_resize[1000-osize5-35-29] PASSED

============================= 108 passed in 0.43s ==============================
