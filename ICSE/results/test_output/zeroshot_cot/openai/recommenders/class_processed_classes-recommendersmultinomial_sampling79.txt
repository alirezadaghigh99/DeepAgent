output file:
processed_classes-recommendersmultinomial_sampling79.json
function:
multinomial_sampling
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_save_load FAILED [100%]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_class_init', 'FAILED ../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_train_param_init', 'FAILED ../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_save_load', '../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_train_param_init FAILED [ 50%]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_sampling_funct', '../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_class_init FAILED [ 25%]', '../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_sampling_funct FAILED [ 75%]'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/recommenders/recommenders/venv/bin/python3
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase(PosixPath('/home/aliredaq/Desktop/ICSE/src/tester/.hypothesis/examples'))
rootdir: /local/data0/moved_data/publishablew/recommenders/recommenders
configfile: pyproject.toml
plugins: typeguard-4.4.1, hypothesis-6.123.13, anyio-4.8.0
collecting ... collected 4 items

../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_class_init FAILED [ 25%]
../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_train_param_init FAILED [ 50%]
../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_sampling_funct FAILED [ 75%]
../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_save_load FAILED [100%]

=================================== FAILURES ===================================
_______________________________ test_class_init ________________________________

init_rbm = {'display_epoch': 20, 'epochs': 10, 'init_stdv': 0.01, 'keep_prob': 0.8, ...}

    @pytest.mark.gpu
    def test_class_init(init_rbm):
>       model = RBM(
            possible_ratings=init_rbm["possible_ratings"],
            visible_units=init_rbm["n_visible"],
            hidden_units=init_rbm["n_hidden"],
            training_epoch=init_rbm["epochs"],
            minibatch_size=init_rbm["minibatch"],
            keep_prob=init_rbm["keep_prob"],
            learning_rate=init_rbm["learning_rate"],
            init_stdv=init_rbm["init_stdv"],
            sampling_protocol=init_rbm["sampling_protocol"],
            display_epoch=init_rbm["display_epoch"],
        )

/local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/models/rbm/rbm.py:70: in __init__
    self.generate_graph()
/local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/models/rbm/rbm.py:302: in generate_graph
    self.gibbs_sampling()
/local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/models/rbm/rbm.py:241: in gibbs_sampling
    _, self.v_k = self.sample_visible_units(h_k)
/local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/models/rbm/rbm.py:218: in sample_visible_units
    v_ = tf.compat.v1.where(mask, x=self.v, y=v_tmp)
/local/data0/moved_data/publishablew/recommenders/recommenders/venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler
    raise e.with_traceback(filtered_tb) from None
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

op_type_name = 'Select'
op_def = name: "Select"
input_arg {
  name: "condition"
  type: DT_BOOL
}
input_arg {
  name: "t"
  type_attr: "T"
}
input_arg {
  name: "e"
  type_attr: "T"
}
output_arg {
  name: "output"
  type_attr: "T"
}
attr {
  name: "T"
  type: "type"
}

allowed_list_attr_map = {}, keywords = {}, default_type_attr_map = {}
attrs = {'T': tf.float32}
inputs = [<tf.Tensor 'gibbs_sampling/sample_visible_units/Equal:0' shape=(None, 500) dtype=bool>, <tf.Tensor 'IteratorGetNext:0' shape=(None, 500) dtype=float32>]
input_types = [tf.bool, tf.float32]

    def _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,
                               keywords, default_type_attr_map, attrs, inputs,
                               input_types):
      """Extracts `attrs`, `inputs`, and `input_types` in _apply_op_helper."""
      inferred_from = {}
      for input_arg in op_def.input_arg:
        input_name = input_arg.name
        if input_name in keywords:
          values = keywords.pop(input_name)
        elif input_name + "_" in keywords:
          # Handle the case where the name is a keyword or built-in
          # for Python so we use the name + _ instead.
          input_name += "_"
          values = keywords.pop(input_name)
        else:
          raise TypeError(f"No argument for input {input_name} found in {op_def}")
    
        # Goals:
        # * Convert values to Tensors if it contains constants.
        # * Verify that values is a list if that matches the input_arg's
        #   type.
        # * If the input_arg's type is determined by attrs, either set
        #   those attrs and validate those attr values are legal (if
        #   they have not yet been set) or validate the input matches
        #   the type indicated by the attrs (if they have already been
        #   inferred via an earlier input).
        # * If the input_arg has an explicit type, make sure the input
        #   conforms.
    
        if _IsListParameter(input_arg):
          if not _IsListValue(values):
            raise TypeError(
                f"Expected list for '{input_name}' argument to '{op_type_name}' "
                f"Op, not {values}.")
          # In cases where we expect all elements of the list to have the
          # same dtype, try to cast non-Tensor elements to that type.
          dtype = None
          default_dtype = None
          if input_arg.type != types_pb2.DT_INVALID:
            dtype = input_arg.type
          elif input_arg.number_attr:
            if input_arg.type_attr in attrs:
              dtype = attrs[input_arg.type_attr]
            else:
              for t in values:
                if isinstance(t, tensor.Tensor):
                  dtype = t.dtype
                  break
    
            # dtype still not found, prefer using the default dtype
            # from the attr.
            if dtype is None and input_arg.type_attr in default_type_attr_map:
              default_dtype = default_type_attr_map[input_arg.type_attr]
    
          try:
            if not input_arg.is_ref and dtype:
              dtype = dtypes.as_dtype(dtype).base_dtype
            values = ops.internal_convert_n_to_tensor(
                values,
                name=input_arg.name,
                dtype=dtype if dtype else None,
                preferred_dtype=default_dtype,
                as_ref=input_arg.is_ref)
            all_types = set(v.dtype.base_dtype for v in values)
            if input_arg.number_attr and len(all_types) > 1:
              # All types should match.
              raise TypeError(f"Not all types matched for {input_arg.name} for "
                              f"{op_type_name}. Got {all_types}")
          except (TypeError, ValueError):
            # What types does the conversion function think values have?
            observed_types = []
            for value in values:
              try:
                converted_value = ops.convert_to_tensor(
                    value, as_ref=input_arg.is_ref)
                observed_types.append(converted_value.dtype.base_dtype.name)
              except (TypeError, ValueError):
                observed_types.append("<NOT CONVERTIBLE TO TENSOR>")
            observed = ", ".join(observed_types)
    
            prefix = ("Tensors in list passed to '%s' of '%s' Op have types [%s]" %
                      (input_name, op_type_name, observed))
            if input_arg.number_attr:
              if input_arg.type != types_pb2.DT_INVALID:
                raise TypeError(f"{prefix} that do not match expected type "
                                f"{dtype.name}.")
              elif input_arg.type_attr in attrs:
                raise TypeError(f"{prefix} that do not match type {dtype.name} "
                                "inferred from earlier arguments.")
              else:
                raise TypeError(f"{prefix} that don't all match.")
            else:
              raise TypeError(f"{prefix} that are invalid. Tensors: {values}")
    
          types = [x.dtype for x in values]
          inputs.extend(values)
        else:
          # In cases where we have an expected type, try to convert non-Tensor
          # arguments to that type.
          dtype = None
          default_dtype = None
          allowed_list = None
          if input_arg.type != types_pb2.DT_INVALID:
            dtype = input_arg.type
          elif input_arg.type_attr in attrs:
            dtype = attrs[input_arg.type_attr]
          elif input_arg.type_attr in default_type_attr_map:
            # The dtype could not be inferred solely from the inputs,
            # so we prefer the attr's default, so code that adds a new attr
            # with a default is backwards compatible.
            default_dtype = default_type_attr_map[input_arg.type_attr]
            allowed_list = allowed_list_attr_map.get(input_arg.type_attr)
    
          try:
            # First see if we can get a valid dtype with the default conversion
            # and see if it matches an allowed dtypes. Some ops like ConcatV2 may
            # not list allowed dtypes, in which case we should skip this.
            if dtype is None and allowed_list:
              inferred = None
              try:
                inferred = ops.convert_to_tensor(
                    values, name=input_arg.name, as_ref=input_arg.is_ref)
              except TypeError as err:
                # When converting a python object such as a list of Dimensions, we
                # need a dtype to be specified, thus tensor conversion may throw
                # an exception which we will ignore and try again below.
                pass
    
              # If we did not match an allowed dtype, try again with the default
              # dtype. This could be because we have an empty tensor and thus we
              # picked the wrong type.
              if inferred is not None and inferred.dtype in allowed_list:
                values = inferred
              else:
                values = ops.convert_to_tensor(
                    values,
                    name=input_arg.name,
                    as_ref=input_arg.is_ref,
                    preferred_dtype=default_dtype)
            else:
              values = ops.convert_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype,
                  as_ref=input_arg.is_ref,
                  preferred_dtype=default_dtype)
          except TypeError as err:
            if dtype is None:
              raise err
            else:
              raise TypeError(
                  f"Expected {dtypes.as_dtype(dtype).name} passed to parameter "
                  f"'{input_arg.name}' of op '{op_type_name}', got "
                  f"{repr(values)} of type '{type(values).__name__}' instead. "
                  f"Error: {err}")
          except ValueError:
            # What type does convert_to_tensor think it has?
            try:
              observed = ops.convert_to_tensor(
                  values, as_ref=input_arg.is_ref).dtype.name
            except ValueError as err:
              raise ValueError(
                  f"Tried to convert '{input_name}' to a tensor and failed. "
                  f"Error: {err}")
            prefix = ("Input '%s' of '%s' Op has type %s that does not match" %
                      (input_name, op_type_name, observed))
            if input_arg.type != types_pb2.DT_INVALID:
              raise TypeError(f"{prefix} expected type of "
                              f"{dtypes.as_dtype(input_arg.type).name}.")
            else:
              # Update the maps with the default, if needed.
              k = input_arg.type_attr
              if k in default_type_attr_map:
                if k not in attrs:
                  attrs[k] = default_type_attr_map[k]
                  if k not in inferred_from:
                    inferred_from[k] = "Default in OpDef"
    
>             raise TypeError(
                  f"{prefix} type "
                  f"{dtypes.as_dtype(attrs[input_arg.type_attr]).name} of "
                  f"argument '{inferred_from[input_arg.type_attr]}'.")
E             TypeError: Input 'e' of 'Select' Op has type int64 that does not match type float32 of argument 't'.

/local/data0/moved_data/publishablew/recommenders/recommenders/venv/lib/python3.11/site-packages/tensorflow/python/framework/op_def_library.py:589: TypeError
------------------------------ Captured log call -------------------------------
WARNING  tensorflow:deprecation.py:50 From /local/data0/moved_data/publishablew/recommenders/recommenders/venv/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
____________________________ test_train_param_init _____________________________

init_rbm = {'display_epoch': 20, 'epochs': 10, 'init_stdv': 0.01, 'keep_prob': 0.8, ...}
affinity_matrix = (array([[0, 0, 0, ..., 0, 1, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [2, 0, 2, ..., 0, 3, 0],
       ...,
       [1...0, 0, 0],
       ...,
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0]]))

    @pytest.mark.gpu
    def test_train_param_init(init_rbm, affinity_matrix):
        # obtain the train/test set matrices
        Xtr, _ = affinity_matrix
    
        # initialize the model
>       model = RBM(
            possible_ratings=np.setdiff1d(np.unique(Xtr), np.array([0])),
            visible_units=Xtr.shape[1],
            hidden_units=init_rbm["n_hidden"],
            training_epoch=init_rbm["epochs"],
            minibatch_size=init_rbm["minibatch"],
        )

/local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py:74: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/models/rbm/rbm.py:70: in __init__
    self.generate_graph()
/local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/models/rbm/rbm.py:302: in generate_graph
    self.gibbs_sampling()
/local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/models/rbm/rbm.py:241: in gibbs_sampling
    _, self.v_k = self.sample_visible_units(h_k)
/local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/models/rbm/rbm.py:218: in sample_visible_units
    v_ = tf.compat.v1.where(mask, x=self.v, y=v_tmp)
/local/data0/moved_data/publishablew/recommenders/recommenders/venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler
    raise e.with_traceback(filtered_tb) from None
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

op_type_name = 'Select'
op_def = name: "Select"
input_arg {
  name: "condition"
  type: DT_BOOL
}
input_arg {
  name: "t"
  type_attr: "T"
}
input_arg {
  name: "e"
  type_attr: "T"
}
output_arg {
  name: "output"
  type_attr: "T"
}
attr {
  name: "T"
  type: "type"
}

allowed_list_attr_map = {}, keywords = {}, default_type_attr_map = {}
attrs = {'T': tf.float32}
inputs = [<tf.Tensor 'gibbs_sampling/sample_visible_units/Equal:0' shape=(None, 53) dtype=bool>, <tf.Tensor 'IteratorGetNext:0' shape=(None, 53) dtype=float32>]
input_types = [tf.bool, tf.float32]

    def _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,
                               keywords, default_type_attr_map, attrs, inputs,
                               input_types):
      """Extracts `attrs`, `inputs`, and `input_types` in _apply_op_helper."""
      inferred_from = {}
      for input_arg in op_def.input_arg:
        input_name = input_arg.name
        if input_name in keywords:
          values = keywords.pop(input_name)
        elif input_name + "_" in keywords:
          # Handle the case where the name is a keyword or built-in
          # for Python so we use the name + _ instead.
          input_name += "_"
          values = keywords.pop(input_name)
        else:
          raise TypeError(f"No argument for input {input_name} found in {op_def}")
    
        # Goals:
        # * Convert values to Tensors if it contains constants.
        # * Verify that values is a list if that matches the input_arg's
        #   type.
        # * If the input_arg's type is determined by attrs, either set
        #   those attrs and validate those attr values are legal (if
        #   they have not yet been set) or validate the input matches
        #   the type indicated by the attrs (if they have already been
        #   inferred via an earlier input).
        # * If the input_arg has an explicit type, make sure the input
        #   conforms.
    
        if _IsListParameter(input_arg):
          if not _IsListValue(values):
            raise TypeError(
                f"Expected list for '{input_name}' argument to '{op_type_name}' "
                f"Op, not {values}.")
          # In cases where we expect all elements of the list to have the
          # same dtype, try to cast non-Tensor elements to that type.
          dtype = None
          default_dtype = None
          if input_arg.type != types_pb2.DT_INVALID:
            dtype = input_arg.type
          elif input_arg.number_attr:
            if input_arg.type_attr in attrs:
              dtype = attrs[input_arg.type_attr]
            else:
              for t in values:
                if isinstance(t, tensor.Tensor):
                  dtype = t.dtype
                  break
    
            # dtype still not found, prefer using the default dtype
            # from the attr.
            if dtype is None and input_arg.type_attr in default_type_attr_map:
              default_dtype = default_type_attr_map[input_arg.type_attr]
    
          try:
            if not input_arg.is_ref and dtype:
              dtype = dtypes.as_dtype(dtype).base_dtype
            values = ops.internal_convert_n_to_tensor(
                values,
                name=input_arg.name,
                dtype=dtype if dtype else None,
                preferred_dtype=default_dtype,
                as_ref=input_arg.is_ref)
            all_types = set(v.dtype.base_dtype for v in values)
            if input_arg.number_attr and len(all_types) > 1:
              # All types should match.
              raise TypeError(f"Not all types matched for {input_arg.name} for "
                              f"{op_type_name}. Got {all_types}")
          except (TypeError, ValueError):
            # What types does the conversion function think values have?
            observed_types = []
            for value in values:
              try:
                converted_value = ops.convert_to_tensor(
                    value, as_ref=input_arg.is_ref)
                observed_types.append(converted_value.dtype.base_dtype.name)
              except (TypeError, ValueError):
                observed_types.append("<NOT CONVERTIBLE TO TENSOR>")
            observed = ", ".join(observed_types)
    
            prefix = ("Tensors in list passed to '%s' of '%s' Op have types [%s]" %
                      (input_name, op_type_name, observed))
            if input_arg.number_attr:
              if input_arg.type != types_pb2.DT_INVALID:
                raise TypeError(f"{prefix} that do not match expected type "
                                f"{dtype.name}.")
              elif input_arg.type_attr in attrs:
                raise TypeError(f"{prefix} that do not match type {dtype.name} "
                                "inferred from earlier arguments.")
              else:
                raise TypeError(f"{prefix} that don't all match.")
            else:
              raise TypeError(f"{prefix} that are invalid. Tensors: {values}")
    
          types = [x.dtype for x in values]
          inputs.extend(values)
        else:
          # In cases where we have an expected type, try to convert non-Tensor
          # arguments to that type.
          dtype = None
          default_dtype = None
          allowed_list = None
          if input_arg.type != types_pb2.DT_INVALID:
            dtype = input_arg.type
          elif input_arg.type_attr in attrs:
            dtype = attrs[input_arg.type_attr]
          elif input_arg.type_attr in default_type_attr_map:
            # The dtype could not be inferred solely from the inputs,
            # so we prefer the attr's default, so code that adds a new attr
            # with a default is backwards compatible.
            default_dtype = default_type_attr_map[input_arg.type_attr]
            allowed_list = allowed_list_attr_map.get(input_arg.type_attr)
    
          try:
            # First see if we can get a valid dtype with the default conversion
            # and see if it matches an allowed dtypes. Some ops like ConcatV2 may
            # not list allowed dtypes, in which case we should skip this.
            if dtype is None and allowed_list:
              inferred = None
              try:
                inferred = ops.convert_to_tensor(
                    values, name=input_arg.name, as_ref=input_arg.is_ref)
              except TypeError as err:
                # When converting a python object such as a list of Dimensions, we
                # need a dtype to be specified, thus tensor conversion may throw
                # an exception which we will ignore and try again below.
                pass
    
              # If we did not match an allowed dtype, try again with the default
              # dtype. This could be because we have an empty tensor and thus we
              # picked the wrong type.
              if inferred is not None and inferred.dtype in allowed_list:
                values = inferred
              else:
                values = ops.convert_to_tensor(
                    values,
                    name=input_arg.name,
                    as_ref=input_arg.is_ref,
                    preferred_dtype=default_dtype)
            else:
              values = ops.convert_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype,
                  as_ref=input_arg.is_ref,
                  preferred_dtype=default_dtype)
          except TypeError as err:
            if dtype is None:
              raise err
            else:
              raise TypeError(
                  f"Expected {dtypes.as_dtype(dtype).name} passed to parameter "
                  f"'{input_arg.name}' of op '{op_type_name}', got "
                  f"{repr(values)} of type '{type(values).__name__}' instead. "
                  f"Error: {err}")
          except ValueError:
            # What type does convert_to_tensor think it has?
            try:
              observed = ops.convert_to_tensor(
                  values, as_ref=input_arg.is_ref).dtype.name
            except ValueError as err:
              raise ValueError(
                  f"Tried to convert '{input_name}' to a tensor and failed. "
                  f"Error: {err}")
            prefix = ("Input '%s' of '%s' Op has type %s that does not match" %
                      (input_name, op_type_name, observed))
            if input_arg.type != types_pb2.DT_INVALID:
              raise TypeError(f"{prefix} expected type of "
                              f"{dtypes.as_dtype(input_arg.type).name}.")
            else:
              # Update the maps with the default, if needed.
              k = input_arg.type_attr
              if k in default_type_attr_map:
                if k not in attrs:
                  attrs[k] = default_type_attr_map[k]
                  if k not in inferred_from:
                    inferred_from[k] = "Default in OpDef"
    
>             raise TypeError(
                  f"{prefix} type "
                  f"{dtypes.as_dtype(attrs[input_arg.type_attr]).name} of "
                  f"argument '{inferred_from[input_arg.type_attr]}'.")
E             TypeError: Input 'e' of 'Select' Op has type int64 that does not match type float32 of argument 't'.

/local/data0/moved_data/publishablew/recommenders/recommenders/venv/lib/python3.11/site-packages/tensorflow/python/framework/op_def_library.py:589: TypeError
_____________________________ test_sampling_funct ______________________________

init_rbm = {'display_epoch': 20, 'epochs': 10, 'init_stdv': 0.01, 'keep_prob': 0.8, ...}
affinity_matrix = (array([[0, 0, 0, ..., 0, 1, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [2, 0, 2, ..., 0, 3, 0],
       ...,
       [1...0, 0, 0],
       ...,
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0]]))

    @pytest.mark.gpu
    def test_sampling_funct(init_rbm, affinity_matrix):
        # obtain the train/test set matrices
        Xtr, _ = affinity_matrix
    
        # initialize the model
>       model = RBM(
            possible_ratings=np.setdiff1d(np.unique(Xtr), np.array([0])),
            visible_units=Xtr.shape[1],
            hidden_units=init_rbm["n_hidden"],
            training_epoch=init_rbm["epochs"],
            minibatch_size=init_rbm["minibatch"],
        )

/local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py:100: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/models/rbm/rbm.py:70: in __init__
    self.generate_graph()
/local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/models/rbm/rbm.py:302: in generate_graph
    self.gibbs_sampling()
/local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/models/rbm/rbm.py:241: in gibbs_sampling
    _, self.v_k = self.sample_visible_units(h_k)
/local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/models/rbm/rbm.py:218: in sample_visible_units
    v_ = tf.compat.v1.where(mask, x=self.v, y=v_tmp)
/local/data0/moved_data/publishablew/recommenders/recommenders/venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler
    raise e.with_traceback(filtered_tb) from None
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

op_type_name = 'Select'
op_def = name: "Select"
input_arg {
  name: "condition"
  type: DT_BOOL
}
input_arg {
  name: "t"
  type_attr: "T"
}
input_arg {
  name: "e"
  type_attr: "T"
}
output_arg {
  name: "output"
  type_attr: "T"
}
attr {
  name: "T"
  type: "type"
}

allowed_list_attr_map = {}, keywords = {}, default_type_attr_map = {}
attrs = {'T': tf.float32}
inputs = [<tf.Tensor 'gibbs_sampling/sample_visible_units/Equal:0' shape=(None, 53) dtype=bool>, <tf.Tensor 'IteratorGetNext:0' shape=(None, 53) dtype=float32>]
input_types = [tf.bool, tf.float32]

    def _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,
                               keywords, default_type_attr_map, attrs, inputs,
                               input_types):
      """Extracts `attrs`, `inputs`, and `input_types` in _apply_op_helper."""
      inferred_from = {}
      for input_arg in op_def.input_arg:
        input_name = input_arg.name
        if input_name in keywords:
          values = keywords.pop(input_name)
        elif input_name + "_" in keywords:
          # Handle the case where the name is a keyword or built-in
          # for Python so we use the name + _ instead.
          input_name += "_"
          values = keywords.pop(input_name)
        else:
          raise TypeError(f"No argument for input {input_name} found in {op_def}")
    
        # Goals:
        # * Convert values to Tensors if it contains constants.
        # * Verify that values is a list if that matches the input_arg's
        #   type.
        # * If the input_arg's type is determined by attrs, either set
        #   those attrs and validate those attr values are legal (if
        #   they have not yet been set) or validate the input matches
        #   the type indicated by the attrs (if they have already been
        #   inferred via an earlier input).
        # * If the input_arg has an explicit type, make sure the input
        #   conforms.
    
        if _IsListParameter(input_arg):
          if not _IsListValue(values):
            raise TypeError(
                f"Expected list for '{input_name}' argument to '{op_type_name}' "
                f"Op, not {values}.")
          # In cases where we expect all elements of the list to have the
          # same dtype, try to cast non-Tensor elements to that type.
          dtype = None
          default_dtype = None
          if input_arg.type != types_pb2.DT_INVALID:
            dtype = input_arg.type
          elif input_arg.number_attr:
            if input_arg.type_attr in attrs:
              dtype = attrs[input_arg.type_attr]
            else:
              for t in values:
                if isinstance(t, tensor.Tensor):
                  dtype = t.dtype
                  break
    
            # dtype still not found, prefer using the default dtype
            # from the attr.
            if dtype is None and input_arg.type_attr in default_type_attr_map:
              default_dtype = default_type_attr_map[input_arg.type_attr]
    
          try:
            if not input_arg.is_ref and dtype:
              dtype = dtypes.as_dtype(dtype).base_dtype
            values = ops.internal_convert_n_to_tensor(
                values,
                name=input_arg.name,
                dtype=dtype if dtype else None,
                preferred_dtype=default_dtype,
                as_ref=input_arg.is_ref)
            all_types = set(v.dtype.base_dtype for v in values)
            if input_arg.number_attr and len(all_types) > 1:
              # All types should match.
              raise TypeError(f"Not all types matched for {input_arg.name} for "
                              f"{op_type_name}. Got {all_types}")
          except (TypeError, ValueError):
            # What types does the conversion function think values have?
            observed_types = []
            for value in values:
              try:
                converted_value = ops.convert_to_tensor(
                    value, as_ref=input_arg.is_ref)
                observed_types.append(converted_value.dtype.base_dtype.name)
              except (TypeError, ValueError):
                observed_types.append("<NOT CONVERTIBLE TO TENSOR>")
            observed = ", ".join(observed_types)
    
            prefix = ("Tensors in list passed to '%s' of '%s' Op have types [%s]" %
                      (input_name, op_type_name, observed))
            if input_arg.number_attr:
              if input_arg.type != types_pb2.DT_INVALID:
                raise TypeError(f"{prefix} that do not match expected type "
                                f"{dtype.name}.")
              elif input_arg.type_attr in attrs:
                raise TypeError(f"{prefix} that do not match type {dtype.name} "
                                "inferred from earlier arguments.")
              else:
                raise TypeError(f"{prefix} that don't all match.")
            else:
              raise TypeError(f"{prefix} that are invalid. Tensors: {values}")
    
          types = [x.dtype for x in values]
          inputs.extend(values)
        else:
          # In cases where we have an expected type, try to convert non-Tensor
          # arguments to that type.
          dtype = None
          default_dtype = None
          allowed_list = None
          if input_arg.type != types_pb2.DT_INVALID:
            dtype = input_arg.type
          elif input_arg.type_attr in attrs:
            dtype = attrs[input_arg.type_attr]
          elif input_arg.type_attr in default_type_attr_map:
            # The dtype could not be inferred solely from the inputs,
            # so we prefer the attr's default, so code that adds a new attr
            # with a default is backwards compatible.
            default_dtype = default_type_attr_map[input_arg.type_attr]
            allowed_list = allowed_list_attr_map.get(input_arg.type_attr)
    
          try:
            # First see if we can get a valid dtype with the default conversion
            # and see if it matches an allowed dtypes. Some ops like ConcatV2 may
            # not list allowed dtypes, in which case we should skip this.
            if dtype is None and allowed_list:
              inferred = None
              try:
                inferred = ops.convert_to_tensor(
                    values, name=input_arg.name, as_ref=input_arg.is_ref)
              except TypeError as err:
                # When converting a python object such as a list of Dimensions, we
                # need a dtype to be specified, thus tensor conversion may throw
                # an exception which we will ignore and try again below.
                pass
    
              # If we did not match an allowed dtype, try again with the default
              # dtype. This could be because we have an empty tensor and thus we
              # picked the wrong type.
              if inferred is not None and inferred.dtype in allowed_list:
                values = inferred
              else:
                values = ops.convert_to_tensor(
                    values,
                    name=input_arg.name,
                    as_ref=input_arg.is_ref,
                    preferred_dtype=default_dtype)
            else:
              values = ops.convert_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype,
                  as_ref=input_arg.is_ref,
                  preferred_dtype=default_dtype)
          except TypeError as err:
            if dtype is None:
              raise err
            else:
              raise TypeError(
                  f"Expected {dtypes.as_dtype(dtype).name} passed to parameter "
                  f"'{input_arg.name}' of op '{op_type_name}', got "
                  f"{repr(values)} of type '{type(values).__name__}' instead. "
                  f"Error: {err}")
          except ValueError:
            # What type does convert_to_tensor think it has?
            try:
              observed = ops.convert_to_tensor(
                  values, as_ref=input_arg.is_ref).dtype.name
            except ValueError as err:
              raise ValueError(
                  f"Tried to convert '{input_name}' to a tensor and failed. "
                  f"Error: {err}")
            prefix = ("Input '%s' of '%s' Op has type %s that does not match" %
                      (input_name, op_type_name, observed))
            if input_arg.type != types_pb2.DT_INVALID:
              raise TypeError(f"{prefix} expected type of "
                              f"{dtypes.as_dtype(input_arg.type).name}.")
            else:
              # Update the maps with the default, if needed.
              k = input_arg.type_attr
              if k in default_type_attr_map:
                if k not in attrs:
                  attrs[k] = default_type_attr_map[k]
                  if k not in inferred_from:
                    inferred_from[k] = "Default in OpDef"
    
>             raise TypeError(
                  f"{prefix} type "
                  f"{dtypes.as_dtype(attrs[input_arg.type_attr]).name} of "
                  f"argument '{inferred_from[input_arg.type_attr]}'.")
E             TypeError: Input 'e' of 'Select' Op has type int64 that does not match type float32 of argument 't'.

/local/data0/moved_data/publishablew/recommenders/recommenders/venv/lib/python3.11/site-packages/tensorflow/python/framework/op_def_library.py:589: TypeError
________________________________ test_save_load ________________________________

init_rbm = {'display_epoch': 20, 'epochs': 10, 'init_stdv': 0.01, 'keep_prob': 0.8, ...}
affinity_matrix = (array([[0, 0, 0, ..., 0, 1, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [2, 0, 2, ..., 0, 3, 0],
       ...,
       [1...0, 0, 0],
       ...,
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0]]))

    @pytest.mark.gpu
    def test_save_load(init_rbm, affinity_matrix):
    
        # obtain the train/test set matrices
        Xtr, _ = affinity_matrix
    
        # initialize the model
>       original_model = RBM(
            possible_ratings=np.setdiff1d(np.unique(Xtr), np.array([0])),
            visible_units=Xtr.shape[1],
            hidden_units=init_rbm["n_hidden"],
            training_epoch=init_rbm["epochs"],
            minibatch_size=init_rbm["minibatch"],
            keep_prob=init_rbm["keep_prob"],
            learning_rate=init_rbm["learning_rate"],
            init_stdv=init_rbm["init_stdv"],
            sampling_protocol=init_rbm["sampling_protocol"],
            display_epoch=init_rbm["display_epoch"],
        )

/local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/models/rbm/rbm.py:70: in __init__
    self.generate_graph()
/local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/models/rbm/rbm.py:302: in generate_graph
    self.gibbs_sampling()
/local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/models/rbm/rbm.py:241: in gibbs_sampling
    _, self.v_k = self.sample_visible_units(h_k)
/local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/models/rbm/rbm.py:218: in sample_visible_units
    v_ = tf.compat.v1.where(mask, x=self.v, y=v_tmp)
/local/data0/moved_data/publishablew/recommenders/recommenders/venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler
    raise e.with_traceback(filtered_tb) from None
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

op_type_name = 'Select'
op_def = name: "Select"
input_arg {
  name: "condition"
  type: DT_BOOL
}
input_arg {
  name: "t"
  type_attr: "T"
}
input_arg {
  name: "e"
  type_attr: "T"
}
output_arg {
  name: "output"
  type_attr: "T"
}
attr {
  name: "T"
  type: "type"
}

allowed_list_attr_map = {}, keywords = {}, default_type_attr_map = {}
attrs = {'T': tf.float32}
inputs = [<tf.Tensor 'gibbs_sampling/sample_visible_units/Equal:0' shape=(None, 53) dtype=bool>, <tf.Tensor 'IteratorGetNext:0' shape=(None, 53) dtype=float32>]
input_types = [tf.bool, tf.float32]

    def _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,
                               keywords, default_type_attr_map, attrs, inputs,
                               input_types):
      """Extracts `attrs`, `inputs`, and `input_types` in _apply_op_helper."""
      inferred_from = {}
      for input_arg in op_def.input_arg:
        input_name = input_arg.name
        if input_name in keywords:
          values = keywords.pop(input_name)
        elif input_name + "_" in keywords:
          # Handle the case where the name is a keyword or built-in
          # for Python so we use the name + _ instead.
          input_name += "_"
          values = keywords.pop(input_name)
        else:
          raise TypeError(f"No argument for input {input_name} found in {op_def}")
    
        # Goals:
        # * Convert values to Tensors if it contains constants.
        # * Verify that values is a list if that matches the input_arg's
        #   type.
        # * If the input_arg's type is determined by attrs, either set
        #   those attrs and validate those attr values are legal (if
        #   they have not yet been set) or validate the input matches
        #   the type indicated by the attrs (if they have already been
        #   inferred via an earlier input).
        # * If the input_arg has an explicit type, make sure the input
        #   conforms.
    
        if _IsListParameter(input_arg):
          if not _IsListValue(values):
            raise TypeError(
                f"Expected list for '{input_name}' argument to '{op_type_name}' "
                f"Op, not {values}.")
          # In cases where we expect all elements of the list to have the
          # same dtype, try to cast non-Tensor elements to that type.
          dtype = None
          default_dtype = None
          if input_arg.type != types_pb2.DT_INVALID:
            dtype = input_arg.type
          elif input_arg.number_attr:
            if input_arg.type_attr in attrs:
              dtype = attrs[input_arg.type_attr]
            else:
              for t in values:
                if isinstance(t, tensor.Tensor):
                  dtype = t.dtype
                  break
    
            # dtype still not found, prefer using the default dtype
            # from the attr.
            if dtype is None and input_arg.type_attr in default_type_attr_map:
              default_dtype = default_type_attr_map[input_arg.type_attr]
    
          try:
            if not input_arg.is_ref and dtype:
              dtype = dtypes.as_dtype(dtype).base_dtype
            values = ops.internal_convert_n_to_tensor(
                values,
                name=input_arg.name,
                dtype=dtype if dtype else None,
                preferred_dtype=default_dtype,
                as_ref=input_arg.is_ref)
            all_types = set(v.dtype.base_dtype for v in values)
            if input_arg.number_attr and len(all_types) > 1:
              # All types should match.
              raise TypeError(f"Not all types matched for {input_arg.name} for "
                              f"{op_type_name}. Got {all_types}")
          except (TypeError, ValueError):
            # What types does the conversion function think values have?
            observed_types = []
            for value in values:
              try:
                converted_value = ops.convert_to_tensor(
                    value, as_ref=input_arg.is_ref)
                observed_types.append(converted_value.dtype.base_dtype.name)
              except (TypeError, ValueError):
                observed_types.append("<NOT CONVERTIBLE TO TENSOR>")
            observed = ", ".join(observed_types)
    
            prefix = ("Tensors in list passed to '%s' of '%s' Op have types [%s]" %
                      (input_name, op_type_name, observed))
            if input_arg.number_attr:
              if input_arg.type != types_pb2.DT_INVALID:
                raise TypeError(f"{prefix} that do not match expected type "
                                f"{dtype.name}.")
              elif input_arg.type_attr in attrs:
                raise TypeError(f"{prefix} that do not match type {dtype.name} "
                                "inferred from earlier arguments.")
              else:
                raise TypeError(f"{prefix} that don't all match.")
            else:
              raise TypeError(f"{prefix} that are invalid. Tensors: {values}")
    
          types = [x.dtype for x in values]
          inputs.extend(values)
        else:
          # In cases where we have an expected type, try to convert non-Tensor
          # arguments to that type.
          dtype = None
          default_dtype = None
          allowed_list = None
          if input_arg.type != types_pb2.DT_INVALID:
            dtype = input_arg.type
          elif input_arg.type_attr in attrs:
            dtype = attrs[input_arg.type_attr]
          elif input_arg.type_attr in default_type_attr_map:
            # The dtype could not be inferred solely from the inputs,
            # so we prefer the attr's default, so code that adds a new attr
            # with a default is backwards compatible.
            default_dtype = default_type_attr_map[input_arg.type_attr]
            allowed_list = allowed_list_attr_map.get(input_arg.type_attr)
    
          try:
            # First see if we can get a valid dtype with the default conversion
            # and see if it matches an allowed dtypes. Some ops like ConcatV2 may
            # not list allowed dtypes, in which case we should skip this.
            if dtype is None and allowed_list:
              inferred = None
              try:
                inferred = ops.convert_to_tensor(
                    values, name=input_arg.name, as_ref=input_arg.is_ref)
              except TypeError as err:
                # When converting a python object such as a list of Dimensions, we
                # need a dtype to be specified, thus tensor conversion may throw
                # an exception which we will ignore and try again below.
                pass
    
              # If we did not match an allowed dtype, try again with the default
              # dtype. This could be because we have an empty tensor and thus we
              # picked the wrong type.
              if inferred is not None and inferred.dtype in allowed_list:
                values = inferred
              else:
                values = ops.convert_to_tensor(
                    values,
                    name=input_arg.name,
                    as_ref=input_arg.is_ref,
                    preferred_dtype=default_dtype)
            else:
              values = ops.convert_to_tensor(
                  values,
                  name=input_arg.name,
                  dtype=dtype,
                  as_ref=input_arg.is_ref,
                  preferred_dtype=default_dtype)
          except TypeError as err:
            if dtype is None:
              raise err
            else:
              raise TypeError(
                  f"Expected {dtypes.as_dtype(dtype).name} passed to parameter "
                  f"'{input_arg.name}' of op '{op_type_name}', got "
                  f"{repr(values)} of type '{type(values).__name__}' instead. "
                  f"Error: {err}")
          except ValueError:
            # What type does convert_to_tensor think it has?
            try:
              observed = ops.convert_to_tensor(
                  values, as_ref=input_arg.is_ref).dtype.name
            except ValueError as err:
              raise ValueError(
                  f"Tried to convert '{input_name}' to a tensor and failed. "
                  f"Error: {err}")
            prefix = ("Input '%s' of '%s' Op has type %s that does not match" %
                      (input_name, op_type_name, observed))
            if input_arg.type != types_pb2.DT_INVALID:
              raise TypeError(f"{prefix} expected type of "
                              f"{dtypes.as_dtype(input_arg.type).name}.")
            else:
              # Update the maps with the default, if needed.
              k = input_arg.type_attr
              if k in default_type_attr_map:
                if k not in attrs:
                  attrs[k] = default_type_attr_map[k]
                  if k not in inferred_from:
                    inferred_from[k] = "Default in OpDef"
    
>             raise TypeError(
                  f"{prefix} type "
                  f"{dtypes.as_dtype(attrs[input_arg.type_attr]).name} of "
                  f"argument '{inferred_from[input_arg.type_attr]}'.")
E             TypeError: Input 'e' of 'Select' Op has type int64 that does not match type float32 of argument 't'.

/local/data0/moved_data/publishablew/recommenders/recommenders/venv/lib/python3.11/site-packages/tensorflow/python/framework/op_def_library.py:589: TypeError
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_class_init
FAILED ../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_train_param_init
FAILED ../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_sampling_funct
FAILED ../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_save_load
============================== 4 failed in 2.23s ===============================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/recommenders/recommenders/venv/bin/python3
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase(PosixPath('/home/aliredaq/Desktop/ICSE/src/tester/.hypothesis/examples'))
rootdir: /local/data0/moved_data/publishablew/recommenders/recommenders
configfile: pyproject.toml
plugins: typeguard-4.4.1, hypothesis-6.123.13, anyio-4.8.0
collecting ... collected 4 items

../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_class_init PASSED [ 25%]
../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_train_param_init PASSED [ 50%]
../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_sampling_funct PASSED [ 75%]
../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_save_load PASSED [100%]

============================== 4 passed in 3.68s ===============================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/recommenders/recommenders/venv/bin/python3
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase(PosixPath('/home/aliredaq/Desktop/ICSE/src/tester/.hypothesis/examples'))
rootdir: /local/data0/moved_data/publishablew/recommenders/recommenders
configfile: pyproject.toml
plugins: typeguard-4.4.1, hypothesis-6.123.13, anyio-4.8.0
collecting ... collected 4 items

../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_class_init PASSED [ 25%]
../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_train_param_init PASSED [ 50%]
../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_sampling_funct PASSED [ 75%]
../../../../../../local/data0/moved_data/publishablew/recommenders/recommenders/tests/unit/recommenders/models/test_rbm.py::test_save_load PASSED [100%]

============================== 4 passed in 3.56s ===============================
