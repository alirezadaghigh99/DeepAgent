output file:
processed_pfrlcompute_policy_gradient_loss259.json
function:
compute_policy_gradient_loss
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian]'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/pfrl/pfrl/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/pfrl/pfrl
configfile: pytest.ini
collecting ... collected 32 items

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax] FAILED

=================================== FAILURES ===================================
____ TestDegenerateDistribution.test_policy_gradient[0-True-True-Gaussian] _____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535afc1d0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([[0.2615, 0.0998]]), advantage = 1
action_distrib = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_distrib_mu = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_value = SingleActionValue, v = 0, truncation_threshold = 0

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
_____ TestDegenerateDistribution.test_policy_gradient[0-True-True-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535afc610>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([0]), advantage = 1
action_distrib = Categorical(probs: torch.Size([1, 2]))
action_distrib_mu = Categorical(probs: torch.Size([1, 2]))
action_value = DiscreteActionValue greedy_actions:[1] q_values:[[1. 3.]], v = 0
truncation_threshold = 0

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
____ TestDegenerateDistribution.test_policy_gradient[0-True-False-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535afc990>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([[0.7457, 0.6878]]), advantage = 1
action_distrib = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_distrib_mu = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_value = SingleActionValue, v = 0, truncation_threshold = 0

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
____ TestDegenerateDistribution.test_policy_gradient[0-True-False-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535afcad0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([0]), advantage = 1
action_distrib = Categorical(logits: torch.Size([1, 2]))
action_distrib_mu = Categorical(probs: torch.Size([1, 2]))
action_value = DiscreteActionValue greedy_actions:[1] q_values:[[1. 3.]], v = 0
truncation_threshold = 0

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
____ TestDegenerateDistribution.test_policy_gradient[0-False-True-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535afcfd0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([[-0.4261, -0.5010]]), advantage = 1
action_distrib = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_distrib_mu = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_value = SingleActionValue, v = 0, truncation_threshold = 0

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
____ TestDegenerateDistribution.test_policy_gradient[0-False-True-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535afd390>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([0]), advantage = 1
action_distrib = Categorical(probs: torch.Size([1, 2]))
action_distrib_mu = Categorical(probs: torch.Size([1, 2]), logits: torch.Size([1, 2]))
action_value = DiscreteActionValue greedy_actions:[1] q_values:[[1. 3.]], v = 0
truncation_threshold = 0

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
___ TestDegenerateDistribution.test_policy_gradient[0-False-False-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535afacd0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([[2.0044, 1.8534]]), advantage = 1
action_distrib = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_distrib_mu = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_value = SingleActionValue, v = 0, truncation_threshold = 0

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
____ TestDegenerateDistribution.test_policy_gradient[0-False-False-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535afbc50>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([1]), advantage = 1
action_distrib = Categorical(probs: torch.Size([1, 2]), logits: torch.Size([1, 2]))
action_distrib_mu = Categorical(probs: torch.Size([1, 2]), logits: torch.Size([1, 2]))
action_value = DiscreteActionValue greedy_actions:[1] q_values:[[1. 3.]], v = 0
truncation_threshold = 0

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
____ TestDegenerateDistribution.test_policy_gradient[1-True-True-Gaussian] _____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535afbf10>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([[0.3023, 0.5481]]), advantage = 1
action_distrib = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_distrib_mu = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_value = SingleActionValue, v = 0, truncation_threshold = 1

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
_____ TestDegenerateDistribution.test_policy_gradient[1-True-True-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535908210>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([0]), advantage = 1
action_distrib = Categorical(probs: torch.Size([1, 2]))
action_distrib_mu = Categorical(probs: torch.Size([1, 2]))
action_value = DiscreteActionValue greedy_actions:[1] q_values:[[1. 3.]], v = 0
truncation_threshold = 1

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
____ TestDegenerateDistribution.test_policy_gradient[1-True-False-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535908490>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([[0.9872, 0.0214]]), advantage = 1
action_distrib = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_distrib_mu = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_value = SingleActionValue, v = 0, truncation_threshold = 1

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
____ TestDegenerateDistribution.test_policy_gradient[1-True-False-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535908710>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([0]), advantage = 1
action_distrib = Categorical(logits: torch.Size([1, 2]))
action_distrib_mu = Categorical(probs: torch.Size([1, 2]))
action_value = DiscreteActionValue greedy_actions:[1] q_values:[[1. 3.]], v = 0
truncation_threshold = 1

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
____ TestDegenerateDistribution.test_policy_gradient[1-False-True-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535908990>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([[-0.7330,  0.7285]]), advantage = 1
action_distrib = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_distrib_mu = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_value = SingleActionValue, v = 0, truncation_threshold = 1

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
____ TestDegenerateDistribution.test_policy_gradient[1-False-True-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535908c10>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([0]), advantage = 1
action_distrib = Categorical(probs: torch.Size([1, 2]))
action_distrib_mu = Categorical(probs: torch.Size([1, 2]), logits: torch.Size([1, 2]))
action_value = DiscreteActionValue greedy_actions:[1] q_values:[[1. 3.]], v = 0
truncation_threshold = 1

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
___ TestDegenerateDistribution.test_policy_gradient[1-False-False-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535908e90>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([[ 1.7427, -1.0175]]), advantage = 1
action_distrib = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_distrib_mu = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_value = SingleActionValue, v = 0, truncation_threshold = 1

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
____ TestDegenerateDistribution.test_policy_gradient[1-False-False-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535909110>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([1]), advantage = 1
action_distrib = Categorical(probs: torch.Size([1, 2]), logits: torch.Size([1, 2]))
action_distrib_mu = Categorical(probs: torch.Size([1, 2]), logits: torch.Size([1, 2]))
action_value = DiscreteActionValue greedy_actions:[1] q_values:[[1. 3.]], v = 0
truncation_threshold = 1

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
____ TestDegenerateDistribution.test_policy_gradient[10-True-True-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535909390>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([[0.3945, 0.8573]]), advantage = 1
action_distrib = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_distrib_mu = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_value = SingleActionValue, v = 0, truncation_threshold = 10

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
____ TestDegenerateDistribution.test_policy_gradient[10-True-True-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535909610>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([0]), advantage = 1
action_distrib = Categorical(probs: torch.Size([1, 2]))
action_distrib_mu = Categorical(probs: torch.Size([1, 2]))
action_value = DiscreteActionValue greedy_actions:[1] q_values:[[1. 3.]], v = 0
truncation_threshold = 10

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
___ TestDegenerateDistribution.test_policy_gradient[10-True-False-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535909890>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([[0.8585, 0.7184]]), advantage = 1
action_distrib = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_distrib_mu = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_value = SingleActionValue, v = 0, truncation_threshold = 10

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
____ TestDegenerateDistribution.test_policy_gradient[10-True-False-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535909b50>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([0]), advantage = 1
action_distrib = Categorical(logits: torch.Size([1, 2]))
action_distrib_mu = Categorical(probs: torch.Size([1, 2]))
action_value = DiscreteActionValue greedy_actions:[1] q_values:[[1. 3.]], v = 0
truncation_threshold = 10

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
___ TestDegenerateDistribution.test_policy_gradient[10-False-True-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7c9535909e50>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([[ 1.7004, -0.1145]]), advantage = 1
action_distrib = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_distrib_mu = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_value = SingleActionValue, v = 0, truncation_threshold = 10

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
____ TestDegenerateDistribution.test_policy_gradient[10-False-True-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x7c953590a150>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([0]), advantage = 1
action_distrib = Categorical(probs: torch.Size([1, 2]))
action_distrib_mu = Categorical(probs: torch.Size([1, 2]), logits: torch.Size([1, 2]))
action_value = DiscreteActionValue greedy_actions:[1] q_values:[[1. 3.]], v = 0
truncation_threshold = 10

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
___ TestDegenerateDistribution.test_policy_gradient[10-False-False-Gaussian] ___

self = <test_acer.TestDegenerateDistribution object at 0x7c953590a450>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([[1.1202, 0.7049]]), advantage = 1
action_distrib = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_distrib_mu = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_value = SingleActionValue, v = 0, truncation_threshold = 10

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
___ TestDegenerateDistribution.test_policy_gradient[10-False-False-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x7c953590a750>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([0]), advantage = 1
action_distrib = Categorical(probs: torch.Size([1, 2]), logits: torch.Size([1, 2]))
action_distrib_mu = Categorical(probs: torch.Size([1, 2]), logits: torch.Size([1, 2]))
action_value = DiscreteActionValue greedy_actions:[1] q_values:[[1. 3.]], v = 0
truncation_threshold = 10

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
___ TestDegenerateDistribution.test_policy_gradient[None-True-True-Gaussian] ___

self = <test_acer.TestDegenerateDistribution object at 0x7c953590aa50>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([[0.5132, 0.7030]]), advantage = 1
action_distrib = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_distrib_mu = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_value = SingleActionValue, v = 0, truncation_threshold = None

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
___ TestDegenerateDistribution.test_policy_gradient[None-True-True-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x7c953590ad50>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([0]), advantage = 1
action_distrib = Categorical(probs: torch.Size([1, 2]))
action_distrib_mu = Categorical(probs: torch.Size([1, 2]))
action_value = DiscreteActionValue greedy_actions:[1] q_values:[[1. 3.]], v = 0
truncation_threshold = None

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
__ TestDegenerateDistribution.test_policy_gradient[None-True-False-Gaussian] ___

self = <test_acer.TestDegenerateDistribution object at 0x7c953590b050>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([[0.1164, 0.4048]]), advantage = 1
action_distrib = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_distrib_mu = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_value = SingleActionValue, v = 0, truncation_threshold = None

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
___ TestDegenerateDistribution.test_policy_gradient[None-True-False-Softmax] ___

self = <test_acer.TestDegenerateDistribution object at 0x7c953590b350>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([0]), advantage = 1
action_distrib = Categorical(logits: torch.Size([1, 2]))
action_distrib_mu = Categorical(probs: torch.Size([1, 2]))
action_value = DiscreteActionValue greedy_actions:[1] q_values:[[1. 3.]], v = 0
truncation_threshold = None

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
__ TestDegenerateDistribution.test_policy_gradient[None-False-True-Gaussian] ___

self = <test_acer.TestDegenerateDistribution object at 0x7c953590b650>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([[1.0838, 2.1020]]), advantage = 1
action_distrib = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_distrib_mu = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_value = SingleActionValue, v = 0, truncation_threshold = None

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
___ TestDegenerateDistribution.test_policy_gradient[None-False-True-Softmax] ___

self = <test_acer.TestDegenerateDistribution object at 0x7c953590b950>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([1]), advantage = 1
action_distrib = Categorical(probs: torch.Size([1, 2]))
action_distrib_mu = Categorical(probs: torch.Size([1, 2]), logits: torch.Size([1, 2]))
action_value = DiscreteActionValue greedy_actions:[1] q_values:[[1. 3.]], v = 0
truncation_threshold = None

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
__ TestDegenerateDistribution.test_policy_gradient[None-False-False-Gaussian] __

self = <test_acer.TestDegenerateDistribution object at 0x7c953590bc50>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([[ 1.4353, -0.6985]]), advantage = 1
action_distrib = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_distrib_mu = Independent(Normal(loc: torch.Size([1, 2]), scale: torch.Size([1, 2])), 1)
action_value = SingleActionValue, v = 0, truncation_threshold = None

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
__ TestDegenerateDistribution.test_policy_gradient[None-False-False-Softmax] ___

self = <test_acer.TestDegenerateDistribution object at 0x7c953590bf50>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

action = tensor([0]), advantage = 1
action_distrib = Categorical(probs: torch.Size([1, 2]), logits: torch.Size([1, 2]))
action_distrib_mu = Categorical(probs: torch.Size([1, 2]), logits: torch.Size([1, 2]))
action_value = DiscreteActionValue greedy_actions:[1] q_values:[[1. 3.]], v = 0
truncation_threshold = None

    def compute_policy_gradient_loss(action, advantage, action_distrib, action_distrib_mu, action_value, v, truncation_threshold):
>       from .temp import compute_policy_gradient_loss
E       ImportError: cannot import name 'compute_policy_gradient_loss' from 'pfrl.agents.temp' (/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py)

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: ImportError
=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax]
======================== 32 failed, 2 warnings in 1.32s ========================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/pfrl/pfrl/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/pfrl/pfrl
configfile: pytest.ini
collecting ... collected 32 items

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian] pg tensor([-21.5640])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian] pg tensor([2.5763])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian] pg tensor([-6.9830])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian] pg tensor([0.6901])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian] pg tensor([-0.7138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian] pg tensor([-16.9011])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax] pg tensor([3.8606e-06])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian] pg tensor([1.9540])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax] pg tensor([0.6931])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian] pg tensor([1.1475])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian] pg tensor([-22.6397])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax] pg tensor([3.8010e-06])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian] pg tensor([2.3779])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax] pg tensor([0.6931])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian] pg tensor([1.7904e-20])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax] pg tensor([0.3466])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian] pg tensor([0.])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax] pg tensor([3.8010e-06])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian] pg tensor([5.3371])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax] pg tensor([0.6931])
PASSED

=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================== 32 passed, 2 warnings in 0.96s ========================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/pfrl/pfrl/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/pfrl/pfrl
configfile: pytest.ini
collecting ... collected 32 items

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian] pg tensor([-27.1328])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian] pg tensor([-1.9594])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian] pg tensor([-50.2771])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian] pg tensor([-1.0004])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian] pg tensor([2.2095])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian] pg tensor([-32.9071])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax] pg tensor([1.7881e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian] pg tensor([3.4783])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax] pg tensor([0.6931])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian] pg tensor([0.7959])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian] pg tensor([-11.5968])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax] pg tensor([2.3842e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian] pg tensor([2.5315])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax] pg tensor([0.6931])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian] pg tensor([1.7717e-20])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax] pg tensor([0.3466])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian] pg tensor([0.])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax] pg tensor([3.8010e-06])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian] pg tensor([2.3828])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax] pg tensor([0.6931])
PASSED

=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================== 32 passed, 2 warnings in 0.97s ========================
