output file:
processed_Laplacefit15.json
function:
fit
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification]'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/Laplace/Laplace/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/Laplace/Laplace
configfile: pyproject.toml
plugins: mock-3.14.0, cov-6.0.0
collecting ... collected 212 items

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED

=================================== FAILURES ===================================
___________ test_laplace_init_prior_mean_and_scatter[FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d788690>

    @pytest.mark.parametrize("laplace", flavors)
    def test_laplace_init_prior_mean_and_scatter(laplace, model, class_loader):
        lap_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=1.0,
        )
        assert torch.allclose(lap_scalar_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1),
        )
        assert torch.allclose(lap_tensor_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1)[0],
        )
        assert torch.allclose(lap_tensor_scalar_mean.prior_mean, torch.tensor(1.0))
        lap_tensor_full_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(20 * 2 + 2),
        )
        assert torch.allclose(lap_tensor_full_mean.prior_mean, torch.ones(20 * 2 + 2))
    
        lap_scalar_mean.fit(class_loader)
        lap_tensor_mean.fit(class_loader)
        lap_tensor_scalar_mean.fit(class_loader)
        lap_tensor_full_mean.fit(class_loader)
        expected = lap_scalar_mean.scatter
        assert expected.ndim == 0
        assert torch.allclose(lap_tensor_mean.scatter, expected)
        assert lap_tensor_mean.scatter.shape == expected.shape
        assert torch.allclose(lap_tensor_scalar_mean.scatter, expected)
        assert lap_tensor_scalar_mean.scatter.shape == expected.shape
>       assert torch.allclose(lap_tensor_full_mean.scatter, expected)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d741790>

    @property
    def scatter(self) -> torch.Tensor:
        """Computes the _scatter_, a term of the log marginal likelihood that
        corresponds to L-2 regularization:
        `scatter` = \\((\\theta_{MAP} - \\mu_0)^{T} P_0 (\\theta_{MAP} - \\mu_0) \\).
    
        Returns
        -------
        scatter: torch.Tensor
        """
>       delta = self.mean - self.prior_mean
E       RuntimeError: The size of tensor a (122) must match the size of tensor b (42) at non-singleton dimension 0

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:943: RuntimeError
___________ test_laplace_init_prior_mean_and_scatter[KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d76ce10>

    @pytest.mark.parametrize("laplace", flavors)
    def test_laplace_init_prior_mean_and_scatter(laplace, model, class_loader):
        lap_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=1.0,
        )
        assert torch.allclose(lap_scalar_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1),
        )
        assert torch.allclose(lap_tensor_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1)[0],
        )
        assert torch.allclose(lap_tensor_scalar_mean.prior_mean, torch.tensor(1.0))
        lap_tensor_full_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(20 * 2 + 2),
        )
        assert torch.allclose(lap_tensor_full_mean.prior_mean, torch.ones(20 * 2 + 2))
    
        lap_scalar_mean.fit(class_loader)
        lap_tensor_mean.fit(class_loader)
        lap_tensor_scalar_mean.fit(class_loader)
        lap_tensor_full_mean.fit(class_loader)
        expected = lap_scalar_mean.scatter
        assert expected.ndim == 0
        assert torch.allclose(lap_tensor_mean.scatter, expected)
        assert lap_tensor_mean.scatter.shape == expected.shape
        assert torch.allclose(lap_tensor_scalar_mean.scatter, expected)
        assert lap_tensor_scalar_mean.scatter.shape == expected.shape
>       assert torch.allclose(lap_tensor_full_mean.scatter, expected)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.KronLLLaplace object at 0x77b27d7f6dd0>

    @property
    def scatter(self) -> torch.Tensor:
        """Computes the _scatter_, a term of the log marginal likelihood that
        corresponds to L-2 regularization:
        `scatter` = \\((\\theta_{MAP} - \\mu_0)^{T} P_0 (\\theta_{MAP} - \\mu_0) \\).
    
        Returns
        -------
        scatter: torch.Tensor
        """
>       delta = self.mean - self.prior_mean
E       RuntimeError: The size of tensor a (122) must match the size of tensor b (42) at non-singleton dimension 0

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:943: RuntimeError
___________ test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d713ad0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_laplace_init_prior_mean_and_scatter(laplace, model, class_loader):
        lap_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=1.0,
        )
        assert torch.allclose(lap_scalar_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1),
        )
        assert torch.allclose(lap_tensor_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1)[0],
        )
        assert torch.allclose(lap_tensor_scalar_mean.prior_mean, torch.tensor(1.0))
        lap_tensor_full_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(20 * 2 + 2),
        )
        assert torch.allclose(lap_tensor_full_mean.prior_mean, torch.ones(20 * 2 + 2))
    
        lap_scalar_mean.fit(class_loader)
        lap_tensor_mean.fit(class_loader)
        lap_tensor_scalar_mean.fit(class_loader)
        lap_tensor_full_mean.fit(class_loader)
        expected = lap_scalar_mean.scatter
        assert expected.ndim == 0
        assert torch.allclose(lap_tensor_mean.scatter, expected)
        assert lap_tensor_mean.scatter.shape == expected.shape
        assert torch.allclose(lap_tensor_scalar_mean.scatter, expected)
        assert lap_tensor_scalar_mean.scatter.shape == expected.shape
>       assert torch.allclose(lap_tensor_full_mean.scatter, expected)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b2a95faa90>

    @property
    def scatter(self) -> torch.Tensor:
        """Computes the _scatter_, a term of the log marginal likelihood that
        corresponds to L-2 regularization:
        `scatter` = \\((\\theta_{MAP} - \\mu_0)^{T} P_0 (\\theta_{MAP} - \\mu_0) \\).
    
        Returns
        -------
        scatter: torch.Tensor
        """
>       delta = self.mean - self.prior_mean
E       RuntimeError: The size of tensor a (122) must match the size of tensor b (42) at non-singleton dimension 0

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:943: RuntimeError
__ test_laplace_functionality[pick_first-False-FullLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc49210>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc4a190>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc4b550>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc49ed0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dc49f50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____ test_laplace_functionality[pick_first-False-FullLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc48690>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d78b210>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7899d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7892d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d788e50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__ test_laplace_functionality[pick_first-False-KronLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbe2b90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbe2dd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbe3610>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbe3390>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____ test_laplace_functionality[pick_first-False-KronLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7ca390>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7cb590>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c82d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7cb650>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__ test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc482d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc4ab90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc48750>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc4a890>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dc48e10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____ test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd04910>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd07d10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd047d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd04d10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dd04dd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___ test_laplace_functionality[pick_first-True-FullLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc4ad10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc4a250>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b2a9408dd0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de2a950>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27de2b890>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[pick_first-True-FullLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd07510>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd04f90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd05050>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd04910>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b2a9408d50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___ test_laplace_functionality[pick_first-True-KronLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de1b0d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de1b010>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de1b190>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de19b90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[pick_first-True-KronLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c09d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c07d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c0a90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c0c50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___ test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dfd1cd0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dfd2790>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dfd1650>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dfd2350>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b2a940a690>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b39ebd0bd0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b284bd0a10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27defb110>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27defb310>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dfea2d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___ test_laplace_functionality[pick_last-False-FullLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b282d55450>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b282d56e50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd9a8d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd9b8d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dd9abd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[pick_last-False-FullLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c1350>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c3e10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c2990>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c3390>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d7c2090>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___ test_laplace_functionality[pick_last-False-KronLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd58bd0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd59b50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd28310>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b282d56450>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[pick_last-False-KronLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d72be50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d729490>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d728c50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d72ba90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___ test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc326d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc30cd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc31e50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc314d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dc31090>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d79c810>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d79de50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d79d290>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d79fe90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d79ea10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___ test_laplace_functionality[pick_last-True-FullLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc7b350>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc79610>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc7a7d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc7b8d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dc79310>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[pick_last-True-FullLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbe3b50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbe3750>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbe0510>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbe3ed0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dbe2490>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___ test_laplace_functionality[pick_last-True-KronLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc49250>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc4b390>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc49810>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc4ad90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[pick_last-True-KronLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de068d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de04910>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de05790>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de06ad0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___ test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc79c90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc7b350>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc78b50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc7bd50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dc7b690>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de04e10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de05c10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd9bf90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd99ad0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dd9a090>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____ test_laplace_functionality[average-False-FullLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c7450>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c77d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c5a50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c6710>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d7c7850>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______ test_laplace_functionality[average-False-FullLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc4a4d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b282d56b10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b282d56710>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b282d55550>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b280f29910>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____ test_laplace_functionality[average-False-KronLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd32a90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd33650>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd32d50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd31e90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______ test_laplace_functionality[average-False-KronLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd28150>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd33b90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd33910>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd33690>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____ test_laplace_functionality[average-False-DiagLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc212d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc20990>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc21790>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc23850>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dc22750>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______ test_laplace_functionality[average-False-DiagLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de04390>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de056d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de055d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de05350>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dbe0250>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____ test_laplace_functionality[average-True-FullLLLaplace-classification] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d75a090>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d75ac10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d75a190>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d75bd50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d758050>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______ test_laplace_functionality[average-True-FullLLLaplace-regression] _______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd33190>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd33b90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd334d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd32450>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dd32f90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____ test_laplace_functionality[average-True-KronLLLaplace-classification] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d79ed10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d79c250>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d79e410>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d79e7d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______ test_laplace_functionality[average-True-KronLLLaplace-regression] _______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbe1d90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbe3750>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbe0190>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbe2bd0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____ test_laplace_functionality[average-True-DiagLLLaplace-classification] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd321d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd32890>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd31890>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd33150>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dd323d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______ test_laplace_functionality[average-True-DiagLLLaplace-regression] _______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d711190>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d713e50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d710950>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d712310>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d7107d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[None-False-FullLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27ddb3b90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27ddb3290>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27ddb3a90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbe3010>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d789550>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_______ test_laplace_functionality[None-False-FullLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbe3490>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbe1410>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbe3e50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbe17d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dbe3510>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[None-False-KronLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd1b410>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd1bf90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd19fd0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd1a0d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_______ test_laplace_functionality[None-False-KronLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27db14410>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27db16dd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27db150d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27db14b90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[None-False-DiagLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dfeed50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27ddb3cd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27ddb3ed0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27ddb2010>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27ddb1e10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_______ test_laplace_functionality[None-False-DiagLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b39ebc7390>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b39ebc6410>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b39ebc7010>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b39ebc5010>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b39ebc79d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______ test_laplace_functionality[None-True-FullLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c7d50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c46d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c53d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c5410>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d7c6210>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_laplace_functionality[None-True-FullLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7f7a10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7f6e50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7f7c90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7f5190>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d7f5310>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______ test_laplace_functionality[None-True-KronLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b39ebc5010>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de04150>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de06750>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de07250>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_laplace_functionality[None-True-KronLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbab950>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dba8310>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbab510>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dba8c90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______ test_laplace_functionality[None-True-DiagLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c50d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c7750>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c4e90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c5950>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d7c6690>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_laplace_functionality[None-True-DiagLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de05a50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de06090>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27de06750>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7f4590>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d7f7c90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________________ test_regression_predictive[FullLLLaplace] ___________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27ddb0850>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:474: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27ddb24d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________________ test_regression_predictive[KronLLLaplace] ___________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc22310>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:474: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________________ test_regression_predictive[DiagLLLaplace] ___________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c0750>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:474: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d7c1390>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________________ test_classification_predictive[FullLLLaplace] _________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc20f50>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:498: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dc23ad0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________________ test_classification_predictive[KronLLLaplace] _________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c2190>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:498: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________________ test_classification_predictive[DiagLLLaplace] _________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7da250>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:498: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d7daf90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_regression_predictive_samples[FullLLLaplace] _______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc23390>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive_samples(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dc20490>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_regression_predictive_samples[KronLLLaplace] _______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd33dd0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive_samples(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_regression_predictive_samples[DiagLLLaplace] _______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d76f8d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive_samples(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d76ff10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_classification_predictive_samples[FullLLLaplace] _____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7ddad0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive_samples(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d7decd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_classification_predictive_samples[KronLLLaplace] _____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd33650>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive_samples(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_classification_predictive_samples[DiagLLLaplace] _____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27db9fc90>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive_samples(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27db9fa10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________________ test_functional_variance_fast[FullLLLaplace] _________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc20390>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, DiagLLLaplace, KronLLLaplace])
    def test_functional_variance_fast(laplace, model, reg_loader):
        if laplace == KronLLLaplace:
            # TODO still!
            return
    
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:588: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dc20b90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________________ test_functional_variance_fast[DiagLLLaplace] _________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7dd910>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, DiagLLLaplace, KronLLLaplace])
    def test_functional_variance_fast(laplace, model, reg_loader):
        if laplace == KronLLLaplace:
            # TODO still!
            return
    
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:588: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d7dc210>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_______________________ test_backprop_glm[FullLLLaplace] _______________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc677d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:614: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dc66b90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_______________________ test_backprop_glm[KronLLLaplace] _______________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dd9b4d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:614: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_______________________ test_backprop_glm[DiagLLLaplace] _______________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7de490>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:614: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d7de7d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________________ test_backprop_glm_joint[FullLLLaplace] ____________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27db7cb90>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_joint(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27db7ead0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________________ test_backprop_glm_joint[KronLLLaplace] ____________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7c4350>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_joint(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________________ test_backprop_glm_joint[DiagLLLaplace] ____________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d7cab90>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_joint(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d7cbed0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________________ test_backprop_glm_mc[FullLLLaplace] ______________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27ddb0650>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_mc(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:652: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d7de290>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________________ test_backprop_glm_mc[KronLLLaplace] ______________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dc790d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_mc(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:652: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________________ test_backprop_glm_mc[DiagLLLaplace] ______________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dbdb490>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_mc(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:652: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dbdb150>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_______________________ test_backprop_nn[FullLLLaplace] ________________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dcf5c50>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_nn(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:671: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dcf6990>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_______________________ test_backprop_nn[KronLLLaplace] ________________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d72b4d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_nn(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:671: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_______________________ test_backprop_nn[DiagLLLaplace] ________________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27dba30d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_nn(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:671: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dba06d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_reg_glm_predictive_correct_behavior[FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d756550>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, KronLLLaplace, DiagLLLaplace])
    def test_reg_glm_predictive_correct_behavior(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        n_batch = X.shape[0]
        n_outputs = y.shape[-1]
    
        lap = laplace(model, "regression")
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:691: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d7578d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_reg_glm_predictive_correct_behavior[KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27d729c50>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, KronLLLaplace, DiagLLLaplace])
    def test_reg_glm_predictive_correct_behavior(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        n_batch = X.shape[0]
        n_outputs = y.shape[-1]
    
        lap = laplace(model, "regression")
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:691: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_reg_glm_predictive_correct_behavior[DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x77b27db18690>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, KronLLLaplace, DiagLLLaplace])
    def test_reg_glm_predictive_correct_behavior(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        n_batch = X.shape[0]
        n_outputs = y.shape[-1]
    
        lap = laplace(model, "regression")
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:691: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27db18ed0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dc0e1d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dbc7cd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dc0d290>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d710b50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d7dfcd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d728650>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dc66190>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d7c1450>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27db9fc90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dc90bd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27db7d090>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dc64310>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dcf5210>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27db7e750>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dc66850>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27db0af10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27db17e10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dbdf010>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dc78ed0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d99b2d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dc30550>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d7f7950>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dc30910>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dc0cfd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d7dd950>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dc0fc90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27db9e750>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d9bd890>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27db9e750>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d9bf150>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dbde810>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27db40bd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27db08950>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d9e2190>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dc95f10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dc30490>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27db19f90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dd89190>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________ test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d9ef890>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________ test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________ test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d900050>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27db15010>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27dbf7810>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dbf51d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d9c2fd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d756650>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27db76190>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dbcc7d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27ddd2a90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d757b50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27ddd0fd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________ test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27db72c50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________ test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________ test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27ddd1390>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d758a10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d759ed0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d758290>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d9110d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dd91810>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d913e90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d79d610>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d902c50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27db0ab90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d920210>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________ test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27db1b7d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________ test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________ test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d983150>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27d7db890>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27db7abd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27db17550>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27db16150>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27db16990>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27db16b50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x77b27dbaa4d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x77b27d9d4190>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION = LooseVersion(version("torch"))

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION_AT_LEAST_1_12_0 = TORCH_VERSION >= LooseVersion("1.12.0")

tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace]
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/curvlinops/_base.py:299: UserWarning: Input matrix is float64, while linear operator is float32. Converting to float32.
    warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace]
================= 188 failed, 24 passed, 3 warnings in 21.19s ==================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/Laplace/Laplace/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/Laplace/Laplace
configfile: pyproject.toml
plugins: mock-3.14.0, cov-6.0.0
collecting ... collected 212 items

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED

=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION = LooseVersion(version("torch"))

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION_AT_LEAST_1_12_0 = TORCH_VERSION >= LooseVersion("1.12.0")

tests/test_lllaplace.py: 27 warnings
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/curvlinops/_base.py:299: UserWarning: Input matrix is float64, while linear operator is float32. Converting to float32.
    warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
====================== 212 passed, 29 warnings in 56.80s =======================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/Laplace/Laplace/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/Laplace/Laplace
configfile: pyproject.toml
plugins: mock-3.14.0, cov-6.0.0
collecting ... collected 212 items

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED

=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION = LooseVersion(version("torch"))

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION_AT_LEAST_1_12_0 = TORCH_VERSION >= LooseVersion("1.12.0")

tests/test_lllaplace.py: 27 warnings
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/curvlinops/_base.py:299: UserWarning: Input matrix is float64, while linear operator is float32. Converting to float32.
    warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
====================== 212 passed, 29 warnings in 57.14s =======================
