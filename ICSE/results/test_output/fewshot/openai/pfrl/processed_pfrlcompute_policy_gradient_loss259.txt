output file:
processed_pfrlcompute_policy_gradient_loss259.json
function:
compute_policy_gradient_loss
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian]'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/pfrl/pfrl/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/pfrl/pfrl
configfile: pytest.ini
collecting ... collected 32 items

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax] FAILED

=================================== FAILURES ===================================
____ TestDegenerateDistribution.test_policy_gradient[0-True-True-Gaussian] _____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb18190>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
_____ TestDegenerateDistribution.test_policy_gradient[0-True-True-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb185d0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
____ TestDegenerateDistribution.test_policy_gradient[0-True-False-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb18950>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
____ TestDegenerateDistribution.test_policy_gradient[0-True-False-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb18a90>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
____ TestDegenerateDistribution.test_policy_gradient[0-False-True-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb18f90>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
____ TestDegenerateDistribution.test_policy_gradient[0-False-True-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb19350>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
___ TestDegenerateDistribution.test_policy_gradient[0-False-False-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb16c90>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
____ TestDegenerateDistribution.test_policy_gradient[0-False-False-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb17c10>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
____ TestDegenerateDistribution.test_policy_gradient[1-True-True-Gaussian] _____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb17ed0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
_____ TestDegenerateDistribution.test_policy_gradient[1-True-True-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb241d0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
____ TestDegenerateDistribution.test_policy_gradient[1-True-False-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb24450>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
____ TestDegenerateDistribution.test_policy_gradient[1-True-False-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb246d0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
____ TestDegenerateDistribution.test_policy_gradient[1-False-True-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb24950>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
____ TestDegenerateDistribution.test_policy_gradient[1-False-True-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb24bd0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
___ TestDegenerateDistribution.test_policy_gradient[1-False-False-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb24e50>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
____ TestDegenerateDistribution.test_policy_gradient[1-False-False-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb250d0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
____ TestDegenerateDistribution.test_policy_gradient[10-True-True-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb25350>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
____ TestDegenerateDistribution.test_policy_gradient[10-True-True-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb255d0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
___ TestDegenerateDistribution.test_policy_gradient[10-True-False-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb25850>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
____ TestDegenerateDistribution.test_policy_gradient[10-True-False-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb25b10>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
___ TestDegenerateDistribution.test_policy_gradient[10-False-True-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb25e10>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
____ TestDegenerateDistribution.test_policy_gradient[10-False-True-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb26110>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
___ TestDegenerateDistribution.test_policy_gradient[10-False-False-Gaussian] ___

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb26410>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
___ TestDegenerateDistribution.test_policy_gradient[10-False-False-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb26710>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
___ TestDegenerateDistribution.test_policy_gradient[None-True-True-Gaussian] ___

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb26a10>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
___ TestDegenerateDistribution.test_policy_gradient[None-True-True-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb26d10>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
__ TestDegenerateDistribution.test_policy_gradient[None-True-False-Gaussian] ___

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb27010>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
___ TestDegenerateDistribution.test_policy_gradient[None-True-False-Softmax] ___

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb27310>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
__ TestDegenerateDistribution.test_policy_gradient[None-False-True-Gaussian] ___

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb27610>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
___ TestDegenerateDistribution.test_policy_gradient[None-False-True-Softmax] ___

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb27910>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
__ TestDegenerateDistribution.test_policy_gradient[None-False-False-Gaussian] __

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb27c10>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
__ TestDegenerateDistribution.test_policy_gradient[None-False-False-Softmax] ___

self = <test_acer.TestDegenerateDistribution object at 0x7a334fb27f10>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:14: NameError
=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax]
======================== 32 failed, 2 warnings in 1.34s ========================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/pfrl/pfrl/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/pfrl/pfrl
configfile: pytest.ini
collecting ... collected 32 items

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian] pg tensor([-44.4153])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian] pg tensor([-0.0082])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian] pg tensor([-7.0998])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian] pg tensor([-0.0670])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian] pg tensor([1.1011])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian] pg tensor([-8.3485])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax] pg tensor([1.7881e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian] pg tensor([2.6222])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax] pg tensor([0.6931])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian] pg tensor([0.4041])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian] pg tensor([-18.8609])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax] pg tensor([2.3842e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian] pg tensor([4.3355])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax] pg tensor([0.6931])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian] pg tensor([1.5357e-20])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax] pg tensor([0.3466])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian] pg tensor([0.])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax] pg tensor([3.8010e-06])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian] pg tensor([2.3620])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax] pg tensor([0.6931])
PASSED

=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================== 32 passed, 2 warnings in 0.96s ========================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/pfrl/pfrl/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/pfrl/pfrl
configfile: pytest.ini
collecting ... collected 32 items

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian] pg tensor([-25.1248])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian] pg tensor([1.1992])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian] pg tensor([-35.9007])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian] pg tensor([1.5663])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian] pg tensor([0.8475])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian] pg tensor([-29.8101])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax] pg tensor([3.8606e-06])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian] pg tensor([3.4809])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax] pg tensor([0.6931])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian] pg tensor([2.0944])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian] pg tensor([-21.7671])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax] pg tensor([2.3842e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian] pg tensor([2.2789])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax] pg tensor([0.6931])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian] pg tensor([1.7895e-20])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax] pg tensor([0.3466])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian] pg tensor([0.])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax] pg tensor([3.8010e-06])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian] pg tensor([2.5755])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax] pg tensor([0.6931])
PASSED

=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================== 32 passed, 2 warnings in 0.97s ========================
