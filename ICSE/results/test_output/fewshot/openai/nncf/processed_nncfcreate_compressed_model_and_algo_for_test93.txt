output file:
processed_nncfcreate_compressed_model_and_algo_for_test93.json
function:
create_compressed_model_and_algo_for_test
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data2] FAILED', '../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data0] FAILED', '../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data3] FAILED', '../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data1] FAILED', '../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data4] FAILED'}

All Test Cases On Generated code:
INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, onnx
============================= test session starts ==============================
platform linux -- Python 3.9.0, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/nncf/nncf/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/nncf/nncf/tests/torch
configfile: pytest.ini
plugins: mock-3.14.0, dependency-0.6.0
collecting ... collected 5 items

../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data0] FAILED
../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data1] FAILED
../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data2] FAILED
../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data3] FAILED
../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data4] FAILED

=================================== FAILURES ===================================
_______________________ test_quantization_preset[data0] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/helpers.py:316: in create_compressed_model_and_algo_for_test
    return create_compressed_model_and_algo_for_test(model, config, dummy_forward_fn, wrap_inputs_fn, compression_state)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model = BasicConvTestModel(
  (conv): Conv2d(1, 2, kernel_size=(2, 2), stride=(1, 1))
)
nncf_config = {'model': 'empty_config', 'model_size': 4, 'input_info': [{'sample_size': [1, 1, 4, 4]}], 'target_device': 'CPU', 'compression': {'algorithm': 'quantization', 'preset': 'performance'}}
dummy_forward_fn = None, wrap_inputs_fn = None, compression_state_dict = None

    def create_compressed_model_and_algo_for_test(model: nn.Module, nncf_config: Optional[NNCFConfig]=None, dummy_forward_fn: Optional[Callable]=None, wrap_inputs_fn: Optional[Callable]=None, compression_state_dict: Optional[Dict]=None) -> Tuple[nn.Module, object]:
        """
        Creates a compressed model and a compression algorithm controller.
    
        Args:
            model (nn.Module): The neural network model to be compressed.
            nncf_config (Optional[NNCFConfig]): The NNCF configuration object. Defaults to None.
            dummy_forward_fn (Optional[Callable]): A function to perform a dummy forward pass. Defaults to None.
            wrap_inputs_fn (Optional[Callable]): A function to wrap inputs for the model. Defaults to None.
            compression_state_dict (Optional[Dict]): A state dictionary for the compression algorithm. Defaults to None.
    
        Returns:
            Tuple[nn.Module, object]: A tuple containing the compressed model and the compression algorithm controller.
        """
        if nncf_config is not None:
>           nncf_config.validate()
E           TypeError: validate() missing 1 required positional argument: 'loaded_json'

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/temp.py:62: TypeError
_______________________ test_quantization_preset[data1] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.AsymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'mixed', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/helpers.py:316: in create_compressed_model_and_algo_for_test
    return create_compressed_model_and_algo_for_test(model, config, dummy_forward_fn, wrap_inputs_fn, compression_state)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model = BasicConvTestModel(
  (conv): Conv2d(1, 2, kernel_size=(2, 2), stride=(1, 1))
)
nncf_config = {'model': 'empty_config', 'model_size': 4, 'input_info': [{'sample_size': [1, 1, 4, 4]}], 'target_device': 'CPU', 'compression': {'algorithm': 'quantization', 'preset': 'mixed'}}
dummy_forward_fn = None, wrap_inputs_fn = None, compression_state_dict = None

    def create_compressed_model_and_algo_for_test(model: nn.Module, nncf_config: Optional[NNCFConfig]=None, dummy_forward_fn: Optional[Callable]=None, wrap_inputs_fn: Optional[Callable]=None, compression_state_dict: Optional[Dict]=None) -> Tuple[nn.Module, object]:
        """
        Creates a compressed model and a compression algorithm controller.
    
        Args:
            model (nn.Module): The neural network model to be compressed.
            nncf_config (Optional[NNCFConfig]): The NNCF configuration object. Defaults to None.
            dummy_forward_fn (Optional[Callable]): A function to perform a dummy forward pass. Defaults to None.
            wrap_inputs_fn (Optional[Callable]): A function to wrap inputs for the model. Defaults to None.
            compression_state_dict (Optional[Dict]): A state dictionary for the compression algorithm. Defaults to None.
    
        Returns:
            Tuple[nn.Module, object]: A tuple containing the compressed model and the compression algorithm controller.
        """
        if nncf_config is not None:
>           nncf_config.validate()
E           TypeError: validate() missing 1 required positional argument: 'loaded_json'

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/temp.py:62: TypeError
_______________________ test_quantization_preset[data2] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/helpers.py:316: in create_compressed_model_and_algo_for_test
    return create_compressed_model_and_algo_for_test(model, config, dummy_forward_fn, wrap_inputs_fn, compression_state)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model = BasicConvTestModel(
  (conv): Conv2d(1, 2, kernel_size=(2, 2), stride=(1, 1))
)
nncf_config = {'model': 'empty_config', 'model_size': 4, 'input_info': [{'sample_size': [1, 1, 4, 4]}], 'target_device': 'GPU', 'compression': {'algorithm': 'quantization', 'preset': 'performance'}}
dummy_forward_fn = None, wrap_inputs_fn = None, compression_state_dict = None

    def create_compressed_model_and_algo_for_test(model: nn.Module, nncf_config: Optional[NNCFConfig]=None, dummy_forward_fn: Optional[Callable]=None, wrap_inputs_fn: Optional[Callable]=None, compression_state_dict: Optional[Dict]=None) -> Tuple[nn.Module, object]:
        """
        Creates a compressed model and a compression algorithm controller.
    
        Args:
            model (nn.Module): The neural network model to be compressed.
            nncf_config (Optional[NNCFConfig]): The NNCF configuration object. Defaults to None.
            dummy_forward_fn (Optional[Callable]): A function to perform a dummy forward pass. Defaults to None.
            wrap_inputs_fn (Optional[Callable]): A function to wrap inputs for the model. Defaults to None.
            compression_state_dict (Optional[Dict]): A state dictionary for the compression algorithm. Defaults to None.
    
        Returns:
            Tuple[nn.Module, object]: A tuple containing the compressed model and the compression algorithm controller.
        """
        if nncf_config is not None:
>           nncf_config.validate()
E           TypeError: validate() missing 1 required positional argument: 'loaded_json'

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/temp.py:62: TypeError
_______________________ test_quantization_preset[data3] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.AsymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'mixed', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/helpers.py:316: in create_compressed_model_and_algo_for_test
    return create_compressed_model_and_algo_for_test(model, config, dummy_forward_fn, wrap_inputs_fn, compression_state)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model = BasicConvTestModel(
  (conv): Conv2d(1, 2, kernel_size=(2, 2), stride=(1, 1))
)
nncf_config = {'model': 'empty_config', 'model_size': 4, 'input_info': [{'sample_size': [1, 1, 4, 4]}], 'target_device': 'GPU', 'compression': {'algorithm': 'quantization', 'preset': 'mixed'}}
dummy_forward_fn = None, wrap_inputs_fn = None, compression_state_dict = None

    def create_compressed_model_and_algo_for_test(model: nn.Module, nncf_config: Optional[NNCFConfig]=None, dummy_forward_fn: Optional[Callable]=None, wrap_inputs_fn: Optional[Callable]=None, compression_state_dict: Optional[Dict]=None) -> Tuple[nn.Module, object]:
        """
        Creates a compressed model and a compression algorithm controller.
    
        Args:
            model (nn.Module): The neural network model to be compressed.
            nncf_config (Optional[NNCFConfig]): The NNCF configuration object. Defaults to None.
            dummy_forward_fn (Optional[Callable]): A function to perform a dummy forward pass. Defaults to None.
            wrap_inputs_fn (Optional[Callable]): A function to wrap inputs for the model. Defaults to None.
            compression_state_dict (Optional[Dict]): A state dictionary for the compression algorithm. Defaults to None.
    
        Returns:
            Tuple[nn.Module, object]: A tuple containing the compressed model and the compression algorithm controller.
        """
        if nncf_config is not None:
>           nncf_config.validate()
E           TypeError: validate() missing 1 required positional argument: 'loaded_json'

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/temp.py:62: TypeError
_______________________ test_quantization_preset[data4] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class '...ion.layers.AsymmetricQuantizer'>, 'overrided_param': {'weights': {'mode': 'asymmetric'}}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/helpers.py:316: in create_compressed_model_and_algo_for_test
    return create_compressed_model_and_algo_for_test(model, config, dummy_forward_fn, wrap_inputs_fn, compression_state)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model = BasicConvTestModel(
  (conv): Conv2d(1, 2, kernel_size=(2, 2), stride=(1, 1))
)
nncf_config = {'model': 'empty_config', 'model_size': 4, 'input_info': [{'sample_size': [1, 1, 4, 4]}], 'target_device': 'CPU', 'compression': {'algorithm': 'quantization', 'preset': 'performance', 'weights': {'mode': 'asymmetric'}}}
dummy_forward_fn = None, wrap_inputs_fn = None, compression_state_dict = None

    def create_compressed_model_and_algo_for_test(model: nn.Module, nncf_config: Optional[NNCFConfig]=None, dummy_forward_fn: Optional[Callable]=None, wrap_inputs_fn: Optional[Callable]=None, compression_state_dict: Optional[Dict]=None) -> Tuple[nn.Module, object]:
        """
        Creates a compressed model and a compression algorithm controller.
    
        Args:
            model (nn.Module): The neural network model to be compressed.
            nncf_config (Optional[NNCFConfig]): The NNCF configuration object. Defaults to None.
            dummy_forward_fn (Optional[Callable]): A function to perform a dummy forward pass. Defaults to None.
            wrap_inputs_fn (Optional[Callable]): A function to wrap inputs for the model. Defaults to None.
            compression_state_dict (Optional[Dict]): A state dictionary for the compression algorithm. Defaults to None.
    
        Returns:
            Tuple[nn.Module, object]: A tuple containing the compressed model and the compression algorithm controller.
        """
        if nncf_config is not None:
>           nncf_config.validate()
E           TypeError: validate() missing 1 required positional argument: 'loaded_json'

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/temp.py:62: TypeError
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data0]
FAILED ../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data1]
FAILED ../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data2]
FAILED ../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data3]
FAILED ../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data4]
============================== 5 failed in 1.73s ===============================


Final Test Result:
INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, onnx
============================= test session starts ==============================
platform linux -- Python 3.9.0, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/nncf/nncf/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/nncf/nncf/tests/torch
configfile: pytest.ini
plugins: mock-3.14.0, dependency-0.6.0
collecting ... collected 5 items

../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data0] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
INFO:nncf:Compiling and loading torch extension: quantized_functions_cpu...
INFO:nncf:Finished loading torch extension: quantized_functions_cpu
FAILED
../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data1] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
FAILED
../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data2] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
FAILED
../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data3] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
FAILED
../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data4] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
INFO:nncf:Preset quantizer parameters {'mode'} explicitly overridden by config.
FAILED

=================================== FAILURES ===================================
_______________________ test_quantization_preset[data0] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
/local/data0/moved_data/publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
_______________________ test_quantization_preset[data1] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.AsymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'mixed', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
/local/data0/moved_data/publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
_______________________ test_quantization_preset[data2] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
/local/data0/moved_data/publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
_______________________ test_quantization_preset[data3] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.AsymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'mixed', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
/local/data0/moved_data/publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
_______________________ test_quantization_preset[data4] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class '...ion.layers.AsymmetricQuantizer'>, 'overrided_param': {'weights': {'mode': 'asymmetric'}}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
/local/data0/moved_data/publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
=============================== warnings summary ===============================
quantization/test_algo_quantization.py::test_quantization_preset[data0]
quantization/test_algo_quantization.py::test_quantization_preset[data1]
quantization/test_algo_quantization.py::test_quantization_preset[data2]
quantization/test_algo_quantization.py::test_quantization_preset[data3]
quantization/test_algo_quantization.py::test_quantization_preset[data4]
  /local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/model_creation.py:105: FutureWarning: The 'nncf.torch.create_compressed_model' function is deprecated and will be removed in a future release.
  To perform post training quantization (PTQ) or quantization aware training (QAT), use the new nncf.quantize() API:
   - https://github.com/openvinotoolkit/nncf?tab=readme-ov-file#post-training-quantization
   - https://github.com/openvinotoolkit/nncf?tab=readme-ov-file#training-time-quantization
  Examples:
   - https://github.com/openvinotoolkit/nncf/tree/develop/examples/post_training_quantization/torch
   - https://github.com/openvinotoolkit/nncf/tree/develop/examples/quantization_aware_training/torch
    warning_deprecated(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data0]
FAILED ../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data1]
FAILED ../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data2]
FAILED ../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data3]
FAILED ../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data4]
======================== 5 failed, 5 warnings in 3.28s =========================


Initial Result:
INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, onnx
============================= test session starts ==============================
platform linux -- Python 3.9.0, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/nncf/nncf/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/nncf/nncf/tests/torch
configfile: pytest.ini
plugins: mock-3.14.0, dependency-0.6.0
collecting ... collected 5 items

../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data0] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
INFO:nncf:Compiling and loading torch extension: quantized_functions_cpu...
INFO:nncf:Finished loading torch extension: quantized_functions_cpu
FAILED
../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data1] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
FAILED
../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data2] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
FAILED
../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data3] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
FAILED
../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data4] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
INFO:nncf:Preset quantizer parameters {'mode'} explicitly overridden by config.
FAILED

=================================== FAILURES ===================================
_______________________ test_quantization_preset[data0] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
/local/data0/moved_data/publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
_______________________ test_quantization_preset[data1] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.AsymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'mixed', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
/local/data0/moved_data/publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
_______________________ test_quantization_preset[data2] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
/local/data0/moved_data/publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
_______________________ test_quantization_preset[data3] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.AsymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'mixed', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
/local/data0/moved_data/publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
_______________________ test_quantization_preset[data4] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class '...ion.layers.AsymmetricQuantizer'>, 'overrided_param': {'weights': {'mode': 'asymmetric'}}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
/local/data0/moved_data/publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
/local/data0/moved_data/publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
/local/data0/moved_data/publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
=============================== warnings summary ===============================
quantization/test_algo_quantization.py::test_quantization_preset[data0]
quantization/test_algo_quantization.py::test_quantization_preset[data1]
quantization/test_algo_quantization.py::test_quantization_preset[data2]
quantization/test_algo_quantization.py::test_quantization_preset[data3]
quantization/test_algo_quantization.py::test_quantization_preset[data4]
  /local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/model_creation.py:105: FutureWarning: The 'nncf.torch.create_compressed_model' function is deprecated and will be removed in a future release.
  To perform post training quantization (PTQ) or quantization aware training (QAT), use the new nncf.quantize() API:
   - https://github.com/openvinotoolkit/nncf?tab=readme-ov-file#post-training-quantization
   - https://github.com/openvinotoolkit/nncf?tab=readme-ov-file#training-time-quantization
  Examples:
   - https://github.com/openvinotoolkit/nncf/tree/develop/examples/post_training_quantization/torch
   - https://github.com/openvinotoolkit/nncf/tree/develop/examples/quantization_aware_training/torch
    warning_deprecated(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data0]
FAILED ../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data1]
FAILED ../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data2]
FAILED ../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data3]
FAILED ../../../../../../local/data0/moved_data/publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data4]
======================== 5 failed, 5 warnings in 3.33s =========================
