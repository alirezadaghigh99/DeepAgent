output file:
processed_classes-pytorch3dcompose69.json
function:
compose
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_compose_fail', '../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_clone FAILED [  1%]', '../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_multiple_broadcast_compose FAILED [ 72%]', 'FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose_fail', '../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose_fail FAILED [ 67%]', 'FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_compose_x_y_z', 'FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_get_se3', 'FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_multiple_broadcast_compose', '../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose FAILED [ 66%]', 'FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_inverse', 'FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose', '../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_compose_fail FAILED [  3%]', '../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_compose_x_y_z FAILED [ 86%]', 'FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_clone', '../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_get_se3 FAILED [  7%]', '../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_inverse FAILED [ 12%]'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.8.5, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/pytorch3d/venv/bin/python3
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/pytorch3d
collecting ... collected 65 items

../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_clone FAILED [  1%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_compose_fail FAILED [  3%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_dtype_propagation PASSED [  4%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_get_item PASSED [  6%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_get_se3 FAILED [  7%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_init_with_custom_matrix PASSED [  9%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_init_with_custom_matrix_errors PASSED [ 10%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_inverse FAILED [ 12%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_axis_angle FAILED [ 13%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_off FAILED [ 15%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_on FAILED [ 16%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale FAILED [ 18%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale_translate FAILED [ 20%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_stack FAILED [ 21%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_to PASSED [ 23%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_eps FAILED [ 24%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_fail PASSED [ 26%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_translate FAILED [ 27%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_bad_broadcast PASSED [ 29%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_get_item PASSED [ 30%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_inverse PASSED [ 32%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_matrix PASSED [ 33%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_matrix_extra_args PASSED [ 35%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_broadcast PASSED [ 36%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_broadcast_grad PASSED [ 38%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_scalars PASSED [ 40%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_python_scalar PASSED [ 41%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_scalar PASSED [ 43%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_scalar_grads PASSED [ 44%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_vectors PASSED [ 46%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_vector_broadcast PASSED [ 47%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_get_item PASSED [ 49%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_inverse PASSED [ 50%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_matrix PASSED [ 52%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_python_scalar PASSED [ 53%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_torch_scalar PASSED [ 55%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_vector PASSED [ 56%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_mixed_broadcast_grad PASSED [ 58%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_mixed_scalar PASSED [ 60%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_python_scalar PASSED [ 61%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_torch_scalar PASSED [ 63%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_vector_broadcast PASSED [ 64%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose FAILED [ 66%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose_fail FAILED [ 67%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_normals PASSED [ 69%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_points FAILED [ 70%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_multiple_broadcast_compose FAILED [ 72%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_get_item PASSED [ 73%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_invalid_dimensions PASSED [ 75%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_inverse PASSED [ 76%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_single_matrix PASSED [ 78%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_axis_fail PASSED [ 80%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_lower_case_axis PASSED [ 81%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_angle_fail PASSED [ 83%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_angle_radians PASSED [ 84%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_compose_x_y_z FAILED [ 86%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_python_scalar FAILED [ 87%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_scalar FAILED [ 89%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_tensor PASSED [ 90%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_python_scalar FAILED [ 92%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_scalar FAILED [ 93%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_tensor PASSED [ 95%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_python_scalar FAILED [ 96%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_scalar FAILED [ 98%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_tensor PASSED [100%]

=================================== FAILURES ===================================
___________________________ TestTransform.test_clone ___________________________

self = <tests.test_transforms.TestTransform testMethod=test_clone>

    def test_clone(self):
        """
        Check that cloned transformations contain different _matrix objects.
        Also, the clone of a composed translation and rotation has to be
        the same as composition of clones of translation and rotation.
        """
        tr = Translate(torch.FloatTensor([[1.0, 2.0, 3.0]]))
        R = torch.FloatTensor([[0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0]])
        R = Rotate(R)
    
        # check that the _matrix property of clones of
        # both transforms are different
        for t in (R, tr):
            self.assertTrue(t._matrix is not t.clone()._matrix)
    
        # check that the _transforms lists of composition of R, tr contain
        # different objects
        t1 = Transform3d().compose(R, tr)
        for t, t_clone in (t1._transforms, t1.clone()._transforms):
            self.assertTrue(t is not t_clone)
>           self.assertTrue(t._matrix is not t_clone._matrix)
E           AttributeError: 'Tensor' object has no attribute '_matrix'

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:143: AttributeError
_______________________ TestTransform.test_compose_fail ________________________

self = <tests.test_transforms.TestTransform testMethod=test_compose_fail>

    def test_compose_fail(self):
        # Only composing Transform3d objects is possible
        t1 = Scale(0.1, 0.1, 0.1)
        with self.assertRaises(ValueError):
>           t1.compose(torch.randn(100))

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:296: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def compose(self, *others: 'Transform3d') -> 'Transform3d':
        for other in others:
            if not isinstance(other, Transform3d):
>               raise TypeError('All arguments must be instances of Transform3d')
E               TypeError: All arguments must be instances of Transform3d

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:183: TypeError
__________________________ TestTransform.test_get_se3 __________________________

self = <tests.test_transforms.TestTransform testMethod=test_get_se3>

    def test_get_se3(self):
        N = 16
        random_rotations(N)
        tr = Translate(torch.rand((N, 3)))
        R = Rotate(random_rotations(N))
        transform = Transform3d().compose(R, tr)
>       se3_log = transform.get_se3_log()

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:172: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:260: in get_se3_log
    return se3_log_map(self.get_matrix(), eps, cos_bound)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x75d3a777d070>

    def get_matrix(self) -> torch.Tensor:
        """
        Returns a 4×4 matrix corresponding to each transform in the batch.
    
        If the transform was composed from others, the matrix for the composite
        transform will be returned.
        For example, if self.transforms contains transforms t1, t2, and t3, and
        given a set of points x, the following should be true:
    
        .. code-block:: python
    
            y1 = t1.compose(t2, t3).transform(x)
            y2 = t3.transform(t2.transform(t1.transform(x)))
            y1.get_matrix() == y2.get_matrix()
    
        Where necessary, those transforms are broadcast against each other.
    
        Returns:
            A (N, 4, 4) batch of transformation matrices representing
                the stored transforms. See the class documentation for the conventions.
        """
        composed_matrix = self._matrix.clone()
        if len(self._transforms) > 0:
            for other in self._transforms:
>               other_matrix = other.get_matrix()
E               AttributeError: 'Tensor' object has no attribute 'get_matrix'

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:215: AttributeError
__________________________ TestTransform.test_inverse __________________________

self = <tests.test_transforms.TestTransform testMethod=test_inverse>
batch_size = 5

    def test_inverse(self, batch_size=5):
        device = torch.device("cuda:0")
    
        # generate a random chain of transforms
        for _ in range(10):  # 10 different tries
    
            # list of transform matrices
            ts = []
    
            for i in range(10):
                choice = float(torch.rand(1))
                if choice <= 1.0 / 3.0:
                    t_ = Translate(
                        torch.randn(
                            (batch_size, 3), dtype=torch.float32, device=device
                        ),
                        device=device,
                    )
                elif choice <= 2.0 / 3.0:
                    t_ = Rotate(
                        so3_exp_map(
                            torch.randn(
                                (batch_size, 3), dtype=torch.float32, device=device
                            )
                        ),
                        device=device,
                    )
                else:
                    rand_t = torch.randn(
                        (batch_size, 3), dtype=torch.float32, device=device
                    )
                    rand_t = rand_t.sign() * torch.clamp(rand_t.abs(), 0.2)
                    t_ = Scale(rand_t, device=device)
                ts.append(t_._matrix.clone())
    
                if i == 0:
                    t = t_
                else:
                    t = t.compose(t_)
    
            # generate the inverse transformation in several possible ways
>           m1 = t.inverse(invert_composed=True).get_matrix()

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:362: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:289: in inverse
    tinv._matrix = torch.inverse(self.get_matrix())
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x75d45bfdbd90>

    def get_matrix(self) -> torch.Tensor:
        """
        Returns a 4×4 matrix corresponding to each transform in the batch.
    
        If the transform was composed from others, the matrix for the composite
        transform will be returned.
        For example, if self.transforms contains transforms t1, t2, and t3, and
        given a set of points x, the following should be true:
    
        .. code-block:: python
    
            y1 = t1.compose(t2, t3).transform(x)
            y2 = t3.transform(t2.transform(t1.transform(x)))
            y1.get_matrix() == y2.get_matrix()
    
        Where necessary, those transforms are broadcast against each other.
    
        Returns:
            A (N, 4, 4) batch of transformation matrices representing
                the stored transforms. See the class documentation for the conventions.
        """
        composed_matrix = self._matrix.clone()
        if len(self._transforms) > 0:
            for other in self._transforms:
>               other_matrix = other.get_matrix()
E               AttributeError: 'Tensor' object has no attribute 'get_matrix'

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:215: AttributeError
_____________________ TestTransform.test_rotate_axis_angle _____________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_axis_angle>

    def test_rotate_axis_angle(self):
        t = Transform3d().rotate_axis_angle(90.0, axis="Z")
        points = torch.tensor([[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 1.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x75d3a76331c0>
points = tensor([[[0., 0., 0.],
         [0., 1., 0.],
         [0., 1., 1.]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:336: RuntimeError
________________ TestTransform.test_rotate_check_rot_valid_off _________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_check_rot_valid_off>

    @mock.patch.dict(os.environ, {"PYTORCH3D_CHECK_ROTATION_MATRICES": "0"}, clear=True)
    def test_rotate_check_rot_valid_off(self):
        R = so3_exp_map(torch.randn((1, 3)))
        t = Transform3d().rotate(R)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x75d45d1e4880>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:336: RuntimeError
_________________ TestTransform.test_rotate_check_rot_valid_on _________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_check_rot_valid_on>

    @mock.patch.dict(os.environ, {"PYTORCH3D_CHECK_ROTATION_MATRICES": "1"}, clear=True)
    def test_rotate_check_rot_valid_on(self):
        R = so3_exp_map(torch.randn((1, 3)))
        t = Transform3d().rotate(R)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:205: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x75d45c04b520>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:336: RuntimeError
___________________________ TestTransform.test_scale ___________________________

self = <tests.test_transforms.TestTransform testMethod=test_scale>

    def test_scale(self):
        t = Transform3d().scale(2.0).scale(0.5, 0.25, 1.0)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:237: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x75d3a77100d0>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:336: RuntimeError
______________________ TestTransform.test_scale_translate ______________________

self = <tests.test_transforms.TestTransform testMethod=test_scale_translate>

    def test_scale_translate(self):
        t = Transform3d().scale(2, 1, 3).translate(1, 2, 3)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x75d3a6e41d60>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:336: RuntimeError
___________________________ TestTransform.test_stack ___________________________

self = <tests.test_transforms.TestTransform testMethod=test_stack>

    def test_stack(self):
        rotations = random_rotations(3)
        transform3 = Transform3d().rotate(rotations).translate(torch.full((3, 3), 0.3))
        transform1 = Scale(37)
>       transform4 = transform1.stack(transform3)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:475: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:313: in stack
    matrix = torch.cat([t.get_matrix() for t in transforms], dim=0)
/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:313: in <listcomp>
    matrix = torch.cat([t.get_matrix() for t in transforms], dim=0)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x75d3a75c7070>

    def get_matrix(self) -> torch.Tensor:
        """
        Returns a 4×4 matrix corresponding to each transform in the batch.
    
        If the transform was composed from others, the matrix for the composite
        transform will be returned.
        For example, if self.transforms contains transforms t1, t2, and t3, and
        given a set of points x, the following should be true:
    
        .. code-block:: python
    
            y1 = t1.compose(t2, t3).transform(x)
            y2 = t3.transform(t2.transform(t1.transform(x)))
            y1.get_matrix() == y2.get_matrix()
    
        Where necessary, those transforms are broadcast against each other.
    
        Returns:
            A (N, 4, 4) batch of transformation matrices representing
                the stored transforms. See the class documentation for the conventions.
        """
        composed_matrix = self._matrix.clone()
        if len(self._transforms) > 0:
            for other in self._transforms:
>               other_matrix = other.get_matrix()
E               AttributeError: 'Tensor' object has no attribute 'get_matrix'

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:215: AttributeError
___________________ TestTransform.test_transform_points_eps ____________________

self = <tests.test_transforms.TestTransform testMethod=test_transform_points_eps>

    def test_transform_points_eps(self):
        t1 = Transform3d()
        persp_proj = [
            [
                [1.0, 0.0, 0.0, 0.0],
                [0.0, 1.0, 0.0, 0.0],
                [0.0, 0.0, 0.0, 1.0],
                [0.0, 0.0, 1.0, 0.0],
            ]
        ]
        t1._matrix = torch.FloatTensor(persp_proj)
        points = torch.tensor(
            [[0.0, 1.0, 0.0], [0.0, 0.0, 1e-5], [-1.0, 0.0, 1e-5]]
        ).view(
            1, 3, 3
        )  # a set of points with z-coord very close to 0
    
>       proj = t1.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x75d45bfdbbe0>
points = tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  1.0000e-05],
         [-1.0000e+00,  0.0000e+00,  1.0000e-05]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:336: RuntimeError
_________________________ TestTransform.test_translate _________________________

self = <tests.test_transforms.TestTransform testMethod=test_translate>

    def test_translate(self):
        t = Transform3d().translate(1, 2, 3)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x75d3a7620700>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:336: RuntimeError
________________ TestTransformBroadcast.test_broadcast_compose _________________

self = <tests.test_transforms.TestTransformBroadcast testMethod=test_broadcast_compose>

    def test_broadcast_compose(self):
        t1 = Scale(0.1, 0.1, 0.1)
        N = 10
        scale_n = torch.tensor([0.3] * N)
        tN = Scale(scale_n)
        t1N = t1.compose(tN)
        self.assertTrue(t1._matrix.shape == (1, 4, 4))
        self.assertTrue(tN._matrix.shape == (N, 4, 4))
>       self.assertTrue(t1N.get_matrix().shape == (N, 4, 4))

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:942: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x75d45c025490>

    def get_matrix(self) -> torch.Tensor:
        """
        Returns a 4×4 matrix corresponding to each transform in the batch.
    
        If the transform was composed from others, the matrix for the composite
        transform will be returned.
        For example, if self.transforms contains transforms t1, t2, and t3, and
        given a set of points x, the following should be true:
    
        .. code-block:: python
    
            y1 = t1.compose(t2, t3).transform(x)
            y2 = t3.transform(t2.transform(t1.transform(x)))
            y1.get_matrix() == y2.get_matrix()
    
        Where necessary, those transforms are broadcast against each other.
    
        Returns:
            A (N, 4, 4) batch of transformation matrices representing
                the stored transforms. See the class documentation for the conventions.
        """
        composed_matrix = self._matrix.clone()
        if len(self._transforms) > 0:
            for other in self._transforms:
>               other_matrix = other.get_matrix()
E               AttributeError: 'Tensor' object has no attribute 'get_matrix'

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:215: AttributeError
______________ TestTransformBroadcast.test_broadcast_compose_fail ______________

self = <tests.test_transforms.TestTransformBroadcast testMethod=test_broadcast_compose_fail>

    def test_broadcast_compose_fail(self):
        # Cannot compose two transforms which have batch dimensions N and M
        # other than the case where either N or M is 1
        N = 10
        M = 20
        scale_n = torch.tensor([0.3] * N)
        tN = Scale(scale_n)
        x = torch.tensor([0.2] * M)
        y = torch.tensor([0.3] * M)
        z = torch.tensor([0.4] * M)
        tM = Translate(x, y, z)
>       t = tN.compose(tM)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:957: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Scale object at 0x75d3a7599400>
others = (<pytorch3d.transforms.transform3d.Translate object at 0x75d3a7599490>,)
other = <pytorch3d.transforms.transform3d.Translate object at 0x75d3a7599490>
composed_matrix = tensor([[[0.3000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.3000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.3000....0000, 0.3000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.3000, 0.0000],
         [0.0000, 0.0000, 0.0000, 1.0000]]])

    def compose(self, *others: 'Transform3d') -> 'Transform3d':
        for other in others:
            if not isinstance(other, Transform3d):
                raise TypeError('All arguments must be instances of Transform3d')
        composed_matrix = self._matrix.clone()
        for other in others:
>           composed_matrix = composed_matrix @ other._matrix
E           RuntimeError: The size of tensor a (10) must match the size of tensor b (20) at non-singleton dimension 0

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:186: RuntimeError
____________ TestTransformBroadcast.test_broadcast_transform_points ____________

self = <tests.test_transforms.TestTransformBroadcast testMethod=test_broadcast_transform_points>

    def test_broadcast_transform_points(self):
        t1 = Scale(0.1, 0.1, 0.1)
        N = 10
        P = 7
        M = 20
        x = torch.tensor([0.2] * N)
        y = torch.tensor([0.3] * N)
        z = torch.tensor([0.4] * N)
        tN = Translate(x, y, z)
        p1 = t1.transform_points(torch.randn(P, 3))
>       self.assertTrue(p1.shape == (P, 3))
E       AssertionError: False is not true

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:904: AssertionError
____________ TestTransformBroadcast.test_multiple_broadcast_compose ____________

self = <tests.test_transforms.TestTransformBroadcast testMethod=test_multiple_broadcast_compose>

    def test_multiple_broadcast_compose(self):
        t1 = Scale(0.1, 0.1, 0.1)
        t2 = Scale(0.2, 0.2, 0.2)
        N = 10
        scale_n = torch.tensor([0.3] * N)
        tN = Scale(scale_n)
        t1N2 = t1.compose(tN.compose(t2))
>       composed_mat = t1N2.get_matrix()

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:968: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x75d3a75e57f0>

    def get_matrix(self) -> torch.Tensor:
        """
        Returns a 4×4 matrix corresponding to each transform in the batch.
    
        If the transform was composed from others, the matrix for the composite
        transform will be returned.
        For example, if self.transforms contains transforms t1, t2, and t3, and
        given a set of points x, the following should be true:
    
        .. code-block:: python
    
            y1 = t1.compose(t2, t3).transform(x)
            y2 = t3.transform(t2.transform(t1.transform(x)))
            y1.get_matrix() == y2.get_matrix()
    
        Where necessary, those transforms are broadcast against each other.
    
        Returns:
            A (N, 4, 4) batch of transformation matrices representing
                the stored transforms. See the class documentation for the conventions.
        """
        composed_matrix = self._matrix.clone()
        if len(self._transforms) > 0:
            for other in self._transforms:
>               other_matrix = other.get_matrix()
E               AttributeError: 'Tensor' object has no attribute 'get_matrix'

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:215: AttributeError
________________ TestRotateAxisAngle.test_rotate_compose_x_y_z _________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_compose_x_y_z>

    def test_rotate_compose_x_y_z(self):
        angle = torch.tensor(90.0)
        t1 = RotateAxisAngle(angle=angle, axis="X")
        t2 = RotateAxisAngle(angle=angle, axis="Y")
        t3 = RotateAxisAngle(angle=angle, axis="Z")
        t = t1.compose(t2, t3)
        # fmt: off
        matrix1 = torch.tensor(
            [
                [
                    [1.0,  0.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 1.0, 0.0],  # noqa: E241, E201
                    [0.0, -1.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        matrix2 = torch.tensor(
            [
                [
                    [0.0, 0.0, -1.0, 0.0],  # noqa: E241, E201
                    [0.0, 1.0,  0.0, 0.0],  # noqa: E241, E201
                    [1.0, 0.0,  0.0, 0.0],  # noqa: E241, E201
                    [0.0, 0.0,  0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        matrix3 = torch.tensor(
            [
                [
                    [ 0.0, 1.0, 0.0, 0.0],  # noqa: E241, E201
                    [-1.0, 0.0, 0.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 1.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        # order of transforms is t1 -> t2
        matrix = torch.matmul(matrix1, torch.matmul(matrix2, matrix3))
>       composed_matrix = t.get_matrix()

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1306: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x75d3a7525dc0>

    def get_matrix(self) -> torch.Tensor:
        """
        Returns a 4×4 matrix corresponding to each transform in the batch.
    
        If the transform was composed from others, the matrix for the composite
        transform will be returned.
        For example, if self.transforms contains transforms t1, t2, and t3, and
        given a set of points x, the following should be true:
    
        .. code-block:: python
    
            y1 = t1.compose(t2, t3).transform(x)
            y2 = t3.transform(t2.transform(t1.transform(x)))
            y1.get_matrix() == y2.get_matrix()
    
        Where necessary, those transforms are broadcast against each other.
    
        Returns:
            A (N, 4, 4) batch of transformation matrices representing
                the stored transforms. See the class documentation for the conventions.
        """
        composed_matrix = self._matrix.clone()
        if len(self._transforms) > 0:
            for other in self._transforms:
>               other_matrix = other.get_matrix()
E               AttributeError: 'Tensor' object has no attribute 'get_matrix'

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:215: AttributeError
_______________ TestRotateAxisAngle.test_rotate_x_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_x_python_scalar>

    def test_rotate_x_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="X")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [1.0,  0.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 1.0, 0.0],  # noqa: E241, E201
                    [0.0, -1.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([0.0, 1.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1034: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x75d3a75911f0>
points = tensor([[[0., 1., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:336: RuntimeError
________________ TestRotateAxisAngle.test_rotate_x_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_x_torch_scalar>

    def test_rotate_x_torch_scalar(self):
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="X")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [1.0,  0.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 1.0, 0.0],  # noqa: E241, E201
                    [0.0, -1.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([0.0, 1.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1058: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x75d3a6e8a7f0>
points = tensor([[[0., 1., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:336: RuntimeError
_______________ TestRotateAxisAngle.test_rotate_y_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_y_python_scalar>

    def test_rotate_y_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="Y")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [0.0, 0.0, -1.0, 0.0],  # noqa: E241, E201
                    [0.0, 1.0,  0.0, 0.0],  # noqa: E241, E201
                    [1.0, 0.0,  0.0, 0.0],  # noqa: E241, E201
                    [0.0, 0.0,  0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1116: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x75d3a76a81f0>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:336: RuntimeError
________________ TestRotateAxisAngle.test_rotate_y_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_y_torch_scalar>

    def test_rotate_y_torch_scalar(self):
        """
        Test rotation about Y axis. With a right hand coordinate system this
        should result in a vector pointing along the x-axis being rotated to
        point along the negative z axis.
        """
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="Y")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [0.0, 0.0, -1.0, 0.0],  # noqa: E241, E201
                    [0.0, 1.0,  0.0, 0.0],  # noqa: E241, E201
                    [1.0, 0.0,  0.0, 0.0],  # noqa: E241, E201
                    [0.0, 0.0,  0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x75d3a7722bb0>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:336: RuntimeError
_______________ TestRotateAxisAngle.test_rotate_z_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_z_python_scalar>

    def test_rotate_z_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="Z")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [ 0.0, 1.0, 0.0, 0.0],  # noqa: E241, E201
                    [-1.0, 0.0, 0.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 1.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x75d3a7710430>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:336: RuntimeError
________________ TestRotateAxisAngle.test_rotate_z_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_z_torch_scalar>

    def test_rotate_z_torch_scalar(self):
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="Z")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [ 0.0, 1.0, 0.0, 0.0],  # noqa: E241, E201
                    [-1.0, 0.0, 0.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 1.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x75d45c052310>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:336: RuntimeError
=============================== warnings summary ===============================
tests/test_transforms.py::TestTransform::test_dtype_propagation
  /local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:334: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3697.)
    transformed_points = points_homogeneous @ self._matrix.T

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_clone
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_compose_fail
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_get_se3
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_inverse
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_axis_angle
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_off
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_on
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale_translate
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_stack
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_eps
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_translate
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose_fail
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_points
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_multiple_broadcast_compose
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_compose_x_y_z
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_scalar
=================== 23 failed, 42 passed, 1 warning in 1.93s ===================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.8.5, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/pytorch3d/venv/bin/python3
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/pytorch3d
collecting ... collected 65 items

../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_clone PASSED [  1%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_compose_fail PASSED [  3%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_dtype_propagation PASSED [  4%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_get_item PASSED [  6%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_get_se3 PASSED [  7%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_init_with_custom_matrix PASSED [  9%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_init_with_custom_matrix_errors PASSED [ 10%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_inverse PASSED [ 12%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_axis_angle FAILED [ 13%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_off FAILED [ 15%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_on FAILED [ 16%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale FAILED [ 18%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale_translate FAILED [ 20%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_stack FAILED [ 21%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_to PASSED [ 23%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_eps FAILED [ 24%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_fail PASSED [ 26%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_translate FAILED [ 27%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_bad_broadcast PASSED [ 29%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_get_item PASSED [ 30%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_inverse PASSED [ 32%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_matrix PASSED [ 33%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_matrix_extra_args PASSED [ 35%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_broadcast PASSED [ 36%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_broadcast_grad PASSED [ 38%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_scalars PASSED [ 40%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_python_scalar PASSED [ 41%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_scalar PASSED [ 43%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_scalar_grads PASSED [ 44%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_vectors PASSED [ 46%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_vector_broadcast PASSED [ 47%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_get_item PASSED [ 49%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_inverse PASSED [ 50%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_matrix PASSED [ 52%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_python_scalar PASSED [ 53%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_torch_scalar PASSED [ 55%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_vector PASSED [ 56%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_mixed_broadcast_grad PASSED [ 58%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_mixed_scalar PASSED [ 60%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_python_scalar PASSED [ 61%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_torch_scalar PASSED [ 63%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_vector_broadcast PASSED [ 64%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose PASSED [ 66%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose_fail PASSED [ 67%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_normals PASSED [ 69%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_points FAILED [ 70%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_multiple_broadcast_compose PASSED [ 72%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_get_item PASSED [ 73%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_invalid_dimensions PASSED [ 75%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_inverse PASSED [ 76%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_single_matrix PASSED [ 78%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_axis_fail PASSED [ 80%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_lower_case_axis PASSED [ 81%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_angle_fail PASSED [ 83%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_angle_radians PASSED [ 84%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_compose_x_y_z PASSED [ 86%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_python_scalar FAILED [ 87%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_scalar FAILED [ 89%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_tensor PASSED [ 90%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_python_scalar FAILED [ 92%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_scalar FAILED [ 93%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_tensor PASSED [ 95%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_python_scalar FAILED [ 96%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_scalar FAILED [ 98%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_tensor PASSED [100%]

=================================== FAILURES ===================================
_____________________ TestTransform.test_rotate_axis_angle _____________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_axis_angle>

    def test_rotate_axis_angle(self):
        t = Transform3d().rotate_axis_angle(90.0, axis="Z")
        points = torch.tensor([[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 1.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x73da76614c10>
points = tensor([[[0., 0., 0.],
         [0., 1., 0.],
         [0., 1., 1.]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
________________ TestTransform.test_rotate_check_rot_valid_off _________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_check_rot_valid_off>

    @mock.patch.dict(os.environ, {"PYTORCH3D_CHECK_ROTATION_MATRICES": "0"}, clear=True)
    def test_rotate_check_rot_valid_off(self):
        R = so3_exp_map(torch.randn((1, 3)))
        t = Transform3d().rotate(R)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x73db2c069880>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
_________________ TestTransform.test_rotate_check_rot_valid_on _________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_check_rot_valid_on>

    @mock.patch.dict(os.environ, {"PYTORCH3D_CHECK_ROTATION_MATRICES": "1"}, clear=True)
    def test_rotate_check_rot_valid_on(self):
        R = so3_exp_map(torch.randn((1, 3)))
        t = Transform3d().rotate(R)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:205: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x73db2c055700>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
___________________________ TestTransform.test_scale ___________________________

self = <tests.test_transforms.TestTransform testMethod=test_scale>

    def test_scale(self):
        t = Transform3d().scale(2.0).scale(0.5, 0.25, 1.0)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:237: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x73da7659d910>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
______________________ TestTransform.test_scale_translate ______________________

self = <tests.test_transforms.TestTransform testMethod=test_scale_translate>

    def test_scale_translate(self):
        t = Transform3d().scale(2, 1, 3).translate(1, 2, 3)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x73db2ae39310>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
___________________________ TestTransform.test_stack ___________________________

self = <tests.test_transforms.TestTransform testMethod=test_stack>

    def test_stack(self):
        rotations = random_rotations(3)
        transform3 = Transform3d().rotate(rotations).translate(torch.full((3, 3), 0.3))
        transform1 = Scale(37)
        transform4 = transform1.stack(transform3)
        self.assertEqual(len(transform1), 1)
        self.assertEqual(len(transform3), 3)
        self.assertEqual(len(transform4), 4)
        self.assertClose(
            transform4.get_matrix(),
            torch.cat([transform1.get_matrix(), transform3.get_matrix()]),
        )
        points = torch.rand(4, 5, 3)
        new_points_expect = torch.cat(
            [
>               transform1.transform_points(points[:1]),
                transform3.transform_points(points[1:]),
            ]
        )

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Scale object at 0x73db2ae336a0>
points = tensor([[[0.1053, 0.2695, 0.3588],
         [0.1994, 0.5472, 0.0062],
         [0.9516, 0.0753, 0.8860],
         [0.5832, 0.3376, 0.8090],
         [0.5779, 0.9040, 0.5547]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
___________________ TestTransform.test_transform_points_eps ____________________

self = <tests.test_transforms.TestTransform testMethod=test_transform_points_eps>

    def test_transform_points_eps(self):
        t1 = Transform3d()
        persp_proj = [
            [
                [1.0, 0.0, 0.0, 0.0],
                [0.0, 1.0, 0.0, 0.0],
                [0.0, 0.0, 0.0, 1.0],
                [0.0, 0.0, 1.0, 0.0],
            ]
        ]
        t1._matrix = torch.FloatTensor(persp_proj)
        points = torch.tensor(
            [[0.0, 1.0, 0.0], [0.0, 0.0, 1e-5], [-1.0, 0.0, 1e-5]]
        ).view(
            1, 3, 3
        )  # a set of points with z-coord very close to 0
    
>       proj = t1.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x73da7667bfd0>
points = tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  1.0000e-05],
         [-1.0000e+00,  0.0000e+00,  1.0000e-05]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
_________________________ TestTransform.test_translate _________________________

self = <tests.test_transforms.TestTransform testMethod=test_translate>

    def test_translate(self):
        t = Transform3d().translate(1, 2, 3)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x73da75927250>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
____________ TestTransformBroadcast.test_broadcast_transform_points ____________

self = <tests.test_transforms.TestTransformBroadcast testMethod=test_broadcast_transform_points>

    def test_broadcast_transform_points(self):
        t1 = Scale(0.1, 0.1, 0.1)
        N = 10
        P = 7
        M = 20
        x = torch.tensor([0.2] * N)
        y = torch.tensor([0.3] * N)
        z = torch.tensor([0.4] * N)
        tN = Translate(x, y, z)
        p1 = t1.transform_points(torch.randn(P, 3))
>       self.assertTrue(p1.shape == (P, 3))
E       AssertionError: False is not true

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:904: AssertionError
_______________ TestRotateAxisAngle.test_rotate_x_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_x_python_scalar>

    def test_rotate_x_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="X")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [1.0,  0.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 1.0, 0.0],  # noqa: E241, E201
                    [0.0, -1.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([0.0, 1.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1034: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x73db2ae8c700>
points = tensor([[[0., 1., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
________________ TestRotateAxisAngle.test_rotate_x_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_x_torch_scalar>

    def test_rotate_x_torch_scalar(self):
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="X")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [1.0,  0.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 1.0, 0.0],  # noqa: E241, E201
                    [0.0, -1.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([0.0, 1.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1058: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x73db2ae2da00>
points = tensor([[[0., 1., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
_______________ TestRotateAxisAngle.test_rotate_y_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_y_python_scalar>

    def test_rotate_y_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="Y")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [0.0, 0.0, -1.0, 0.0],  # noqa: E241, E201
                    [0.0, 1.0,  0.0, 0.0],  # noqa: E241, E201
                    [1.0, 0.0,  0.0, 0.0],  # noqa: E241, E201
                    [0.0, 0.0,  0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1116: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x73da74fb73d0>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
________________ TestRotateAxisAngle.test_rotate_y_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_y_torch_scalar>

    def test_rotate_y_torch_scalar(self):
        """
        Test rotation about Y axis. With a right hand coordinate system this
        should result in a vector pointing along the x-axis being rotated to
        point along the negative z axis.
        """
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="Y")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [0.0, 0.0, -1.0, 0.0],  # noqa: E241, E201
                    [0.0, 1.0,  0.0, 0.0],  # noqa: E241, E201
                    [1.0, 0.0,  0.0, 0.0],  # noqa: E241, E201
                    [0.0, 0.0,  0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x73da74ef1a30>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
_______________ TestRotateAxisAngle.test_rotate_z_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_z_python_scalar>

    def test_rotate_z_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="Z")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [ 0.0, 1.0, 0.0, 0.0],  # noqa: E241, E201
                    [-1.0, 0.0, 0.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 1.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x73da759b6430>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
________________ TestRotateAxisAngle.test_rotate_z_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_z_torch_scalar>

    def test_rotate_z_torch_scalar(self):
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="Z")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [ 0.0, 1.0, 0.0, 0.0],  # noqa: E241, E201
                    [-1.0, 0.0, 0.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 1.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x73da765bd370>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
=============================== warnings summary ===============================
tests/test_transforms.py::TestTransform::test_dtype_propagation
  /local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:343: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3697.)
    transformed_points = points_homogeneous @ self._matrix.T

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_axis_angle
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_off
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_on
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale_translate
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_stack
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_eps
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_translate
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_points
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_scalar
=================== 15 failed, 50 passed, 1 warning in 1.77s ===================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.8.5, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/pytorch3d/venv/bin/python3
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/pytorch3d
collecting ... collected 65 items

../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_clone PASSED [  1%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_compose_fail PASSED [  3%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_dtype_propagation PASSED [  4%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_get_item PASSED [  6%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_get_se3 PASSED [  7%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_init_with_custom_matrix PASSED [  9%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_init_with_custom_matrix_errors PASSED [ 10%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_inverse PASSED [ 12%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_axis_angle FAILED [ 13%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_off FAILED [ 15%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_on FAILED [ 16%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale FAILED [ 18%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale_translate FAILED [ 20%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_stack FAILED [ 21%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_to PASSED [ 23%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_eps FAILED [ 24%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_fail PASSED [ 26%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_translate FAILED [ 27%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_bad_broadcast PASSED [ 29%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_get_item PASSED [ 30%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_inverse PASSED [ 32%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_matrix PASSED [ 33%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_matrix_extra_args PASSED [ 35%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_broadcast PASSED [ 36%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_broadcast_grad PASSED [ 38%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_scalars PASSED [ 40%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_python_scalar PASSED [ 41%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_scalar PASSED [ 43%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_scalar_grads PASSED [ 44%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_vectors PASSED [ 46%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_vector_broadcast PASSED [ 47%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_get_item PASSED [ 49%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_inverse PASSED [ 50%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_matrix PASSED [ 52%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_python_scalar PASSED [ 53%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_torch_scalar PASSED [ 55%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_vector PASSED [ 56%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_mixed_broadcast_grad PASSED [ 58%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_mixed_scalar PASSED [ 60%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_python_scalar PASSED [ 61%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_torch_scalar PASSED [ 63%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_vector_broadcast PASSED [ 64%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose PASSED [ 66%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose_fail PASSED [ 67%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_normals PASSED [ 69%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_points FAILED [ 70%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_multiple_broadcast_compose PASSED [ 72%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_get_item PASSED [ 73%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_invalid_dimensions PASSED [ 75%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_inverse PASSED [ 76%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_single_matrix PASSED [ 78%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_axis_fail PASSED [ 80%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_lower_case_axis PASSED [ 81%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_angle_fail PASSED [ 83%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_angle_radians PASSED [ 84%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_compose_x_y_z PASSED [ 86%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_python_scalar FAILED [ 87%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_scalar FAILED [ 89%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_tensor PASSED [ 90%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_python_scalar FAILED [ 92%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_scalar FAILED [ 93%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_tensor PASSED [ 95%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_python_scalar FAILED [ 96%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_scalar FAILED [ 98%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_tensor PASSED [100%]

=================================== FAILURES ===================================
_____________________ TestTransform.test_rotate_axis_angle _____________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_axis_angle>

    def test_rotate_axis_angle(self):
        t = Transform3d().rotate_axis_angle(90.0, axis="Z")
        points = torch.tensor([[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 1.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x701e407c7c70>
points = tensor([[[0., 0., 0.],
         [0., 1., 0.],
         [0., 1., 1.]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
________________ TestTransform.test_rotate_check_rot_valid_off _________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_check_rot_valid_off>

    @mock.patch.dict(os.environ, {"PYTORCH3D_CHECK_ROTATION_MATRICES": "0"}, clear=True)
    def test_rotate_check_rot_valid_off(self):
        R = so3_exp_map(torch.randn((1, 3)))
        t = Transform3d().rotate(R)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x701ef621c880>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
_________________ TestTransform.test_rotate_check_rot_valid_on _________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_check_rot_valid_on>

    @mock.patch.dict(os.environ, {"PYTORCH3D_CHECK_ROTATION_MATRICES": "1"}, clear=True)
    def test_rotate_check_rot_valid_on(self):
        R = so3_exp_map(torch.randn((1, 3)))
        t = Transform3d().rotate(R)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:205: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x701ef6208700>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
___________________________ TestTransform.test_scale ___________________________

self = <tests.test_transforms.TestTransform testMethod=test_scale>

    def test_scale(self):
        t = Transform3d().scale(2.0).scale(0.5, 0.25, 1.0)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:237: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x701e40750f70>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
______________________ TestTransform.test_scale_translate ______________________

self = <tests.test_transforms.TestTransform testMethod=test_scale_translate>

    def test_scale_translate(self):
        t = Transform3d().scale(2, 1, 3).translate(1, 2, 3)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x701ef4fe3070>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
___________________________ TestTransform.test_stack ___________________________

self = <tests.test_transforms.TestTransform testMethod=test_stack>

    def test_stack(self):
        rotations = random_rotations(3)
        transform3 = Transform3d().rotate(rotations).translate(torch.full((3, 3), 0.3))
        transform1 = Scale(37)
        transform4 = transform1.stack(transform3)
        self.assertEqual(len(transform1), 1)
        self.assertEqual(len(transform3), 3)
        self.assertEqual(len(transform4), 4)
        self.assertClose(
            transform4.get_matrix(),
            torch.cat([transform1.get_matrix(), transform3.get_matrix()]),
        )
        points = torch.rand(4, 5, 3)
        new_points_expect = torch.cat(
            [
>               transform1.transform_points(points[:1]),
                transform3.transform_points(points[1:]),
            ]
        )

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Scale object at 0x701e3fb36310>
points = tensor([[[0.1053, 0.2695, 0.3588],
         [0.1994, 0.5472, 0.0062],
         [0.9516, 0.0753, 0.8860],
         [0.5832, 0.3376, 0.8090],
         [0.5779, 0.9040, 0.5547]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
___________________ TestTransform.test_transform_points_eps ____________________

self = <tests.test_transforms.TestTransform testMethod=test_transform_points_eps>

    def test_transform_points_eps(self):
        t1 = Transform3d()
        persp_proj = [
            [
                [1.0, 0.0, 0.0, 0.0],
                [0.0, 1.0, 0.0, 0.0],
                [0.0, 0.0, 0.0, 1.0],
                [0.0, 0.0, 1.0, 0.0],
            ]
        ]
        t1._matrix = torch.FloatTensor(persp_proj)
        points = torch.tensor(
            [[0.0, 1.0, 0.0], [0.0, 0.0, 1e-5], [-1.0, 0.0, 1e-5]]
        ).view(
            1, 3, 3
        )  # a set of points with z-coord very close to 0
    
>       proj = t1.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x701e429f98e0>
points = tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  1.0000e-05],
         [-1.0000e+00,  0.0000e+00,  1.0000e-05]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
_________________________ TestTransform.test_translate _________________________

self = <tests.test_transforms.TestTransform testMethod=test_translate>

    def test_translate(self):
        t = Transform3d().translate(1, 2, 3)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x701ef504ae80>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
____________ TestTransformBroadcast.test_broadcast_transform_points ____________

self = <tests.test_transforms.TestTransformBroadcast testMethod=test_broadcast_transform_points>

    def test_broadcast_transform_points(self):
        t1 = Scale(0.1, 0.1, 0.1)
        N = 10
        P = 7
        M = 20
        x = torch.tensor([0.2] * N)
        y = torch.tensor([0.3] * N)
        z = torch.tensor([0.4] * N)
        tN = Translate(x, y, z)
        p1 = t1.transform_points(torch.randn(P, 3))
>       self.assertTrue(p1.shape == (P, 3))
E       AssertionError: False is not true

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:904: AssertionError
_______________ TestRotateAxisAngle.test_rotate_x_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_x_python_scalar>

    def test_rotate_x_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="X")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [1.0,  0.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 1.0, 0.0],  # noqa: E241, E201
                    [0.0, -1.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([0.0, 1.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1034: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x701ef50526a0>
points = tensor([[[0., 1., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
________________ TestRotateAxisAngle.test_rotate_x_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_x_torch_scalar>

    def test_rotate_x_torch_scalar(self):
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="X")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [1.0,  0.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 1.0, 0.0],  # noqa: E241, E201
                    [0.0, -1.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([0.0, 1.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1058: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x701e406e3d60>
points = tensor([[[0., 1., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
_______________ TestRotateAxisAngle.test_rotate_y_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_y_python_scalar>

    def test_rotate_y_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="Y")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [0.0, 0.0, -1.0, 0.0],  # noqa: E241, E201
                    [0.0, 1.0,  0.0, 0.0],  # noqa: E241, E201
                    [1.0, 0.0,  0.0, 0.0],  # noqa: E241, E201
                    [0.0, 0.0,  0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1116: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x701ef50362b0>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
________________ TestRotateAxisAngle.test_rotate_y_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_y_torch_scalar>

    def test_rotate_y_torch_scalar(self):
        """
        Test rotation about Y axis. With a right hand coordinate system this
        should result in a vector pointing along the x-axis being rotated to
        point along the negative z axis.
        """
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="Y")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [0.0, 0.0, -1.0, 0.0],  # noqa: E241, E201
                    [0.0, 1.0,  0.0, 0.0],  # noqa: E241, E201
                    [1.0, 0.0,  0.0, 0.0],  # noqa: E241, E201
                    [0.0, 0.0,  0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x701ef4fe3070>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
_______________ TestRotateAxisAngle.test_rotate_z_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_z_python_scalar>

    def test_rotate_z_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="Z")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [ 0.0, 1.0, 0.0, 0.0],  # noqa: E241, E201
                    [-1.0, 0.0, 0.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 1.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x701e3f16d580>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
________________ TestRotateAxisAngle.test_rotate_z_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_z_torch_scalar>

    def test_rotate_z_torch_scalar(self):
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="Z")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [ 0.0, 1.0, 0.0, 0.0],  # noqa: E241, E201
                    [-1.0, 0.0, 0.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 1.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x701e3f0b16a0>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
=============================== warnings summary ===============================
tests/test_transforms.py::TestTransform::test_dtype_propagation
  /local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:343: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3697.)
    transformed_points = points_homogeneous @ self._matrix.T

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_axis_angle
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_off
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_on
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale_translate
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_stack
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_eps
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_translate
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_points
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_scalar
=================== 15 failed, 50 passed, 1 warning in 2.08s ===================
