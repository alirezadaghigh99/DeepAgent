output file:
processed_pytorch3dcorresponding_points_alignment304.json
function:
corresponding_points_alignment
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh', '../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh FAILED', 'FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestCorrespondingPointsAlignment::test_corresponding_points_alignment', '../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestCorrespondingPointsAlignment::test_corresponding_points_alignment FAILED'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.8.5, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/pytorch3d/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/pytorch3d
collecting ... collected 4 items

../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh FAILED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs FAILED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_init_transformation PASSED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestCorrespondingPointsAlignment::test_corresponding_points_alignment FAILED

=================================== FAILURES ===================================
______________________ TestICP.test_compare_with_trimesh _______________________

self = <tests.test_points_alignment.TestICP testMethod=test_compare_with_trimesh>

    def test_compare_with_trimesh(self):
        """
        Compares the outputs of `iterative_closest_point` with the results
        of `trimesh.registration.icp` from the `trimesh` python package:
        https://github.com/mikedh/trimesh
    
        We have run `trimesh.registration.icp` on several random problems
        with different point cloud sizes. The results of trimesh, together with
        the randomly generated input clouds are loaded in the constructor of
        this class and this test compares the loaded results to our runs.
        """
        for n_points_X in (10, 20, 50, 100):
            for n_points_Y in (10, 20, 50, 100):
>               self._compare_with_trimesh(n_points_X=n_points_X, n_points_Y=n_points_Y)

/local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:295: in _compare_with_trimesh
    self.assertClose(R_ours, R_trimesh, atol=atol)
/local/data0/moved_data/pytorch3d/tests/common_testing.py:209: in assertClose
    self.fail(err)
E   AssertionError: Not close. Max diff 0.20238623023033142. Max relative diff 495.3662109375 Shape (4, 3, 3). At (0, 2, 0).
______________________ TestICP.test_heterogeneous_inputs _______________________

self = <tests.test_points_alignment.TestICP testMethod=test_heterogeneous_inputs>
batch_size = 7

    def test_heterogeneous_inputs(self, batch_size=7):
        """
        Tests whether we get the same result when running ICP on
        a set of randomly-sized Pointclouds and on their padded versions.
        """
    
        torch.manual_seed(4)
        device = torch.device("cuda:0")
    
        for estimate_scale in (True, False):
            for max_n_points in (10, 30, 100):
                # initialize ground truth point clouds
                X_pcl, Y_pcl = [
                    TestCorrespondingPointsAlignment.init_point_cloud(
                        batch_size=batch_size,
                        n_points=max_n_points,
                        dim=3,
                        device=device,
                        use_pointclouds=True,
                        random_pcl_size=True,
                    )
                    for _ in range(2)
                ]
    
                # get the padded versions and their num of points
                X_padded = X_pcl.points_padded()
                Y_padded = Y_pcl.points_padded()
                n_points_X = X_pcl.num_points_per_cloud()
                n_points_Y = Y_pcl.num_points_per_cloud()
    
                # run icp with Pointlouds inputs
                (
                    _,
                    _,
                    Xt_pcl,
                    (R_pcl, T_pcl, s_pcl),
                    _,
>               ) = points_alignment.iterative_closest_point(
                    X_pcl,
                    Y_pcl,
                    estimate_scale=estimate_scale,
                    allow_reflection=False,
                    verbose=False,
                    max_iterations=100,
                )

/local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/pytorch3d/pytorch3d/ops/points_alignment.py:103: in iterative_closest_point
    R, T, s = corresponding_points_alignment(Xt_init, Xt_nn_points, weights=mask_X, estimate_scale=estimate_scale, allow_reflection=allow_reflection)
/local/data0/moved_data/pytorch3d/pytorch3d/ops/points_alignment.py:131: in corresponding_points_alignment
    return corresponding_points_alignment(X, Y, weights, estimate_scale, allow_reflection, eps)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = tensor([[[-2.9381e-01,  7.8191e-01, -1.4731e+00],
         [ 1.0391e+00,  5.1852e-01,  1.8115e+00],
         [ 7.7186e...
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')
Y = tensor([[[-0.4988, -0.0691, -1.7824],
         [-0.6657, -0.2052,  0.6723],
         [ 1.2416,  0.0864, -0.7847],
    ...7235,  0.7561, -0.8980],
         [-1.7235,  0.7561, -0.8980],
         [-1.7235,  0.7561, -0.8980]]], device='cuda:0')
weights = tensor([[0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111],
        [0.2000, 0.2000, 0.2000, 0.2...00, 0.0000],
        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],
       device='cuda:0')
estimate_scale = True, allow_reflection = False, eps = 1e-09

    def corresponding_points_alignment(X, Y, weights=None, estimate_scale=True, allow_reflection=False, eps=1e-08):
        """
        Finds a similarity transformation (rotation R, translation T, and optionally scale s)
        between two given sets of corresponding d-dimensional points X and Y.
    
        Args:
            X: Batch of d-dimensional points of shape (minibatch, num_point, d).
            Y: Batch of d-dimensional points of shape (minibatch, num_point, d).
            weights: Batch of non-negative weights of shape (minibatch, num_point).
                     Passing None means uniform weights.
            estimate_scale: If True, also estimates a scaling component s of the transformation.
            allow_reflection: If True, allows the algorithm to return R which is orthonormal but has determinant==-1.
            eps: A scalar for clamping to avoid dividing by zero.
    
        Returns:
            SimilarityTransform: A named tuple containing R, T, and s.
        """
        if X.shape != Y.shape:
            raise ValueError('Point sets X and Y must have the same shape.')
        minibatch, num_points, d = X.shape
        if weights is None:
            weights = torch.ones((minibatch, num_points), device=X.device, dtype=X.dtype)
        elif X.shape[:2] != weights.shape:
            raise ValueError('weights should have the same first two dimensions as X.')
        weights_sum = weights.sum(dim=1, keepdim=True)
        weights = weights / (weights_sum + eps)
        X_centroid = (weights.unsqueeze(-1) * X).sum(dim=1)
        Y_centroid = (weights.unsqueeze(-1) * Y).sum(dim=1)
        X_centered = X - X_centroid.unsqueeze(1)
        Y_centered = Y - Y_centroid.unsqueeze(1)
        cov_matrix = torch.einsum('bni,bnj->bij', weights.unsqueeze(-1) * X_centered, Y_centered)
        U, S, Vt = torch.linalg.svd(cov_matrix)
        V = Vt.transpose(-2, -1)
        det = torch.det(U @ V.transpose(-2, -1))
        if not allow_reflection:
            V[:, :, -1] *= torch.sign(det).unsqueeze(-1)
        R = U @ V.transpose(-2, -1)
        if estimate_scale:
            var_X = torch.einsum('bni,bni->b', weights.unsqueeze(-1) * X_centered, X_centered)
>           scale = (S * torch.sign(det)).sum(dim=1) / (var_X + eps)
E           RuntimeError: The size of tensor a (3) must match the size of tensor b (7) at non-singleton dimension 1

/local/data0/moved_data/pytorch3d/pytorch3d/ops/temp.py:51: RuntimeError
_____ TestCorrespondingPointsAlignment.test_corresponding_points_alignment _____

self = <tests.test_points_alignment.TestCorrespondingPointsAlignment testMethod=test_corresponding_points_alignment>
batch_size = 10

    def test_corresponding_points_alignment(self, batch_size=10):
        """
        Tests whether we can estimate a rigid/similarity motion between
        a randomly initialized point cloud and its randomly transformed version.
    
        The tests are done for all possible combinations
        of the following boolean flags:
            - estimate_scale ... Estimate also a scaling component of
                                 the transformation.
            - reflect ... The ground truth orthonormal part of the generated
                         transformation is a reflection (det==-1).
            - allow_reflection ... If True, the orthonormal matrix of the
                                  estimated transformation is allowed to be
                                  a reflection (det==-1).
            - use_pointclouds ... If True, passes the Pointclouds objects
                                  to corresponding_points_alignment.
        """
        # run this for several different point cloud sizes
        for n_points in (100, 3, 2, 1):
            # run this for several different dimensionalities
            for dim in range(2, 10):
                # switches whether we should use the Pointclouds inputs
                use_point_clouds_cases = (
                    (True, False) if dim == 3 and n_points > 3 else (False,)
                )
                for random_weights in (False, True):
                    for use_pointclouds in use_point_clouds_cases:
                        for estimate_scale in (False, True):
                            for reflect in (False, True):
                                for allow_reflection in (False, True):
>                                   self._test_single_corresponding_points_alignment(
                                        batch_size=10,
                                        n_points=n_points,
                                        dim=dim,
                                        use_pointclouds=use_pointclouds,
                                        estimate_scale=estimate_scale,
                                        reflect=reflect,
                                        allow_reflection=allow_reflection,
                                        random_weights=random_weights,
                                    )

/local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:519: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:664: in _test_single_corresponding_points_alignment
    self._assert_all_close(T_est, T, msg, w[:, None])
/local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:689: in _assert_all_close
    self.assertClose(a_ * weights, b_ * weights, atol=atol, msg=err_message)
/local/data0/moved_data/pytorch3d/tests/common_testing.py:208: in assertClose
    self.fail(f"{msg} {err}")
E   AssertionError: Corresponding_points_alignment assertion failure for n_points=100, dim=2, use_pointclouds=False, estimate_scale=False, reflect=False, allow_reflection=False,random_weights=False. Not close. Max diff 0.32610246539115906. Max relative diff 2.8734474182128906 Shape (10, 2). At (9, 0).
=============================== warnings summary ===============================
tests/test_points_alignment.py::TestICP::test_compare_with_trimesh
tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
tests/test_points_alignment.py::TestICP::test_init_transformation
  /local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
    self.trimesh_results = torch.load(trimesh_results_path)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestCorrespondingPointsAlignment::test_corresponding_points_alignment
=================== 3 failed, 1 passed, 3 warnings in 1.70s ====================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.8.5, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/pytorch3d/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/pytorch3d
collecting ... collected 4 items

../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh PASSED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs FAILED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_init_transformation PASSED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestCorrespondingPointsAlignment::test_corresponding_points_alignment PASSED

=================================== FAILURES ===================================
______________________ TestICP.test_heterogeneous_inputs _______________________

self = <tests.test_points_alignment.TestICP testMethod=test_heterogeneous_inputs>
batch_size = 7

    def test_heterogeneous_inputs(self, batch_size=7):
        """
        Tests whether we get the same result when running ICP on
        a set of randomly-sized Pointclouds and on their padded versions.
        """
    
        torch.manual_seed(4)
        device = torch.device("cuda:0")
    
        for estimate_scale in (True, False):
            for max_n_points in (10, 30, 100):
                # initialize ground truth point clouds
                X_pcl, Y_pcl = [
                    TestCorrespondingPointsAlignment.init_point_cloud(
                        batch_size=batch_size,
                        n_points=max_n_points,
                        dim=3,
                        device=device,
                        use_pointclouds=True,
                        random_pcl_size=True,
                    )
                    for _ in range(2)
                ]
    
                # get the padded versions and their num of points
                X_padded = X_pcl.points_padded()
                Y_padded = Y_pcl.points_padded()
                n_points_X = X_pcl.num_points_per_cloud()
                n_points_Y = Y_pcl.num_points_per_cloud()
    
                # run icp with Pointlouds inputs
                (
                    _,
                    _,
                    Xt_pcl,
                    (R_pcl, T_pcl, s_pcl),
                    _,
                ) = points_alignment.iterative_closest_point(
                    X_pcl,
                    Y_pcl,
                    estimate_scale=estimate_scale,
                    allow_reflection=False,
                    verbose=False,
                    max_iterations=100,
                )
                Xt_pcl = Xt_pcl.points_padded()
    
                # run icp with tensor inputs on each element
                # of the batch separately
                icp_results = [
                    points_alignment.iterative_closest_point(
                        X_[None, :n_X, :],
                        Y_[None, :n_Y, :],
                        estimate_scale=estimate_scale,
                        allow_reflection=False,
                        verbose=False,
                        max_iterations=100,
                    )
                    for X_, Y_, n_X, n_Y in zip(
                        X_padded, Y_padded, n_points_X, n_points_Y
                    )
                ]
    
                # parse out the transformation results
                R, T, s = [
                    torch.cat([x.RTs[i] for x in icp_results], dim=0) for i in range(3)
                ]
    
                # check that both sets of transforms are the same
                atol = 1e-5
>               self.assertClose(R_pcl, R, atol=atol)

/local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:233: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/pytorch3d/tests/common_testing.py:209: in assertClose
    self.fail(err)
E   AssertionError: Not close. Max diff 1.4095808267593384. Max relative diff 9.08298397064209 Shape (7, 3, 3). At (4, 0, 0).
=============================== warnings summary ===============================
tests/test_points_alignment.py::TestICP::test_compare_with_trimesh
tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
tests/test_points_alignment.py::TestICP::test_init_transformation
  /local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
    self.trimesh_results = torch.load(trimesh_results_path)

tests/test_points_alignment.py::TestCorrespondingPointsAlignment::test_corresponding_points_alignment
  /local/data0/moved_data/pytorch3d/pytorch3d/ops/points_alignment.py:324: UserWarning: The size of one of the point clouds is <= dim+1. corresponding_points_alignment cannot return a unique rotation.
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
=================== 1 failed, 3 passed, 4 warnings in 2.95s ====================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.8.5, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/pytorch3d/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/pytorch3d
collecting ... collected 4 items

../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh PASSED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs FAILED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_init_transformation PASSED
../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestCorrespondingPointsAlignment::test_corresponding_points_alignment PASSED

=================================== FAILURES ===================================
______________________ TestICP.test_heterogeneous_inputs _______________________

self = <tests.test_points_alignment.TestICP testMethod=test_heterogeneous_inputs>
batch_size = 7

    def test_heterogeneous_inputs(self, batch_size=7):
        """
        Tests whether we get the same result when running ICP on
        a set of randomly-sized Pointclouds and on their padded versions.
        """
    
        torch.manual_seed(4)
        device = torch.device("cuda:0")
    
        for estimate_scale in (True, False):
            for max_n_points in (10, 30, 100):
                # initialize ground truth point clouds
                X_pcl, Y_pcl = [
                    TestCorrespondingPointsAlignment.init_point_cloud(
                        batch_size=batch_size,
                        n_points=max_n_points,
                        dim=3,
                        device=device,
                        use_pointclouds=True,
                        random_pcl_size=True,
                    )
                    for _ in range(2)
                ]
    
                # get the padded versions and their num of points
                X_padded = X_pcl.points_padded()
                Y_padded = Y_pcl.points_padded()
                n_points_X = X_pcl.num_points_per_cloud()
                n_points_Y = Y_pcl.num_points_per_cloud()
    
                # run icp with Pointlouds inputs
                (
                    _,
                    _,
                    Xt_pcl,
                    (R_pcl, T_pcl, s_pcl),
                    _,
                ) = points_alignment.iterative_closest_point(
                    X_pcl,
                    Y_pcl,
                    estimate_scale=estimate_scale,
                    allow_reflection=False,
                    verbose=False,
                    max_iterations=100,
                )
                Xt_pcl = Xt_pcl.points_padded()
    
                # run icp with tensor inputs on each element
                # of the batch separately
                icp_results = [
                    points_alignment.iterative_closest_point(
                        X_[None, :n_X, :],
                        Y_[None, :n_Y, :],
                        estimate_scale=estimate_scale,
                        allow_reflection=False,
                        verbose=False,
                        max_iterations=100,
                    )
                    for X_, Y_, n_X, n_Y in zip(
                        X_padded, Y_padded, n_points_X, n_points_Y
                    )
                ]
    
                # parse out the transformation results
                R, T, s = [
                    torch.cat([x.RTs[i] for x in icp_results], dim=0) for i in range(3)
                ]
    
                # check that both sets of transforms are the same
                atol = 1e-5
>               self.assertClose(R_pcl, R, atol=atol)

/local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:233: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/pytorch3d/tests/common_testing.py:209: in assertClose
    self.fail(err)
E   AssertionError: Not close. Max diff 1.4095808267593384. Max relative diff 9.08298397064209 Shape (7, 3, 3). At (4, 0, 0).
=============================== warnings summary ===============================
tests/test_points_alignment.py::TestICP::test_compare_with_trimesh
tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
tests/test_points_alignment.py::TestICP::test_init_transformation
  /local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
    self.trimesh_results = torch.load(trimesh_results_path)

tests/test_points_alignment.py::TestCorrespondingPointsAlignment::test_corresponding_points_alignment
  /local/data0/moved_data/pytorch3d/pytorch3d/ops/points_alignment.py:324: UserWarning: The size of one of the point clouds is <= dim+1. corresponding_points_alignment cannot return a unique rotation.
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
=================== 1 failed, 3 passed, 4 warnings in 2.99s ====================
