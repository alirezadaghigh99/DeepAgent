output file:
processed_Laplacefit15.json
function:
fit
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification]'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/Laplace/Laplace/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/Laplace/Laplace
configfile: pyproject.toml
plugins: mock-3.14.0, cov-6.0.0
collecting ... collected 212 items

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED

=================================== FAILURES ===================================
___________ test_laplace_init_prior_mean_and_scatter[FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3d17b90>

    @pytest.mark.parametrize("laplace", flavors)
    def test_laplace_init_prior_mean_and_scatter(laplace, model, class_loader):
        lap_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=1.0,
        )
        assert torch.allclose(lap_scalar_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1),
        )
        assert torch.allclose(lap_tensor_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1)[0],
        )
        assert torch.allclose(lap_tensor_scalar_mean.prior_mean, torch.tensor(1.0))
        lap_tensor_full_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(20 * 2 + 2),
        )
        assert torch.allclose(lap_tensor_full_mean.prior_mean, torch.ones(20 * 2 + 2))
    
        lap_scalar_mean.fit(class_loader)
        lap_tensor_mean.fit(class_loader)
        lap_tensor_scalar_mean.fit(class_loader)
        lap_tensor_full_mean.fit(class_loader)
        expected = lap_scalar_mean.scatter
        assert expected.ndim == 0
        assert torch.allclose(lap_tensor_mean.scatter, expected)
        assert lap_tensor_mean.scatter.shape == expected.shape
        assert torch.allclose(lap_tensor_scalar_mean.scatter, expected)
        assert lap_tensor_scalar_mean.scatter.shape == expected.shape
>       assert torch.allclose(lap_tensor_full_mean.scatter, expected)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3b87cd0>

    @property
    def scatter(self) -> torch.Tensor:
        """Computes the _scatter_, a term of the log marginal likelihood that
        corresponds to L-2 regularization:
        `scatter` = \\((\\theta_{MAP} - \\mu_0)^{T} P_0 (\\theta_{MAP} - \\mu_0) \\).
    
        Returns
        -------
        scatter: torch.Tensor
        """
>       delta = self.mean - self.prior_mean
E       RuntimeError: The size of tensor a (122) must match the size of tensor b (42) at non-singleton dimension 0

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:943: RuntimeError
___________ test_laplace_init_prior_mean_and_scatter[KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3bc5710>

    @pytest.mark.parametrize("laplace", flavors)
    def test_laplace_init_prior_mean_and_scatter(laplace, model, class_loader):
        lap_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=1.0,
        )
        assert torch.allclose(lap_scalar_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1),
        )
        assert torch.allclose(lap_tensor_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1)[0],
        )
        assert torch.allclose(lap_tensor_scalar_mean.prior_mean, torch.tensor(1.0))
        lap_tensor_full_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(20 * 2 + 2),
        )
        assert torch.allclose(lap_tensor_full_mean.prior_mean, torch.ones(20 * 2 + 2))
    
        lap_scalar_mean.fit(class_loader)
        lap_tensor_mean.fit(class_loader)
        lap_tensor_scalar_mean.fit(class_loader)
        lap_tensor_full_mean.fit(class_loader)
        expected = lap_scalar_mean.scatter
        assert expected.ndim == 0
        assert torch.allclose(lap_tensor_mean.scatter, expected)
        assert lap_tensor_mean.scatter.shape == expected.shape
        assert torch.allclose(lap_tensor_scalar_mean.scatter, expected)
        assert lap_tensor_scalar_mean.scatter.shape == expected.shape
>       assert torch.allclose(lap_tensor_full_mean.scatter, expected)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.KronLLLaplace object at 0x72f6c3bc7010>

    @property
    def scatter(self) -> torch.Tensor:
        """Computes the _scatter_, a term of the log marginal likelihood that
        corresponds to L-2 regularization:
        `scatter` = \\((\\theta_{MAP} - \\mu_0)^{T} P_0 (\\theta_{MAP} - \\mu_0) \\).
    
        Returns
        -------
        scatter: torch.Tensor
        """
>       delta = self.mean - self.prior_mean
E       RuntimeError: The size of tensor a (122) must match the size of tensor b (42) at non-singleton dimension 0

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:943: RuntimeError
___________ test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3bc5b90>

    @pytest.mark.parametrize("laplace", flavors)
    def test_laplace_init_prior_mean_and_scatter(laplace, model, class_loader):
        lap_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=1.0,
        )
        assert torch.allclose(lap_scalar_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1),
        )
        assert torch.allclose(lap_tensor_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1)[0],
        )
        assert torch.allclose(lap_tensor_scalar_mean.prior_mean, torch.tensor(1.0))
        lap_tensor_full_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(20 * 2 + 2),
        )
        assert torch.allclose(lap_tensor_full_mean.prior_mean, torch.ones(20 * 2 + 2))
    
        lap_scalar_mean.fit(class_loader)
        lap_tensor_mean.fit(class_loader)
        lap_tensor_scalar_mean.fit(class_loader)
        lap_tensor_full_mean.fit(class_loader)
        expected = lap_scalar_mean.scatter
        assert expected.ndim == 0
        assert torch.allclose(lap_tensor_mean.scatter, expected)
        assert lap_tensor_mean.scatter.shape == expected.shape
        assert torch.allclose(lap_tensor_scalar_mean.scatter, expected)
        assert lap_tensor_scalar_mean.scatter.shape == expected.shape
>       assert torch.allclose(lap_tensor_full_mean.scatter, expected)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3b86790>

    @property
    def scatter(self) -> torch.Tensor:
        """Computes the _scatter_, a term of the log marginal likelihood that
        corresponds to L-2 regularization:
        `scatter` = \\((\\theta_{MAP} - \\mu_0)^{T} P_0 (\\theta_{MAP} - \\mu_0) \\).
    
        Returns
        -------
        scatter: torch.Tensor
        """
>       delta = self.mean - self.prior_mean
E       RuntimeError: The size of tensor a (122) must match the size of tensor b (42) at non-singleton dimension 0

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:943: RuntimeError
__ test_laplace_functionality[pick_first-False-FullLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf123810>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf122510>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf120ed0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf122310>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6bf120410>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____ test_laplace_functionality[pick_first-False-FullLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3dfaad0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3dfb290>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3dfbb10>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3dfb790>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3df8e90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__ test_laplace_functionality[pick_first-False-KronLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2718810>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2718910>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2718410>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2718a50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____ test_laplace_functionality[pick_first-False-KronLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c0a153d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c0a15550>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c0a15250>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c0a14d90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__ test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3dfa850>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3dfbb50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3dfad90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3df9190>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c279c150>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____ test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b69790>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b6b4d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b6bcd0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b69ed0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3b6a510>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___ test_laplace_functionality[pick_first-True-FullLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b068d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b065d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b04310>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b044d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3b04850>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[pick_first-True-FullLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3dfaf50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3dfafd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f7e57dcf90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f7e4acac50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f7e4acbd90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___ test_laplace_functionality[pick_first-True-KronLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf1fb3d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf1f9750>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf1fa850>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf1fae90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[pick_first-True-KronLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27bc0d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27bc490>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27bfd50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27bd910>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___ test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3dfb550>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3df92d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3bb80d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3bb8290>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3bb9a50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c17890>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c14dd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c16950>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b27e90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3b27590>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___ test_laplace_functionality[pick_last-False-FullLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3bade50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3baf690>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3bafe10>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3bae7d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3bae350>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[pick_last-False-FullLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b9f4d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b9c110>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b9f810>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b9d590>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3b9c850>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___ test_laplace_functionality[pick_last-False-KronLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c03c10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f7e4adc650>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f7e4adc350>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f7e63927d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[pick_last-False-KronLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b09710>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b09a50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b09950>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b096d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___ test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18c090>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18cf10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18d0d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18e490>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6bf18c710>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b84910>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b87110>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b84f50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b85310>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3b86910>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___ test_laplace_functionality[pick_last-True-FullLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf121410>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf1226d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf123c90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf1204d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6bf120550>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[pick_last-True-FullLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf165850>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf165dd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf166690>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf1661d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6bf165ed0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___ test_laplace_functionality[pick_last-True-KronLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b85850>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b87a10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f7e4acac90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f7e4acb350>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[pick_last-True-KronLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2776650>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2776490>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2774090>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2774990>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___ test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c279f510>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c279efd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c279f010>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c279cc10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c279d390>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c279f790>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c279f5d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c279db50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c279e1d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c279cf10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____ test_laplace_functionality[average-False-FullLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f7e4adc350>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b50810>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b51910>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b528d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3b53e10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______ test_laplace_functionality[average-False-FullLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27756d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27757d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2774dd0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2776790>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c2774290>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____ test_laplace_functionality[average-False-KronLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b9ddd0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b9f510>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b9fcd0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b9c710>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______ test_laplace_functionality[average-False-KronLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6ef4fb990>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f7e4adc8d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c28090>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f7e4acb090>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____ test_laplace_functionality[average-False-DiagLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27ac050>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27af450>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27ac090>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27ae790>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c27af710>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______ test_laplace_functionality[average-False-DiagLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c0a16ed0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c0a15ad0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c0a15490>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c0a15e50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c0a16c50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____ test_laplace_functionality[average-True-FullLLLaplace-classification] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18d050>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18da50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18d150>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18c710>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6bf18d410>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______ test_laplace_functionality[average-True-FullLLLaplace-regression] _______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b84e10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b9d750>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b9c090>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b9ef10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3b9f4d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____ test_laplace_functionality[average-True-KronLLLaplace-classification] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b246d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b24210>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b24450>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b24190>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______ test_laplace_functionality[average-True-KronLLLaplace-regression] _______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27ac710>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27ae610>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27ac750>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27ae2d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____ test_laplace_functionality[average-True-DiagLLLaplace-classification] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18e190>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18e3d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18cc50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18c150>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6bf18d650>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______ test_laplace_functionality[average-True-DiagLLLaplace-regression] _______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2776ad0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2777950>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2777050>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27749d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c27756d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[None-False-FullLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27ad150>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27ae150>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27ad090>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27aeb50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c27afa50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_______ test_laplace_functionality[None-False-FullLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27acbd0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27af6d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27ac110>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27afad0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c27af010>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[None-False-KronLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c965d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c958d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c96510>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c96350>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_______ test_laplace_functionality[None-False-KronLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27b7650>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27b4090>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27b5150>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27b4ad0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[None-False-DiagLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c38ad0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c38cd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c38f10>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18c6d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6bf18c850>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_______ test_laplace_functionality[None-False-DiagLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf14dc50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf14f190>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf14d8d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf14ce50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6bf14d310>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______ test_laplace_functionality[None-True-FullLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3bf5c10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3bf4050>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3bf7990>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3bf6790>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3bf67d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_laplace_functionality[None-True-FullLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2702550>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2701310>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2700ad0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2703610>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c2700f90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______ test_laplace_functionality[None-True-KronLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c97610>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c95490>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18c290>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18d890>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_laplace_functionality[None-True-KronLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27f2b90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27f2410>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27f0650>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27f0990>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______ test_laplace_functionality[None-True-DiagLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b08850>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b0b690>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b0a810>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b0a190>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3b09f10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_laplace_functionality[None-True-DiagLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18c110>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18cf10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf18d650>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c0e210>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3c0f450>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________________ test_regression_predictive[FullLLLaplace] ___________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b04b10>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:474: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3b05e10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________________ test_regression_predictive[KronLLLaplace] ___________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3bae350>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:474: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________________ test_regression_predictive[DiagLLLaplace] ___________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2707b50>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:474: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3bac550>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________________ test_classification_predictive[FullLLLaplace] _________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c0d810>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:498: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3c0d910>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________________ test_classification_predictive[KronLLLaplace] _________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3bdaf10>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:498: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________________ test_classification_predictive[DiagLLLaplace] _________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2781cd0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:498: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c2783150>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_regression_predictive_samples[FullLLLaplace] _______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c0fbd0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive_samples(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3bac550>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_regression_predictive_samples[KronLLLaplace] _______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b25b90>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive_samples(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_regression_predictive_samples[DiagLLLaplace] _______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b9ca90>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive_samples(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3b09a10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_classification_predictive_samples[FullLLLaplace] _____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2775750>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive_samples(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c2776950>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_classification_predictive_samples[KronLLLaplace] _____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b27150>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive_samples(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_classification_predictive_samples[DiagLLLaplace] _____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c279c4d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive_samples(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c279ec50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________________ test_functional_variance_fast[FullLLLaplace] _________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b09b50>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, DiagLLLaplace, KronLLLaplace])
    def test_functional_variance_fast(laplace, model, reg_loader):
        if laplace == KronLLLaplace:
            # TODO still!
            return
    
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:588: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3b0a890>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________________ test_functional_variance_fast[DiagLLLaplace] _________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b25890>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, DiagLLLaplace, KronLLLaplace])
    def test_functional_variance_fast(laplace, model, reg_loader):
        if laplace == KronLLLaplace:
            # TODO still!
            return
    
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:588: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3b26e10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_______________________ test_backprop_glm[FullLLLaplace] _______________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf14e350>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:614: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6bf14f890>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_______________________ test_backprop_glm[KronLLLaplace] _______________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27bcb10>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:614: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_______________________ test_backprop_glm[DiagLLLaplace] _______________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3b081d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:614: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3b0b210>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________________ test_backprop_glm_joint[FullLLLaplace] ____________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27bde50>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_joint(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c27be410>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________________ test_backprop_glm_joint[KronLLLaplace] ____________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c48a10>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_joint(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________________ test_backprop_glm_joint[DiagLLLaplace] ____________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3bc6090>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_joint(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6bf14ca10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________________ test_backprop_glm_mc[FullLLLaplace] ______________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c438d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_mc(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:652: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3b0bad0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________________ test_backprop_glm_mc[KronLLLaplace] ______________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c2749610>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_mc(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:652: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________________ test_backprop_glm_mc[DiagLLLaplace] ______________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf14edd0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_mc(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:652: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6bf14dd10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_______________________ test_backprop_nn[FullLLLaplace] ________________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3c49a50>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_nn(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:671: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3c48a10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_______________________ test_backprop_nn[KronLLLaplace] ________________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3cf1a90>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_nn(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:671: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_______________________ test_backprop_nn[DiagLLLaplace] ________________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3bf4fd0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_nn(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:671: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3bf7d90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_reg_glm_predictive_correct_behavior[FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6bf1fa190>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, KronLLLaplace, DiagLLLaplace])
    def test_reg_glm_predictive_correct_behavior(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        n_batch = X.shape[0]
        n_outputs = y.shape[-1]
    
        lap = laplace(model, "regression")
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:691: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6bf1fbf50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_reg_glm_predictive_correct_behavior[KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c3cf1b10>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, KronLLLaplace, DiagLLLaplace])
    def test_reg_glm_predictive_correct_behavior(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        n_batch = X.shape[0]
        n_outputs = y.shape[-1]
    
        lap = laplace(model, "regression")
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:691: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_reg_glm_predictive_correct_behavior[DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x72f6c27aa950>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, KronLLLaplace, DiagLLLaplace])
    def test_reg_glm_predictive_correct_behavior(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        n_batch = X.shape[0]
        n_outputs = y.shape[-1]
    
        lap = laplace(model, "regression")
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:691: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c27a8690>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c27f2110>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c27b8590>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c27f3990>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3cf1410>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3bdbb90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c2776f10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c2786790>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c2776a90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c27b0390>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c2701310>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6bf14edd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c2721e50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c274b650>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6bf121450>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c27bc750>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c27d4590>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3b6ae50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c276f550>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3b52a10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c27ee850>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c0a15210>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6bf122fd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c0a14f90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3c74f10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6bf1f9190>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c0a14290>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c27d1410>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3195ad0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3b0bc50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c31ce350>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3b3c890>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3197650>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c27ec1d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c318fe50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3b3f0d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3ccc3d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c276ff50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3ccf5d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________ test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3bf7190>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________ test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________ test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3b06110>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c2722fd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c276d0d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c2705110>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c319d690>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3bb8410>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c316ed90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3bb95d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3c5c650>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3b04dd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3df9190>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________ test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6bf12e990>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________ test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________ test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c27183d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3c77f90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3c55a90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3bf61d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c2787e50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6bf12c890>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c27d30d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3c56b90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c2723810>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c27ef110>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c27b7d90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________ test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c31c7a90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________ test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________ test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c31dfad0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6bf178c50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c27d69d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c310c690>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c27d61d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c270f210>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c27d7150>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x72f6c3133bd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x72f6c3178e10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION = LooseVersion(version("torch"))

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION_AT_LEAST_1_12_0 = TORCH_VERSION >= LooseVersion("1.12.0")

tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace]
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/curvlinops/_base.py:299: UserWarning: Input matrix is float64, while linear operator is float32. Converting to float32.
    warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace]
================= 188 failed, 24 passed, 3 warnings in 21.26s ==================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/Laplace/Laplace/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/Laplace/Laplace
configfile: pyproject.toml
plugins: mock-3.14.0, cov-6.0.0
collecting ... collected 212 items

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED

=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION = LooseVersion(version("torch"))

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION_AT_LEAST_1_12_0 = TORCH_VERSION >= LooseVersion("1.12.0")

tests/test_lllaplace.py: 27 warnings
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/curvlinops/_base.py:299: UserWarning: Input matrix is float64, while linear operator is float32. Converting to float32.
    warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================= 212 passed, 29 warnings in 63.01s (0:01:03) ==================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/Laplace/Laplace/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/Laplace/Laplace
configfile: pyproject.toml
plugins: mock-3.14.0, cov-6.0.0
collecting ... collected 212 items

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED

=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION = LooseVersion(version("torch"))

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION_AT_LEAST_1_12_0 = TORCH_VERSION >= LooseVersion("1.12.0")

tests/test_lllaplace.py: 27 warnings
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/curvlinops/_base.py:299: UserWarning: Input matrix is float64, while linear operator is float32. Converting to float32.
    warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================= 212 passed, 29 warnings in 64.53s (0:01:04) ==================
