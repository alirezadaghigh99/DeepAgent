output file:
processed_kornia_compute_tiles364.json
function:
_compute_tiles
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] FAILED'}

All Test Cases On Generated code:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'onnxrt', 'inductor', 'jit', 'tvm', 'openxla', 'cudagraphs', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 25 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[0-1.0-grid0-ValueError-Invalid input tensor, it is empty.] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_type PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_jit[cpu-float32] SKIPPED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_module PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] FAILED

=================================== FAILURES ===================================
___________________ TestEqualization.test_smoke[cpu-float32] ___________________

self = <test_equalization.TestEqualization object at 0x722ba5941660>
device = device(type='cpu'), dtype = torch.float32

    def test_smoke(self, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:245: in equalize_clahe
    hist_tiles, img_padded = _compute_tiles(imgs, grid_size, True)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:12: in _compute_tiles
    return _compute_tiles(imgs, grid_size, even_tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

images = tensor([[[[0.5063, 0.7735, 0.7475, 0.9602, 0.3738, 0.1115, 0.8234, 0.1299,
           0.4350, 0.6940, 0.9640, 0.5064, ...         0.6634, 0.2012, 0.3155, 0.5065, 0.3610, 0.2151, 0.3570, 0.1714,
           0.3815, 0.6220, 0.5375, 0.3850]]]])
grid_size = (8, 8), even_tile_size = True

    def _compute_tiles(images: torch.Tensor, grid_size: tuple, even_tile_size: bool=False) -> tuple:
        """
        Compute tiles from a batch of 2D images.
    
        Args:
            images (torch.Tensor): A tensor of shape (B, C, H, W) representing the batch of images.
            grid_size (tuple): A tuple (GH, GW) representing the number of tiles in height and width.
            even_tile_size (bool): If True, ensures the tiles have even dimensions.
    
        Returns:
            tuple: A tuple containing two tensors:
                - tiles: A tensor of shape (B, GH, GW, C, TH, TW) with the computed tiles.
                - padded_images: A tensor of the padded batch of images.
        """
        B, C, H, W = images.shape
        GH, GW = grid_size
        tile_height = H // GH
        tile_width = W // GW
        if even_tile_size:
            tile_height += tile_height % 2
            tile_width += tile_width % 2
        pad_height = tile_height * GH - H
        pad_width = tile_width * GW - W
        if pad_height < 0 or pad_width < 0:
>           raise ValueError('Grid size exceeds image dimensions after padding.')
E           ValueError: Grid size exceeds image dimensions after padding.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:35: ValueError
____________ TestEqualization.test_cardinality[cpu-float32-None-1] _____________

self = <test_equalization.TestEqualization object at 0x722ba5941b10>, B = None
C = 1, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:245: in equalize_clahe
    hist_tiles, img_padded = _compute_tiles(imgs, grid_size, True)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:12: in _compute_tiles
    return _compute_tiles(imgs, grid_size, even_tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

images = tensor([[[[0.9195, 0.5895, 0.3011, 0.2140, 0.7235, 0.0897, 0.6394, 0.5489,
           0.2418, 0.3618, 0.8923, 0.5961, ...         0.6759, 0.3722, 0.9684, 0.1939, 0.3223, 0.7190, 0.5695, 0.6230,
           0.6103, 0.4314, 0.5367, 0.6939]]]])
grid_size = (8, 8), even_tile_size = True

    def _compute_tiles(images: torch.Tensor, grid_size: tuple, even_tile_size: bool=False) -> tuple:
        """
        Compute tiles from a batch of 2D images.
    
        Args:
            images (torch.Tensor): A tensor of shape (B, C, H, W) representing the batch of images.
            grid_size (tuple): A tuple (GH, GW) representing the number of tiles in height and width.
            even_tile_size (bool): If True, ensures the tiles have even dimensions.
    
        Returns:
            tuple: A tuple containing two tensors:
                - tiles: A tensor of shape (B, GH, GW, C, TH, TW) with the computed tiles.
                - padded_images: A tensor of the padded batch of images.
        """
        B, C, H, W = images.shape
        GH, GW = grid_size
        tile_height = H // GH
        tile_width = W // GW
        if even_tile_size:
            tile_height += tile_height % 2
            tile_width += tile_width % 2
        pad_height = tile_height * GH - H
        pad_width = tile_width * GW - W
        if pad_height < 0 or pad_width < 0:
>           raise ValueError('Grid size exceeds image dimensions after padding.')
E           ValueError: Grid size exceeds image dimensions after padding.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:35: ValueError
____________ TestEqualization.test_cardinality[cpu-float32-None-3] _____________

self = <test_equalization.TestEqualization object at 0x722ba5941a50>, B = None
C = 3, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:245: in equalize_clahe
    hist_tiles, img_padded = _compute_tiles(imgs, grid_size, True)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:12: in _compute_tiles
    return _compute_tiles(imgs, grid_size, even_tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

images = tensor([[[[0.8667, 0.3267, 0.7442, 0.7189, 0.5928, 0.8043, 0.7267, 0.0071,
           0.2207, 0.1062, 0.6141, 0.0466, ...         0.1646, 0.8069, 0.4599, 0.7180, 0.6802, 0.3409, 0.6802, 0.3947,
           0.6291, 0.7197, 0.9369, 0.2560]]]])
grid_size = (8, 8), even_tile_size = True

    def _compute_tiles(images: torch.Tensor, grid_size: tuple, even_tile_size: bool=False) -> tuple:
        """
        Compute tiles from a batch of 2D images.
    
        Args:
            images (torch.Tensor): A tensor of shape (B, C, H, W) representing the batch of images.
            grid_size (tuple): A tuple (GH, GW) representing the number of tiles in height and width.
            even_tile_size (bool): If True, ensures the tiles have even dimensions.
    
        Returns:
            tuple: A tuple containing two tensors:
                - tiles: A tensor of shape (B, GH, GW, C, TH, TW) with the computed tiles.
                - padded_images: A tensor of the padded batch of images.
        """
        B, C, H, W = images.shape
        GH, GW = grid_size
        tile_height = H // GH
        tile_width = W // GW
        if even_tile_size:
            tile_height += tile_height % 2
            tile_width += tile_width % 2
        pad_height = tile_height * GH - H
        pad_width = tile_width * GW - W
        if pad_height < 0 or pad_width < 0:
>           raise ValueError('Grid size exceeds image dimensions after padding.')
E           ValueError: Grid size exceeds image dimensions after padding.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:35: ValueError
______________ TestEqualization.test_cardinality[cpu-float32-1-1] ______________

self = <test_equalization.TestEqualization object at 0x722ba5941ed0>, B = 1
C = 1, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:245: in equalize_clahe
    hist_tiles, img_padded = _compute_tiles(imgs, grid_size, True)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:12: in _compute_tiles
    return _compute_tiles(imgs, grid_size, even_tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

images = tensor([[[[0.8584, 0.7046, 0.3779, 0.2807, 0.0828, 0.0346, 0.8316, 0.0330,
           0.0742, 0.5450, 0.9017, 0.0774, ...         0.6273, 0.8146, 0.3485, 0.3444, 0.9315, 0.5481, 0.6780, 0.9555,
           0.1849, 0.2563, 0.9297, 0.2447]]]])
grid_size = (8, 8), even_tile_size = True

    def _compute_tiles(images: torch.Tensor, grid_size: tuple, even_tile_size: bool=False) -> tuple:
        """
        Compute tiles from a batch of 2D images.
    
        Args:
            images (torch.Tensor): A tensor of shape (B, C, H, W) representing the batch of images.
            grid_size (tuple): A tuple (GH, GW) representing the number of tiles in height and width.
            even_tile_size (bool): If True, ensures the tiles have even dimensions.
    
        Returns:
            tuple: A tuple containing two tensors:
                - tiles: A tensor of shape (B, GH, GW, C, TH, TW) with the computed tiles.
                - padded_images: A tensor of the padded batch of images.
        """
        B, C, H, W = images.shape
        GH, GW = grid_size
        tile_height = H // GH
        tile_width = W // GW
        if even_tile_size:
            tile_height += tile_height % 2
            tile_width += tile_width % 2
        pad_height = tile_height * GH - H
        pad_width = tile_width * GW - W
        if pad_height < 0 or pad_width < 0:
>           raise ValueError('Grid size exceeds image dimensions after padding.')
E           ValueError: Grid size exceeds image dimensions after padding.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:35: ValueError
______________ TestEqualization.test_cardinality[cpu-float32-1-3] ______________

self = <test_equalization.TestEqualization object at 0x722ba5941f90>, B = 1
C = 3, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:245: in equalize_clahe
    hist_tiles, img_padded = _compute_tiles(imgs, grid_size, True)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:12: in _compute_tiles
    return _compute_tiles(imgs, grid_size, even_tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

images = tensor([[[[0.9398, 0.3526, 0.0938, 0.2274, 0.6083, 0.4657, 0.5521, 0.9956,
           0.4695, 0.6855, 0.1177, 0.3994, ...         0.9107, 0.6406, 0.3194, 0.2012, 0.1241, 0.2401, 0.8528, 0.1552,
           0.9800, 0.0572, 0.5474, 0.7095]]]])
grid_size = (8, 8), even_tile_size = True

    def _compute_tiles(images: torch.Tensor, grid_size: tuple, even_tile_size: bool=False) -> tuple:
        """
        Compute tiles from a batch of 2D images.
    
        Args:
            images (torch.Tensor): A tensor of shape (B, C, H, W) representing the batch of images.
            grid_size (tuple): A tuple (GH, GW) representing the number of tiles in height and width.
            even_tile_size (bool): If True, ensures the tiles have even dimensions.
    
        Returns:
            tuple: A tuple containing two tensors:
                - tiles: A tensor of shape (B, GH, GW, C, TH, TW) with the computed tiles.
                - padded_images: A tensor of the padded batch of images.
        """
        B, C, H, W = images.shape
        GH, GW = grid_size
        tile_height = H // GH
        tile_width = W // GW
        if even_tile_size:
            tile_height += tile_height % 2
            tile_width += tile_width % 2
        pad_height = tile_height * GH - H
        pad_width = tile_width * GW - W
        if pad_height < 0 or pad_width < 0:
>           raise ValueError('Grid size exceeds image dimensions after padding.')
E           ValueError: Grid size exceeds image dimensions after padding.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:35: ValueError
______________ TestEqualization.test_cardinality[cpu-float32-4-1] ______________

self = <test_equalization.TestEqualization object at 0x722ba5942050>, B = 4
C = 1, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:245: in equalize_clahe
    hist_tiles, img_padded = _compute_tiles(imgs, grid_size, True)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:12: in _compute_tiles
    return _compute_tiles(imgs, grid_size, even_tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

images = tensor([[[[7.1729e-01, 4.8164e-01, 4.6696e-01, 9.7721e-01, 5.8503e-01,
           8.7559e-04, 7.2401e-01, 1.9809e-01, ...575e-01, 2.2986e-01, 3.5018e-01, 4.4705e-01,
           1.9309e-01, 4.2077e-01, 6.0503e-01, 6.8766e-01, 9.3948e-01]]]])
grid_size = (8, 8), even_tile_size = True

    def _compute_tiles(images: torch.Tensor, grid_size: tuple, even_tile_size: bool=False) -> tuple:
        """
        Compute tiles from a batch of 2D images.
    
        Args:
            images (torch.Tensor): A tensor of shape (B, C, H, W) representing the batch of images.
            grid_size (tuple): A tuple (GH, GW) representing the number of tiles in height and width.
            even_tile_size (bool): If True, ensures the tiles have even dimensions.
    
        Returns:
            tuple: A tuple containing two tensors:
                - tiles: A tensor of shape (B, GH, GW, C, TH, TW) with the computed tiles.
                - padded_images: A tensor of the padded batch of images.
        """
        B, C, H, W = images.shape
        GH, GW = grid_size
        tile_height = H // GH
        tile_width = W // GW
        if even_tile_size:
            tile_height += tile_height % 2
            tile_width += tile_width % 2
        pad_height = tile_height * GH - H
        pad_width = tile_width * GW - W
        if pad_height < 0 or pad_width < 0:
>           raise ValueError('Grid size exceeds image dimensions after padding.')
E           ValueError: Grid size exceeds image dimensions after padding.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:35: ValueError
______________ TestEqualization.test_cardinality[cpu-float32-4-3] ______________

self = <test_equalization.TestEqualization object at 0x722ba5942110>, B = 4
C = 3, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:245: in equalize_clahe
    hist_tiles, img_padded = _compute_tiles(imgs, grid_size, True)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:12: in _compute_tiles
    return _compute_tiles(imgs, grid_size, even_tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

images = tensor([[[[0.5797, 0.7501, 0.6891,  ..., 0.6378, 0.8611, 0.4042],
          [0.5859, 0.3061, 0.4399,  ..., 0.8717, 0.4...32, 0.1443, 0.1573,  ..., 0.4758, 0.6968, 0.3979],
          [0.2891, 0.5726, 0.3787,  ..., 0.3398, 0.6803, 0.7077]]]])
grid_size = (8, 8), even_tile_size = True

    def _compute_tiles(images: torch.Tensor, grid_size: tuple, even_tile_size: bool=False) -> tuple:
        """
        Compute tiles from a batch of 2D images.
    
        Args:
            images (torch.Tensor): A tensor of shape (B, C, H, W) representing the batch of images.
            grid_size (tuple): A tuple (GH, GW) representing the number of tiles in height and width.
            even_tile_size (bool): If True, ensures the tiles have even dimensions.
    
        Returns:
            tuple: A tuple containing two tensors:
                - tiles: A tensor of shape (B, GH, GW, C, TH, TW) with the computed tiles.
                - padded_images: A tensor of the padded batch of images.
        """
        B, C, H, W = images.shape
        GH, GW = grid_size
        tile_height = H // GH
        tile_width = W // GW
        if even_tile_size:
            tile_height += tile_height % 2
            tile_width += tile_width % 2
        pad_height = tile_height * GH - H
        pad_width = tile_width * GW - W
        if pad_height < 0 or pad_width < 0:
>           raise ValueError('Grid size exceeds image dimensions after padding.')
E           ValueError: Grid size exceeds image dimensions after padding.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:35: ValueError
_________ TestEqualization.test_optional_params[cpu-float32-0.0-None] __________

self = <test_equalization.TestEqualization object at 0x722ba59424a0>, clip = 0.0
grid = None, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("clip, grid", [(0.0, None), (None, (2, 2)), (2.0, (2, 2))])
    def test_optional_params(self, clip, grid, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
        if clip is None:
            res = enhance.equalize_clahe(img, grid_size=grid)
        elif grid is None:
>           res = enhance.equalize_clahe(img, clip_limit=clip)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:39: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:245: in equalize_clahe
    hist_tiles, img_padded = _compute_tiles(imgs, grid_size, True)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:12: in _compute_tiles
    return _compute_tiles(imgs, grid_size, even_tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

images = tensor([[[[0.4087, 0.1710, 0.9400, 0.2773, 0.0025, 0.1391, 0.0844, 0.0424,
           0.7034, 0.1191, 0.6305, 0.6390, ...         0.1743, 0.8758, 0.2215, 0.6859, 0.9571, 0.7699, 0.5995, 0.7129,
           0.0167, 0.4263, 0.6250, 0.0211]]]])
grid_size = (8, 8), even_tile_size = True

    def _compute_tiles(images: torch.Tensor, grid_size: tuple, even_tile_size: bool=False) -> tuple:
        """
        Compute tiles from a batch of 2D images.
    
        Args:
            images (torch.Tensor): A tensor of shape (B, C, H, W) representing the batch of images.
            grid_size (tuple): A tuple (GH, GW) representing the number of tiles in height and width.
            even_tile_size (bool): If True, ensures the tiles have even dimensions.
    
        Returns:
            tuple: A tuple containing two tensors:
                - tiles: A tensor of shape (B, GH, GW, C, TH, TW) with the computed tiles.
                - padded_images: A tensor of the padded batch of images.
        """
        B, C, H, W = images.shape
        GH, GW = grid_size
        tile_height = H // GH
        tile_width = W // GW
        if even_tile_size:
            tile_height += tile_height % 2
            tile_width += tile_width % 2
        pad_height = tile_height * GH - H
        pad_width = tile_width * GW - W
        if pad_height < 0 or pad_width < 0:
>           raise ValueError('Grid size exceeds image dimensions after padding.')
E           ValueError: Grid size exceeds image dimensions after padding.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:35: ValueError
________ TestEqualization.test_optional_params[cpu-float32-None-grid1] _________

self = <test_equalization.TestEqualization object at 0x722ba59423e0>
clip = None, grid = (2, 2), device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("clip, grid", [(0.0, None), (None, (2, 2)), (2.0, (2, 2))])
    def test_optional_params(self, clip, grid, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
        if clip is None:
>           res = enhance.equalize_clahe(img, grid_size=grid)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[0.6780, 0.6949, 0.5947, 0.9498, 0.0084, 0.9102, 0.1611, 0.1023,
             0.4043, 0.4255],
           ....0000],
            [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
             0.0000, 0.0000]]]]]])
num_bins = 256, clip = 40.0, diff = False

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
_________ TestEqualization.test_optional_params[cpu-float32-2.0-grid2] _________

self = <test_equalization.TestEqualization object at 0x722ba5942740>, clip = 2.0
grid = (2, 2), device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("clip, grid", [(0.0, None), (None, (2, 2)), (2.0, (2, 2))])
    def test_optional_params(self, clip, grid, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
        if clip is None:
            res = enhance.equalize_clahe(img, grid_size=grid)
        elif grid is None:
            res = enhance.equalize_clahe(img, clip_limit=clip)
        else:
>           res = enhance.equalize_clahe(img, clip, grid)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[9.3691e-01, 3.3095e-01, 8.2719e-01, 1.2683e-01, 6.1797e-01,
             5.8426e-02, 7.6677e-01, 9.3933e-...+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
             0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]]]])
num_bins = 256, clip = 2.0, diff = False

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
_____________________ TestEqualization.test_gradcheck[cpu] _____________________

self = <test_equalization.TestEqualization object at 0x722ba5943700>
device = device(type='cpu')

    def test_gradcheck(self, device):
        torch.random.manual_seed(4)
        bs, channels, height, width = 1, 1, 11, 11
        inputs = torch.rand(bs, channels, height, width, device=device, dtype=torch.float64)
    
        def grad_rot(data, a, b, c):
            rot = rotate(data, torch.tensor(30.0, dtype=data.dtype, device=device))
            return enhance.equalize_clahe(rot, a, b, c)
    
>       self.gradcheck(grad_rot, (inputs, 40.0, (2, 2), True), nondet_tol=1e-4)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2074: in _gradcheck_helper
    func_out = func(*tupled_inputs)
/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:80: in grad_rot
    return enhance.equalize_clahe(rot, a, b, c)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[0.0000, 0.0000, 0.1003, 0.2967, 0.6151, 0.3659],
            [0.0234, 0.5070, 0.7737, 0.4968, 0.6719, 0.4...         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]]]],
       dtype=torch.float64, grad_fn=<PermuteBackward0>)
num_bins = 256, clip = 40.0, diff = True

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
____________________ TestEqualization.test_ahe[cpu-float32] ____________________

self = <test_equalization.TestEqualization object at 0x722ba59682e0>
img = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ...         0.4211, 0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895,
           0.8421, 0.8947, 0.9474, 1.0000]]]])

    def test_ahe(self, img):
        clip_limit: float = 0.0
        grid_size: Tuple = (8, 8)
>       res = enhance.equalize_clahe(img, clip_limit=clip_limit, grid_size=grid_size)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:245: in equalize_clahe
    hist_tiles, img_padded = _compute_tiles(imgs, grid_size, True)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:12: in _compute_tiles
    return _compute_tiles(imgs, grid_size, even_tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

images = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ...         0.4211, 0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895,
           0.8421, 0.8947, 0.9474, 1.0000]]]])
grid_size = (8, 8), even_tile_size = True

    def _compute_tiles(images: torch.Tensor, grid_size: tuple, even_tile_size: bool=False) -> tuple:
        """
        Compute tiles from a batch of 2D images.
    
        Args:
            images (torch.Tensor): A tensor of shape (B, C, H, W) representing the batch of images.
            grid_size (tuple): A tuple (GH, GW) representing the number of tiles in height and width.
            even_tile_size (bool): If True, ensures the tiles have even dimensions.
    
        Returns:
            tuple: A tuple containing two tensors:
                - tiles: A tensor of shape (B, GH, GW, C, TH, TW) with the computed tiles.
                - padded_images: A tensor of the padded batch of images.
        """
        B, C, H, W = images.shape
        GH, GW = grid_size
        tile_height = H // GH
        tile_width = W // GW
        if even_tile_size:
            tile_height += tile_height % 2
            tile_width += tile_width % 2
        pad_height = tile_height * GH - H
        pad_width = tile_width * GW - W
        if pad_height < 0 or pad_width < 0:
>           raise ValueError('Grid size exceeds image dimensions after padding.')
E           ValueError: Grid size exceeds image dimensions after padding.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:35: ValueError
___________________ TestEqualization.test_clahe[cpu-float32] ___________________

self = <test_equalization.TestEqualization object at 0x722ba5968640>
img = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ...         0.4211, 0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895,
           0.8421, 0.8947, 0.9474, 1.0000]]]])

    def test_clahe(self, img):
        clip_limit: float = 2.0
        grid_size: Tuple = (8, 8)
>       res = enhance.equalize_clahe(img, clip_limit=clip_limit, grid_size=grid_size)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:245: in equalize_clahe
    hist_tiles, img_padded = _compute_tiles(imgs, grid_size, True)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:12: in _compute_tiles
    return _compute_tiles(imgs, grid_size, even_tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

images = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ...         0.4211, 0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895,
           0.8421, 0.8947, 0.9474, 1.0000]]]])
grid_size = (8, 8), even_tile_size = True

    def _compute_tiles(images: torch.Tensor, grid_size: tuple, even_tile_size: bool=False) -> tuple:
        """
        Compute tiles from a batch of 2D images.
    
        Args:
            images (torch.Tensor): A tensor of shape (B, C, H, W) representing the batch of images.
            grid_size (tuple): A tuple (GH, GW) representing the number of tiles in height and width.
            even_tile_size (bool): If True, ensures the tiles have even dimensions.
    
        Returns:
            tuple: A tuple containing two tensors:
                - tiles: A tensor of shape (B, GH, GW, C, TH, TW) with the computed tiles.
                - padded_images: A tensor of the padded batch of images.
        """
        B, C, H, W = images.shape
        GH, GW = grid_size
        tile_height = H // GH
        tile_width = W // GW
        if even_tile_size:
            tile_height += tile_height % 2
            tile_width += tile_width % 2
        pad_height = tile_height * GH - H
        pad_width = tile_width * GW - W
        if pad_height < 0 or pad_width < 0:
>           raise ValueError('Grid size exceeds image dimensions after padding.')
E           ValueError: Grid size exceeds image dimensions after padding.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:35: ValueError
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32]
=================== 13 failed, 11 passed, 1 skipped in 0.51s ===================


Final Test Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', None, 'openxla', 'tvm', 'jit', 'inductor', 'onnxrt', 'cudagraphs'}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 25 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[0-1.0-grid0-ValueError-Invalid input tensor, it is empty.] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_type PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_jit[cpu-float32] SKIPPED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_module PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] PASSED

======================== 24 passed, 1 skipped in 0.24s =========================


Initial Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'openxla', 'cudagraphs', 'tvm', 'inductor', 'jit', None, 'onnxrt'}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 25 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[0-1.0-grid0-ValueError-Invalid input tensor, it is empty.] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_type PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_jit[cpu-float32] SKIPPED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_module PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] PASSED

======================== 24 passed, 1 skipped in 0.31s =========================
