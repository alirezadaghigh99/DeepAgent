output file:
processed_pfrl_flatten_and_concat_variables354.json
function:
_flatten_and_concat_variables
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-True-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-False-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-False-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-False-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-False-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-True-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-False-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-False-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-True-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-False-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-False-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-False-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-True-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-False-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-True-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-False-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-False-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-True-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-True-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-True-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-True-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-True-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-True-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-False-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-True-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-True-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-True-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-False-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-False-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-True-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-True-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-True-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-True-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-False-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-False-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-False-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-True-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-True-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-False-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-True-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-False-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-False-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-False-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-False-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-False-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-True-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-True-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-True-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-True-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-False-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-True-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-True-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-True-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-True-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-True-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-False-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-False-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-True-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-False-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-True-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-True-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-False-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-False-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-True-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-True-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-True-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-False-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-True-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-True-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-False-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-True-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-False-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-False-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-True-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-True-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-True-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-True-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-False-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-False-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-True-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-False-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-False-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-False-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-False-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-True-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-False-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-False-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-True-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-True-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-False-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-False-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-True-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-True-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-True-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-False-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-True-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-True-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-False-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-True-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-True-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-True-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-False-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-False-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-True-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-False-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-True-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-True-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-True-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-True-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-False-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-False-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-False-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-True-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-True-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-False-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-False-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-True-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-False-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-False-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-True-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-False-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-False-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-False-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-False-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-False-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-True-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-False-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-False-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-False-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-False-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-True-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-False-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-False-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-False-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-True-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-True-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-False-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-True-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-False-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-False-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-True-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-True-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-False-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-False-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-True-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-False-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-True-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-False-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-True-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-False-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-True-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-False-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-False-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-True-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-True-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-True-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-False-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-False-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-False-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-False-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-False-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-False-True] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-True-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-True-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-True-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-True-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-False-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-True-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-True-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-False-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-True-False]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-True-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-False-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-False-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-False-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-False-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-False-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-False-False]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-False-False] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-True-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-False-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-True-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-True-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-True-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-False-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-True-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-True-True]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-True-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-True-False] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-True-True] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-False-True]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-True-False] FAILED'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/pfrl/pfrl/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/pfrl/pfrl
configfile: pytest.ini
collecting ... collected 96 items

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-True-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-False-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-False-True] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-True-False] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-True-True] FAILED

=================================== FAILURES ===================================
______ TestTRPONonRecurrent.test_abc_cpu[False-False-0.0-0.0-False-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6dae43cb10>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-False-0.0-0.0-False-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6dae5adc50>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ... 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-False-0.0-0.0-True-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b497490>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[False-False-0.0-0.0-True-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b497410>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ... 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-False-0.0-0.5-False-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4972d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-False-0.0-0.5-False-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b497b10>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-1.0297e-09,  2.3179e-11,  0.0000e+00,  0.0000e+00],
        [-6.0066e-10,  8.4636e-11,  0.0000e+00,  0.0000...  2.5115e-09, -5.4985e-10]],
       grad_fn=<TBackward0>), tensor([-4.9360e-08,  5.1223e-09], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-False-0.0-0.5-True-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b497510>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[False-False-0.0-0.5-True-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b497850>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 4.1224e-10,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-2.3100e-10,  0.0000e+00,  0.0000e+00,  0.0000...9, -2.1139e-09,  9.2769e-09]],
       grad_fn=<TBackward0>), tensor([0.0000e+00, 1.9558e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-False-0.0-1.0-False-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b497a10>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-False-0.0-1.0-False-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4af310>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-3.8191e-10,  5.0826e-10,  0.0000e+00,  0.0000e+00],
        [-2.8192e-10,  1.3255e-10,  0.0000e+00,  0.0000... -1.1785e-09,  9.6769e-09]],
       grad_fn=<TBackward0>), tensor([-9.3132e-09, -2.0489e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-False-0.0-1.0-True-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4ac190>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[False-False-0.0-1.0-True-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4ac2d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 1.4448e-11, -9.3147e-11,  0.0000e+00,  0.0000e+00],
        [ 9.7227e-11,  1.0473e-10,  0.0000e+00,  0.0000...8,  2.2385e-08, -1.3538e-09]],
       grad_fn=<TBackward0>), tensor([1.0245e-08, 5.9605e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_____ TestTRPONonRecurrent.test_abc_cpu[False-False-1e-05-0.0-False-False] _____

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4ac7d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_____ TestTRPONonRecurrent.test_abc_cpu[False-False-1e-05-0.0-False-True] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4acb90>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-2.2262e-10, -1.0488e-10,  0.0000e+00,  0.0000e+00],
        [ 2.0496e-10,  7.6901e-11,  0.0000e+00,  0.0000...0,  0.0000e+00,  0.0000e+00]],
       grad_fn=<TBackward0>), tensor([2.9802e-08, 0.0000e+00], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_____ TestTRPONonRecurrent.test_abc_cpu[False-False-1e-05-0.0-True-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4acf90>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-False-1e-05-0.0-True-True] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4ad5d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 4.5680e-10,  5.7192e-11,  0.0000e+00,  0.0000e+00],
        [-1.6971e-10,  1.5926e-10,  0.0000e+00,  0.0000... -4.3860e-09, -6.6651e-09]],
       grad_fn=<TBackward0>), tensor([ 3.9116e-08, -1.0245e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_____ TestTRPONonRecurrent.test_abc_cpu[False-False-1e-05-0.5-False-False] _____

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4adad0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_____ TestTRPONonRecurrent.test_abc_cpu[False-False-1e-05-0.5-False-True] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4ae390>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 3.1608e-10, -8.9915e-12,  0.0000e+00,  0.0000e+00],
        [-3.2883e-10,  1.5454e-10,  0.0000e+00,  0.0000...  3.1696e-09, -8.3862e-09]],
       grad_fn=<TBackward0>), tensor([ 2.4214e-08, -1.1176e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_____ TestTRPONonRecurrent.test_abc_cpu[False-False-1e-05-0.5-True-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4ae9d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-False-1e-05-0.5-True-True] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4aeed0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ... 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_____ TestTRPONonRecurrent.test_abc_cpu[False-False-1e-05-1.0-False-False] _____

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4aa1d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_____ TestTRPONonRecurrent.test_abc_cpu[False-False-1e-05-1.0-False-True] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4aa4d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 5.8866e-10,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-3.1758e-10,  0.0000e+00,  0.0000e+00,  0.0000...  4.6748e-09,  2.8372e-08]],
       grad_fn=<TBackward0>), tensor([-2.2817e-08, -4.5635e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_____ TestTRPONonRecurrent.test_abc_cpu[False-False-1e-05-1.0-True-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4aa710>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-False-1e-05-1.0-True-True] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4aab50>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 0.0000e+00,  1.3997e-10,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00, -9.7906e-11,  0.0000e+00,  0.0000...  0.0000e+00,  0.0000e+00]],
       grad_fn=<TBackward0>), tensor([-8.3819e-09,  0.0000e+00], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-True-0.0-0.0-False-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4aadd0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[False-True-0.0-0.0-False-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4ab290>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 0.0000e+00, -3.3226e-11,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  3.6652e-10,  0.0000e+00,  0.0000...  0.0000e+00,  0.0000e+00]],
       grad_fn=<TBackward0>), tensor([-1.7695e-08,  0.0000e+00], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[False-True-0.0-0.0-True-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4ab750>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[False-True-0.0-0.0-True-True] ________

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4ab7d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 3.6702e-10,  8.6576e-11,  0.0000e+00,  0.0000e+00],
        [-2.0367e-10, -6.8633e-11,  0.0000e+00,  0.0000...  3.4130e-09, -5.4839e-09]],
       grad_fn=<TBackward0>), tensor([-5.9605e-08, -1.9092e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-True-0.0-0.5-False-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4abc90>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[False-True-0.0-0.5-False-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4c3610>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ... 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[False-True-0.0-0.5-True-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4c3890>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[False-True-0.0-0.5-True-True] ________

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4c3b10>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-1.6091e-11,  2.4498e-11,  0.0000e+00,  0.0000e+00],
        [-2.6569e-10,  1.8065e-10,  0.0000e+00,  0.0000...9,  5.9970e-09, -1.8713e-09]],
       grad_fn=<TBackward0>), tensor([0.0000e+00, 5.5879e-09], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-True-0.0-1.0-False-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4c3d90>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[False-True-0.0-1.0-False-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cc050>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 2.9103e-10,  2.5671e-10,  0.0000e+00,  0.0000e+00],
        [ 3.2172e-10,  8.2644e-11,  0.0000e+00,  0.0000... -1.7343e-09, -2.7263e-09]],
       grad_fn=<TBackward0>), tensor([-2.9802e-08, -1.3039e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[False-True-0.0-1.0-True-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cc2d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[False-True-0.0-1.0-True-True] ________

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cc550>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ... 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_____ TestTRPONonRecurrent.test_abc_cpu[False-True-1e-05-0.0-False-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cc7d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-True-1e-05-0.0-False-True] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cca50>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 0.0000e+00,  7.4665e-11,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00, -3.2474e-11,  0.0000e+00,  0.0000...0, -1.1244e-09,  4.2794e-09]],
       grad_fn=<TBackward0>), tensor([0.0000e+00, 7.4506e-09], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-True-1e-05-0.0-True-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cccd0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-True-1e-05-0.0-True-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4ccf90>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-6.7614e-10,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 3.4598e-10,  0.0000e+00,  0.0000e+00,  0.0000... -1.0237e-08,  5.7316e-09]],
       grad_fn=<TBackward0>), tensor([-2.0489e-08, -4.0978e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_____ TestTRPONonRecurrent.test_abc_cpu[False-True-1e-05-0.5-False-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cd290>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-True-1e-05-0.5-False-True] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cd590>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 7.1031e-11, -2.0216e-11,  0.0000e+00,  0.0000e+00],
        [-4.0599e-10,  1.2005e-10,  0.0000e+00,  0.0000...  0.0000e+00,  0.0000e+00]],
       grad_fn=<TBackward0>), tensor([-1.6764e-08,  0.0000e+00], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-True-1e-05-0.5-True-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cd890>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-True-1e-05-0.5-True-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cdb90>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-2.3612e-10,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 1.8587e-10,  0.0000e+00,  0.0000e+00,  0.0000...  0.0000e+00,  0.0000e+00]],
       grad_fn=<TBackward0>), tensor([-2.2817e-08,  0.0000e+00], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_____ TestTRPONonRecurrent.test_abc_cpu[False-True-1e-05-1.0-False-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cde90>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-True-1e-05-1.0-False-True] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4ce190>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-3.8032e-10,  8.6108e-11,  0.0000e+00,  0.0000e+00],
        [-3.2614e-10,  9.7064e-11,  0.0000e+00,  0.0000...8,  2.0210e-08,  8.2445e-09]],
       grad_fn=<TBackward0>), tensor([1.7695e-08, 3.5390e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-True-1e-05-1.0-True-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4ce490>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[False-True-1e-05-1.0-True-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4ce790>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-1.3523e-10,  9.7847e-11,  0.0000e+00,  0.0000e+00],
        [ 4.7767e-10, -3.4351e-10,  0.0000e+00,  0.0000... -5.9694e-09,  1.6302e-08]],
       grad_fn=<TBackward0>), tensor([-1.0245e-08, -2.0489e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-False-0.0-0.0-False-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cea90>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-False-0.0-0.0-False-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4ced90>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 2.0915e-10, -2.0915e-10,  0.0000e+00,  0.0000e+00],
        [-1.4909e-10,  1.4909e-10,  0.0000e+00,  0.0000...  0.0000e+00,  0.0000e+00]],
       grad_fn=<TBackward0>), tensor([-6.5193e-09,  0.0000e+00], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-False-0.0-0.0-True-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cf090>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-False-0.0-0.0-True-True] ________

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cf390>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 1.7633e-10, -1.7633e-10,  0.0000e+00,  0.0000e+00],
        [ 4.9475e-11, -4.9475e-11,  0.0000e+00,  0.0000... -7.8791e-09, -9.6166e-09]],
       grad_fn=<TBackward0>), tensor([ 0.0000e+00, -4.3772e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-False-0.0-0.5-False-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cf690>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-False-0.0-0.5-False-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cf990>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-1.0269e-10,  1.0269e-10,  0.0000e+00,  0.0000e+00],
        [ 4.7383e-10, -4.7383e-10,  0.0000e+00,  0.0000...0, -8.1989e-09,  1.8301e-09]],
       grad_fn=<TBackward0>), tensor([4.1910e-08, 2.0955e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-False-0.0-0.5-True-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cfc90>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-False-0.0-0.5-True-True] ________

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4cff90>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-3.8131e-10,  3.8131e-10,  0.0000e+00,  0.0000e+00],
        [ 4.6105e-10, -4.6105e-10,  0.0000e+00,  0.0000...0,  0.0000e+00,  0.0000e+00]],
       grad_fn=<TBackward0>), tensor([4.4703e-08, 0.0000e+00], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-False-0.0-1.0-False-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4dc2d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-False-0.0-1.0-False-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4dc5d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-4.2013e-10,  4.2013e-10,  0.0000e+00,  0.0000e+00],
        [ 1.3401e-10, -1.3401e-10,  0.0000e+00,  0.0000...  2.2350e-08,  1.1653e-08]],
       grad_fn=<TBackward0>), tensor([-2.2352e-08, -4.4703e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-False-0.0-1.0-True-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4dc8d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-False-0.0-1.0-True-True] ________

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4dcbd0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 3.2397e-10, -3.2397e-10,  0.0000e+00,  0.0000e+00],
        [ 1.5207e-10, -1.5207e-10,  0.0000e+00,  0.0000... -6.7601e-09, -4.7365e-09]],
       grad_fn=<TBackward0>), tensor([-4.0047e-08, -2.0023e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_____ TestTRPONonRecurrent.test_abc_cpu[True-False-1e-05-0.0-False-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4dced0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-False-1e-05-0.0-False-True] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4dd1d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ... 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-False-1e-05-0.0-True-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4dd4d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-False-1e-05-0.0-True-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4dd7d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-2.0104e-10,  2.0104e-10,  0.0000e+00,  0.0000e+00],
        [-4.6232e-11,  4.6232e-11,  0.0000e+00,  0.0000...9, -4.1372e-09, -8.2319e-09]],
       grad_fn=<TBackward0>), tensor([0.0000e+00, 1.0710e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_____ TestTRPONonRecurrent.test_abc_cpu[True-False-1e-05-0.5-False-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4ddad0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-False-1e-05-0.5-False-True] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4dddd0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-3.3733e-10,  3.3733e-10,  0.0000e+00,  0.0000e+00],
        [ 4.5895e-10, -4.5895e-10,  0.0000e+00,  0.0000...  0.0000e+00,  0.0000e+00]],
       grad_fn=<TBackward0>), tensor([-2.1420e-08,  0.0000e+00], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-False-1e-05-0.5-True-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4de0d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-False-1e-05-0.5-True-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4de3d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 3.0024e-11, -3.0024e-11,  0.0000e+00,  0.0000e+00],
        [-1.5337e-11,  1.5337e-11,  0.0000e+00,  0.0000... -2.2660e-09, -2.1326e-10]],
       grad_fn=<TBackward0>), tensor([-5.9605e-08, -2.0489e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_____ TestTRPONonRecurrent.test_abc_cpu[True-False-1e-05-1.0-False-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4de6d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-False-1e-05-1.0-False-True] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4de9d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 1.9044e-10, -1.9044e-10,  0.0000e+00,  0.0000e+00],
        [ 6.0020e-10, -6.0020e-10,  0.0000e+00,  0.0000... -7.2890e-09, -1.5462e-08]],
       grad_fn=<TBackward0>), tensor([-1.1176e-08, -4.2841e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-False-1e-05-1.0-True-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4decd0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-False-1e-05-1.0-True-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4defd0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-3.9223e-11,  3.9223e-11,  0.0000e+00,  0.0000e+00],
        [ 1.0601e-10, -1.0601e-10,  0.0000e+00,  0.0000...  0.0000e+00,  0.0000e+00]],
       grad_fn=<TBackward0>), tensor([-9.3132e-09,  0.0000e+00], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-True-0.0-0.0-False-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4df2d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-True-0.0-0.0-False-True] ________

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4df5d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-1.0539e-10,  1.0539e-10,  0.0000e+00,  0.0000e+00],
        [-8.8101e-11,  8.8101e-11,  0.0000e+00,  0.0000... -1.4842e-08, -6.8529e-09]],
       grad_fn=<TBackward0>), tensor([-2.9802e-08, -1.8626e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-True-0.0-0.0-True-False] ________

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4df8d0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
________ TestTRPONonRecurrent.test_abc_cpu[True-True-0.0-0.0-True-True] ________

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4dfbd0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-4.4787e-10,  4.4787e-10,  0.0000e+00,  0.0000e+00],
        [ 5.7683e-10, -5.7683e-10,  0.0000e+00,  0.0000... -3.4101e-09,  1.4902e-08]],
       grad_fn=<TBackward0>), tensor([-1.8626e-08, -2.0489e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-True-0.0-0.5-False-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4dfed0>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-True-0.0-0.5-False-True] ________

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e4210>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ... 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-True-0.0-0.5-True-False] ________

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e4510>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
________ TestTRPONonRecurrent.test_abc_cpu[True-True-0.0-0.5-True-True] ________

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e4810>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-1.7165e-10,  1.7165e-10,  0.0000e+00,  0.0000e+00],
        [ 3.1485e-10, -3.1485e-10,  0.0000e+00,  0.0000...9, -2.6154e-09,  2.0154e-09]],
       grad_fn=<TBackward0>), tensor([0.0000e+00, 1.8161e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-True-0.0-1.0-False-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e4b10>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-True-0.0-1.0-False-True] ________

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e4e10>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ... 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-True-0.0-1.0-True-False] ________

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e5110>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
________ TestTRPONonRecurrent.test_abc_cpu[True-True-0.0-1.0-True-True] ________

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e5410>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-6.2160e-11,  6.2160e-11,  0.0000e+00,  0.0000e+00],
        [ 9.8004e-11, -9.8004e-11,  0.0000e+00,  0.0000...  0.0000e+00,  0.0000e+00]],
       grad_fn=<TBackward0>), tensor([-9.7789e-09,  0.0000e+00], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-True-1e-05-0.0-False-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e5710>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-True-1e-05-0.0-False-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e5a10>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 5.7133e-11, -5.7133e-11,  0.0000e+00,  0.0000e+00],
        [-4.5881e-11,  4.5881e-11,  0.0000e+00,  0.0000...  1.2288e-08,  1.6176e-09]],
       grad_fn=<TBackward0>), tensor([-3.8184e-08, -2.9802e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-True-1e-05-0.0-True-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e5d10>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-True-1e-05-0.0-True-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e6010>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-6.8565e-11,  6.8565e-11,  0.0000e+00,  0.0000e+00],
        [ 5.1168e-11, -5.1168e-11,  0.0000e+00,  0.0000... -1.0764e-08,  2.0834e-09]],
       grad_fn=<TBackward0>), tensor([ 0.0000e+00, -1.3504e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-True-1e-05-0.5-False-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e6310>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-True-1e-05-0.5-False-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e6610>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[-4.8451e-10,  4.8451e-10,  0.0000e+00,  0.0000e+00],
        [ 4.2072e-10, -4.2072e-10,  0.0000e+00,  0.0000...9,  3.6295e-09, -8.4267e-09]],
       grad_fn=<TBackward0>), tensor([0.0000e+00, 1.2107e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-True-1e-05-0.5-True-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e6910>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-True-1e-05-0.5-True-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e6c10>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ... 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-True-1e-05-1.0-False-False] ______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e6f10>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-True-1e-05-1.0-False-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e7210>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ... 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
______ TestTRPONonRecurrent.test_abc_cpu[True-True-1e-05-1.0-True-False] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e7510>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., ....]],
       grad_fn=<TBackward0>), tensor([0., 0.], grad_fn=<ViewBackward0>), tensor([0., 0.], grad_fn=<MulBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
_______ TestTRPONonRecurrent.test_abc_cpu[True-True-1e-05-1.0-True-True] _______

self = <test_trpo.TestTRPONonRecurrent object at 0x7a6d8b4e7810>

    @pytest.mark.slow
    def test_abc_cpu(self):
>       self._test_abc()

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py:156: in _test_abc
    train_agent_with_evaluation(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:206: in train_agent_with_evaluation
    eval_stats_history = train_agent(
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/experiments/train_agent.py:62: in train_agent
    agent.observe(obs, r, done, reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:164: in observe
    self.batch_observe([obs], [reward], [done], [reset])
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:431: in batch_observe
    self._batch_observe_train(batch_obs, batch_reward, batch_done, batch_reset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:504: in _batch_observe_train
    self._update_if_dataset_is_ready()
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:202: in _update_if_dataset_is_ready
    self._update(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:220: in _update
    self._update_policy(dataset)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:310: in _update_policy
    full_step = self._compute_kl_constrained_step(action_distrib=action_distrib, action_distrib_old=action_distrib_old, gain=gain)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:347: in _compute_kl_constrained_step
    flat_kl_grads = _flatten_and_concat_variables(kl_grads)
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/trpo.py:18: in _flatten_and_concat_variables
    return _flatten_and_concat_variables(vs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

vs = (tensor([[ 3.6446e-10, -3.6446e-10,  0.0000e+00,  0.0000e+00],
        [-1.6026e-10,  1.6026e-10,  0.0000e+00,  0.0000...  7.9848e-10,  7.0210e-09]],
       grad_fn=<TBackward0>), tensor([-4.0047e-08, -2.0023e-08], grad_fn=<ViewBackward0>))

    def _flatten_and_concat_variables(vs):
        """
        Flattens each variable in the list and concatenates them along dimension 0.
    
        Parameters:
        vs (list of torch.Tensor): A list of PyTorch variables to be flattened and concatenated.
    
        Returns:
        torch.Tensor: A single flat vector containing all elements from the input variables.
        """
        if not isinstance(vs, list) or not all((isinstance(v, torch.Tensor) for v in vs)):
>           raise ValueError('Input must be a list of torch.Tensor objects.')
E           ValueError: Input must be a list of torch.Tensor objects.

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:28: ValueError
=============================== warnings summary ===============================
tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-False-False]
  /local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/ppo.py:132: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)
    actions = torch.tensor([b["action"] for b in dataset], device=device)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-True-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-False-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-False-True]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-True-False]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-True-True]
======================== 96 failed, 1 warning in 6.97s =========================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/pfrl/pfrl/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/pfrl/pfrl
configfile: pytest.ini
collecting ... collected 96 items

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-False-False] Load agent from /tmp/tmpitmj5km2/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-False-True] Load agent from /tmp/tmpgkgeeoin/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-True-False] Load agent from /tmp/tmpzlmjvhi2/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-True-True] Load agent from /tmp/tmpmnjp_un1/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-False-False] Load agent from /tmp/tmpzgub7p4i/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-False-True] Load agent from /tmp/tmpvmepbuu8/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-True-False] Load agent from /tmp/tmp9addpzgh/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-True-True] Load agent from /tmp/tmpr685yzuz/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-False-False] Load agent from /tmp/tmp2oxhuphg/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-False-True] Load agent from /tmp/tmplwhfj4is/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-True-False] Load agent from /tmp/tmpty22gxdt/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-True-True] Load agent from /tmp/tmpy2e28c1w/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-False-False] Load agent from /tmp/tmp1jlcgw0w/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-False-True] Load agent from /tmp/tmp9d6zqeop/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-True-False] Load agent from /tmp/tmpebgqedlb/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-True-True] Load agent from /tmp/tmpl1hy5zmj/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-False-False] Load agent from /tmp/tmpko6uw0eb/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-False-True] Load agent from /tmp/tmpfapv3amx/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-True-False] Load agent from /tmp/tmpcl99j8_m/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-True-True] Load agent from /tmp/tmptx7wsuld/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-False-False] Load agent from /tmp/tmpwya_5jqm/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-False-True] Load agent from /tmp/tmpapkpnri0/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-True-False] Load agent from /tmp/tmprie41xyc/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-True-True] Load agent from /tmp/tmpczneuk23/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-False-False] Load agent from /tmp/tmp3dw9wbms/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-False-True] Load agent from /tmp/tmp1id4q1lo/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-True-False] Load agent from /tmp/tmpk4g14wup/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-True-True] Load agent from /tmp/tmptbv8bjdj/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-False-False] Load agent from /tmp/tmpsek4sv2r/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-False-True] Load agent from /tmp/tmpah4bmq8h/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-True-False] Load agent from /tmp/tmpk8z1_9vv/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-True-True] Load agent from /tmp/tmpni2ra6qk/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-False-False] Load agent from /tmp/tmp8kg4o7s_/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-False-True] Load agent from /tmp/tmpvjcai1fd/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-True-False] Load agent from /tmp/tmp_4q3cr82/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-True-True] Load agent from /tmp/tmp3kybks3e/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-False-False] Load agent from /tmp/tmprojhafai/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-False-True] Load agent from /tmp/tmpscxpy9rz/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-True-False] Load agent from /tmp/tmpr45jdcr4/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-True-True] Load agent from /tmp/tmpkq92vune/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-False-False] Load agent from /tmp/tmpavckwlxx/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-False-True] Load agent from /tmp/tmp0oqw4b4d/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-True-False] Load agent from /tmp/tmpzs18gk81/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-True-True] Load agent from /tmp/tmphszbywgb/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-False-False] Load agent from /tmp/tmpi1e9usyh/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-False-True] Load agent from /tmp/tmpfir8y3j1/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-True-False] Load agent from /tmp/tmp_5ti6n50/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-True-True] Load agent from /tmp/tmptuiv7pvm/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-False-False] Load agent from /tmp/tmp63l9ypgy/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-False-True] Load agent from /tmp/tmpdp4hef82/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-True-False] Load agent from /tmp/tmp64uemrh8/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-True-True] Load agent from /tmp/tmpvbuxyr_y/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-False-False] Load agent from /tmp/tmprzcmgxh9/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-False-True] Load agent from /tmp/tmp69u21dzr/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-True-False] Load agent from /tmp/tmpvx96tkwo/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-True-True] Load agent from /tmp/tmp08bd31e8/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-False-False] Load agent from /tmp/tmp8i32vgsl/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-False-True] Load agent from /tmp/tmpjjf9jy0l/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-True-False] Load agent from /tmp/tmpkik_oo5f/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-True-True] Load agent from /tmp/tmp_pzmm388/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-False-False] Load agent from /tmp/tmpv_l26s1y/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-False-True] Load agent from /tmp/tmpkwynwf7_/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-True-False] Load agent from /tmp/tmptfqcufqh/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-True-True] Load agent from /tmp/tmpmvctlshc/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-False-False] Load agent from /tmp/tmp5p0287de/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-False-True] Load agent from /tmp/tmpmlu54qr8/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-True-False] Load agent from /tmp/tmpi4mgtsi4/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-True-True] Load agent from /tmp/tmp7y9zfji3/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-False-False] Load agent from /tmp/tmp5zninrug/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-False-True] Load agent from /tmp/tmpydtw_1gx/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-True-False] Load agent from /tmp/tmpw_jflh0l/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-True-True] Load agent from /tmp/tmpwm020rim/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-False-False] Load agent from /tmp/tmpvvt8_8w_/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-False-True] Load agent from /tmp/tmpll42c95v/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-True-False] Load agent from /tmp/tmpyqon9y06/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-True-True] Load agent from /tmp/tmp0v1itzgh/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-False-False] Load agent from /tmp/tmp88m2pc_6/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-False-True] Load agent from /tmp/tmp_740scl2/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-True-False] Load agent from /tmp/tmpgejm0yzd/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-True-True] Load agent from /tmp/tmpf3txyx9s/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-False-False] Load agent from /tmp/tmpqyvt_osh/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-False-True] Load agent from /tmp/tmpq6rbulw9/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-True-False] Load agent from /tmp/tmpnsjrcuzi/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-True-True] Load agent from /tmp/tmpioc8vzu1/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-False-False] Load agent from /tmp/tmp26q69qu6/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-False-True] Load agent from /tmp/tmph_nxoecu/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-True-False] Load agent from /tmp/tmp77lzu_uj/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-True-True] Load agent from /tmp/tmpcm7bd_p2/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-False-False] Load agent from /tmp/tmpnts6byy5/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-False-True] Load agent from /tmp/tmpg2dg096r/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-True-False] Load agent from /tmp/tmpn4axkxl7/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-True-True] Load agent from /tmp/tmpto1adloa/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-False-False] Load agent from /tmp/tmpoe8ctqj_/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-False-True] Load agent from /tmp/tmp_cxqq9xu/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-True-False] Load agent from /tmp/tmp5m6aeyjm/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-True-True] Load agent from /tmp/tmpzc9r_fyf/agent_final
PASSED

=============================== warnings summary ===============================
tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-False-False]
  /local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/ppo.py:132: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)
    actions = torch.tensor([b["action"] for b in dataset], device=device)

tests/agents_tests/test_trpo.py: 96 warnings
  /local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:133: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
    torch.load(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================= 96 passed, 97 warnings in 13.75s =======================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/pfrl/pfrl/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/pfrl/pfrl
configfile: pytest.ini
collecting ... collected 96 items

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-False-False] Load agent from /tmp/tmpr_dila6l/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-False-True] Load agent from /tmp/tmp0gzzl8nr/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-True-False] Load agent from /tmp/tmper1d01k1/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-True-True] Load agent from /tmp/tmpn_g_gu6c/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-False-False] Load agent from /tmp/tmp47kvgcjb/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-False-True] Load agent from /tmp/tmp_9zfcr2j/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-True-False] Load agent from /tmp/tmp6md6rjzx/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.5-True-True] Load agent from /tmp/tmp68gax053/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-False-False] Load agent from /tmp/tmpmrzebjev/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-False-True] Load agent from /tmp/tmp4o4x87iy/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-True-False] Load agent from /tmp/tmpnflnuwnh/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-1.0-True-True] Load agent from /tmp/tmp623ayuzs/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-False-False] Load agent from /tmp/tmpvduqhv46/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-False-True] Load agent from /tmp/tmpbyb95qz9/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-True-False] Load agent from /tmp/tmpfzs3ao7e/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.0-True-True] Load agent from /tmp/tmpnirsoobx/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-False-False] Load agent from /tmp/tmp87ts2tvt/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-False-True] Load agent from /tmp/tmp5aqn2lz_/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-True-False] Load agent from /tmp/tmp32b6_qby/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-0.5-True-True] Load agent from /tmp/tmpubkyukux/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-False-False] Load agent from /tmp/tmpd89j9d3a/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-False-True] Load agent from /tmp/tmp3b0bk0ui/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-True-False] Load agent from /tmp/tmp1wify80c/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-1e-05-1.0-True-True] Load agent from /tmp/tmpgebcpg5x/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-False-False] Load agent from /tmp/tmpiw8n4y_0/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-False-True] Load agent from /tmp/tmp7vln8bou/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-True-False] Load agent from /tmp/tmpe9xxybwz/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.0-True-True] Load agent from /tmp/tmpq4mqrphu/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-False-False] Load agent from /tmp/tmpsf20x2hy/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-False-True] Load agent from /tmp/tmpmhsrci53/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-True-False] Load agent from /tmp/tmpo_g6wp0g/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-0.5-True-True] Load agent from /tmp/tmpnfpxr4xn/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-False-False] Load agent from /tmp/tmppnihh4hd/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-False-True] Load agent from /tmp/tmp_tt1n2p7/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-True-False] Load agent from /tmp/tmpon3nw3a7/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-0.0-1.0-True-True] Load agent from /tmp/tmpvu0ppo46/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-False-False] Load agent from /tmp/tmpx8mt3if4/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-False-True] Load agent from /tmp/tmptwkqg_w_/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-True-False] Load agent from /tmp/tmp0u51tblw/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.0-True-True] Load agent from /tmp/tmpgi85iyjy/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-False-False] Load agent from /tmp/tmp6bxucktf/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-False-True] Load agent from /tmp/tmpf3qynie3/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-True-False] Load agent from /tmp/tmpr8dicybn/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-0.5-True-True] Load agent from /tmp/tmpn7hkadyy/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-False-False] Load agent from /tmp/tmpqywgp14h/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-False-True] Load agent from /tmp/tmp0wi_u0pq/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-True-False] Load agent from /tmp/tmp0l14g0f9/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-True-1e-05-1.0-True-True] Load agent from /tmp/tmp_74t6hcn/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-False-False] Load agent from /tmp/tmpiwl74gze/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-False-True] Load agent from /tmp/tmp_nusl7ma/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-True-False] Load agent from /tmp/tmphdz5yehx/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.0-True-True] Load agent from /tmp/tmp5et1nxac/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-False-False] Load agent from /tmp/tmpldqgt4q2/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-False-True] Load agent from /tmp/tmprex_hh_j/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-True-False] Load agent from /tmp/tmpgamz41e9/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-0.5-True-True] Load agent from /tmp/tmpa87yqs5w/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-False-False] Load agent from /tmp/tmph2f386nk/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-False-True] Load agent from /tmp/tmp0c7fnz86/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-True-False] Load agent from /tmp/tmposkkudgq/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-0.0-1.0-True-True] Load agent from /tmp/tmpclj0ygs7/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-False-False] Load agent from /tmp/tmpn7o6oiux/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-False-True] Load agent from /tmp/tmpuoutcphj/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-True-False] Load agent from /tmp/tmpe67k31m5/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.0-True-True] Load agent from /tmp/tmpkhef43ys/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-False-False] Load agent from /tmp/tmpp1g7e8we/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-False-True] Load agent from /tmp/tmpn1tk00ko/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-True-False] Load agent from /tmp/tmp789s7tbw/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-0.5-True-True] Load agent from /tmp/tmp3mq0wrrq/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-False-False] Load agent from /tmp/tmpovangvb0/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-False-True] Load agent from /tmp/tmp85h5awph/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-True-False] Load agent from /tmp/tmpgzqqbly1/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-False-1e-05-1.0-True-True] Load agent from /tmp/tmpxpjlyo0f/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-False-False] Load agent from /tmp/tmp72s7k84n/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-False-True] Load agent from /tmp/tmp_j2xn6pb/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-True-False] Load agent from /tmp/tmpgqr4659o/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.0-True-True] Load agent from /tmp/tmpku_hrp3u/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-False-False] Load agent from /tmp/tmpzmwbpw3z/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-False-True] Load agent from /tmp/tmpb5c_o79y/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-True-False] Load agent from /tmp/tmpqlvfblag/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-0.5-True-True] Load agent from /tmp/tmp8ol907ud/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-False-False] Load agent from /tmp/tmp3hn64pyt/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-False-True] Load agent from /tmp/tmpxyguq1b8/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-True-False] Load agent from /tmp/tmpiqiy_6z9/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-0.0-1.0-True-True] Load agent from /tmp/tmpgjw675le/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-False-False] Load agent from /tmp/tmpq63946ji/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-False-True] Load agent from /tmp/tmph3rzta5a/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-True-False] Load agent from /tmp/tmpr6rfjm5c/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.0-True-True] Load agent from /tmp/tmpo5e8rpj7/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-False-False] Load agent from /tmp/tmp_a3dd1hc/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-False-True] Load agent from /tmp/tmpxy_6bvav/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-True-False] Load agent from /tmp/tmpcwlvl62r/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-0.5-True-True] Load agent from /tmp/tmp3uoe8qmr/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-False-False] Load agent from /tmp/tmpokvb1w0w/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-False-True] Load agent from /tmp/tmpeixag34g/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-True-False] Load agent from /tmp/tmp78byfx8d/agent_final
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[True-True-1e-05-1.0-True-True] Load agent from /tmp/tmpxgwu1ub4/agent_final
PASSED

=============================== warnings summary ===============================
tests/agents_tests/test_trpo.py::TestTRPONonRecurrent::test_abc_cpu[False-False-0.0-0.0-False-False]
  /local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/ppo.py:132: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)
    actions = torch.tensor([b["action"] for b in dataset], device=device)

tests/agents_tests/test_trpo.py: 96 warnings
  /local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agent.py:133: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
    torch.load(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================= 96 passed, 97 warnings in 19.96s =======================
