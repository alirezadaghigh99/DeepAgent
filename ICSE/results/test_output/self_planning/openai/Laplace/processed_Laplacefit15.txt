output file:
processed_Laplacefit15.json
function:
fit
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification]'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/Laplace/Laplace/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/Laplace/Laplace
configfile: pyproject.toml
plugins: mock-3.14.0, cov-6.0.0
collecting ... collected 212 items

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED

=================================== FAILURES ===================================
___________ test_laplace_init_prior_mean_and_scatter[FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1081f1d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_laplace_init_prior_mean_and_scatter(laplace, model, class_loader):
        lap_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=1.0,
        )
        assert torch.allclose(lap_scalar_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1),
        )
        assert torch.allclose(lap_tensor_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1)[0],
        )
        assert torch.allclose(lap_tensor_scalar_mean.prior_mean, torch.tensor(1.0))
        lap_tensor_full_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(20 * 2 + 2),
        )
        assert torch.allclose(lap_tensor_full_mean.prior_mean, torch.ones(20 * 2 + 2))
    
        lap_scalar_mean.fit(class_loader)
        lap_tensor_mean.fit(class_loader)
        lap_tensor_scalar_mean.fit(class_loader)
        lap_tensor_full_mean.fit(class_loader)
        expected = lap_scalar_mean.scatter
        assert expected.ndim == 0
        assert torch.allclose(lap_tensor_mean.scatter, expected)
        assert lap_tensor_mean.scatter.shape == expected.shape
        assert torch.allclose(lap_tensor_scalar_mean.scatter, expected)
        assert lap_tensor_scalar_mean.scatter.shape == expected.shape
>       assert torch.allclose(lap_tensor_full_mean.scatter, expected)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e19fea1d0>

    @property
    def scatter(self) -> torch.Tensor:
        """Computes the _scatter_, a term of the log marginal likelihood that
        corresponds to L-2 regularization:
        `scatter` = \\((\\theta_{MAP} - \\mu_0)^{T} P_0 (\\theta_{MAP} - \\mu_0) \\).
    
        Returns
        -------
        scatter: torch.Tensor
        """
>       delta = self.mean - self.prior_mean
E       RuntimeError: The size of tensor a (122) must match the size of tensor b (42) at non-singleton dimension 0

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:943: RuntimeError
___________ test_laplace_init_prior_mean_and_scatter[KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10375490>

    @pytest.mark.parametrize("laplace", flavors)
    def test_laplace_init_prior_mean_and_scatter(laplace, model, class_loader):
        lap_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=1.0,
        )
        assert torch.allclose(lap_scalar_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1),
        )
        assert torch.allclose(lap_tensor_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1)[0],
        )
        assert torch.allclose(lap_tensor_scalar_mean.prior_mean, torch.tensor(1.0))
        lap_tensor_full_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(20 * 2 + 2),
        )
        assert torch.allclose(lap_tensor_full_mean.prior_mean, torch.ones(20 * 2 + 2))
    
        lap_scalar_mean.fit(class_loader)
        lap_tensor_mean.fit(class_loader)
        lap_tensor_scalar_mean.fit(class_loader)
        lap_tensor_full_mean.fit(class_loader)
        expected = lap_scalar_mean.scatter
        assert expected.ndim == 0
        assert torch.allclose(lap_tensor_mean.scatter, expected)
        assert lap_tensor_mean.scatter.shape == expected.shape
        assert torch.allclose(lap_tensor_scalar_mean.scatter, expected)
        assert lap_tensor_scalar_mean.scatter.shape == expected.shape
>       assert torch.allclose(lap_tensor_full_mean.scatter, expected)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.KronLLLaplace object at 0x7a4e109fe250>

    @property
    def scatter(self) -> torch.Tensor:
        """Computes the _scatter_, a term of the log marginal likelihood that
        corresponds to L-2 regularization:
        `scatter` = \\((\\theta_{MAP} - \\mu_0)^{T} P_0 (\\theta_{MAP} - \\mu_0) \\).
    
        Returns
        -------
        scatter: torch.Tensor
        """
>       delta = self.mean - self.prior_mean
E       RuntimeError: The size of tensor a (122) must match the size of tensor b (42) at non-singleton dimension 0

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:943: RuntimeError
___________ test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e109ff010>

    @pytest.mark.parametrize("laplace", flavors)
    def test_laplace_init_prior_mean_and_scatter(laplace, model, class_loader):
        lap_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=1.0,
        )
        assert torch.allclose(lap_scalar_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1),
        )
        assert torch.allclose(lap_tensor_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1)[0],
        )
        assert torch.allclose(lap_tensor_scalar_mean.prior_mean, torch.tensor(1.0))
        lap_tensor_full_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(20 * 2 + 2),
        )
        assert torch.allclose(lap_tensor_full_mean.prior_mean, torch.ones(20 * 2 + 2))
    
        lap_scalar_mean.fit(class_loader)
        lap_tensor_mean.fit(class_loader)
        lap_tensor_scalar_mean.fit(class_loader)
        lap_tensor_full_mean.fit(class_loader)
        expected = lap_scalar_mean.scatter
        assert expected.ndim == 0
        assert torch.allclose(lap_tensor_mean.scatter, expected)
        assert lap_tensor_mean.scatter.shape == expected.shape
        assert torch.allclose(lap_tensor_scalar_mean.scatter, expected)
        assert lap_tensor_scalar_mean.scatter.shape == expected.shape
>       assert torch.allclose(lap_tensor_full_mean.scatter, expected)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10bdb390>

    @property
    def scatter(self) -> torch.Tensor:
        """Computes the _scatter_, a term of the log marginal likelihood that
        corresponds to L-2 regularization:
        `scatter` = \\((\\theta_{MAP} - \\mu_0)^{T} P_0 (\\theta_{MAP} - \\mu_0) \\).
    
        Returns
        -------
        scatter: torch.Tensor
        """
>       delta = self.mean - self.prior_mean
E       RuntimeError: The size of tensor a (122) must match the size of tensor b (42) at non-singleton dimension 0

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:943: RuntimeError
__ test_laplace_functionality[pick_first-False-FullLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1038f9d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1038c3d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1038c690>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1038c250>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e1038d810>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____ test_laplace_functionality[pick_first-False-FullLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10851590>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10851cd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e108514d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10853990>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e108530d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__ test_laplace_functionality[pick_first-False-KronLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10808590>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10808190>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1080a750>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1080aa90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____ test_laplace_functionality[pick_first-False-KronLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10399a50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10399490>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10399b90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10398890>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__ test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1038ef50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1038fed0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1038d950>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1038c8d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e1038f390>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____ test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e103a7250>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e103a7690>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e103a6950>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e103a4a90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e103a7d90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___ test_laplace_functionality[pick_first-True-FullLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10bee1d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10bedc10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10bed210>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10befe90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10bed6d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[pick_first-True-FullLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1038f710>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1038cd10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1038fed0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1038c9d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e1038c750>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___ test_laplace_functionality[pick_first-True-KronLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1083ae50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10838190>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e108394d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10839250>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[pick_first-True-KronLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10305190>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10307990>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10305c10>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10306590>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___ test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10bed210>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10bef950>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10bed590>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10bee790>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10810210>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1035b2d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10358750>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1035bbd0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10358250>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10359350>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___ test_laplace_functionality[pick_last-False-FullLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10af2b90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10af3a90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10af3ad0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10af0f10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10af3950>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[pick_last-False-FullLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4f319ad850>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4f319aedd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4f319af490>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4f319ae490>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4f319af110>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___ test_laplace_functionality[pick_last-False-KronLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1035bb50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10358790>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10359350>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10358cd0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[pick_last-False-KronLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e106cd750>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e106ceb50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e106cec50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e106cffd0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___ test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1081c750>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1081ec50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1081dc90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1081e410>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e1081fdd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e109094d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10908210>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e109095d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1090ac10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10908990>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___ test_laplace_functionality[pick_last-True-FullLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1080b650>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1080b090>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1080a750>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10808990>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e1080a310>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[pick_last-True-FullLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10666a90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10666d50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10667850>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10664a90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e106641d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___ test_laplace_functionality[pick_last-True-KronLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10909290>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e109084d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10908390>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10908f10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[pick_last-True-KronLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e103bc1d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e103bc290>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e103bc250>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e103bc650>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___ test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e106017d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10601810>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10603e10>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e106036d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10602cd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10909190>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10909150>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1090b110>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10909210>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10909250>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____ test_laplace_functionality[average-False-FullLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1091e610>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1091de10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1091db10>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1091e510>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e1091dfd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______ test_laplace_functionality[average-False-FullLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e103bfb90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e103bcdd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e103be790>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e103bd710>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e103bd6d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____ test_laplace_functionality[average-False-KronLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1099b190>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1099b310>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10998310>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10998b50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______ test_laplace_functionality[average-False-KronLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10be03d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10be1990>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10be06d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10944b90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____ test_laplace_functionality[average-False-DiagLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10665e50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10664bd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10664690>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10664e10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e106654d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______ test_laplace_functionality[average-False-DiagLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1067ff50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1067d710>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1067f4d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1067f110>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e1067fd90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____ test_laplace_functionality[average-True-FullLLLaplace-classification] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e106abb50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e106a8f50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e106a8850>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e106aa190>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e106a9750>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______ test_laplace_functionality[average-True-FullLLLaplace-regression] _______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10908a10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10909090>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10908210>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10908490>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e109fd790>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____ test_laplace_functionality[average-True-KronLLLaplace-classification] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10667f10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e106669d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10666810>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10667310>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______ test_laplace_functionality[average-True-KronLLLaplace-regression] _______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1082a3d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1082aed0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1082a810>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1082a550>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____ test_laplace_functionality[average-True-DiagLLLaplace-classification] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e109fd490>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e109fd410>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10908a90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10909250>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e109090d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______ test_laplace_functionality[average-True-DiagLLLaplace-regression] _______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10813e90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e108104d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10813550>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10813d50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10811dd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[None-False-FullLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10358450>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10358a10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1035bb90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10359e10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e1035b3d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_______ test_laplace_functionality[None-False-FullLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10929890>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10928c10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10928590>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e109fcd90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10bdb710>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[None-False-KronLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1080b590>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10809390>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10809a90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1080b290>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_______ test_laplace_functionality[None-False-KronLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1067ad10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1067b5d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1067a5d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10678d10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[None-False-DiagLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e109fdb90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e109fcd90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e109fd790>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1092a0d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e109289d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_______ test_laplace_functionality[None-False-DiagLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1080a850>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10809f90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e108098d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e108086d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10809a90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______ test_laplace_functionality[None-True-FullLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10986950>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10987910>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10987450>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10987490>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10985d10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_laplace_functionality[None-True-FullLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1032e250>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1032f3d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1032f250>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1032c090>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e1032ef50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______ test_laplace_functionality[None-True-KronLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10986b90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10987c50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10985d10>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e3e482810>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_laplace_functionality[None-True-KronLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10660890>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e106614d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10661310>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10661450>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______ test_laplace_functionality[None-True-DiagLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e106792d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1067a350>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10678710>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1067bc10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e1067a7d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_laplace_functionality[None-True-DiagLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10358750>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1035b810>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1091f310>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10985910>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10987690>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________________ test_regression_predictive[FullLLLaplace] ___________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10307590>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:474: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10304050>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________________ test_regression_predictive[KronLLLaplace] ___________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1099ae10>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:474: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________________ test_regression_predictive[DiagLLLaplace] ___________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1065afd0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:474: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e1065aed0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________________ test_classification_predictive[FullLLLaplace] _________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10bda190>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:498: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10986b50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________________ test_classification_predictive[KronLLLaplace] _________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10314950>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:498: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________________ test_classification_predictive[DiagLLLaplace] _________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e106b5150>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:498: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e106b5790>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_regression_predictive_samples[FullLLLaplace] _______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10986b90>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive_samples(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10987450>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_regression_predictive_samples[KronLLLaplace] _______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10af2390>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive_samples(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_regression_predictive_samples[DiagLLLaplace] _______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e108e1d50>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive_samples(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e108e3310>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_classification_predictive_samples[FullLLLaplace] _____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1038c250>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive_samples(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e1038e1d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_classification_predictive_samples[KronLLLaplace] _____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10af3190>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive_samples(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_classification_predictive_samples[DiagLLLaplace] _____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10616b90>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive_samples(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10617250>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________________ test_functional_variance_fast[FullLLLaplace] _________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e106b5850>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, DiagLLLaplace, KronLLLaplace])
    def test_functional_variance_fast(laplace, model, reg_loader):
        if laplace == KronLLLaplace:
            # TODO still!
            return
    
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:588: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e106b6750>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________________ test_functional_variance_fast[DiagLLLaplace] _________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10af3790>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, DiagLLLaplace, KronLLLaplace])
    def test_functional_variance_fast(laplace, model, reg_loader):
        if laplace == KronLLLaplace:
            # TODO still!
            return
    
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:588: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10af2050>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_______________________ test_backprop_glm[FullLLLaplace] _______________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1064a810>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:614: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10649b90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_______________________ test_backprop_glm[KronLLLaplace] _______________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e103bd1d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:614: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_______________________ test_backprop_glm[DiagLLLaplace] _______________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10af19d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:614: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e1087e790>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________________ test_backprop_glm_joint[FullLLLaplace] ____________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10999ad0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_joint(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e1099b610>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________________ test_backprop_glm_joint[KronLLLaplace] ____________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1067ac10>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_joint(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________________ test_backprop_glm_joint[DiagLLLaplace] ____________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e108e1fd0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_joint(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e108e1b50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________________ test_backprop_glm_mc[FullLLLaplace] ______________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10af0e10>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_mc(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:652: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10987310>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________________ test_backprop_glm_mc[KronLLLaplace] ______________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e108e0c10>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_mc(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:652: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________________ test_backprop_glm_mc[DiagLLLaplace] ______________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e106bb4d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_mc(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:652: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e106ba290>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_______________________ test_backprop_nn[FullLLLaplace] ________________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e1093d110>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_nn(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:671: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e1093e290>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_______________________ test_backprop_nn[KronLLLaplace] ________________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e106aa690>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_nn(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:671: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_______________________ test_backprop_nn[DiagLLLaplace] ________________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e103147d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_nn(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:671: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10317790>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_reg_glm_predictive_correct_behavior[FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10666650>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, KronLLLaplace, DiagLLLaplace])
    def test_reg_glm_predictive_correct_behavior(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        n_batch = X.shape[0]
        n_outputs = y.shape[-1]
    
        lap = laplace(model, "regression")
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:691: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10666990>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_reg_glm_predictive_correct_behavior[KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10af3ad0>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, KronLLLaplace, DiagLLLaplace])
    def test_reg_glm_predictive_correct_behavior(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        n_batch = X.shape[0]
        n_outputs = y.shape[-1]
    
        lap = laplace(model, "regression")
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:691: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_reg_glm_predictive_correct_behavior[DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7a4e10671fd0>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, KronLLLaplace, DiagLLLaplace])
    def test_reg_glm_predictive_correct_behavior(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        n_batch = X.shape[0]
        n_outputs = y.shape[-1]
    
        lap = laplace(model, "regression")
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:691: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10672350>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10317610>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e106eb0d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10852410>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10667ed0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10314bd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10667290>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e1099a490>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e1093e090>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e1032f5d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10659c10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e1083a610>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e1065c490>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10838390>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10649110>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e1083bdd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10677010>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10343610>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e106facd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e103f8a90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e1063edd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e103fb1d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10340090>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e103c81d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10340c90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10601750>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e1093ef90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10600890>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e0f9537d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10342490>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10304d50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e106032d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e0f953610>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e106a8550>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e106d3690>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10868a10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10974e50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10829910>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e109daed0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________ test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10828ad0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________ test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________ test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e0f9b2110>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e106b6550>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e106c0d90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e106faf90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e0f966a50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10304a90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e0f9ac090>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e106c1990>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e1065b5d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10869fd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10659b90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________ test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e1086bb10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________ test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________ test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10869b90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10617dd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10828c10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e106d0b50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e1032df50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e108e2cd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e0f956610>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e1097dbd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e0f9f6310>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e106c3150>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e0f92c890>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________ test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e10601c50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________ test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________ test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e0f9132d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e1067dc50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e0f9ac110>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e0f90bf50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e1097f750>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e0f909e90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e0f90bd50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7a4e106a6290>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7a4e10376450>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION = LooseVersion(version("torch"))

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION_AT_LEAST_1_12_0 = TORCH_VERSION >= LooseVersion("1.12.0")

tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace]
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/curvlinops/_base.py:299: UserWarning: Input matrix is float64, while linear operator is float32. Converting to float32.
    warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace]
================= 188 failed, 24 passed, 3 warnings in 21.25s ==================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/Laplace/Laplace/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/Laplace/Laplace
configfile: pyproject.toml
plugins: mock-3.14.0, cov-6.0.0
collecting ... collected 212 items

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED

=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION = LooseVersion(version("torch"))

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION_AT_LEAST_1_12_0 = TORCH_VERSION >= LooseVersion("1.12.0")

tests/test_lllaplace.py: 27 warnings
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/curvlinops/_base.py:299: UserWarning: Input matrix is float64, while linear operator is float32. Converting to float32.
    warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================= 212 passed, 29 warnings in 63.91s (0:01:03) ==================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/Laplace/Laplace/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/Laplace/Laplace
configfile: pyproject.toml
plugins: mock-3.14.0, cov-6.0.0
collecting ... collected 212 items

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED

=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION = LooseVersion(version("torch"))

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION_AT_LEAST_1_12_0 = TORCH_VERSION >= LooseVersion("1.12.0")

tests/test_lllaplace.py: 27 warnings
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/curvlinops/_base.py:299: UserWarning: Input matrix is float64, while linear operator is float32. Converting to float32.
    warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================= 212 passed, 29 warnings in 64.73s (0:01:04) ==================
