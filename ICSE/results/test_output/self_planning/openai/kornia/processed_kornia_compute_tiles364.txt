output file:
processed_kornia_compute_tiles364.json
function:
_compute_tiles
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] FAILED'}

All Test Cases On Generated code:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'cudagraphs', None, 'onnxrt', 'openxla', 'tvm', 'inductor', 'jit'}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 25 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[0-1.0-grid0-ValueError-Invalid input tensor, it is empty.] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_type PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_jit[cpu-float32] SKIPPED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_module PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] FAILED

=================================== FAILURES ===================================
___________________ TestEqualization.test_smoke[cpu-float32] ___________________

self = <test_equalization.TestEqualization object at 0x7b5d6ed35780>
device = device(type='cpu'), dtype = torch.float32

    def test_smoke(self, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[0.2202, 0.6799],
            [0.8006, 0.9566]]],


          [[[0.8584, 0.1993],
            [0.7178, 0.9... [[[0.0000, 0.0000],
            [0.0000, 0.0000]]],


          [[[0.0000, 0.0000],
            [0.0000, 0.0000]]]]]])
num_bins = 256, clip = 40.0, diff = False

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
____________ TestEqualization.test_cardinality[cpu-float32-None-1] _____________

self = <test_equalization.TestEqualization object at 0x7b5d6ed35c30>, B = None
C = 1, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[0.2958, 0.9601],
            [0.8963, 0.8781]]],


          [[[0.3522, 0.8032],
            [0.3755, 0.8... [[[0.0000, 0.0000],
            [0.0000, 0.0000]]],


          [[[0.0000, 0.0000],
            [0.0000, 0.0000]]]]]])
num_bins = 256, clip = 40.0, diff = False

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
____________ TestEqualization.test_cardinality[cpu-float32-None-3] _____________

self = <test_equalization.TestEqualization object at 0x7b5d6ed35b70>, B = None
C = 3, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[0.3054, 0.4647],
            [0.2111, 0.6693]],

           [[0.2818, 0.5463],
            [0.7963, 0.806...    [[0.0000, 0.0000],
            [0.0000, 0.0000]],

           [[0.0000, 0.0000],
            [0.0000, 0.0000]]]]]])
num_bins = 256, clip = 40.0, diff = False

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
______________ TestEqualization.test_cardinality[cpu-float32-1-1] ______________

self = <test_equalization.TestEqualization object at 0x7b5d6ed35ff0>, B = 1
C = 1, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[0.3414, 0.4893],
            [0.3852, 0.0224]]],


          [[[0.3543, 0.7378],
            [0.8120, 0.5... [[[0.0000, 0.0000],
            [0.0000, 0.0000]]],


          [[[0.0000, 0.0000],
            [0.0000, 0.0000]]]]]])
num_bins = 256, clip = 40.0, diff = False

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
______________ TestEqualization.test_cardinality[cpu-float32-1-3] ______________

self = <test_equalization.TestEqualization object at 0x7b5d6ed360b0>, B = 1
C = 3, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[0.4511, 0.3012],
            [0.1411, 0.3288]],

           [[0.8754, 0.2361],
            [0.8339, 0.684...    [[0.0000, 0.0000],
            [0.0000, 0.0000]],

           [[0.0000, 0.0000],
            [0.0000, 0.0000]]]]]])
num_bins = 256, clip = 40.0, diff = False

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
______________ TestEqualization.test_cardinality[cpu-float32-4-1] ______________

self = <test_equalization.TestEqualization object at 0x7b5d6ed36170>, B = 4
C = 1, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[0.1037, 0.9792],
            [0.8426, 0.2660]]],


          [[[0.2770, 0.6220],
            [0.7119, 0.7... [[[0.0000, 0.0000],
            [0.0000, 0.0000]]],


          [[[0.0000, 0.0000],
            [0.0000, 0.0000]]]]]])
num_bins = 256, clip = 40.0, diff = False

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
______________ TestEqualization.test_cardinality[cpu-float32-4-3] ______________

self = <test_equalization.TestEqualization object at 0x7b5d6ed36230>, B = 4
C = 3, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[0.5048, 0.3068],
            [0.5957, 0.7682]],

           [[0.3094, 0.3902],
            [0.8996, 0.738...    [[0.0000, 0.0000],
            [0.0000, 0.0000]],

           [[0.0000, 0.0000],
            [0.0000, 0.0000]]]]]])
num_bins = 256, clip = 40.0, diff = False

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
_________ TestEqualization.test_optional_params[cpu-float32-0.0-None] __________

self = <test_equalization.TestEqualization object at 0x7b5d6ed365c0>, clip = 0.0
grid = None, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("clip, grid", [(0.0, None), (None, (2, 2)), (2.0, (2, 2))])
    def test_optional_params(self, clip, grid, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
        if clip is None:
            res = enhance.equalize_clahe(img, grid_size=grid)
        elif grid is None:
>           res = enhance.equalize_clahe(img, clip_limit=clip)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:39: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[0.0616, 0.6222],
            [0.6135, 0.6730]]],


          [[[0.0724, 0.0255],
            [0.2193, 0.7... [[[0.0000, 0.0000],
            [0.0000, 0.0000]]],


          [[[0.0000, 0.0000],
            [0.0000, 0.0000]]]]]])
num_bins = 256, clip = 0.0, diff = False

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
________ TestEqualization.test_optional_params[cpu-float32-None-grid1] _________

self = <test_equalization.TestEqualization object at 0x7b5d6ed36500>
clip = None, grid = (2, 2), device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("clip, grid", [(0.0, None), (None, (2, 2)), (2.0, (2, 2))])
    def test_optional_params(self, clip, grid, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
        if clip is None:
>           res = enhance.equalize_clahe(img, grid_size=grid)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[0.3920, 0.9822, 0.8737, 0.3958, 0.5265, 0.8423, 0.6873, 0.4455,
             0.8788, 0.4248],
           ....0000],
            [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
             0.0000, 0.0000]]]]]])
num_bins = 256, clip = 40.0, diff = False

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
_________ TestEqualization.test_optional_params[cpu-float32-2.0-grid2] _________

self = <test_equalization.TestEqualization object at 0x7b5d6ed36860>, clip = 2.0
grid = (2, 2), device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("clip, grid", [(0.0, None), (None, (2, 2)), (2.0, (2, 2))])
    def test_optional_params(self, clip, grid, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
        if clip is None:
            res = enhance.equalize_clahe(img, grid_size=grid)
        elif grid is None:
            res = enhance.equalize_clahe(img, clip_limit=clip)
        else:
>           res = enhance.equalize_clahe(img, clip, grid)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[0.1717, 0.0723, 0.6454, 0.2538, 0.4277, 0.2696, 0.9964, 0.3086,
             0.4243, 0.5681],
           ....0000],
            [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
             0.0000, 0.0000]]]]]])
num_bins = 256, clip = 2.0, diff = False

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
______________ TestEqualization.test_exception_tensor_dims[dims0] ______________

self = <test_equalization.TestEqualization object at 0x7b5d6ed37250>
dims = (1, 1, 1, 1, 1)

    @pytest.mark.parametrize("dims", [(1, 1, 1, 1, 1), (1, 1)])
    def test_exception_tensor_dims(self, dims):
        img = torch.rand(dims)
        with pytest.raises(ValueError):
>           enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:245: in equalize_clahe
    hist_tiles, img_padded = _compute_tiles(imgs, grid_size, True)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:12: in _compute_tiles
    return _compute_tiles(imgs, grid_size, even_tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

images = tensor([[[[0.9549]]]]), grid_size = (8, 8), even_tile_size = True

    def _compute_tiles(images, grid_size, even_tile_size=False):
        B, C, H, W = images.shape
        GH, GW = grid_size
        TH = H // GH
        TW = W // GW
        if even_tile_size:
            if TH % 2 != 0:
                TH += 1
            if TW % 2 != 0:
                TW += 1
        pad_h = GH * TH - H if GH * TH > H else 0
        pad_w = GW * TW - W if GW * TW > W else 0
        padded_images = F.pad(images, (0, pad_w, 0, pad_h))
        padded_H, padded_W = (padded_images.shape[2], padded_images.shape[3])
        if GH * TH > padded_H or GW * TW > padded_W:
            raise ValueError('Grid size exceeds image dimensions after padding.')
>       tiles = padded_images.unfold(2, TH, TH).unfold(3, TW, TW)
E       RuntimeError: step is 0 but must be > 0

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:27: RuntimeError
______________ TestEqualization.test_exception_tensor_dims[dims1] ______________

self = <test_equalization.TestEqualization object at 0x7b5d6ed37310>
dims = (1, 1)

    @pytest.mark.parametrize("dims", [(1, 1, 1, 1, 1), (1, 1)])
    def test_exception_tensor_dims(self, dims):
        img = torch.rand(dims)
        with pytest.raises(ValueError):
>           enhance.equalize_clahe(img)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:245: in equalize_clahe
    hist_tiles, img_padded = _compute_tiles(imgs, grid_size, True)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:12: in _compute_tiles
    return _compute_tiles(imgs, grid_size, even_tile_size)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

images = tensor([[[[0.5844]]]]), grid_size = (8, 8), even_tile_size = True

    def _compute_tiles(images, grid_size, even_tile_size=False):
        B, C, H, W = images.shape
        GH, GW = grid_size
        TH = H // GH
        TW = W // GW
        if even_tile_size:
            if TH % 2 != 0:
                TH += 1
            if TW % 2 != 0:
                TW += 1
        pad_h = GH * TH - H if GH * TH > H else 0
        pad_w = GW * TW - W if GW * TW > W else 0
        padded_images = F.pad(images, (0, pad_w, 0, pad_h))
        padded_H, padded_W = (padded_images.shape[2], padded_images.shape[3])
        if GH * TH > padded_H or GW * TW > padded_W:
            raise ValueError('Grid size exceeds image dimensions after padding.')
>       tiles = padded_images.unfold(2, TH, TH).unfold(3, TW, TW)
E       RuntimeError: step is 0 but must be > 0

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/temp.py:27: RuntimeError
_____________________ TestEqualization.test_gradcheck[cpu] _____________________

self = <test_equalization.TestEqualization object at 0x7b5d6ed37820>
device = device(type='cpu')

    def test_gradcheck(self, device):
        torch.random.manual_seed(4)
        bs, channels, height, width = 1, 1, 11, 11
        inputs = torch.rand(bs, channels, height, width, device=device, dtype=torch.float64)
    
        def grad_rot(data, a, b, c):
            rot = rotate(data, torch.tensor(30.0, dtype=data.dtype, device=device))
            return enhance.equalize_clahe(rot, a, b, c)
    
>       self.gradcheck(grad_rot, (inputs, 40.0, (2, 2), True), nondet_tol=1e-4)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2074: in _gradcheck_helper
    func_out = func(*tupled_inputs)
/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:80: in grad_rot
    return enhance.equalize_clahe(rot, a, b, c)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[0.0000, 0.0000, 0.1003, 0.2967, 0.6151, 0.3659],
            [0.0234, 0.5070, 0.7737, 0.4968, 0.6719, 0.4...         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]]]],
       dtype=torch.float64, grad_fn=<PermuteBackward0>)
num_bins = 256, clip = 40.0, diff = True

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
____________________ TestEqualization.test_ahe[cpu-float32] ____________________

self = <test_equalization.TestEqualization object at 0x7b5d6ed5c400>
img = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ...         0.4211, 0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895,
           0.8421, 0.8947, 0.9474, 1.0000]]]])

    def test_ahe(self, img):
        clip_limit: float = 0.0
        grid_size: Tuple = (8, 8)
>       res = enhance.equalize_clahe(img, clip_limit=clip_limit, grid_size=grid_size)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[0.0000, 0.0526],
            [0.0000, 0.0526]]],


          [[[0.1053, 0.1579],
            [0.1053, 0.1... [[[0.8421, 0.8947],
            [0.8421, 0.8947]]],


          [[[0.9474, 1.0000],
            [0.9474, 1.0000]]]]]])
num_bins = 256, clip = 0.0, diff = False

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
___________________ TestEqualization.test_clahe[cpu-float32] ___________________

self = <test_equalization.TestEqualization object at 0x7b5d6ed5c760>
img = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ...         0.4211, 0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895,
           0.8421, 0.8947, 0.9474, 1.0000]]]])

    def test_clahe(self, img):
        clip_limit: float = 2.0
        grid_size: Tuple = (8, 8)
>       res = enhance.equalize_clahe(img, clip_limit=clip_limit, grid_size=grid_size)

/local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:248: in equalize_clahe
    luts: torch.Tensor = _compute_luts(hist_tiles, clip=clip_limit, diff=slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tiles_x_im = tensor([[[[[[0.0000, 0.0526],
            [0.0000, 0.0526]]],


          [[[0.1053, 0.1579],
            [0.1053, 0.1... [[[0.8421, 0.8947],
            [0.8421, 0.8947]]],


          [[[0.9474, 1.0000],
            [0.9474, 1.0000]]]]]])
num_bins = 256, clip = 2.0, diff = False

    def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int=256, clip: float=40.0, diff: bool=False) -> torch.Tensor:
        """Compute luts for a batched set of tiles.
    
        Same approach as in OpenCV (https://github.com/opencv/opencv/blob/master/modules/imgproc/src/clahe.cpp)
    
        Args:
            tiles_x_im: set of tiles per image to apply the lut. (B, GH, GW, C, TH, TW)
            num_bins: number of bins. default: 256
            clip: threshold value for contrast limiting. If it is 0 then the clipping is disabled.
            diff: denote if the differentiable histagram will be used. Default: False
    
        Returns:
            Lut for each tile (B, GH, GW, C, 256).
        """
        if tiles_x_im.dim() != 6:
            raise AssertionError('Tensor must be 6D.')
        b, gh, gw, c, th, tw = tiles_x_im.shape
        pixels: int = th * tw
>       tiles: torch.Tensor = tiles_x_im.view(-1, pixels)
E       RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/enhance/equalization.py:102: RuntimeError
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32]
=================== 15 failed, 9 passed, 1 skipped in 0.51s ====================


Final Test Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'tvm', 'openxla', 'onnxrt', 'jit', 'inductor', 'cudagraphs', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 25 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[0-1.0-grid0-ValueError-Invalid input tensor, it is empty.] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_type PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_jit[cpu-float32] SKIPPED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_module PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] PASSED

======================== 24 passed, 1 skipped in 0.22s =========================


Initial Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'inductor', 'onnxrt', 'cudagraphs', 'tvm', 'openxla', 'jit', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 25 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[0-1.0-grid0-ValueError-Invalid input tensor, it is empty.] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_type PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_jit[cpu-float32] SKIPPED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_module PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] PASSED

======================== 24 passed, 1 skipped in 0.26s =========================
