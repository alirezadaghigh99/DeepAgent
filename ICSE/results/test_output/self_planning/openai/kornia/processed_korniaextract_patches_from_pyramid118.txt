output file:
processed_korniaextract_patches_from_pyramid118.json
function:
extract_patches_from_pyramid
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_gradcheck[cpu] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_odd[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_even[cpu-float32] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_odd[cpu-float32] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_gradcheck[cpu]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_even[cpu-float32]'}

All Test Cases On Generated code:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'onnxrt', 'tvm', 'jit', 'cudagraphs', None, 'openxla', 'inductor'}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 5 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_shape[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_non_zero[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_odd[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_even[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_gradcheck[cpu] FAILED

=================================== FAILURES ===================================
_______________ TestExtractPatchesPyr.test_same_odd[cpu-float32] _______________

self = <test_laf.TestExtractPatchesPyr object at 0x73dcc075c280>
device = device(type='cpu'), dtype = torch.float32

    def test_same_odd(self, device, dtype):
        img = torch.arange(5)[None].repeat(5, 1)[None, None].to(device, dtype)
        laf = torch.tensor([[2.0, 0, 2.0], [0, 2.0, 2.0]]).reshape(1, 1, 2, 3).to(device, dtype)
    
        patch = kornia.feature.extract_patches_from_pyramid(img, laf, 5, 1.0)
>       self.assert_close(img, patch[0])

/local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py:438: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/testing/base.py:106: in assert_close
    return assert_close(actual, expected, rtol=rtol, atol=atol)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = tensor([[[[0., 1., 2., 3., 4.],
          [0., 1., 2., 3., 4.],
          [0., 1., 2., 3., 4.],
          [0., 1., 2., 3., 4.],
          [0., 1., 2., 3., 4.]]]])
expected = tensor([[[[3., 4., 4., 4., 4.],
          [3., 4., 4., 4., 4.],
          [3., 4., 4., 4., 4.],
          [3., 4., 4., 4., 4.],
          [3., 4., 4., 4., 4.]]]])
rtol = 0.0001, atol = 1e-05, kwargs = {}

    def assert_close(
        actual: Tensor, expected: Tensor, *, rtol: Optional[float] = None, atol: Optional[float] = None, **kwargs: Any
    ) -> None:
        if rtol is None and atol is None:
            # `torch.testing.assert_close` used different default tolerances than `torch.testing.assert_allclose`.
            # TODO: remove this special handling as soon as https://github.com/kornia/kornia/issues/1134 is resolved
            #  Basically, this whole wrapper function can be removed and `torch.testing.assert_close` can be used
            #  directly.
            rtol, atol = _default_tolerances(actual, expected)
    
>       return _assert_close(
            actual,
            expected,
            rtol=rtol,
            atol=atol,
            # this is the default value for torch>=1.10, but not for torch==1.9
            # TODO: remove this if kornia relies on torch>=1.10
            check_stride=False,
            equal_nan=False,
            **kwargs,
        )
E       AssertionError: Tensor-likes are not close!
E       
E       Mismatched elements: 20 / 25 (80.0%)
E       Greatest absolute difference: 3.0 at index (0, 0, 0, 0) (up to 1e-05 allowed)
E       Greatest relative difference: 1.0 at index (0, 0, 0, 0) (up to 0.0001 allowed)

/local/data0/moved_data/publishablew/kornia/kornia/testing/base.py:37: AssertionError
______________ TestExtractPatchesPyr.test_same_even[cpu-float32] _______________

self = <test_laf.TestExtractPatchesPyr object at 0x73dcc075c5b0>
device = device(type='cpu'), dtype = torch.float32

    def test_same_even(self, device, dtype):
        img = torch.arange(4)[None].repeat(4, 1)[None, None].to(device, dtype)
        laf = torch.tensor([[1.5, 0, 1.5], [0, 1.5, 1.5]]).reshape(1, 1, 2, 3).to(device, dtype)
    
        patch = kornia.feature.extract_patches_from_pyramid(img, laf, 4, 1.0)
>       self.assert_close(img, patch[0])

/local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py:445: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/testing/base.py:106: in assert_close
    return assert_close(actual, expected, rtol=rtol, atol=atol)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = tensor([[[[0., 1., 2., 3.],
          [0., 1., 2., 3.],
          [0., 1., 2., 3.],
          [0., 1., 2., 3.]]]])
expected = tensor([[[[2.2500, 3.0000, 3.0000, 3.0000],
          [2.2500, 3.0000, 3.0000, 3.0000],
          [2.2500, 3.0000, 3.0000, 3.0000],
          [2.2500, 3.0000, 3.0000, 3.0000]]]])
rtol = 0.0001, atol = 1e-05, kwargs = {}

    def assert_close(
        actual: Tensor, expected: Tensor, *, rtol: Optional[float] = None, atol: Optional[float] = None, **kwargs: Any
    ) -> None:
        if rtol is None and atol is None:
            # `torch.testing.assert_close` used different default tolerances than `torch.testing.assert_allclose`.
            # TODO: remove this special handling as soon as https://github.com/kornia/kornia/issues/1134 is resolved
            #  Basically, this whole wrapper function can be removed and `torch.testing.assert_close` can be used
            #  directly.
            rtol, atol = _default_tolerances(actual, expected)
    
>       return _assert_close(
            actual,
            expected,
            rtol=rtol,
            atol=atol,
            # this is the default value for torch>=1.10, but not for torch==1.9
            # TODO: remove this if kornia relies on torch>=1.10
            check_stride=False,
            equal_nan=False,
            **kwargs,
        )
E       AssertionError: Tensor-likes are not close!
E       
E       Mismatched elements: 12 / 16 (75.0%)
E       Greatest absolute difference: 2.25 at index (0, 0, 0, 0) (up to 1e-05 allowed)
E       Greatest relative difference: 1.0 at index (0, 0, 0, 0) (up to 0.0001 allowed)

/local/data0/moved_data/publishablew/kornia/kornia/testing/base.py:37: AssertionError
__________________ TestExtractPatchesPyr.test_gradcheck[cpu] ___________________

self = <test_laf.TestExtractPatchesPyr object at 0x73dcc075c880>
device = device(type='cpu')

    def test_gradcheck(self, device):
        nlaf = torch.tensor([[0.1, 0.001, 0.5], [0, 0.1, 0.5]], device=device, dtype=torch.float64)
        nlaf = nlaf.view(1, 1, 2, 3)
        img = torch.rand(1, 3, 20, 30, device=device, dtype=torch.float64)
        PS = 11
>       self.gradcheck(
            kornia.feature.extract_patches_from_pyramid,
            (img, nlaf, PS, False),
            nondet_tol=1e-8,
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py:452: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2081: in _gradcheck_helper
    _gradcheck_real_imag(
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:1491: in _gradcheck_real_imag
    gradcheck_fn(
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:1925: in _fast_gradcheck
    _check_analytical_numerical_equal(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

all_analytical = [[tensor(0.3789, dtype=torch.float64), tensor(0.9959, dtype=torch.float64)]]
all_numerical = [[tensor(0.3789, dtype=torch.float64)], [tensor(0.8850, dtype=torch.float64)]]
complex_indices = None
tupled_inputs = (tensor([[[[0.8029, 0.7773, 0.2405,  ..., 0.2261, 0.0319, 0.5116],
          [0.7885, 0.3435, 0.8087,  ..., 0.9626, 0....[[[0.1000, 0.0010, 0.5000],
          [0.0000, 0.1000, 0.5000]]]], dtype=torch.float64, requires_grad=True), 11, False)
outputs = (tensor([[[[[0.5330, 0.5422, 0.5515, 0.5607, 0.5699, 0.5792, 0.5884, 0.5964,
            0.5951, 0.5937, 0.5924],
    ...5, 0.4775, 0.4845, 0.4912,
            0.4968, 0.5025, 0.5081]]]]], dtype=torch.float64,
       grad_fn=<CopySlices>),)
func = <function extract_patches_from_pyramid at 0x73dd1bd8ecb0>
all_v = [tensor([0.0612, 0.0060, 0.0463, 0.0260, 0.0249, 0.0197, 0.0504, 0.0439, 0.0242,
        0.0573, 0.0456, 0.0671, 0.078... 0.0304, 0.0158, 0.0312, 0.0849, 0.0183, 0.0025, 0.0737, 0.0730,
        0.0849, 0.0166, 0.0042], dtype=torch.float64)]
all_u = [tensor([0.0110, 0.0357, 0.0137,  ..., 0.0238, 0.0246, 0.0390],
       dtype=torch.float64), tensor([0.4991, 0.2874, 0.6391, 0.4893, 0.1150, 0.0850], dtype=torch.float64)]
rtol = 0.001, atol = 1e-05, eps = 1e-06, test_imag = False

    def _check_analytical_numerical_equal(
        all_analytical,
        all_numerical,
        complex_indices,
        tupled_inputs,
        outputs,
        func,
        all_v,
        all_u,
        rtol,
        atol,
        eps,
        test_imag,
        *,
        is_forward_ad=False,
    ):
        for i, all_numerical_for_input_i in enumerate(all_numerical):
            for j, n in enumerate(all_numerical_for_input_i):
                # Forward AD generates the transpose of what this function expects
                if is_forward_ad:
                    a = all_analytical[i][j]
                else:
                    a = all_analytical[j][i]
                n = n.to(device=a.device)
                updated_atol = _adjusted_atol(atol, all_u[i], all_v[j] if all_v else None)
                if not _allclose_with_type_promotion(a, n.to(a.device), rtol, updated_atol):
                    jacobians_str = _run_slow_mode_and_get_error(
                        func, tupled_inputs, outputs, i, j, rtol, atol, eps, is_forward_ad
                    )
>                   raise GradcheckError(
                        _get_notallclose_msg(
                            a, n, j, i, complex_indices, test_imag, is_forward_ad
                        )
                        + jacobians_str
                    )
E                   torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 1,
E                   numerical:tensor(0.8850, dtype=torch.float64)
E                   analytical:tensor(0.9959, dtype=torch.float64)
E                   
E                   The above quantities relating the numerical and analytical jacobians are computed 
E                   in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
E                   about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:
E                   
E                   Numerical:
E                    tensor([[-0.4622, -0.3697, -0.2773,  ...,  0.1686,  0.2248,  0.2810],
E                           [-0.4622, -0.4622, -0.4622,  ...,  0.2810,  0.2810,  0.2810],
E                           [ 0.5084,  0.5084,  0.5084,  ...,  0.3091,  0.3091,  0.3091],
E                           [ 0.4961,  0.5087,  0.4653,  ...,  0.1715,  0.1085, -0.0146],
E                           [ 0.4961,  0.6358,  0.7755,  ...,  0.2859,  0.1357, -0.0146],
E                           [-0.5458, -0.6994, -0.8531,  ...,  0.3145,  0.1492, -0.0160]],
E                          dtype=torch.float64)
E                   Analytical:
E                   tensor([[-0.4622, -0.3697, -0.2773,  ...,  0.1686,  0.2248,  0.2810],
E                           [-0.4622, -0.4622, -0.4622,  ...,  0.2810,  0.2810,  0.2810],
E                           [ 0.5084,  0.5084,  0.5084,  ...,  0.3091,  0.3091,  0.3091],
E                           [ 0.4961,  0.5087,  0.4653,  ...,  0.1715,  0.1085, -0.0146],
E                           [ 0.4961,  0.6358,  0.7755,  ...,  0.2859,  0.1357, -0.0146],
E                           [-0.5458, -0.6994, -0.8531,  ...,  0.3145,  0.1492, -0.0160]],
E                          dtype=torch.float64)
E                   
E                   The max per-element difference (slow mode) is: 1.113254890635541.

/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:1854: GradcheckError
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_odd[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_even[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_gradcheck[cpu]
========================= 3 failed, 2 passed in 1.31s ==========================


Final Test Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'tvm', 'cudagraphs', 'onnxrt', 'inductor', 'jit', 'openxla', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 5 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_shape[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_non_zero[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_odd[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_even[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_gradcheck[cpu] PASSED

============================== 5 passed in 0.16s ===============================


Initial Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'jit', 'onnxrt', 'openxla', 'inductor', 'tvm', 'cudagraphs', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 5 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_shape[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_non_zero[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_odd[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_even[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_gradcheck[cpu] PASSED

============================== 5 passed in 0.17s ===============================
