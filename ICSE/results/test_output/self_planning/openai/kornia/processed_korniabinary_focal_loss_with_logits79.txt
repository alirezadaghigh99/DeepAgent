output file:
processed_korniabinary_focal_loss_with_logits79.json
function:
binary_focal_loss_with_logits
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] FAILED'}

All Test Cases On Generated code:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'tvm', 'cudagraphs', 'jit', 'inductor', 'onnxrt', 'openxla', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 59 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] FAILED

=================================== FAILURES ===================================
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32--100-none] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb320e0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
ignore_index = -100

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6492, 0.2801],
         [0.4980, 0.8321],
         [0.0436, 0.0085]],

        [[0.7571, 0.8785],
         [0.8924, 0.0829],
         [0.0975, 0.6248]]])
target = tensor([[[0.8629, 0.9769],
         [0.5387, 0.1807],
         [0.1505, 0.8510]],

        [[0.4884, 0.7616],
         [0.8454, 0.0419],
         [0.5922, 0.1993]]])
alpha = None, gamma = 0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32--100-mean] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb31f00>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
ignore_index = -100

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5396, 0.3508],
         [0.0096, 0.2850],
         [0.0761, 0.7510]],

        [[0.9518, 0.5291],
         [0.1728, 0.4316],
         [0.9317, 0.4325]]])
target = tensor([[[0.7894, 0.4277],
         [0.1289, 0.2503],
         [0.0995, 0.6303]],

        [[0.7059, 0.7398],
         [0.2686, 0.0959],
         [0.3177, 0.1672]]])
alpha = None, gamma = 0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32--100-sum] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb32380>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
ignore_index = -100

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9716, 0.1765],
         [0.6372, 0.5849],
         [0.0895, 0.1042]],

        [[0.9637, 0.6054],
         [0.3208, 0.9977],
         [0.8245, 0.0305]]])
target = tensor([[[0.7437, 0.8980],
         [0.1589, 0.1740],
         [0.6641, 0.0413]],

        [[0.1955, 0.1301],
         [0.8791, 0.7533],
         [0.9051, 0.1365]]])
alpha = None, gamma = 0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32-None-none] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb32440>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
ignore_index = None

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9246, 0.2447],
         [0.7639, 0.9063],
         [0.5211, 0.4886]],

        [[0.0738, 0.9134],
         [0.6568, 0.7756],
         [0.7880, 0.2982]]])
target = tensor([[[0.7552, 0.9033],
         [0.3949, 0.3289],
         [0.5200, 0.4814]],

        [[0.6349, 0.2061],
         [0.8370, 0.5682],
         [0.5078, 0.3925]]])
alpha = None, gamma = 0, reduction = 'none', pos_weight = None, weight = None
ignore_index = None

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32-None-mean] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb32500>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
ignore_index = None

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0645, 0.2860],
         [0.6838, 0.3279],
         [0.1652, 0.0573]],

        [[0.7057, 0.9251],
         [0.9407, 0.6247],
         [0.3394, 0.7064]]])
target = tensor([[[0.9217, 0.7302],
         [0.5981, 0.6405],
         [0.2229, 0.6953]],

        [[0.0962, 0.5511],
         [0.8634, 0.0336],
         [0.9552, 0.5635]]])
alpha = None, gamma = 0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = None

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32-None-sum] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb325c0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
ignore_index = None

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0427, 0.0725],
         [0.5530, 0.4135],
         [0.2883, 0.3803]],

        [[0.1958, 0.4167],
         [0.3857, 0.0631],
         [0.3302, 0.8529]]])
target = tensor([[[0.6435, 0.8528],
         [0.4651, 0.1992],
         [0.4222, 0.1253]],

        [[0.7398, 0.8694],
         [0.5020, 0.1739],
         [0.3938, 0.7198]]])
alpha = None, gamma = 0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = None

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb32980>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    def test_value_same_as_torch_bce_loss_pos_weight_weight(self, device, dtype, reduction):
        num_classes = 3
        logits = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
        labels = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
    
        pos_weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
        weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, pos_weight=pos_weight, weight=weight
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3029, 0.0942],
         [0.1454, 0.4322],
         [0.2458, 0.6101]],

        [[0.3528, 0.1674],
         [0.5640, 0.7577],
         [0.3260, 0.9119]]])
target = tensor([[[0.5566, 0.2660],
         [0.1466, 0.7267],
         [0.3410, 0.4455]],

        [[0.3587, 0.2289],
         [0.7777, 0.0521],
         [0.4408, 0.6948]]])
alpha = None, gamma = 0, reduction = 'none'
pos_weight = tensor([[0.1767],
        [0.8081],
        [0.4178]])
weight = tensor([[0.7391],
        [0.0736],
        [0.7716]])
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb328c0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    def test_value_same_as_torch_bce_loss_pos_weight_weight(self, device, dtype, reduction):
        num_classes = 3
        logits = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
        labels = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
    
        pos_weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
        weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, pos_weight=pos_weight, weight=weight
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7027, 0.3367],
         [0.5001, 0.3770],
         [0.7363, 0.3247]],

        [[0.7189, 0.9773],
         [0.1838, 0.1450],
         [0.3505, 0.4519]]])
target = tensor([[[0.1525, 0.4980],
         [0.9925, 0.1910],
         [0.0402, 0.2320]],

        [[0.8302, 0.4665],
         [0.8273, 0.2504],
         [0.7813, 0.2040]]])
alpha = None, gamma = 0, reduction = 'mean'
pos_weight = tensor([[0.6809],
        [0.4082],
        [0.4136]])
weight = tensor([[0.4572],
        [0.1916],
        [0.2900]])
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb32bc0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    def test_value_same_as_torch_bce_loss_pos_weight_weight(self, device, dtype, reduction):
        num_classes = 3
        logits = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
        labels = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
    
        pos_weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
        weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, pos_weight=pos_weight, weight=weight
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3935, 0.4702],
         [0.8164, 0.8416],
         [0.5793, 0.8962]],

        [[0.6865, 0.8220],
         [0.1431, 0.0380],
         [0.2515, 0.1180]]])
target = tensor([[[0.0775, 0.7316],
         [0.4973, 0.3916],
         [0.5471, 0.4060]],

        [[0.4891, 0.8672],
         [0.5916, 0.3381],
         [0.1090, 0.3090]]])
alpha = None, gamma = 0, reduction = 'sum'
pos_weight = tensor([[0.2891],
        [0.7551],
        [0.0354]])
weight = tensor([[0.4099],
        [0.8929],
        [0.6123]])
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb332b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = None, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4982, 0.3382],
         [0.4069, 0.8156],
         [0.0048, 0.4817]],

        [[0.4072, 0.8557],
         [0.6129, 0.3371],
         [0.6718, 0.3925]]])
target = tensor([[[0.7517, 0.5374],
         [0.6448, 0.5754],
         [0.3594, 0.5967]],

        [[0.3897, 0.7269],
         [0.4530, 0.8613],
         [0.3522, 0.2728]]])
alpha = None, gamma = 0.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb33010>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = None, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8414, 0.3576],
         [0.7276, 0.7341],
         [0.5719, 0.3371]],

        [[0.2273, 0.5820],
         [0.4548, 0.9235],
         [0.3414, 0.2778]]])
target = tensor([[[0.2254, 0.9471],
         [0.5691, 0.8053],
         [0.4764, 0.9828]],

        [[0.5938, 0.0697],
         [0.3777, 0.9287],
         [0.9997, 0.1542]]])
alpha = None, gamma = 0.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb330d0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = None, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4651, 0.2243],
         [0.5055, 0.2048],
         [0.4608, 0.6294]],

        [[0.9207, 0.7049],
         [0.6836, 0.7394],
         [0.4880, 0.8689]]])
target = tensor([[[0.5090, 0.2279],
         [0.7104, 0.4255],
         [0.4740, 0.1927]],

        [[0.4924, 0.6301],
         [0.8020, 0.8393],
         [0.6032, 0.1917]]])
alpha = None, gamma = 0.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb33190>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.2, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9825, 0.9462],
         [0.5241, 0.5887],
         [0.2518, 0.5731]],

        [[0.9796, 0.1133],
         [0.7683, 0.1787],
         [0.1318, 0.6705]]])
target = tensor([[[0.1434, 0.4113],
         [0.4806, 0.5331],
         [0.7189, 0.5165]],

        [[0.1067, 0.5158],
         [0.9165, 0.1619],
         [0.2423, 0.8909]]])
alpha = 0.2, gamma = 0.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb33250>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.2, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5450, 0.1265],
         [0.0662, 0.7274],
         [0.1095, 0.5088]],

        [[0.2916, 0.9772],
         [0.8445, 0.0897],
         [0.0264, 0.3472]]])
target = tensor([[[0.9477, 0.1451],
         [0.8503, 0.4970],
         [0.4907, 0.7931]],

        [[0.1882, 0.0287],
         [0.7305, 0.9332],
         [0.8756, 0.8947]]])
alpha = 0.2, gamma = 0.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb32f50>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.2, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3379, 0.8508],
         [0.0379, 0.5990],
         [0.5640, 0.1450]],

        [[0.6835, 0.2672],
         [0.0291, 0.5752],
         [0.0017, 0.9697]]])
target = tensor([[[0.4265, 0.6170],
         [0.9598, 0.6370],
         [0.3133, 0.3345]],

        [[0.4875, 0.2197],
         [0.7443, 0.2314],
         [0.0463, 0.5899]]])
alpha = 0.2, gamma = 0.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb33d60>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.5, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7831, 0.2724],
         [0.1048, 0.4193],
         [0.8981, 0.4659]],

        [[0.9672, 0.6251],
         [0.2035, 0.5188],
         [0.5724, 0.1561]]])
target = tensor([[[0.7962, 0.9682],
         [0.9010, 0.6086],
         [0.2933, 0.9036]],

        [[0.8677, 0.6337],
         [0.4926, 0.2682],
         [0.5968, 0.8731]]])
alpha = 0.5, gamma = 0.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb33e20>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.5, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3143, 0.2086],
         [0.7201, 0.7978],
         [0.7408, 0.8722]],

        [[0.4696, 0.8578],
         [0.7422, 0.0153],
         [0.7337, 0.1264]]])
target = tensor([[[0.9538, 0.3791],
         [0.8521, 0.1460],
         [0.0640, 0.7324]],

        [[0.5662, 0.0581],
         [0.8392, 0.9408],
         [0.6384, 0.6972]]])
alpha = 0.5, gamma = 0.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb33ee0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.5, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1174, 0.5449],
         [0.2494, 0.9325],
         [0.1786, 0.3393]],

        [[0.7261, 0.0605],
         [0.7187, 0.8940],
         [0.6299, 0.0310]]])
target = tensor([[[0.1081, 0.6887],
         [0.2596, 0.3861],
         [0.4151, 0.3202]],

        [[0.9847, 0.6523],
         [0.8972, 0.2737],
         [0.9743, 0.6263]]])
alpha = 0.5, gamma = 0.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb33fa0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = None, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7224, 0.9527],
         [0.7400, 0.8626],
         [0.8244, 0.5934]],

        [[0.6031, 0.1355],
         [0.9110, 0.5785],
         [0.4033, 0.1119]]])
target = tensor([[[0.3912, 0.7787],
         [0.7034, 0.4128],
         [0.7031, 0.7246]],

        [[0.2230, 0.7431],
         [0.5952, 0.9786],
         [0.9931, 0.6202]]])
alpha = None, gamma = 1.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb600a0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = None, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7506, 0.1099],
         [0.1681, 0.0514],
         [0.0431, 0.4570]],

        [[0.3474, 0.2428],
         [0.0675, 0.8214],
         [0.8718, 0.3135]]])
target = tensor([[[0.0606, 0.2045],
         [0.7875, 0.6584],
         [0.3264, 0.9943]],

        [[0.1495, 0.4644],
         [0.8306, 0.4418],
         [0.6847, 0.3620]]])
alpha = None, gamma = 1.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb60160>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = None, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4104, 0.3335],
         [0.3802, 0.4614],
         [0.4126, 0.0066]],

        [[0.7683, 0.4338],
         [0.1401, 0.4023],
         [0.2328, 0.6909]]])
target = tensor([[[0.8781, 0.5000],
         [0.9863, 0.2804],
         [0.0912, 0.9983]],

        [[0.7032, 0.4567],
         [0.8300, 0.6481],
         [0.2024, 0.4518]]])
alpha = None, gamma = 1.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb60220>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.2, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0111, 0.9166],
         [0.6693, 0.4872],
         [0.1244, 0.0065]],

        [[0.8310, 0.3630],
         [0.5502, 0.1595],
         [0.4936, 0.9754]]])
target = tensor([[[0.3202, 0.0908],
         [0.1437, 0.9083],
         [0.1918, 0.0298]],

        [[0.6461, 0.6696],
         [0.7695, 0.8677],
         [0.4816, 0.3763]]])
alpha = 0.2, gamma = 1.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb602e0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.2, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4527, 0.5207],
         [0.3144, 0.7153],
         [0.9785, 0.4702]],

        [[0.0089, 0.7113],
         [0.6075, 0.7404],
         [0.9118, 0.6421]]])
target = tensor([[[0.3602, 0.8652],
         [0.3166, 0.7318],
         [0.5045, 0.2589]],

        [[0.8431, 0.9479],
         [0.8558, 0.1407],
         [0.6608, 0.7791]]])
alpha = 0.2, gamma = 1.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb603a0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.2, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5129, 0.4386],
         [0.5258, 0.0848],
         [0.0578, 0.6643]],

        [[0.4782, 0.5513],
         [0.2425, 0.8917],
         [0.3288, 0.2722]]])
target = tensor([[[0.7270, 0.5328],
         [0.6096, 0.2092],
         [0.2381, 0.6676]],

        [[0.4331, 0.7056],
         [0.7577, 0.7429],
         [0.8581, 0.6612]]])
alpha = 0.2, gamma = 1.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb60460>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.5, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6793, 0.1753],
         [0.4008, 0.6677],
         [0.1071, 0.2322]],

        [[0.3015, 0.0997],
         [0.0122, 0.2723],
         [0.0068, 0.1156]]])
target = tensor([[[0.8952, 0.0782],
         [0.4447, 0.6969],
         [0.5760, 0.0672]],

        [[0.6960, 0.9420],
         [0.0312, 0.4510],
         [0.7856, 0.2517]]])
alpha = 0.5, gamma = 1.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb60520>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.5, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1218, 0.1945],
         [0.9787, 0.1265],
         [0.3688, 0.6035]],

        [[0.9821, 0.9342],
         [0.7414, 0.5232],
         [0.4347, 0.8149]]])
target = tensor([[[0.4594, 0.5436],
         [0.7762, 0.7326],
         [0.0772, 0.6678]],

        [[0.8421, 0.4073],
         [0.5430, 0.5594],
         [0.2632, 0.7082]]])
alpha = 0.5, gamma = 1.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb605e0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.5, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8350, 0.6454],
         [0.5163, 0.5600],
         [0.5365, 0.0811]],

        [[0.8868, 0.2505],
         [0.7981, 0.7043],
         [0.0798, 0.6527]]])
target = tensor([[[0.3624, 0.1809],
         [0.5168, 0.3911],
         [0.5487, 0.6079]],

        [[0.1999, 0.0671],
         [0.1123, 0.0475],
         [0.0389, 0.8809]]])
alpha = 0.5, gamma = 1.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb606a0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = None, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8133, 0.9270],
         [0.6055, 0.6266],
         [0.6515, 0.0062]],

        [[0.0368, 0.8429],
         [0.0984, 0.0404],
         [0.4358, 0.5037]]])
target = tensor([[[0.2760, 0.3315],
         [0.8776, 0.5697],
         [0.6825, 0.3063]],

        [[0.1474, 0.0382],
         [0.4839, 0.5361],
         [0.7950, 0.9846]]])
alpha = None, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb60760>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = None, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0862, 0.6357],
         [0.1380, 0.6928],
         [0.2447, 0.1189]],

        [[0.9402, 0.5280],
         [0.2332, 0.1437],
         [0.4418, 0.2183]]])
target = tensor([[[0.9641, 0.8260],
         [0.2821, 0.8750],
         [0.0240, 0.3426]],

        [[0.1740, 0.7565],
         [0.0107, 0.0855],
         [0.7113, 0.5946]]])
alpha = None, gamma = 2.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb60820>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = None, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7001, 0.2825],
         [0.6194, 0.8289],
         [0.2291, 0.0944]],

        [[0.6527, 0.1681],
         [0.8893, 0.6816],
         [0.7303, 0.7012]]])
target = tensor([[[0.3092, 0.9487],
         [0.2198, 0.0462],
         [0.1165, 0.3968]],

        [[0.7352, 0.8815],
         [0.6645, 0.8006],
         [0.0038, 0.8477]]])
alpha = None, gamma = 2.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb608e0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.2, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0961, 0.0912],
         [0.8867, 0.2887],
         [0.0182, 0.6254]],

        [[0.9234, 0.1443],
         [0.7727, 0.1464],
         [0.7491, 0.5441]]])
target = tensor([[[0.0259, 0.1376],
         [0.3083, 0.8599],
         [0.9578, 0.5962]],

        [[0.7867, 0.1314],
         [0.0340, 0.5281],
         [0.3385, 0.6707]]])
alpha = 0.2, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb609a0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.2, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3796, 0.6208],
         [0.0281, 0.3281],
         [0.7602, 0.3394]],

        [[0.4797, 0.9340],
         [0.1754, 0.4542],
         [0.9425, 0.0735]]])
target = tensor([[[0.4607, 0.2987],
         [0.8278, 0.8269],
         [0.9641, 0.0188]],

        [[0.7767, 0.6999],
         [0.7148, 0.5257],
         [0.4773, 0.8565]]])
alpha = 0.2, gamma = 2.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb60a60>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.2, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6676, 0.6391],
         [0.8235, 0.3453],
         [0.4625, 0.3112]],

        [[0.0175, 0.2359],
         [0.4303, 0.5824],
         [0.4228, 0.1016]]])
target = tensor([[[0.3938, 0.7914],
         [0.7512, 0.2479],
         [0.3002, 0.9899]],

        [[0.1871, 0.1084],
         [0.9152, 0.3741],
         [0.2151, 0.3394]]])
alpha = 0.2, gamma = 2.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb60b20>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.5, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8046, 0.0964],
         [0.7808, 0.2594],
         [0.4293, 0.6002]],

        [[0.0244, 0.4177],
         [0.0442, 0.5907],
         [0.8313, 0.8119]]])
target = tensor([[[0.7237, 0.8249],
         [0.3018, 0.8198],
         [0.0784, 0.2693]],

        [[0.2137, 0.7890],
         [0.8970, 0.8544],
         [0.3983, 0.9575]]])
alpha = 0.5, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb60be0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.5, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2933, 0.5200],
         [0.1524, 0.9711],
         [0.0514, 0.0048]],

        [[0.5450, 0.4546],
         [0.7167, 0.2498],
         [0.5952, 0.2472]]])
target = tensor([[[0.3368, 0.5648],
         [0.8688, 0.3465],
         [0.7038, 0.7625]],

        [[0.2761, 0.6791],
         [0.2814, 0.2823],
         [0.1804, 0.8566]]])
alpha = 0.5, gamma = 2.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb60ca0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.5, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2871, 0.5331],
         [0.8985, 0.6028],
         [0.5706, 0.0596]],

        [[0.0814, 0.1311],
         [0.8018, 0.1397],
         [0.6151, 0.2671]]])
target = tensor([[[0.9423, 0.3598],
         [0.6921, 0.5621],
         [0.4111, 0.3993]],

        [[0.0791, 0.3729],
         [0.4768, 0.7322],
         [0.6623, 0.1010]]])
alpha = 0.5, gamma = 2.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb612a0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = None, weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8424, 0.5415],
         [0.2595, 0.4694],
         [0.3242, 0.2048]],

        [[0.3097, 0.9171],
         [0.9013, 0.4641],
         [0.1571, 0.5183]]])
target = tensor([[[0.4419, 0.7129],
         [0.4330, 0.9775],
         [0.9597, 0.9980]],

        [[0.0437, 0.0348],
         [0.0255, 0.8105],
         [0.1592, 0.1817]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb611e0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = None, weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4480, 0.2790],
         [0.5343, 0.1433],
         [0.1623, 0.5520]],

        [[0.8210, 0.6016],
         [0.5012, 0.1961],
         [0.5523, 0.8578]]])
target = tensor([[[0.8511, 0.7292],
         [0.8643, 0.8125],
         [0.8456, 0.1049]],

        [[0.4456, 0.3928],
         [0.7648, 0.5429],
         [0.1492, 0.6289]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb610c0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = None, weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8767, 0.0342],
         [0.9405, 0.6245],
         [0.9152, 0.2412]],

        [[0.4422, 0.7165],
         [0.9421, 0.9690],
         [0.4279, 0.7068]]])
target = tensor([[[0.2094, 0.0486],
         [0.8008, 0.2910],
         [0.4412, 0.8282]],

        [[0.0412, 0.2659],
         [0.1673, 0.4092],
         [0.7179, 0.2916]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb617b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = tensor([1., 2., 5.]), weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2940, 0.3632],
         [0.6649, 0.7933],
         [0.5393, 0.1013]],

        [[0.3842, 0.6567],
         [0.6799, 0.4662],
         [0.2240, 0.7433]]])
target = tensor([[[0.6629, 0.7548],
         [0.9151, 0.0796],
         [0.0957, 0.2443]],

        [[0.6870, 0.2246],
         [0.4007, 0.7071],
         [0.0067, 0.7984]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = tensor([1., 2., 5.])
weight = None, ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb61870>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = tensor([1., 2., 5.]), weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5299, 0.4675],
         [0.5587, 0.0052],
         [0.9513, 0.4669]],

        [[0.4749, 0.1424],
         [0.0992, 0.0329],
         [0.9724, 0.1218]]])
target = tensor([[[0.2423, 0.6384],
         [0.9420, 0.3088],
         [0.5965, 0.2132]],

        [[0.2288, 0.8126],
         [0.4952, 0.0064],
         [0.2525, 0.1190]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = tensor([1., 2., 5.])
weight = None, ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb61930>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = tensor([1., 2., 5.]), weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2018, 0.1159],
         [0.3817, 0.8753],
         [0.6116, 0.7415]],

        [[0.9143, 0.5528],
         [0.2224, 0.0459],
         [0.0206, 0.0124]]])
target = tensor([[[0.9695, 0.6823],
         [0.9673, 0.2365],
         [0.1207, 0.8305]],

        [[0.0161, 0.0472],
         [0.6928, 0.2725],
         [0.1430, 0.6369]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = tensor([1., 2., 5.])
weight = None, ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb619f0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8678, 0.9374],
         [0.2611, 0.4939],
         [0.5345, 0.3080]],

        [[0.7876, 0.6075],
         [0.5533, 0.4160],
         [0.0884, 0.3344]]])
target = tensor([[[0.5133, 0.8876],
         [0.4337, 0.4209],
         [0.2488, 0.7251]],

        [[0.0352, 0.9054],
         [0.1532, 0.5380],
         [0.2107, 0.9614]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb61ab0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2476, 0.6946],
         [0.2186, 0.4624],
         [0.5451, 0.0270]],

        [[0.9814, 0.2580],
         [0.3179, 0.9997],
         [0.2518, 0.6220]]])
target = tensor([[[0.0428, 0.3444],
         [0.3165, 0.8633],
         [0.5553, 0.1495]],

        [[0.7155, 0.1910],
         [0.5385, 0.3539],
         [0.9074, 0.7478]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb61b70>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6861, 0.3085],
         [0.2397, 0.9431],
         [0.6064, 0.5597]],

        [[0.0576, 0.8042],
         [0.9388, 0.9571],
         [0.5030, 0.4224]]])
target = tensor([[[0.3146, 0.6787],
         [0.0097, 0.8138],
         [0.3009, 0.7261]],

        [[0.5785, 0.0947],
         [0.3155, 0.6703],
         [0.5699, 0.9556]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb61c30>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0901, 0.2742],
         [0.1172, 0.4138],
         [0.4825, 0.7139]],

        [[0.4965, 0.9078],
         [0.0960, 0.3118],
         [0.9398, 0.9184]]])
target = tensor([[[0.1327, 0.2481],
         [0.5964, 0.6952],
         [0.3157, 0.8146]],

        [[0.6564, 0.6821],
         [0.7927, 0.0687],
         [0.3440, 0.7964]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb61cf0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4842, 0.0685],
         [0.2330, 0.2450],
         [0.8592, 0.9315]],

        [[0.9735, 0.4278],
         [0.7199, 0.6108],
         [0.5511, 0.9233]]])
target = tensor([[[0.2043, 0.6881],
         [0.9835, 0.2927],
         [0.2406, 0.6069]],

        [[0.3925, 0.4033],
         [0.3077, 0.7457],
         [0.7261, 0.9155]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb61db0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4385, 0.9924],
         [0.5172, 0.5316],
         [0.5610, 0.6668]],

        [[0.9369, 0.9914],
         [0.5473, 0.0029],
         [0.4297, 0.0670]]])
target = tensor([[[0.1374, 0.7522],
         [0.3066, 0.3746],
         [0.5511, 0.2486]],

        [[0.3939, 0.2469],
         [0.5186, 0.2046],
         [0.8548, 0.0748]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32--100-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb62230>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), ignore_index = -100

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6443, 0.3758],
         [0.0503, 0.4143],
         [0.8017, 0.9826]],

        [[0.1668, 0.9303],
         [0.9058, 0.2444],
         [0.0126, 0.6248]]])
target = tensor([[[-100.0000, -100.0000],
         [-100.0000, -100.0000],
         [   0.4665,    0.9833]],

        [[-100.0000,    0.5282],
         [   0.5105, -100.0000],
         [   0.1395, -100.0000]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb620e0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), ignore_index = -100

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6568, 0.0659],
         [0.7751, 0.9401],
         [0.0501, 0.5145]],

        [[0.1225, 0.7800],
         [0.0970, 0.4711],
         [0.6637, 0.4103]]])
target = tensor([[[   0.3712,    0.3114],
         [   0.4391, -100.0000],
         [-100.0000, -100.0000]],

        [[-100.0000,    0.6949],
         [-100.0000, -100.0000],
         [   0.9764,    0.4393]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb62560>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), ignore_index = -100

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1808, 0.3329],
         [0.4057, 0.6265],
         [0.3739, 0.8527]],

        [[0.7965, 0.9292],
         [0.0305, 0.3913],
         [0.1579, 0.1899]]])
target = tensor([[[-100.0000,    0.1062],
         [-100.0000,    0.8089],
         [   0.5508,    0.4260]],

        [[   0.4327, -100.0000],
         [-100.0000,    0.4810],
         [   0.7857,    0.4033]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32-255-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb62620>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), ignore_index = 255

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8336, 0.4420],
         [0.2726, 0.6256],
         [0.9855, 0.5018]],

        [[0.6948, 0.0496],
         [0.0875, 0.1511],
         [0.6245, 0.4090]]])
target = tensor([[[255.0000,   0.7479],
         [255.0000, 255.0000],
         [255.0000,   0.9447]],

        [[  0.5174,   0.5689],
         [255.0000,   0.6675],
         [255.0000, 255.0000]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None, weight = None
ignore_index = 255

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb626e0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), ignore_index = 255

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9608, 0.9725],
         [0.3800, 0.0057],
         [0.9661, 0.5399]],

        [[0.5133, 0.5850],
         [0.9732, 0.2903],
         [0.9597, 0.5468]]])
target = tensor([[[4.2734e-01, 2.5500e+02],
         [2.5500e+02, 2.5500e+02],
         [1.6099e-01, 1.1806e-01]],

        [[2.1261e-01, 6.0164e-01],
         [3.1442e-01, 8.3665e-01],
         [7.7490e-01, 5.3776e-01]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None, weight = None
ignore_index = 255

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb627a0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), ignore_index = 255

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1466, 0.4645],
         [0.1694, 0.8356],
         [0.1884, 0.3031]],

        [[0.1352, 0.3724],
         [0.8862, 0.0994],
         [0.9962, 0.6092]]])
target = tensor([[[  0.8107, 255.0000],
         [  0.4529,   0.7018],
         [  0.6543,   0.9121]],

        [[255.0000,   0.4931],
         [255.0000, 255.0000],
         [  0.8447,   0.5961]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None, weight = None
ignore_index = 255

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_______ TestBinaryFocalLossWithLogits.test_dynamo[cpu-float32-inductor] ________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb62b30>
device = device(type='cpu'), dtype = torch.float32
torch_optimizer = functools.partial(<function compile at 0x7da611f272e0>, backend='inductor')

    def test_dynamo(self, device, dtype, torch_optimizer):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        op = kornia.losses.binary_focal_loss_with_logits
        op_optimized = torch_optimizer(op)
    
        args = (0.25, 2.0)
>       actual = op_optimized(logits, labels, *args)

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:89: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:465: in _fn
    return fn(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6534, 0.3778],
         [0.5991, 0.0060],
         [0.4405, 0.9444]],

        [[0.5202, 0.1700],
         [0.8450, 0.0077],
         [0.1338, 0.3756]]])
target = tensor([[[0.3830, 0.3724],
         [0.4519, 0.0623],
         [0.2198, 0.1601]],

        [[0.7194, 0.8876],
         [0.2091, 0.3824],
         [0.9082, 0.1832]]])
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
______________ TestBinaryFocalLossWithLogits.test_gradcheck[cpu] _______________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb62dd0>
device = device(type='cpu')

    def test_gradcheck(self, device):
        logits = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
        labels = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
    
        args = (0.25, 2.0)
        op = kornia.losses.binary_focal_loss_with_logits
>       self.gradcheck(op, (logits, labels, *args))

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:99: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2074: in _gradcheck_helper
    func_out = func(*tupled_inputs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0248, 0.6859],
         [0.6873, 0.9751],
         [0.5343, 0.7607]],

        [[0.6233, 0.4992],
         [0.1573, 0.5374],
         [0.8779, 0.7697]]], dtype=torch.float64, requires_grad=True)
target = tensor([[[0.6555, 0.6074],
         [0.5020, 0.3278],
         [0.8917, 0.7981]],

        [[0.5580, 0.1013],
         [0.6205, 0.3257],
         [0.3158, 0.0486]]], dtype=torch.float64, requires_grad=True)
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
________ TestBinaryFocalLossWithLogits.test_gradcheck_ignore_index[cpu] ________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb63070>
device = device(type='cpu')

    def test_gradcheck_ignore_index(self, device):
        logits = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
        labels = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
        ignore = torch.rand(2, 3, 2, device=device) > 0.8
        labels[ignore] = -100
    
        args = (0.25, 2.0)
        op = kornia.losses.binary_focal_loss_with_logits
>       self.gradcheck(op, (logits, labels, *args), requires_grad=[True, False, False, False])

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2074: in _gradcheck_helper
    func_out = func(*tupled_inputs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4029, 0.6469],
         [0.9115, 0.1978],
         [0.7215, 0.3508]],

        [[0.8893, 0.8860],
         [0.4897, 0.6695],
         [0.5228, 0.3977]]], dtype=torch.float64, requires_grad=True)
target = tensor([[[ 5.0704e-01,  4.2301e-02],
         [ 1.7840e-01, -1.0000e+02],
         [ 9.5937e-01,  5.9633e-01]],

     ...863e-01,  1.5745e-01],
         [ 2.9474e-01,  4.1579e-01],
         [ 2.1976e-01, -1.0000e+02]]], dtype=torch.float64)
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
____________ TestBinaryFocalLossWithLogits.test_module[cpu-float32] ____________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb60ee0>
device = device(type='cpu'), dtype = torch.float32

    def test_module(self, device, dtype):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        args = (0.25, 2.0)
        op = kornia.losses.binary_focal_loss_with_logits
        op_module = kornia.losses.BinaryFocalLossWithLogits(*args)
>       self.assert_close(op_module(logits, labels), op(logits, labels, *args))

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:261: in forward
    return binary_focal_loss_with_logits(pred, target, self.alpha, self.gamma, self.reduction, self.pos_weight, self.weight, self.ignore_index)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1420, 0.7197],
         [0.2428, 0.8666],
         [0.8544, 0.8128]],

        [[0.0188, 0.3005],
         [0.8964, 0.3233],
         [0.6114, 0.6051]]])
target = tensor([[[0.5788, 0.1563],
         [0.0686, 0.9707],
         [0.5752, 0.5014]],

        [[0.3266, 0.2750],
         [0.8799, 0.8950],
         [0.8929, 0.1110]]])
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
______ TestBinaryFocalLossWithLogits.test_numeric_stability[cpu-float32] _______

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7da53cb63460>
device = device(type='cpu'), dtype = torch.float32

    def test_numeric_stability(self, device, dtype):
        logits = torch.tensor([[100.0, -100]], dtype=dtype, device=device)
        labels = torch.tensor([[1.0, 0.0]], dtype=dtype, device=device)
    
        args = (0.25, 2.0)
>       actual = kornia.losses.binary_focal_loss_with_logits(logits, labels, *args)

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[ 100., -100.]]), target = tensor([[1., 0.]]), alpha = 0.25
gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32]
============================== 59 failed in 0.89s ==============================


Final Test Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'tvm', 'cudagraphs', 'inductor', 'openxla', 'jit', None, 'onnxrt'}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 59 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] PASSED

============================== 59 passed in 2.09s ==============================


Initial Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'jit', 'cudagraphs', 'tvm', 'openxla', 'onnxrt', None, 'inductor'}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 59 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] PASSED

============================== 59 passed in 2.10s ==============================
