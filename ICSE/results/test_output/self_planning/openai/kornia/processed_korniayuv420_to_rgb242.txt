output file:
processed_korniayuv420_to_rgb242.json
function:
yuv420_to_rgb
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_unit_red[cpu-float32]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_unit_white[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_forth_and_back[cpu-float32] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape1]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_unit_red[cpu-float32] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_forth_and_back[cpu-float32]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_gradcheck[cpu-float32]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape3]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape3] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_unit_white[cpu-float32] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_smoke[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_gradcheck[cpu-float32] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_module[cpu-float32] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_smoke[cpu-float32] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_module[cpu-float32]'}

All Test Cases On Generated code:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'onnxrt', 'tvm', 'cudagraphs', 'openxla', 'jit', None, 'inductor'}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 12 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_smoke[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape3] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_exception[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_unit_white[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_unit_red[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_forth_and_back[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_gradcheck[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_jit[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_module[cpu-float32] FAILED

=================================== FAILURES ===================================
___________________ TestYuv420ToRgb.test_smoke[cpu-float32] ____________________

self = <test_yuv.TestYuv420ToRgb object at 0x78c4d2b29de0>
device = device(type='cpu'), dtype = torch.float32

    def test_smoke(self, device, dtype):
        H, W = 4, 6
        imgy = torch.rand(1, H, W, device=device, dtype=dtype)
        imguv = torch.rand(2, int(H / 2), int(W / 2), device=device, dtype=dtype)
>       assert isinstance(kornia.color.yuv420_to_rgb(imgy, imguv), torch.Tensor)

/local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py:359: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/yuv.py:143: in yuv420_to_rgb
    return yuv420_to_rgb(imagey, imageuv)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imagey = tensor([[[0.9384, 0.0151, 0.3867, 0.6324, 0.4717, 0.4988],
         [0.5120, 0.4334, 0.9900, 0.9578, 0.0304, 0.9008],
         [0.1425, 0.2846, 0.9843, 0.0375, 0.1542, 0.3860],
         [0.4757, 0.8267, 0.4017, 0.9507, 0.0304, 0.1382]]])
imageuv = tensor([[[0.7666, 0.5317, 0.2659],
         [0.2551, 0.0811, 0.6758]],

        [[0.1455, 0.4797, 0.7952],
         [0.4990, 0.8399, 0.3154]]])

    def yuv420_to_rgb(imagey, imageuv):
        if not isinstance(imagey, torch.Tensor) or not isinstance(imageuv, torch.Tensor):
            raise TypeError('Inputs must be torch Tensors.')
        if imagey.shape[-3] != 1 or imageuv.shape[-3] != 2:
            raise ValueError('Invalid channel dimensions for imagey or imageuv.')
        if imagey.min() < 0 or imagey.max() > 1 or imageuv.min() < -0.5 or (imageuv.max() > 0.5):
>           raise ValueError('Input values are out of the expected range.')
E           ValueError: Input values are out of the expected range.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/temp.py:15: ValueError
_____________ TestYuv420ToRgb.test_cardinality[cpu-float32-shape0] _____________

self = <test_yuv.TestYuv420ToRgb object at 0x78c4d2b2a290>
device = device(type='cpu'), dtype = torch.float32, shape = (1, 3, 4, 4)

    @pytest.mark.parametrize("shape", [(1, 3, 4, 4), (2, 3, 2, 4), (3, 3, 4, 2), (3, 2, 2)])
    def test_cardinality(self, device, dtype, shape):
        shapey = list(shape)
        shapey[-3] = 1
        shapeuv = list(shape)
        shapeuv[-3] = 2
        shapeuv[-2] = int(shapeuv[-2] / 2)
        shapeuv[-1] = int(shapeuv[-1] / 2)
    
        imgy = torch.ones(shapey, device=device, dtype=dtype)
        imguv = torch.ones(shapeuv, device=device, dtype=dtype)
>       assert kornia.color.yuv420_to_rgb(imgy, imguv).shape == shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py:372: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/yuv.py:143: in yuv420_to_rgb
    return yuv420_to_rgb(imagey, imageuv)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imagey = tensor([[[[1., 1., 1., 1.],
          [1., 1., 1., 1.],
          [1., 1., 1., 1.],
          [1., 1., 1., 1.]]]])
imageuv = tensor([[[[1., 1.],
          [1., 1.]],

         [[1., 1.],
          [1., 1.]]]])

    def yuv420_to_rgb(imagey, imageuv):
        if not isinstance(imagey, torch.Tensor) or not isinstance(imageuv, torch.Tensor):
            raise TypeError('Inputs must be torch Tensors.')
        if imagey.shape[-3] != 1 or imageuv.shape[-3] != 2:
            raise ValueError('Invalid channel dimensions for imagey or imageuv.')
        if imagey.min() < 0 or imagey.max() > 1 or imageuv.min() < -0.5 or (imageuv.max() > 0.5):
>           raise ValueError('Input values are out of the expected range.')
E           ValueError: Input values are out of the expected range.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/temp.py:15: ValueError
_____________ TestYuv420ToRgb.test_cardinality[cpu-float32-shape1] _____________

self = <test_yuv.TestYuv420ToRgb object at 0x78c4d2b2a1d0>
device = device(type='cpu'), dtype = torch.float32, shape = (2, 3, 2, 4)

    @pytest.mark.parametrize("shape", [(1, 3, 4, 4), (2, 3, 2, 4), (3, 3, 4, 2), (3, 2, 2)])
    def test_cardinality(self, device, dtype, shape):
        shapey = list(shape)
        shapey[-3] = 1
        shapeuv = list(shape)
        shapeuv[-3] = 2
        shapeuv[-2] = int(shapeuv[-2] / 2)
        shapeuv[-1] = int(shapeuv[-1] / 2)
    
        imgy = torch.ones(shapey, device=device, dtype=dtype)
        imguv = torch.ones(shapeuv, device=device, dtype=dtype)
>       assert kornia.color.yuv420_to_rgb(imgy, imguv).shape == shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py:372: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/yuv.py:143: in yuv420_to_rgb
    return yuv420_to_rgb(imagey, imageuv)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imagey = tensor([[[[1., 1., 1., 1.],
          [1., 1., 1., 1.]]],


        [[[1., 1., 1., 1.],
          [1., 1., 1., 1.]]]])
imageuv = tensor([[[[1., 1.]],

         [[1., 1.]]],


        [[[1., 1.]],

         [[1., 1.]]]])

    def yuv420_to_rgb(imagey, imageuv):
        if not isinstance(imagey, torch.Tensor) or not isinstance(imageuv, torch.Tensor):
            raise TypeError('Inputs must be torch Tensors.')
        if imagey.shape[-3] != 1 or imageuv.shape[-3] != 2:
            raise ValueError('Invalid channel dimensions for imagey or imageuv.')
        if imagey.min() < 0 or imagey.max() > 1 or imageuv.min() < -0.5 or (imageuv.max() > 0.5):
>           raise ValueError('Input values are out of the expected range.')
E           ValueError: Input values are out of the expected range.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/temp.py:15: ValueError
_____________ TestYuv420ToRgb.test_cardinality[cpu-float32-shape2] _____________

self = <test_yuv.TestYuv420ToRgb object at 0x78c4d2b2a530>
device = device(type='cpu'), dtype = torch.float32, shape = (3, 3, 4, 2)

    @pytest.mark.parametrize("shape", [(1, 3, 4, 4), (2, 3, 2, 4), (3, 3, 4, 2), (3, 2, 2)])
    def test_cardinality(self, device, dtype, shape):
        shapey = list(shape)
        shapey[-3] = 1
        shapeuv = list(shape)
        shapeuv[-3] = 2
        shapeuv[-2] = int(shapeuv[-2] / 2)
        shapeuv[-1] = int(shapeuv[-1] / 2)
    
        imgy = torch.ones(shapey, device=device, dtype=dtype)
        imguv = torch.ones(shapeuv, device=device, dtype=dtype)
>       assert kornia.color.yuv420_to_rgb(imgy, imguv).shape == shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py:372: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/yuv.py:143: in yuv420_to_rgb
    return yuv420_to_rgb(imagey, imageuv)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imagey = tensor([[[[1., 1.],
          [1., 1.],
          [1., 1.],
          [1., 1.]]],


        [[[1., 1.],
          [1.,...   [1., 1.],
          [1., 1.]]],


        [[[1., 1.],
          [1., 1.],
          [1., 1.],
          [1., 1.]]]])
imageuv = tensor([[[[1.],
          [1.]],

         [[1.],
          [1.]]],


        [[[1.],
          [1.]],

         [[1.],
          [1.]]],


        [[[1.],
          [1.]],

         [[1.],
          [1.]]]])

    def yuv420_to_rgb(imagey, imageuv):
        if not isinstance(imagey, torch.Tensor) or not isinstance(imageuv, torch.Tensor):
            raise TypeError('Inputs must be torch Tensors.')
        if imagey.shape[-3] != 1 or imageuv.shape[-3] != 2:
            raise ValueError('Invalid channel dimensions for imagey or imageuv.')
        if imagey.min() < 0 or imagey.max() > 1 or imageuv.min() < -0.5 or (imageuv.max() > 0.5):
>           raise ValueError('Input values are out of the expected range.')
E           ValueError: Input values are out of the expected range.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/temp.py:15: ValueError
_____________ TestYuv420ToRgb.test_cardinality[cpu-float32-shape3] _____________

self = <test_yuv.TestYuv420ToRgb object at 0x78c4d2b2a5f0>
device = device(type='cpu'), dtype = torch.float32, shape = (3, 2, 2)

    @pytest.mark.parametrize("shape", [(1, 3, 4, 4), (2, 3, 2, 4), (3, 3, 4, 2), (3, 2, 2)])
    def test_cardinality(self, device, dtype, shape):
        shapey = list(shape)
        shapey[-3] = 1
        shapeuv = list(shape)
        shapeuv[-3] = 2
        shapeuv[-2] = int(shapeuv[-2] / 2)
        shapeuv[-1] = int(shapeuv[-1] / 2)
    
        imgy = torch.ones(shapey, device=device, dtype=dtype)
        imguv = torch.ones(shapeuv, device=device, dtype=dtype)
>       assert kornia.color.yuv420_to_rgb(imgy, imguv).shape == shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py:372: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/yuv.py:143: in yuv420_to_rgb
    return yuv420_to_rgb(imagey, imageuv)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imagey = tensor([[[1., 1.],
         [1., 1.]]])
imageuv = tensor([[[1.]],

        [[1.]]])

    def yuv420_to_rgb(imagey, imageuv):
        if not isinstance(imagey, torch.Tensor) or not isinstance(imageuv, torch.Tensor):
            raise TypeError('Inputs must be torch Tensors.')
        if imagey.shape[-3] != 1 or imageuv.shape[-3] != 2:
            raise ValueError('Invalid channel dimensions for imagey or imageuv.')
        if imagey.min() < 0 or imagey.max() > 1 or imageuv.min() < -0.5 or (imageuv.max() > 0.5):
>           raise ValueError('Input values are out of the expected range.')
E           ValueError: Input values are out of the expected range.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/temp.py:15: ValueError
_________________ TestYuv420ToRgb.test_exception[cpu-float32] __________________

self = <test_yuv.TestYuv420ToRgb object at 0x78c4d2b29fc0>
device = device(type='cpu'), dtype = torch.float32

    def test_exception(self, device, dtype):
        with pytest.raises(TypeError):
            assert kornia.color.yuv420_to_rgb([0.0], [0.0])
    
        with pytest.raises(ValueError):
            imguv = torch.ones(1, 1, device=device, dtype=dtype)
            imgy = torch.ones(1, 1, device=device, dtype=dtype)
>           assert kornia.color.yuv420_to_rgb(imgy, imguv)

/local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py:381: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/yuv.py:143: in yuv420_to_rgb
    return yuv420_to_rgb(imagey, imageuv)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imagey = tensor([[1.]]), imageuv = tensor([[1.]])

    def yuv420_to_rgb(imagey, imageuv):
        if not isinstance(imagey, torch.Tensor) or not isinstance(imageuv, torch.Tensor):
            raise TypeError('Inputs must be torch Tensors.')
>       if imagey.shape[-3] != 1 or imageuv.shape[-3] != 2:
E       IndexError: tuple index out of range

/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/temp.py:12: IndexError
_________________ TestYuv420ToRgb.test_unit_white[cpu-float32] _________________

self = <test_yuv.TestYuv420ToRgb object at 0x78c4d2b2aad0>
device = device(type='cpu'), dtype = torch.float32

    def test_unit_white(self, device, dtype):  # skipcq: PYL-R0201
        refrgb = torch.tensor(
            [[[255, 255], [255, 255]], [[255, 255], [255, 255]], [[255, 255], [255, 255]]],
            device=device,
            dtype=torch.uint8,
        )
        y = torch.tensor([[[255, 255], [255, 255]]], device=device, dtype=torch.uint8).type(dtype) / 255.0
        uv = torch.tensor([[[0]], [[0]]], device=device, dtype=torch.int8).type(torch.float) / 255.0
    
>       resrgb = (kornia.color.yuv420_to_rgb(y, uv) * 255.0).round().type(torch.uint8)

/local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py:411: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/yuv.py:143: in yuv420_to_rgb
    return yuv420_to_rgb(imagey, imageuv)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/temp.py:20: in yuv420_to_rgb
    imageuv_upsampled = F.interpolate(imageuv, scale_factor=2, mode='bilinear', align_corners=False)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[0.]],

        [[0.]]]), size = None, scale_factor = 2
mode = 'bilinear', align_corners = False, recompute_scale_factor = None
antialias = False

    def interpolate(  # noqa: F811
        input: Tensor,
        size: Optional[int] = None,
        scale_factor: Optional[List[float]] = None,
        mode: str = "nearest",
        align_corners: Optional[bool] = None,
        recompute_scale_factor: Optional[bool] = None,
        antialias: bool = False,
    ) -> Tensor:  # noqa: B950
        r"""Down/up samples the input.
    
        Tensor interpolated to either the given :attr:`size` or the given
        :attr:`scale_factor`
    
        The algorithm used for interpolation is determined by :attr:`mode`.
    
        Currently temporal, spatial and volumetric sampling are supported, i.e.
        expected inputs are 3-D, 4-D or 5-D in shape.
    
        The input dimensions are interpreted in the form:
        `mini-batch x channels x [optional depth] x [optional height] x width`.
    
        The modes available for resizing are: `nearest`, `linear` (3D-only),
        `bilinear`, `bicubic` (4D-only), `trilinear` (5D-only), `area`, `nearest-exact`
    
        Args:
            input (Tensor): the input tensor
            size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int]):
                output spatial size.
            scale_factor (float or Tuple[float]): multiplier for spatial size. If `scale_factor` is a tuple,
                its length has to match the number of spatial dimensions; `input.dim() - 2`.
            mode (str): algorithm used for upsampling:
                ``'nearest'`` | ``'linear'`` | ``'bilinear'`` | ``'bicubic'`` |
                ``'trilinear'`` | ``'area'`` | ``'nearest-exact'``. Default: ``'nearest'``
            align_corners (bool, optional): Geometrically, we consider the pixels of the
                input and output as squares rather than points.
                If set to ``True``, the input and output tensors are aligned by the
                center points of their corner pixels, preserving the values at the corner pixels.
                If set to ``False``, the input and output tensors are aligned by the corner
                points of their corner pixels, and the interpolation uses edge value padding
                for out-of-boundary values, making this operation *independent* of input size
                when :attr:`scale_factor` is kept the same. This only has an effect when :attr:`mode`
                is ``'linear'``, ``'bilinear'``, ``'bicubic'`` or ``'trilinear'``.
                Default: ``False``
            recompute_scale_factor (bool, optional): recompute the scale_factor for use in the
                interpolation calculation. If `recompute_scale_factor` is ``True``, then
                `scale_factor` must be passed in and `scale_factor` is used to compute the
                output `size`. The computed output `size` will be used to infer new scales for
                the interpolation. Note that when `scale_factor` is floating-point, it may differ
                from the recomputed `scale_factor` due to rounding and precision issues.
                If `recompute_scale_factor` is ``False``, then `size` or `scale_factor` will
                be used directly for interpolation. Default: ``None``.
            antialias (bool, optional): flag to apply anti-aliasing. Default: ``False``. Using anti-alias
                option together with ``align_corners=False``, interpolation result would match Pillow
                result for downsampling operation. Supported modes: ``'bilinear'``, ``'bicubic'``.
    
        .. note::
            With ``mode='bicubic'``, it's possible to cause overshoot, in other words it can produce
            negative values or values greater than 255 for images.
            Explicitly call ``result.clamp(min=0, max=255)`` if you want to reduce the overshoot
            when displaying the image.
    
        .. note::
            Mode ``mode='nearest-exact'`` matches Scikit-Image and PIL nearest neighbours interpolation
            algorithms and fixes known issues with ``mode='nearest'``. This mode is introduced to keep
            backward compatibility.
            Mode ``mode='nearest'`` matches buggy OpenCV's ``INTER_NEAREST`` interpolation algorithm.
    
        .. note::
            The gradients for the dtype ``float16`` on CUDA may be inaccurate in the upsample operation
            when using modes ``['linear', 'bilinear', 'bicubic', 'trilinear', 'area']``.
            For more details, please refer to the discussion in
            `issue#104157 <https://github.com/pytorch/pytorch/issues/104157>`_.
    
        Note:
            {backward_reproducibility_note}
        """
        if has_torch_function_unary(input):
            return handle_torch_function(
                interpolate,
                (input,),
                input,
                size=size,
                scale_factor=scale_factor,
                mode=mode,
                align_corners=align_corners,
                recompute_scale_factor=recompute_scale_factor,
                antialias=antialias,
            )
    
        if mode in ("nearest", "area", "nearest-exact"):
            if align_corners is not None:
                raise ValueError(
                    "align_corners option can only be set with the "
                    "interpolating modes: linear | bilinear | bicubic | trilinear"
                )
        else:
            if align_corners is None:
                align_corners = False
    
        dim = input.dim() - 2  # Number of spatial dimensions.
    
        # Process size and scale_factor.  Validate that exactly one is set.
        # Validate its length if it is a list, or expand it if it is a scalar.
        # After this block, exactly one of output_size and scale_factors will
        # be non-None, and it will be a list (or tuple).
        if size is not None and scale_factor is not None:
            raise ValueError("only one of size or scale_factor should be defined")
        elif size is not None:
            assert scale_factor is None
            scale_factors = None
            if isinstance(size, (list, tuple)):
                if len(size) != dim:
                    raise ValueError(
                        "Input and output must have the same number of spatial dimensions, but got "
                        f"input with spatial dimensions of {list(input.shape[2:])} and output size of {size}. "
                        "Please provide input tensor in (N, C, d1, d2, ...,dK) format and "
                        "output size in (o1, o2, ...,oK) format."
                    )
                if not torch.jit.is_scripting():
                    if not all(_is_integer(x) for x in size):
                        raise TypeError(
                            "expected size to be one of int or Tuple[int] or Tuple[int, int] or "
                            f"Tuple[int, int, int], but got size with types {[type(x) for x in size]}"
                        )
                output_size = size
            else:
                output_size = [size for _ in range(dim)]
        elif scale_factor is not None:
            assert size is None
            output_size = None
            if isinstance(scale_factor, (list, tuple)):
                if len(scale_factor) != dim:
                    raise ValueError(
                        "Input and scale_factor must have the same number of spatial dimensions, but "
                        f"got input with spatial dimensions of {list(input.shape[2:])} and "
                        f"scale_factor of shape {scale_factor}. "
                        "Please provide input tensor in (N, C, d1, d2, ...,dK) format and "
                        "scale_factor in (s1, s2, ...,sK) format."
                    )
                scale_factors = scale_factor
            else:
                scale_factors = [scale_factor for _ in range(dim)]
        else:
            raise ValueError("either size or scale_factor should be defined")
    
        if (
            recompute_scale_factor is not None
            and recompute_scale_factor
            and size is not None
        ):
            raise ValueError(
                "recompute_scale_factor is not meaningful with an explicit size."
            )
    
        # "area" mode always requires an explicit size rather than scale factor.
        # Re-use the recompute_scale_factor code path.
        if mode == "area" and output_size is None:
            recompute_scale_factor = True
    
        if recompute_scale_factor is not None and recompute_scale_factor:
            # We compute output_size here, then un-set scale_factors.
            # The C++ code will recompute it based on the (integer) output size.
            assert scale_factors is not None
            if not torch.jit.is_scripting() and torch._C._get_tracing_state():
                # make scale_factor a tensor in tracing so constant doesn't get baked in
                output_size = [
                    (
                        torch.floor(
                            (
                                input.size(i + 2).float()
                                * torch.tensor(scale_factors[i], dtype=torch.float32)
                            ).float()
                        )
                    )
                    for i in range(dim)
                ]
            elif torch.jit.is_scripting():
                output_size = [
                    int(math.floor(float(input.size(i + 2)) * scale_factors[i]))
                    for i in range(dim)
                ]
            else:
                output_size = [
                    _sym_int(input.size(i + 2) * scale_factors[i]) for i in range(dim)
                ]
            scale_factors = None
    
        if antialias and not (mode in ("bilinear", "bicubic") and input.ndim == 4):
            raise ValueError(
                "Anti-alias option is restricted to bilinear and bicubic modes and requires a 4-D tensor as input"
            )
    
        if input.dim() == 3 and mode == "nearest":
            return torch._C._nn.upsample_nearest1d(input, output_size, scale_factors)
        if input.dim() == 4 and mode == "nearest":
            return torch._C._nn.upsample_nearest2d(input, output_size, scale_factors)
        if input.dim() == 5 and mode == "nearest":
            return torch._C._nn.upsample_nearest3d(input, output_size, scale_factors)
    
        if input.dim() == 3 and mode == "nearest-exact":
            return torch._C._nn._upsample_nearest_exact1d(input, output_size, scale_factors)
        if input.dim() == 4 and mode == "nearest-exact":
            return torch._C._nn._upsample_nearest_exact2d(input, output_size, scale_factors)
        if input.dim() == 5 and mode == "nearest-exact":
            return torch._C._nn._upsample_nearest_exact3d(input, output_size, scale_factors)
    
        if input.dim() == 3 and mode == "area":
            assert output_size is not None
            return adaptive_avg_pool1d(input, output_size)
        if input.dim() == 4 and mode == "area":
            assert output_size is not None
            return adaptive_avg_pool2d(input, output_size)
        if input.dim() == 5 and mode == "area":
            assert output_size is not None
            return adaptive_avg_pool3d(input, output_size)
    
        if input.dim() == 3 and mode == "linear":
            assert align_corners is not None
            return torch._C._nn.upsample_linear1d(
                input, output_size, align_corners, scale_factors
            )
        if input.dim() == 4 and mode == "bilinear":
            assert align_corners is not None
            if antialias:
                return torch._C._nn._upsample_bilinear2d_aa(
                    input, output_size, align_corners, scale_factors
                )
            # Two levels are necessary to prevent TorchScript from touching
            # are_deterministic_algorithms_enabled.
            if not torch.jit.is_scripting():
                if torch.are_deterministic_algorithms_enabled() and (
                    input.is_cuda or input.is_xpu
                ):
                    # Use slow decomp whose backward will be in terms of index_put
                    # importlib is required because the import cannot be top level
                    # (cycle) and cannot be nested (TS doesn't support)
                    return importlib.import_module(
                        "torch._decomp.decompositions"
                    )._upsample_linear_vec(input, output_size, align_corners, scale_factors)
            return torch._C._nn.upsample_bilinear2d(
                input, output_size, align_corners, scale_factors
            )
        if input.dim() == 5 and mode == "trilinear":
            assert align_corners is not None
            return torch._C._nn.upsample_trilinear3d(
                input, output_size, align_corners, scale_factors
            )
        if input.dim() == 4 and mode == "bicubic":
            assert align_corners is not None
            if antialias:
                return torch._C._nn._upsample_bicubic2d_aa(
                    input, output_size, align_corners, scale_factors
                )
            return torch._C._nn.upsample_bicubic2d(
                input, output_size, align_corners, scale_factors
            )
    
        if input.dim() == 3 and mode == "bilinear":
>           raise NotImplementedError("Got 3D input, but bilinear mode needs 4D input")
E           NotImplementedError: Got 3D input, but bilinear mode needs 4D input

/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/functional.py:4599: NotImplementedError
__________________ TestYuv420ToRgb.test_unit_red[cpu-float32] __________________

self = <test_yuv.TestYuv420ToRgb object at 0x78c4d2b2ae00>
device = device(type='cpu'), dtype = torch.float32

    def test_unit_red(self, device, dtype):  # skipcq: PYL-R0201
        refrgb = torch.tensor(
            [[[221, 221], [221, 221]], [[17, 17], [17, 17]], [[1, 1], [1, 1]]], device=device, dtype=torch.uint8
        )
        y = torch.tensor([[[76, 76], [76, 76]]], device=device, dtype=torch.uint8).type(dtype) / 255.0
        uv = torch.tensor([[[-37]], [[127]]], device=device, dtype=torch.int8).type(torch.float) / 255.0
    
>       resrgb = (kornia.color.yuv420_to_rgb(y, uv) * 255.0).round().type(torch.uint8)

/local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py:421: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/yuv.py:143: in yuv420_to_rgb
    return yuv420_to_rgb(imagey, imageuv)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/temp.py:20: in yuv420_to_rgb
    imageuv_upsampled = F.interpolate(imageuv, scale_factor=2, mode='bilinear', align_corners=False)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[-0.1451]],

        [[ 0.4980]]]), size = None
scale_factor = 2, mode = 'bilinear', align_corners = False
recompute_scale_factor = None, antialias = False

    def interpolate(  # noqa: F811
        input: Tensor,
        size: Optional[int] = None,
        scale_factor: Optional[List[float]] = None,
        mode: str = "nearest",
        align_corners: Optional[bool] = None,
        recompute_scale_factor: Optional[bool] = None,
        antialias: bool = False,
    ) -> Tensor:  # noqa: B950
        r"""Down/up samples the input.
    
        Tensor interpolated to either the given :attr:`size` or the given
        :attr:`scale_factor`
    
        The algorithm used for interpolation is determined by :attr:`mode`.
    
        Currently temporal, spatial and volumetric sampling are supported, i.e.
        expected inputs are 3-D, 4-D or 5-D in shape.
    
        The input dimensions are interpreted in the form:
        `mini-batch x channels x [optional depth] x [optional height] x width`.
    
        The modes available for resizing are: `nearest`, `linear` (3D-only),
        `bilinear`, `bicubic` (4D-only), `trilinear` (5D-only), `area`, `nearest-exact`
    
        Args:
            input (Tensor): the input tensor
            size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int]):
                output spatial size.
            scale_factor (float or Tuple[float]): multiplier for spatial size. If `scale_factor` is a tuple,
                its length has to match the number of spatial dimensions; `input.dim() - 2`.
            mode (str): algorithm used for upsampling:
                ``'nearest'`` | ``'linear'`` | ``'bilinear'`` | ``'bicubic'`` |
                ``'trilinear'`` | ``'area'`` | ``'nearest-exact'``. Default: ``'nearest'``
            align_corners (bool, optional): Geometrically, we consider the pixels of the
                input and output as squares rather than points.
                If set to ``True``, the input and output tensors are aligned by the
                center points of their corner pixels, preserving the values at the corner pixels.
                If set to ``False``, the input and output tensors are aligned by the corner
                points of their corner pixels, and the interpolation uses edge value padding
                for out-of-boundary values, making this operation *independent* of input size
                when :attr:`scale_factor` is kept the same. This only has an effect when :attr:`mode`
                is ``'linear'``, ``'bilinear'``, ``'bicubic'`` or ``'trilinear'``.
                Default: ``False``
            recompute_scale_factor (bool, optional): recompute the scale_factor for use in the
                interpolation calculation. If `recompute_scale_factor` is ``True``, then
                `scale_factor` must be passed in and `scale_factor` is used to compute the
                output `size`. The computed output `size` will be used to infer new scales for
                the interpolation. Note that when `scale_factor` is floating-point, it may differ
                from the recomputed `scale_factor` due to rounding and precision issues.
                If `recompute_scale_factor` is ``False``, then `size` or `scale_factor` will
                be used directly for interpolation. Default: ``None``.
            antialias (bool, optional): flag to apply anti-aliasing. Default: ``False``. Using anti-alias
                option together with ``align_corners=False``, interpolation result would match Pillow
                result for downsampling operation. Supported modes: ``'bilinear'``, ``'bicubic'``.
    
        .. note::
            With ``mode='bicubic'``, it's possible to cause overshoot, in other words it can produce
            negative values or values greater than 255 for images.
            Explicitly call ``result.clamp(min=0, max=255)`` if you want to reduce the overshoot
            when displaying the image.
    
        .. note::
            Mode ``mode='nearest-exact'`` matches Scikit-Image and PIL nearest neighbours interpolation
            algorithms and fixes known issues with ``mode='nearest'``. This mode is introduced to keep
            backward compatibility.
            Mode ``mode='nearest'`` matches buggy OpenCV's ``INTER_NEAREST`` interpolation algorithm.
    
        .. note::
            The gradients for the dtype ``float16`` on CUDA may be inaccurate in the upsample operation
            when using modes ``['linear', 'bilinear', 'bicubic', 'trilinear', 'area']``.
            For more details, please refer to the discussion in
            `issue#104157 <https://github.com/pytorch/pytorch/issues/104157>`_.
    
        Note:
            {backward_reproducibility_note}
        """
        if has_torch_function_unary(input):
            return handle_torch_function(
                interpolate,
                (input,),
                input,
                size=size,
                scale_factor=scale_factor,
                mode=mode,
                align_corners=align_corners,
                recompute_scale_factor=recompute_scale_factor,
                antialias=antialias,
            )
    
        if mode in ("nearest", "area", "nearest-exact"):
            if align_corners is not None:
                raise ValueError(
                    "align_corners option can only be set with the "
                    "interpolating modes: linear | bilinear | bicubic | trilinear"
                )
        else:
            if align_corners is None:
                align_corners = False
    
        dim = input.dim() - 2  # Number of spatial dimensions.
    
        # Process size and scale_factor.  Validate that exactly one is set.
        # Validate its length if it is a list, or expand it if it is a scalar.
        # After this block, exactly one of output_size and scale_factors will
        # be non-None, and it will be a list (or tuple).
        if size is not None and scale_factor is not None:
            raise ValueError("only one of size or scale_factor should be defined")
        elif size is not None:
            assert scale_factor is None
            scale_factors = None
            if isinstance(size, (list, tuple)):
                if len(size) != dim:
                    raise ValueError(
                        "Input and output must have the same number of spatial dimensions, but got "
                        f"input with spatial dimensions of {list(input.shape[2:])} and output size of {size}. "
                        "Please provide input tensor in (N, C, d1, d2, ...,dK) format and "
                        "output size in (o1, o2, ...,oK) format."
                    )
                if not torch.jit.is_scripting():
                    if not all(_is_integer(x) for x in size):
                        raise TypeError(
                            "expected size to be one of int or Tuple[int] or Tuple[int, int] or "
                            f"Tuple[int, int, int], but got size with types {[type(x) for x in size]}"
                        )
                output_size = size
            else:
                output_size = [size for _ in range(dim)]
        elif scale_factor is not None:
            assert size is None
            output_size = None
            if isinstance(scale_factor, (list, tuple)):
                if len(scale_factor) != dim:
                    raise ValueError(
                        "Input and scale_factor must have the same number of spatial dimensions, but "
                        f"got input with spatial dimensions of {list(input.shape[2:])} and "
                        f"scale_factor of shape {scale_factor}. "
                        "Please provide input tensor in (N, C, d1, d2, ...,dK) format and "
                        "scale_factor in (s1, s2, ...,sK) format."
                    )
                scale_factors = scale_factor
            else:
                scale_factors = [scale_factor for _ in range(dim)]
        else:
            raise ValueError("either size or scale_factor should be defined")
    
        if (
            recompute_scale_factor is not None
            and recompute_scale_factor
            and size is not None
        ):
            raise ValueError(
                "recompute_scale_factor is not meaningful with an explicit size."
            )
    
        # "area" mode always requires an explicit size rather than scale factor.
        # Re-use the recompute_scale_factor code path.
        if mode == "area" and output_size is None:
            recompute_scale_factor = True
    
        if recompute_scale_factor is not None and recompute_scale_factor:
            # We compute output_size here, then un-set scale_factors.
            # The C++ code will recompute it based on the (integer) output size.
            assert scale_factors is not None
            if not torch.jit.is_scripting() and torch._C._get_tracing_state():
                # make scale_factor a tensor in tracing so constant doesn't get baked in
                output_size = [
                    (
                        torch.floor(
                            (
                                input.size(i + 2).float()
                                * torch.tensor(scale_factors[i], dtype=torch.float32)
                            ).float()
                        )
                    )
                    for i in range(dim)
                ]
            elif torch.jit.is_scripting():
                output_size = [
                    int(math.floor(float(input.size(i + 2)) * scale_factors[i]))
                    for i in range(dim)
                ]
            else:
                output_size = [
                    _sym_int(input.size(i + 2) * scale_factors[i]) for i in range(dim)
                ]
            scale_factors = None
    
        if antialias and not (mode in ("bilinear", "bicubic") and input.ndim == 4):
            raise ValueError(
                "Anti-alias option is restricted to bilinear and bicubic modes and requires a 4-D tensor as input"
            )
    
        if input.dim() == 3 and mode == "nearest":
            return torch._C._nn.upsample_nearest1d(input, output_size, scale_factors)
        if input.dim() == 4 and mode == "nearest":
            return torch._C._nn.upsample_nearest2d(input, output_size, scale_factors)
        if input.dim() == 5 and mode == "nearest":
            return torch._C._nn.upsample_nearest3d(input, output_size, scale_factors)
    
        if input.dim() == 3 and mode == "nearest-exact":
            return torch._C._nn._upsample_nearest_exact1d(input, output_size, scale_factors)
        if input.dim() == 4 and mode == "nearest-exact":
            return torch._C._nn._upsample_nearest_exact2d(input, output_size, scale_factors)
        if input.dim() == 5 and mode == "nearest-exact":
            return torch._C._nn._upsample_nearest_exact3d(input, output_size, scale_factors)
    
        if input.dim() == 3 and mode == "area":
            assert output_size is not None
            return adaptive_avg_pool1d(input, output_size)
        if input.dim() == 4 and mode == "area":
            assert output_size is not None
            return adaptive_avg_pool2d(input, output_size)
        if input.dim() == 5 and mode == "area":
            assert output_size is not None
            return adaptive_avg_pool3d(input, output_size)
    
        if input.dim() == 3 and mode == "linear":
            assert align_corners is not None
            return torch._C._nn.upsample_linear1d(
                input, output_size, align_corners, scale_factors
            )
        if input.dim() == 4 and mode == "bilinear":
            assert align_corners is not None
            if antialias:
                return torch._C._nn._upsample_bilinear2d_aa(
                    input, output_size, align_corners, scale_factors
                )
            # Two levels are necessary to prevent TorchScript from touching
            # are_deterministic_algorithms_enabled.
            if not torch.jit.is_scripting():
                if torch.are_deterministic_algorithms_enabled() and (
                    input.is_cuda or input.is_xpu
                ):
                    # Use slow decomp whose backward will be in terms of index_put
                    # importlib is required because the import cannot be top level
                    # (cycle) and cannot be nested (TS doesn't support)
                    return importlib.import_module(
                        "torch._decomp.decompositions"
                    )._upsample_linear_vec(input, output_size, align_corners, scale_factors)
            return torch._C._nn.upsample_bilinear2d(
                input, output_size, align_corners, scale_factors
            )
        if input.dim() == 5 and mode == "trilinear":
            assert align_corners is not None
            return torch._C._nn.upsample_trilinear3d(
                input, output_size, align_corners, scale_factors
            )
        if input.dim() == 4 and mode == "bicubic":
            assert align_corners is not None
            if antialias:
                return torch._C._nn._upsample_bicubic2d_aa(
                    input, output_size, align_corners, scale_factors
                )
            return torch._C._nn.upsample_bicubic2d(
                input, output_size, align_corners, scale_factors
            )
    
        if input.dim() == 3 and mode == "bilinear":
>           raise NotImplementedError("Got 3D input, but bilinear mode needs 4D input")
E           NotImplementedError: Got 3D input, but bilinear mode needs 4D input

/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/functional.py:4599: NotImplementedError
_______________ TestYuv420ToRgb.test_forth_and_back[cpu-float32] _______________

self = <test_yuv.TestYuv420ToRgb object at 0x78c4d2b2b130>
device = device(type='cpu'), dtype = torch.float32

    def test_forth_and_back(self, device, dtype):  # skipcq: PYL-R0201
        datay = torch.rand(1, 4, 6, device=device, dtype=dtype)
        datauv = torch.rand(2, 2, 3, device=device, dtype=dtype)
        rgb = kornia.color.yuv420_to_rgb
        yuv = kornia.color.rgb_to_yuv420
    
>       (data_outy, data_outuv) = yuv(rgb(datay, datauv))

/local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py:431: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/yuv.py:143: in yuv420_to_rgb
    return yuv420_to_rgb(imagey, imageuv)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imagey = tensor([[[0.9650, 0.1468, 0.6748, 0.3477, 0.6079, 0.1304],
         [0.2253, 0.1447, 0.6064, 0.3740, 0.5018, 0.6763],
         [0.3136, 0.0679, 0.2069, 0.3724, 0.3306, 0.6060],
         [0.2159, 0.9503, 0.1586, 0.6938, 0.2565, 0.9092]]])
imageuv = tensor([[[0.2763, 0.7425, 0.0982],
         [0.7736, 0.3436, 0.9283]],

        [[0.5652, 0.8991, 0.7905],
         [0.6000, 0.3047, 0.6768]]])

    def yuv420_to_rgb(imagey, imageuv):
        if not isinstance(imagey, torch.Tensor) or not isinstance(imageuv, torch.Tensor):
            raise TypeError('Inputs must be torch Tensors.')
        if imagey.shape[-3] != 1 or imageuv.shape[-3] != 2:
            raise ValueError('Invalid channel dimensions for imagey or imageuv.')
        if imagey.min() < 0 or imagey.max() > 1 or imageuv.min() < -0.5 or (imageuv.max() > 0.5):
>           raise ValueError('Input values are out of the expected range.')
E           ValueError: Input values are out of the expected range.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/temp.py:15: ValueError
_________________ TestYuv420ToRgb.test_gradcheck[cpu-float32] __________________

self = <test_yuv.TestYuv420ToRgb object at 0x78c4d2b2b460>
device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.grad()
    def test_gradcheck(self, device, dtype):
        B, H, W = 2, 4, 4
        imgy = torch.rand(B, 1, H, W, device=device, dtype=torch.float64, requires_grad=True)
        imguv = torch.rand(B, 2, int(H / 2), int(W / 2), device=device, dtype=torch.float64, requires_grad=True)
>       assert gradcheck(kornia.color.yuv420_to_rgb, (imgy, imguv), raise_exception=True, fast_mode=True)

/local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py:440: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2074: in _gradcheck_helper
    func_out = func(*tupled_inputs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/yuv.py:143: in yuv420_to_rgb
    return yuv420_to_rgb(imagey, imageuv)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imagey = tensor([[[[0.2230, 0.4651, 0.4990, 0.6622],
          [0.7757, 0.2825, 0.6711, 0.1069],
          [0.9364, 0.7349, 0.3...0.3301, 0.4259, 0.9424],
          [0.3702, 0.0571, 0.5522, 0.6146]]]], dtype=torch.float64,
       requires_grad=True)
imageuv = tensor([[[[0.2921, 0.5588],
          [0.7405, 0.7844]],

         [[0.8989, 0.4430],
          [0.4169, 0.7172]]],


...[0.8172, 0.8792]],

         [[0.9422, 0.0732],
          [0.5829, 0.0490]]]], dtype=torch.float64, requires_grad=True)

    def yuv420_to_rgb(imagey, imageuv):
        if not isinstance(imagey, torch.Tensor) or not isinstance(imageuv, torch.Tensor):
            raise TypeError('Inputs must be torch Tensors.')
        if imagey.shape[-3] != 1 or imageuv.shape[-3] != 2:
            raise ValueError('Invalid channel dimensions for imagey or imageuv.')
        if imagey.min() < 0 or imagey.max() > 1 or imageuv.min() < -0.5 or (imageuv.max() > 0.5):
>           raise ValueError('Input values are out of the expected range.')
E           ValueError: Input values are out of the expected range.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/temp.py:15: ValueError
____________________ TestYuv420ToRgb.test_jit[cpu-float32] _____________________

self = <test_yuv.TestYuv420ToRgb object at 0x78c4d2b2b790>
device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.jit()
    def test_jit(self, device, dtype):
        B, H, W = 2, 4, 4
        imgy = torch.ones(B, 1, H, W, device=device, dtype=dtype)
        imguv = torch.ones(B, 2, int(H / 2), int(W / 2), device=device, dtype=dtype)
        op = kornia.color.yuv420_to_rgb
>       op_jit = torch.jit.script(op)

/local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py:448: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/jit/_script.py:1429: in script
    ret = _script_impl(
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/jit/_script.py:1202: in _script_impl
    ast = get_jit_def(obj, obj.__name__)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/jit/frontend.py:383: in get_jit_def
    return build_def(
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/jit/frontend.py:444: in build_def
    return Def(Ident(r, def_name), decl, build_stmts(ctx, body))
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/jit/frontend.py:197: in build_stmts
    stmts = [build_stmt(ctx, s) for s in stmts]
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/jit/frontend.py:197: in <listcomp>
    stmts = [build_stmt(ctx, s) for s in stmts]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.jit.frontend.StmtBuilder object at 0x78c5a9189ba0>
ctx = <torch._sources.SourceContext object at 0x78c4d2b6f5b0>
node = <ast.ImportFrom object at 0x78c4d2967280>

    def __call__(self, ctx, node):
        method = getattr(self, "build_" + node.__class__.__name__, None)
        if method is None:
>           raise UnsupportedNodeError(ctx, node)
E           torch.jit.frontend.UnsupportedNodeError: import statements aren't supported:
E             File "/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/yuv.py", line 142
E           def yuv420_to_rgb(imagey: Tensor, imageuv: Tensor) -> Tensor:
E               from .temp import yuv420_to_rgb
E               ~~~~ <--- HERE
E               return yuv420_to_rgb(imagey, imageuv)

/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/jit/frontend.py:416: UnsupportedNodeError
___________________ TestYuv420ToRgb.test_module[cpu-float32] ___________________

self = <test_yuv.TestYuv420ToRgb object at 0x78c4d2b2bac0>
device = device(type='cpu'), dtype = torch.float32

    def test_module(self, device, dtype):
        B, H, W = 2, 4, 4
        imgy = torch.ones(B, 1, H, W, device=device, dtype=dtype)
        imguv = torch.ones(B, 2, int(H / 2), int(W / 2), device=device, dtype=dtype)
        ops = kornia.color.Yuv420ToRgb().to(device, dtype)
        fcn = kornia.color.yuv420_to_rgb
>       self.assert_close(ops(imgy, imguv), fcn(imgy, imguv))

/local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py:457: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/core/module.py:274: in __call__
    _output_image = decorated_forward(*inputs, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/core/module.py:63: in wrapper
    tensor_outputs = func(*args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/yuv.py:372: in forward
    return yuv420_to_rgb(inputy, inputuv)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/yuv.py:143: in yuv420_to_rgb
    return yuv420_to_rgb(imagey, imageuv)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

imagey = tensor([[[[1., 1., 1., 1.],
          [1., 1., 1., 1.],
          [1., 1., 1., 1.],
          [1., 1., 1., 1.]]],


        [[[1., 1., 1., 1.],
          [1., 1., 1., 1.],
          [1., 1., 1., 1.],
          [1., 1., 1., 1.]]]])
imageuv = tensor([[[[1., 1.],
          [1., 1.]],

         [[1., 1.],
          [1., 1.]]],


        [[[1., 1.],
          [1., 1.]],

         [[1., 1.],
          [1., 1.]]]])

    def yuv420_to_rgb(imagey, imageuv):
        if not isinstance(imagey, torch.Tensor) or not isinstance(imageuv, torch.Tensor):
            raise TypeError('Inputs must be torch Tensors.')
        if imagey.shape[-3] != 1 or imageuv.shape[-3] != 2:
            raise ValueError('Invalid channel dimensions for imagey or imageuv.')
        if imagey.min() < 0 or imagey.max() > 1 or imageuv.min() < -0.5 or (imageuv.max() > 0.5):
>           raise ValueError('Input values are out of the expected range.')
E           ValueError: Input values are out of the expected range.

/local/data0/moved_data/publishablew/kornia/kornia/kornia/color/temp.py:15: ValueError
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_smoke[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape3]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_exception[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_unit_white[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_unit_red[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_forth_and_back[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_gradcheck[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_jit[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_module[cpu-float32]
============================== 12 failed in 0.70s ==============================


Final Test Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'jit', 'openxla', 'cudagraphs', 'inductor', 'onnxrt', 'tvm', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 12 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_smoke[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_exception[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_unit_white[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_unit_red[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_forth_and_back[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_gradcheck[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_jit[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_module[cpu-float32] PASSED

============================== 12 passed in 0.23s ==============================


Initial Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'openxla', 'jit', 'inductor', 'cudagraphs', 'onnxrt', 'tvm', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 12 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_smoke[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_cardinality[cpu-float32-shape3] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_exception[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_unit_white[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_unit_red[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_forth_and_back[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_gradcheck[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_jit[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/color/test_yuv.py::TestYuv420ToRgb::test_module[cpu-float32] PASSED

============================== 12 passed in 0.23s ==============================
