output file:
processed_Laplacefit15.json
function:
fit
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] FAILED', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace]', '../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] FAILED'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/Laplace/Laplace/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/Laplace/Laplace
configfile: pyproject.toml
plugins: mock-3.14.0, cov-6.0.0
collecting ... collected 212 items

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED

=================================== FAILURES ===================================
___________ test_laplace_init_prior_mean_and_scatter[FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f66710>

    @pytest.mark.parametrize("laplace", flavors)
    def test_laplace_init_prior_mean_and_scatter(laplace, model, class_loader):
        lap_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=1.0,
        )
        assert torch.allclose(lap_scalar_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1),
        )
        assert torch.allclose(lap_tensor_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1)[0],
        )
        assert torch.allclose(lap_tensor_scalar_mean.prior_mean, torch.tensor(1.0))
        lap_tensor_full_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(20 * 2 + 2),
        )
        assert torch.allclose(lap_tensor_full_mean.prior_mean, torch.ones(20 * 2 + 2))
    
        lap_scalar_mean.fit(class_loader)
        lap_tensor_mean.fit(class_loader)
        lap_tensor_scalar_mean.fit(class_loader)
        lap_tensor_full_mean.fit(class_loader)
        expected = lap_scalar_mean.scatter
        assert expected.ndim == 0
        assert torch.allclose(lap_tensor_mean.scatter, expected)
        assert lap_tensor_mean.scatter.shape == expected.shape
        assert torch.allclose(lap_tensor_scalar_mean.scatter, expected)
        assert lap_tensor_scalar_mean.scatter.shape == expected.shape
>       assert torch.allclose(lap_tensor_full_mean.scatter, expected)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac9942c610>

    @property
    def scatter(self) -> torch.Tensor:
        """Computes the _scatter_, a term of the log marginal likelihood that
        corresponds to L-2 regularization:
        `scatter` = \\((\\theta_{MAP} - \\mu_0)^{T} P_0 (\\theta_{MAP} - \\mu_0) \\).
    
        Returns
        -------
        scatter: torch.Tensor
        """
>       delta = self.mean - self.prior_mean
E       RuntimeError: The size of tensor a (122) must match the size of tensor b (42) at non-singleton dimension 0

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:943: RuntimeError
___________ test_laplace_init_prior_mean_and_scatter[KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f67dd0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_laplace_init_prior_mean_and_scatter(laplace, model, class_loader):
        lap_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=1.0,
        )
        assert torch.allclose(lap_scalar_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1),
        )
        assert torch.allclose(lap_tensor_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1)[0],
        )
        assert torch.allclose(lap_tensor_scalar_mean.prior_mean, torch.tensor(1.0))
        lap_tensor_full_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(20 * 2 + 2),
        )
        assert torch.allclose(lap_tensor_full_mean.prior_mean, torch.ones(20 * 2 + 2))
    
        lap_scalar_mean.fit(class_loader)
        lap_tensor_mean.fit(class_loader)
        lap_tensor_scalar_mean.fit(class_loader)
        lap_tensor_full_mean.fit(class_loader)
        expected = lap_scalar_mean.scatter
        assert expected.ndim == 0
        assert torch.allclose(lap_tensor_mean.scatter, expected)
        assert lap_tensor_mean.scatter.shape == expected.shape
        assert torch.allclose(lap_tensor_scalar_mean.scatter, expected)
        assert lap_tensor_scalar_mean.scatter.shape == expected.shape
>       assert torch.allclose(lap_tensor_full_mean.scatter, expected)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.KronLLLaplace object at 0x76ac98f07cd0>

    @property
    def scatter(self) -> torch.Tensor:
        """Computes the _scatter_, a term of the log marginal likelihood that
        corresponds to L-2 regularization:
        `scatter` = \\((\\theta_{MAP} - \\mu_0)^{T} P_0 (\\theta_{MAP} - \\mu_0) \\).
    
        Returns
        -------
        scatter: torch.Tensor
        """
>       delta = self.mean - self.prior_mean
E       RuntimeError: The size of tensor a (122) must match the size of tensor b (42) at non-singleton dimension 0

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:943: RuntimeError
___________ test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997f4650>

    @pytest.mark.parametrize("laplace", flavors)
    def test_laplace_init_prior_mean_and_scatter(laplace, model, class_loader):
        lap_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=1.0,
        )
        assert torch.allclose(lap_scalar_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1),
        )
        assert torch.allclose(lap_tensor_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1)[0],
        )
        assert torch.allclose(lap_tensor_scalar_mean.prior_mean, torch.tensor(1.0))
        lap_tensor_full_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(20 * 2 + 2),
        )
        assert torch.allclose(lap_tensor_full_mean.prior_mean, torch.ones(20 * 2 + 2))
    
        lap_scalar_mean.fit(class_loader)
        lap_tensor_mean.fit(class_loader)
        lap_tensor_scalar_mean.fit(class_loader)
        lap_tensor_full_mean.fit(class_loader)
        expected = lap_scalar_mean.scatter
        assert expected.ndim == 0
        assert torch.allclose(lap_tensor_mean.scatter, expected)
        assert lap_tensor_mean.scatter.shape == expected.shape
        assert torch.allclose(lap_tensor_scalar_mean.scatter, expected)
        assert lap_tensor_scalar_mean.scatter.shape == expected.shape
>       assert torch.allclose(lap_tensor_full_mean.scatter, expected)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac997d3f10>

    @property
    def scatter(self) -> torch.Tensor:
        """Computes the _scatter_, a term of the log marginal likelihood that
        corresponds to L-2 regularization:
        `scatter` = \\((\\theta_{MAP} - \\mu_0)^{T} P_0 (\\theta_{MAP} - \\mu_0) \\).
    
        Returns
        -------
        scatter: torch.Tensor
        """
>       delta = self.mean - self.prior_mean
E       RuntimeError: The size of tensor a (122) must match the size of tensor b (42) at non-singleton dimension 0

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:943: RuntimeError
__ test_laplace_functionality[pick_first-False-FullLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99461790>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99461150>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99460c10>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99460b50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac99462c50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____ test_laplace_functionality[pick_first-False-FullLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f65190>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f649d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f67210>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f65dd0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac98f64410>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__ test_laplace_functionality[pick_first-False-KronLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f9ed90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f9d490>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f9d650>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f9d590>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____ test_laplace_functionality[pick_first-False-KronLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76adba3c44d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76adba3c7c10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76adba3c5490>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99612150>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__ test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f67110>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f676d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f653d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f64390>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac98f66310>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____ test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f51850>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f52b50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f52e10>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f51050>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76adba3c6950>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___ test_laplace_functionality[pick_first-True-FullLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997d3490>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997d1a10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997d3790>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76acc834d290>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac99463810>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[pick_first-True-FullLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99612510>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99612150>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99610e50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99612c90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac99611f90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___ test_laplace_functionality[pick_first-True-KronLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fda750>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fd9750>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fd9fd0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fd9610>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[pick_first-True-KronLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f70810>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f702d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f70a90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f71510>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___ test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76adba3c7750>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76adba3c7610>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9b3dcb90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997d3790>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac997d3c90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997eb610>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997e9f90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997eaad0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997e8410>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac997ea6d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___ test_laplace_functionality[pick_last-False-FullLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9951f810>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9951eb90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9951f2d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9951dc50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac9951ed90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[pick_last-False-FullLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f87dd0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f86050>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f87ad0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f84f50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac98f85b50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___ test_laplace_functionality[pick_last-False-KronLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9951e790>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9951e450>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9951fcd0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9951f310>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[pick_last-False-KronLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99278bd0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99278a90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac992791d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9927b090>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___ test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99460890>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99461850>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac994611d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99463410>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99460b90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9942f690>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9942f750>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9942e190>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99478e10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac9947b190>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___ test_laplace_functionality[pick_last-True-FullLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac994ff410>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac994fd250>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac994fd690>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac994fc910>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac994fd5d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[pick_last-True-FullLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac992b6650>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac992b6d50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac992b7c50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac992b4bd0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac992b7250>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___ test_laplace_functionality[pick_last-True-KronLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac992b7f50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac992b5890>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac992b79d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac992b72d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[pick_last-True-KronLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99209490>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99208610>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99208810>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99208690>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___ test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fc51d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fc4dd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fc5e50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fc7bd0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac98fc5f50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76adbbbe6090>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76adbbbe5e90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f9c650>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f9ee10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac98f9e690>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____ test_laplace_functionality[average-False-FullLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99461d50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99462f10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99460510>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99461290>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac99461bd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______ test_laplace_functionality[average-False-FullLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac995a9cd0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac995a8510>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac995ab250>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac995a87d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac995abc50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____ test_laplace_functionality[average-False-KronLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fdb6d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fd8cd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fd84d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fdbdd0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______ test_laplace_functionality[average-False-KronLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99462450>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99460390>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99460e50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99463c50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____ test_laplace_functionality[average-False-DiagLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fa9650>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fab6d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fa8690>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fabb10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac98fa8bd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______ test_laplace_functionality[average-False-DiagLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98ff4150>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98ff5d50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98ff7f10>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98ff76d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac98ff4e50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____ test_laplace_functionality[average-True-FullLLLaplace-classification] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9948dad0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9948e050>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9948e2d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9948cf90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac9948d450>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______ test_laplace_functionality[average-True-FullLLLaplace-regression] _______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99461790>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99462450>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99460b50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99461d50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac99461050>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____ test_laplace_functionality[average-True-KronLLLaplace-classification] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac995c41d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac995c4150>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac995c7fd0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac995c5810>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______ test_laplace_functionality[average-True-KronLLLaplace-regression] _______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98ff43d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98ff4650>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98ff7910>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98ff4ed0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____ test_laplace_functionality[average-True-DiagLLLaplace-classification] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac994617d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99463c50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99463550>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac994635d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99462110>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______ test_laplace_functionality[average-True-DiagLLLaplace-regression] _______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f1dc10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f1fc10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f1ec10>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f1eb50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac98f1f4d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[None-False-FullLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997ecbd0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997ef190>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997ed250>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997ec810>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac997ef9d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_______ test_laplace_functionality[None-False-FullLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99461fd0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99460e50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99462d50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99463810>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac99460c10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[None-False-KronLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997d3c90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997d3a50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac994ffb90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac994ffd10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_______ test_laplace_functionality[None-False-KronLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac992b9950>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac992b9a50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac992b9e90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac992b9f10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[None-False-DiagLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99539790>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99539f50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997ecf90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997ef410>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac997ee450>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_______ test_laplace_functionality[None-False-DiagLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997ea450>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997ebcd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997e8390>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997eb4d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99209f10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______ test_laplace_functionality[None-True-FullLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98faad10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fa9e90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fab6d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fa8f10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac98faacd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_laplace_functionality[None-True-FullLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f077d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f05850>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f07050>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f06b10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac98f07090>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______ test_laplace_functionality[None-True-KronLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fabb90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98faa050>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fa9110>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98faa450>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_laplace_functionality[None-True-KronLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f53210>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f504d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f53f90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f529d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______ test_laplace_functionality[None-True-DiagLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9944a4d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99448950>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac994481d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99448a90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99448050>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_laplace_functionality[None-True-DiagLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fa8bd0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98faa290>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98faaf50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fa8490>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac98fab410>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________________ test_regression_predictive[FullLLLaplace] ___________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fab690>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:474: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac992b4d90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________________ test_regression_predictive[KronLLLaplace] ___________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f06010>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:474: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________________ test_regression_predictive[DiagLLLaplace] ___________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99460890>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:474: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99463550>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________________ test_classification_predictive[FullLLLaplace] _________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997d1390>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:498: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac98fa85d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________________ test_classification_predictive[KronLLLaplace] _________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99202890>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:498: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________________ test_classification_predictive[DiagLLLaplace] _________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f50410>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:498: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac98f510d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_regression_predictive_samples[FullLLLaplace] _______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99461e10>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive_samples(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac99460c50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_regression_predictive_samples[KronLLLaplace] _______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f50910>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive_samples(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_regression_predictive_samples[DiagLLLaplace] _______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fe3c90>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive_samples(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac98fe2e10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_classification_predictive_samples[FullLLLaplace] _____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98f3a550>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive_samples(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac98f38550>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_classification_predictive_samples[KronLLLaplace] _____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac994612d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive_samples(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_classification_predictive_samples[DiagLLLaplace] _____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac992e4190>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive_samples(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac992e4950>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________________ test_functional_variance_fast[FullLLLaplace] _________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9953bcd0>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, DiagLLLaplace, KronLLLaplace])
    def test_functional_variance_fast(laplace, model, reg_loader):
        if laplace == KronLLLaplace:
            # TODO still!
            return
    
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:588: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac9951ff50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________________ test_functional_variance_fast[DiagLLLaplace] _________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac997ece50>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, DiagLLLaplace, KronLLLaplace])
    def test_functional_variance_fast(laplace, model, reg_loader):
        if laplace == KronLLLaplace:
            # TODO still!
            return
    
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:588: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99463810>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_______________________ test_backprop_glm[FullLLLaplace] _______________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9941fa10>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:614: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac9941d490>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_______________________ test_backprop_glm[KronLLLaplace] _______________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9922dfd0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:614: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_______________________ test_backprop_glm[DiagLLLaplace] _______________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac995387d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:614: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac9953ba90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________________ test_backprop_glm_joint[FullLLLaplace] ____________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fdb2d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_joint(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac98fda550>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________________ test_backprop_glm_joint[KronLLLaplace] ____________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac9954c510>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_joint(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________________ test_backprop_glm_joint[DiagLLLaplace] ____________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99249d10>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_joint(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99249f10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________________ test_backprop_glm_mc[FullLLLaplace] ______________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fd8450>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_mc(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:652: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac98fda090>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________________ test_backprop_glm_mc[KronLLLaplace] ______________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac99203bd0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_mc(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:652: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________________ test_backprop_glm_mc[DiagLLLaplace] ______________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac992a60d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_mc(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:652: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac992a4e50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_______________________ test_backprop_nn[FullLLLaplace] ________________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fdbb50>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_nn(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:671: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac997ee990>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_______________________ test_backprop_nn[KronLLLaplace] ________________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac995e4b90>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_nn(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:671: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_______________________ test_backprop_nn[DiagLLLaplace] ________________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac995e6250>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_nn(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:671: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac995e4290>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_reg_glm_predictive_correct_behavior[FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fc6310>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, KronLLLaplace, DiagLLLaplace])
    def test_reg_glm_predictive_correct_behavior(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        n_batch = X.shape[0]
        n_outputs = y.shape[-1]
    
        lap = laplace(model, "regression")
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:691: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac98fc70d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_reg_glm_predictive_correct_behavior[KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac98fda010>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, KronLLLaplace, DiagLLLaplace])
    def test_reg_glm_predictive_correct_behavior(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        n_batch = X.shape[0]
        n_outputs = y.shape[-1]
    
        lap = laplace(model, "regression")
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:691: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_reg_glm_predictive_correct_behavior[DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x76ac992aa650>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, KronLLLaplace, DiagLLLaplace])
    def test_reg_glm_predictive_correct_behavior(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        n_batch = X.shape[0]
        n_outputs = y.shape[-1]
    
        lap = laplace(model, "regression")
>       lap.fit(reg_loader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:691: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac992a9c50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac98f51510>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac9929e250>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac9923ff10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac98f51890>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac98f06f10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99555cd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac995e4c90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac994ffad0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac992498d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99266690>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac98f38d90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99275e90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac9924d090>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac98fdf750>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac9924e750>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac992a1810>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac98f3b610>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac992ac210>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac99266fd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac992a10d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac98f86c50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99575dd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac9927b750>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac9954f450>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac99264610>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99266d50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac9944b8d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac992a76d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac9944a590>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac993684d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac9940bdd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac992a6150>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac992af0d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac993f1fd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac99580f90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99580d10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac99259810>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac992651d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________ test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac993df590>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________ test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________ test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac993112d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac9941e9d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac9925add0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac9941e410>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac98fe2f90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac992a3250>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99314b50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac99583bd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99582b10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac995c6d50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac992a34d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________ test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac992bac50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________ test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________ test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac992b8e50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac992e4750>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac992bac50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac98fdc150>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac993c4f10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac98f71b90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac9932fe90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac9955e190>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99369d50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac992a9c90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99377190>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________ test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac99478ad0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________ test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________ test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac9933aa90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac99315f50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99369350>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac992ad610>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac9922e250>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac98f84390>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac9922cf50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x76ac993068d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

/local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x76ac99361990>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

/local/data0/moved_data/publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION = LooseVersion(version("torch"))

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION_AT_LEAST_1_12_0 = TORCH_VERSION >= LooseVersion("1.12.0")

tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace]
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/curvlinops/_base.py:299: UserWarning: Input matrix is float64, while linear operator is float32. Converting to float32.
    warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace]
FAILED ../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace]
================= 188 failed, 24 passed, 3 warnings in 21.45s ==================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/Laplace/Laplace/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/Laplace/Laplace
configfile: pyproject.toml
plugins: mock-3.14.0, cov-6.0.0
collecting ... collected 212 items

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED

=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION = LooseVersion(version("torch"))

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION_AT_LEAST_1_12_0 = TORCH_VERSION >= LooseVersion("1.12.0")

tests/test_lllaplace.py: 27 warnings
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/curvlinops/_base.py:299: UserWarning: Input matrix is float64, while linear operator is float32. Converting to float32.
    warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================= 212 passed, 29 warnings in 64.60s (0:01:04) ==================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/Laplace/Laplace/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/Laplace/Laplace
configfile: pyproject.toml
plugins: mock-3.14.0, cov-6.0.0
collecting ... collected 212 items

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED

=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION = LooseVersion(version("torch"))

../../../../../../local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION_AT_LEAST_1_12_0 = TORCH_VERSION >= LooseVersion("1.12.0")

tests/test_lllaplace.py: 27 warnings
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/curvlinops/_base.py:299: UserWarning: Input matrix is float64, while linear operator is float32. Converting to float32.
    warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
====================== 212 passed, 29 warnings in 58.20s =======================
