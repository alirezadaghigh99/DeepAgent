output file:
processed_pfrlcompute_policy_gradient_loss259.json
function:
compute_policy_gradient_loss
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian]', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax] FAILED', '../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax]'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/pfrl/pfrl/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/pfrl/pfrl
configfile: pytest.ini
collecting ... collected 32 items

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian] FAILED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax] FAILED

=================================== FAILURES ===================================
____ TestDegenerateDistribution.test_policy_gradient[0-True-True-Gaussian] _____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be50ba10>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
_____ TestDegenerateDistribution.test_policy_gradient[0-True-True-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be50bcd0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
____ TestDegenerateDistribution.test_policy_gradient[0-True-False-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be50bfd0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
____ TestDegenerateDistribution.test_policy_gradient[0-True-False-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be511290>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
____ TestDegenerateDistribution.test_policy_gradient[0-False-True-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be510390>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
____ TestDegenerateDistribution.test_policy_gradient[0-False-True-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be5104d0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
___ TestDegenerateDistribution.test_policy_gradient[0-False-False-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be510990>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
____ TestDegenerateDistribution.test_policy_gradient[0-False-False-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be510d50>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
____ TestDegenerateDistribution.test_policy_gradient[1-True-True-Gaussian] _____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be510e90>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
_____ TestDegenerateDistribution.test_policy_gradient[1-True-True-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be513f90>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
____ TestDegenerateDistribution.test_policy_gradient[1-True-False-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51c250>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
____ TestDegenerateDistribution.test_policy_gradient[1-True-False-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51c4d0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
____ TestDegenerateDistribution.test_policy_gradient[1-False-True-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51c750>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
____ TestDegenerateDistribution.test_policy_gradient[1-False-True-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51c9d0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
___ TestDegenerateDistribution.test_policy_gradient[1-False-False-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51cc50>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
____ TestDegenerateDistribution.test_policy_gradient[1-False-False-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51ced0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
____ TestDegenerateDistribution.test_policy_gradient[10-True-True-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51d150>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
____ TestDegenerateDistribution.test_policy_gradient[10-True-True-Softmax] _____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51d3d0>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
___ TestDegenerateDistribution.test_policy_gradient[10-True-False-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51d650>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
____ TestDegenerateDistribution.test_policy_gradient[10-True-False-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51d910>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
___ TestDegenerateDistribution.test_policy_gradient[10-False-True-Gaussian] ____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51dc10>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
____ TestDegenerateDistribution.test_policy_gradient[10-False-True-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51df10>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
___ TestDegenerateDistribution.test_policy_gradient[10-False-False-Gaussian] ___

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51e210>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
___ TestDegenerateDistribution.test_policy_gradient[10-False-False-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51e510>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
___ TestDegenerateDistribution.test_policy_gradient[None-True-True-Gaussian] ___

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51e810>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
___ TestDegenerateDistribution.test_policy_gradient[None-True-True-Softmax] ____

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51eb10>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
__ TestDegenerateDistribution.test_policy_gradient[None-True-False-Gaussian] ___

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51ee10>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
___ TestDegenerateDistribution.test_policy_gradient[None-True-False-Softmax] ___

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51f110>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
__ TestDegenerateDistribution.test_policy_gradient[None-False-True-Gaussian] ___

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51f410>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
___ TestDegenerateDistribution.test_policy_gradient[None-False-True-Softmax] ___

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51f710>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
__ TestDegenerateDistribution.test_policy_gradient[None-False-False-Gaussian] __

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51fa10>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
__ TestDegenerateDistribution.test_policy_gradient[None-False-False-Softmax] ___

self = <test_acer.TestDegenerateDistribution object at 0x70b9be51fd10>

    def test_policy_gradient(self):
        action = self.mu.sample()
>       pg = acer.compute_policy_gradient_loss(
            action, 1, self.pi, self.mu, self.action_value, 0, self.truncation_threshold
        )

/local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/acer.py:52: in compute_policy_gradient_loss
    from .temp import compute_policy_gradient_loss
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import copy
    from logging import getLogger
    import numpy as np
    import torch
    from torch import nn
    from pfrl import agent
    from pfrl.action_value import SingleActionValue
    from pfrl.utils import clip_l2_grad_norm_, copy_param
    from pfrl.utils.batch_states import batch_states
    from pfrl.utils.mode_of_distribution import mode_of_distribution
    from pfrl.utils.recurrent import detach_recurrent_state, one_step_forward
    import torch
    import torch.nn.functional as F
    
>   def compute_policy_gradient_loss(action: torch.Tensor, advantage: torch.Tensor, action_distrib: torch.distributions.Distribution, action_distrib_mu: torch.distributions.Distribution, action_value: torch.Tensor, v: torch.Tensor, truncation_threshold: Optional[float]=None) -> torch.Tensor:
E   NameError: name 'Optional' is not defined

/local/data0/moved_data/publishablew/pfrl/pfrl/pfrl/agents/temp.py:15: NameError
=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian]
FAILED ../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax]
======================== 32 failed, 2 warnings in 1.35s ========================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/pfrl/pfrl/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/pfrl/pfrl
configfile: pytest.ini
collecting ... collected 32 items

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian] pg tensor([-19.1486])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian] pg tensor([9.2661])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian] pg tensor([-46.7282])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian] pg tensor([0.3202])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian] pg tensor([1.1989])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian] pg tensor([-28.4762])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax] pg tensor([1.7881e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian] pg tensor([1.9847])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax] pg tensor([0.6931])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian] pg tensor([2.2951])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian] pg tensor([-24.4438])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax] pg tensor([2.3842e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian] pg tensor([3.8284])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax] pg tensor([0.6931])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian] pg tensor([1.4384e-20])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax] pg tensor([0.3466])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian] pg tensor([0.])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax] pg tensor([3.8010e-06])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian] pg tensor([5.2723])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax] pg tensor([0.6931])
PASSED

=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================== 32 passed, 2 warnings in 0.97s ========================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/pfrl/pfrl/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/pfrl/pfrl
configfile: pytest.ini
collecting ... collected 32 items

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Gaussian] pg tensor([-17.0214])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Gaussian] pg tensor([-0.4737])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Gaussian] pg tensor([-37.4797])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Gaussian] pg tensor([2.8586])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[0-False-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Gaussian] pg tensor([0.5772])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Gaussian] pg tensor([-39.8264])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-True-Softmax] pg tensor([1.7881e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Gaussian] pg tensor([2.3665])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[1-False-False-Softmax] pg tensor([0.6931])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Gaussian] pg tensor([1.2887])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-True-False-Softmax] pg tensor([1.3863])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Gaussian] pg tensor([-22.7128])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-True-Softmax] pg tensor([2.3842e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Gaussian] pg tensor([2.0022])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[10-False-False-Softmax] pg tensor([0.6931])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Gaussian] pg tensor([-44.2138])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-True-Softmax] pg tensor([1.1921e-07])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Gaussian] pg tensor([1.5821e-20])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-True-False-Softmax] pg tensor([0.3466])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Gaussian] pg tensor([0.])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-True-Softmax] pg tensor([3.8010e-06])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Gaussian] pg tensor([1.9607])
PASSED
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py::TestDegenerateDistribution::test_policy_gradient[None-False-False-Softmax] pg tensor([0.6931])
PASSED

=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:326: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

../../../../../../local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333
  /local/data0/moved_data/publishablew/pfrl/pfrl/tests/agents_tests/test_acer.py:333: PytestUnknownMarkWarning: Unknown pytest.mark.async_ - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.async_

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================== 32 passed, 2 warnings in 0.97s ========================
