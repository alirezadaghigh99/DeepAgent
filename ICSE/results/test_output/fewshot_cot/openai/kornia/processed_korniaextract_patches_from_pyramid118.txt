output file:
processed_korniaextract_patches_from_pyramid118.json
function:
extract_patches_from_pyramid
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_shape[cpu]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_non_zero[cpu]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_gradcheck[cpu]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_shape[cpu] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_non_zero[cpu] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_odd[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_gradcheck[cpu] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_odd[cpu-float32] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_even[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_even[cpu-float32] FAILED'}

All Test Cases On Generated code:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'tvm', 'jit', 'inductor', 'onnxrt', None, 'openxla', 'cudagraphs'}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 5 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_shape[cpu] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_non_zero[cpu] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_odd[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_even[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_gradcheck[cpu] FAILED

=================================== FAILURES ===================================
____________________ TestExtractPatchesPyr.test_shape[cpu] _____________________

self = <test_laf.TestExtractPatchesPyr object at 0x7f07d9333760>
device = device(type='cpu')

    def test_shape(self, device):
        laf = torch.rand(5, 4, 2, 3, device=device)
        img = torch.rand(5, 3, 100, 30, device=device)
        PS = 10
>       patches = kornia.feature.extract_patches_from_pyramid(img, laf, PS)

/local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py:420: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/feature/laf.py:348: in extract_patches_from_pyramid
    return extract_patches_from_pyramid(img, laf, PS, normalize_lafs_before_extraction)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/feature/temp.py:37: in extract_patches_from_pyramid
    level = determine_pyramid_level(scale, pyramid)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

scale = tensor(nan)
pyramid = [tensor([[[[3.3193e-01, 1.1801e-02, 3.4745e-01,  ..., 2.3126e-01,
           2.1022e-01, 1.8893e-01],
          [6.924...     [[0.4945],
          [0.4957],
          [0.5127],
          [0.5101],
          [0.5082],
          [0.4557]]]])]

    def determine_pyramid_level(scale: torch.Tensor, pyramid: list) -> int:
>       return min(int(scale.item()), len(pyramid) - 1)
E       ValueError: cannot convert float NaN to integer

/local/data0/moved_data/publishablew/kornia/kornia/kornia/feature/temp.py:53: ValueError
___________________ TestExtractPatchesPyr.test_non_zero[cpu] ___________________

self = <test_laf.TestExtractPatchesPyr object at 0x7f07d9333a90>
device = device(type='cpu')

    def test_non_zero(self, device):
        img = torch.zeros(1, 1, 24, 24, device=device)
        img[:, :, 10:, 20:] = 1.0
        laf = torch.tensor([[8.0, 0, 14.0], [0, 8.0, 8.0]], device=device).reshape(1, 1, 2, 3)
    
        PS = 32
>       patches = kornia.feature.extract_patches_from_pyramid(img, laf, PS)

/local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py:429: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/feature/laf.py:348: in extract_patches_from_pyramid
    return extract_patches_from_pyramid(img, laf, PS, normalize_lafs_before_extraction)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/feature/temp.py:38: in extract_patches_from_pyramid
    patch = extract_patch_from_level(pyramid[level][b], A, t, patch_size)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/feature/temp.py:56: in extract_patch_from_level
    grid = F.affine_grid(A.unsqueeze(0), [1, img.size(0), patch_size, patch_size], align_corners=False)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

theta = tensor([[[8., 0.],
         [0., 8.]]]), size = [1, 1, 32, 32]
align_corners = False

    def affine_grid(
        theta: Tensor,
        size: List[int],
        align_corners: Optional[bool] = None,
    ) -> Tensor:
        r"""Generate 2D or 3D flow field (sampling grid), given a batch of affine matrices :attr:`theta`.
    
        .. note::
            This function is often used in conjunction with :func:`grid_sample`
            to build `Spatial Transformer Networks`_ .
    
        Args:
            theta (Tensor): input batch of affine matrices with shape
                (:math:`N \times 2 \times 3`) for 2D or
                (:math:`N \times 3 \times 4`) for 3D
            size (torch.Size): the target output image size.
                (:math:`N \times C \times H \times W` for 2D or
                :math:`N \times C \times D \times H \times W` for 3D)
                Example: torch.Size((32, 3, 24, 24))
            align_corners (bool, optional): if ``True``, consider ``-1`` and ``1``
                to refer to the centers of the corner pixels rather than the image corners.
                Refer to :func:`grid_sample` for a more complete description.
                A grid generated by :func:`affine_grid` should be passed to :func:`grid_sample`
                with the same setting for this option.
                Default: ``False``
    
        Returns:
            output (Tensor): output Tensor of size (:math:`N \times H \times W \times 2`)
    
        .. _`Spatial Transformer Networks`:
            https://arxiv.org/abs/1506.02025
    
        .. warning::
            When ``align_corners = True``, the grid positions depend on the pixel
            size relative to the input image size, and so the locations sampled by
            :func:`grid_sample` will differ for the same input given at different
            resolutions (that is, after being upsampled or downsampled).
            The default behavior up to version 1.2.0 was ``align_corners = True``.
            Since then, the default behavior has been changed to ``align_corners = False``,
            in order to bring it in line with the default for :func:`interpolate`.
        .. warning::
            When ``align_corners = True``, 2D affine transforms on 1D data and
            3D affine transforms on 2D data (that is, when one of the spatial
            dimensions has unit size) are ill-defined, and not an intended use case.
            This is not a problem when ``align_corners = False``.
            Up to version 1.2.0, all grid points along a unit dimension were
            considered arbitrarily to be at ``-1``.
            From version 1.3.0, under ``align_corners = True`` all grid points
            along a unit dimension are considered to be at ``0``
            (the center of the input image).
        """
        if has_torch_function_unary(theta):
            return handle_torch_function(
                affine_grid, (theta,), theta, size, align_corners=align_corners
            )
        if align_corners is None:
            warnings.warn(
                "Default grid_sample and affine_grid behavior has changed "
                "to align_corners=False since 1.3.0. Please specify "
                "align_corners=True if the old behavior is desired. "
                "See the documentation of grid_sample for details."
            )
            align_corners = False
    
        # enforce floating point dtype on theta
        if not theta.is_floating_point():
            raise ValueError(
                f"Expected theta to have floating point type, but got {theta.dtype}"
            )
        # check that shapes and sizes match
        if len(size) == 4:
            if theta.dim() != 3 or theta.shape[-2] != 2 or theta.shape[-1] != 3:
>               raise ValueError(
                    f"Expected a batch of 2D affine matrices of shape Nx2x3 for size {size}. Got {theta.shape}."
                )
E               ValueError: Expected a batch of 2D affine matrices of shape Nx2x3 for size [1, 1, 32, 32]. Got torch.Size([1, 2, 2]).

/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/functional.py:4985: ValueError
_______________ TestExtractPatchesPyr.test_same_odd[cpu-float32] _______________

self = <test_laf.TestExtractPatchesPyr object at 0x7f07d9333d90>
device = device(type='cpu'), dtype = torch.float32

    def test_same_odd(self, device, dtype):
        img = torch.arange(5)[None].repeat(5, 1)[None, None].to(device, dtype)
        laf = torch.tensor([[2.0, 0, 2.0], [0, 2.0, 2.0]]).reshape(1, 1, 2, 3).to(device, dtype)
    
>       patch = kornia.feature.extract_patches_from_pyramid(img, laf, 5, 1.0)

/local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py:437: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/feature/laf.py:348: in extract_patches_from_pyramid
    return extract_patches_from_pyramid(img, laf, PS, normalize_lafs_before_extraction)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/feature/temp.py:30: in extract_patches_from_pyramid
    pyramid = create_image_pyramid(img)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/feature/temp.py:48: in create_image_pyramid
    img = F.interpolate(img, scale_factor=0.5, mode='bilinear', align_corners=False)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[1.5000]]]]), size = None, scale_factor = 0.5
mode = 'bilinear', align_corners = False, recompute_scale_factor = None
antialias = False

    def interpolate(  # noqa: F811
        input: Tensor,
        size: Optional[int] = None,
        scale_factor: Optional[List[float]] = None,
        mode: str = "nearest",
        align_corners: Optional[bool] = None,
        recompute_scale_factor: Optional[bool] = None,
        antialias: bool = False,
    ) -> Tensor:  # noqa: B950
        r"""Down/up samples the input.
    
        Tensor interpolated to either the given :attr:`size` or the given
        :attr:`scale_factor`
    
        The algorithm used for interpolation is determined by :attr:`mode`.
    
        Currently temporal, spatial and volumetric sampling are supported, i.e.
        expected inputs are 3-D, 4-D or 5-D in shape.
    
        The input dimensions are interpreted in the form:
        `mini-batch x channels x [optional depth] x [optional height] x width`.
    
        The modes available for resizing are: `nearest`, `linear` (3D-only),
        `bilinear`, `bicubic` (4D-only), `trilinear` (5D-only), `area`, `nearest-exact`
    
        Args:
            input (Tensor): the input tensor
            size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int]):
                output spatial size.
            scale_factor (float or Tuple[float]): multiplier for spatial size. If `scale_factor` is a tuple,
                its length has to match the number of spatial dimensions; `input.dim() - 2`.
            mode (str): algorithm used for upsampling:
                ``'nearest'`` | ``'linear'`` | ``'bilinear'`` | ``'bicubic'`` |
                ``'trilinear'`` | ``'area'`` | ``'nearest-exact'``. Default: ``'nearest'``
            align_corners (bool, optional): Geometrically, we consider the pixels of the
                input and output as squares rather than points.
                If set to ``True``, the input and output tensors are aligned by the
                center points of their corner pixels, preserving the values at the corner pixels.
                If set to ``False``, the input and output tensors are aligned by the corner
                points of their corner pixels, and the interpolation uses edge value padding
                for out-of-boundary values, making this operation *independent* of input size
                when :attr:`scale_factor` is kept the same. This only has an effect when :attr:`mode`
                is ``'linear'``, ``'bilinear'``, ``'bicubic'`` or ``'trilinear'``.
                Default: ``False``
            recompute_scale_factor (bool, optional): recompute the scale_factor for use in the
                interpolation calculation. If `recompute_scale_factor` is ``True``, then
                `scale_factor` must be passed in and `scale_factor` is used to compute the
                output `size`. The computed output `size` will be used to infer new scales for
                the interpolation. Note that when `scale_factor` is floating-point, it may differ
                from the recomputed `scale_factor` due to rounding and precision issues.
                If `recompute_scale_factor` is ``False``, then `size` or `scale_factor` will
                be used directly for interpolation. Default: ``None``.
            antialias (bool, optional): flag to apply anti-aliasing. Default: ``False``. Using anti-alias
                option together with ``align_corners=False``, interpolation result would match Pillow
                result for downsampling operation. Supported modes: ``'bilinear'``, ``'bicubic'``.
    
        .. note::
            With ``mode='bicubic'``, it's possible to cause overshoot, in other words it can produce
            negative values or values greater than 255 for images.
            Explicitly call ``result.clamp(min=0, max=255)`` if you want to reduce the overshoot
            when displaying the image.
    
        .. note::
            Mode ``mode='nearest-exact'`` matches Scikit-Image and PIL nearest neighbours interpolation
            algorithms and fixes known issues with ``mode='nearest'``. This mode is introduced to keep
            backward compatibility.
            Mode ``mode='nearest'`` matches buggy OpenCV's ``INTER_NEAREST`` interpolation algorithm.
    
        .. note::
            The gradients for the dtype ``float16`` on CUDA may be inaccurate in the upsample operation
            when using modes ``['linear', 'bilinear', 'bicubic', 'trilinear', 'area']``.
            For more details, please refer to the discussion in
            `issue#104157 <https://github.com/pytorch/pytorch/issues/104157>`_.
    
        Note:
            {backward_reproducibility_note}
        """
        if has_torch_function_unary(input):
            return handle_torch_function(
                interpolate,
                (input,),
                input,
                size=size,
                scale_factor=scale_factor,
                mode=mode,
                align_corners=align_corners,
                recompute_scale_factor=recompute_scale_factor,
                antialias=antialias,
            )
    
        if mode in ("nearest", "area", "nearest-exact"):
            if align_corners is not None:
                raise ValueError(
                    "align_corners option can only be set with the "
                    "interpolating modes: linear | bilinear | bicubic | trilinear"
                )
        else:
            if align_corners is None:
                align_corners = False
    
        dim = input.dim() - 2  # Number of spatial dimensions.
    
        # Process size and scale_factor.  Validate that exactly one is set.
        # Validate its length if it is a list, or expand it if it is a scalar.
        # After this block, exactly one of output_size and scale_factors will
        # be non-None, and it will be a list (or tuple).
        if size is not None and scale_factor is not None:
            raise ValueError("only one of size or scale_factor should be defined")
        elif size is not None:
            assert scale_factor is None
            scale_factors = None
            if isinstance(size, (list, tuple)):
                if len(size) != dim:
                    raise ValueError(
                        "Input and output must have the same number of spatial dimensions, but got "
                        f"input with spatial dimensions of {list(input.shape[2:])} and output size of {size}. "
                        "Please provide input tensor in (N, C, d1, d2, ...,dK) format and "
                        "output size in (o1, o2, ...,oK) format."
                    )
                if not torch.jit.is_scripting():
                    if not all(_is_integer(x) for x in size):
                        raise TypeError(
                            "expected size to be one of int or Tuple[int] or Tuple[int, int] or "
                            f"Tuple[int, int, int], but got size with types {[type(x) for x in size]}"
                        )
                output_size = size
            else:
                output_size = [size for _ in range(dim)]
        elif scale_factor is not None:
            assert size is None
            output_size = None
            if isinstance(scale_factor, (list, tuple)):
                if len(scale_factor) != dim:
                    raise ValueError(
                        "Input and scale_factor must have the same number of spatial dimensions, but "
                        f"got input with spatial dimensions of {list(input.shape[2:])} and "
                        f"scale_factor of shape {scale_factor}. "
                        "Please provide input tensor in (N, C, d1, d2, ...,dK) format and "
                        "scale_factor in (s1, s2, ...,sK) format."
                    )
                scale_factors = scale_factor
            else:
                scale_factors = [scale_factor for _ in range(dim)]
        else:
            raise ValueError("either size or scale_factor should be defined")
    
        if (
            recompute_scale_factor is not None
            and recompute_scale_factor
            and size is not None
        ):
            raise ValueError(
                "recompute_scale_factor is not meaningful with an explicit size."
            )
    
        # "area" mode always requires an explicit size rather than scale factor.
        # Re-use the recompute_scale_factor code path.
        if mode == "area" and output_size is None:
            recompute_scale_factor = True
    
        if recompute_scale_factor is not None and recompute_scale_factor:
            # We compute output_size here, then un-set scale_factors.
            # The C++ code will recompute it based on the (integer) output size.
            assert scale_factors is not None
            if not torch.jit.is_scripting() and torch._C._get_tracing_state():
                # make scale_factor a tensor in tracing so constant doesn't get baked in
                output_size = [
                    (
                        torch.floor(
                            (
                                input.size(i + 2).float()
                                * torch.tensor(scale_factors[i], dtype=torch.float32)
                            ).float()
                        )
                    )
                    for i in range(dim)
                ]
            elif torch.jit.is_scripting():
                output_size = [
                    int(math.floor(float(input.size(i + 2)) * scale_factors[i]))
                    for i in range(dim)
                ]
            else:
                output_size = [
                    _sym_int(input.size(i + 2) * scale_factors[i]) for i in range(dim)
                ]
            scale_factors = None
    
        if antialias and not (mode in ("bilinear", "bicubic") and input.ndim == 4):
            raise ValueError(
                "Anti-alias option is restricted to bilinear and bicubic modes and requires a 4-D tensor as input"
            )
    
        if input.dim() == 3 and mode == "nearest":
            return torch._C._nn.upsample_nearest1d(input, output_size, scale_factors)
        if input.dim() == 4 and mode == "nearest":
            return torch._C._nn.upsample_nearest2d(input, output_size, scale_factors)
        if input.dim() == 5 and mode == "nearest":
            return torch._C._nn.upsample_nearest3d(input, output_size, scale_factors)
    
        if input.dim() == 3 and mode == "nearest-exact":
            return torch._C._nn._upsample_nearest_exact1d(input, output_size, scale_factors)
        if input.dim() == 4 and mode == "nearest-exact":
            return torch._C._nn._upsample_nearest_exact2d(input, output_size, scale_factors)
        if input.dim() == 5 and mode == "nearest-exact":
            return torch._C._nn._upsample_nearest_exact3d(input, output_size, scale_factors)
    
        if input.dim() == 3 and mode == "area":
            assert output_size is not None
            return adaptive_avg_pool1d(input, output_size)
        if input.dim() == 4 and mode == "area":
            assert output_size is not None
            return adaptive_avg_pool2d(input, output_size)
        if input.dim() == 5 and mode == "area":
            assert output_size is not None
            return adaptive_avg_pool3d(input, output_size)
    
        if input.dim() == 3 and mode == "linear":
            assert align_corners is not None
            return torch._C._nn.upsample_linear1d(
                input, output_size, align_corners, scale_factors
            )
        if input.dim() == 4 and mode == "bilinear":
            assert align_corners is not None
            if antialias:
                return torch._C._nn._upsample_bilinear2d_aa(
                    input, output_size, align_corners, scale_factors
                )
            # Two levels are necessary to prevent TorchScript from touching
            # are_deterministic_algorithms_enabled.
            if not torch.jit.is_scripting():
                if torch.are_deterministic_algorithms_enabled() and (
                    input.is_cuda or input.is_xpu
                ):
                    # Use slow decomp whose backward will be in terms of index_put
                    # importlib is required because the import cannot be top level
                    # (cycle) and cannot be nested (TS doesn't support)
                    return importlib.import_module(
                        "torch._decomp.decompositions"
                    )._upsample_linear_vec(input, output_size, align_corners, scale_factors)
>           return torch._C._nn.upsample_bilinear2d(
                input, output_size, align_corners, scale_factors
            )
E           RuntimeError: Input and output sizes should be greater than 0, but got input (H: 1, W: 1) output (H: 0, W: 0)

/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/functional.py:4580: RuntimeError
______________ TestExtractPatchesPyr.test_same_even[cpu-float32] _______________

self = <test_laf.TestExtractPatchesPyr object at 0x7f07d9370100>
device = device(type='cpu'), dtype = torch.float32

    def test_same_even(self, device, dtype):
        img = torch.arange(4)[None].repeat(4, 1)[None, None].to(device, dtype)
        laf = torch.tensor([[1.5, 0, 1.5], [0, 1.5, 1.5]]).reshape(1, 1, 2, 3).to(device, dtype)
    
>       patch = kornia.feature.extract_patches_from_pyramid(img, laf, 4, 1.0)

/local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py:444: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/kornia/feature/laf.py:348: in extract_patches_from_pyramid
    return extract_patches_from_pyramid(img, laf, PS, normalize_lafs_before_extraction)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/feature/temp.py:30: in extract_patches_from_pyramid
    pyramid = create_image_pyramid(img)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/feature/temp.py:48: in create_image_pyramid
    img = F.interpolate(img, scale_factor=0.5, mode='bilinear', align_corners=False)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[1.5000]]]]), size = None, scale_factor = 0.5
mode = 'bilinear', align_corners = False, recompute_scale_factor = None
antialias = False

    def interpolate(  # noqa: F811
        input: Tensor,
        size: Optional[int] = None,
        scale_factor: Optional[List[float]] = None,
        mode: str = "nearest",
        align_corners: Optional[bool] = None,
        recompute_scale_factor: Optional[bool] = None,
        antialias: bool = False,
    ) -> Tensor:  # noqa: B950
        r"""Down/up samples the input.
    
        Tensor interpolated to either the given :attr:`size` or the given
        :attr:`scale_factor`
    
        The algorithm used for interpolation is determined by :attr:`mode`.
    
        Currently temporal, spatial and volumetric sampling are supported, i.e.
        expected inputs are 3-D, 4-D or 5-D in shape.
    
        The input dimensions are interpreted in the form:
        `mini-batch x channels x [optional depth] x [optional height] x width`.
    
        The modes available for resizing are: `nearest`, `linear` (3D-only),
        `bilinear`, `bicubic` (4D-only), `trilinear` (5D-only), `area`, `nearest-exact`
    
        Args:
            input (Tensor): the input tensor
            size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int]):
                output spatial size.
            scale_factor (float or Tuple[float]): multiplier for spatial size. If `scale_factor` is a tuple,
                its length has to match the number of spatial dimensions; `input.dim() - 2`.
            mode (str): algorithm used for upsampling:
                ``'nearest'`` | ``'linear'`` | ``'bilinear'`` | ``'bicubic'`` |
                ``'trilinear'`` | ``'area'`` | ``'nearest-exact'``. Default: ``'nearest'``
            align_corners (bool, optional): Geometrically, we consider the pixels of the
                input and output as squares rather than points.
                If set to ``True``, the input and output tensors are aligned by the
                center points of their corner pixels, preserving the values at the corner pixels.
                If set to ``False``, the input and output tensors are aligned by the corner
                points of their corner pixels, and the interpolation uses edge value padding
                for out-of-boundary values, making this operation *independent* of input size
                when :attr:`scale_factor` is kept the same. This only has an effect when :attr:`mode`
                is ``'linear'``, ``'bilinear'``, ``'bicubic'`` or ``'trilinear'``.
                Default: ``False``
            recompute_scale_factor (bool, optional): recompute the scale_factor for use in the
                interpolation calculation. If `recompute_scale_factor` is ``True``, then
                `scale_factor` must be passed in and `scale_factor` is used to compute the
                output `size`. The computed output `size` will be used to infer new scales for
                the interpolation. Note that when `scale_factor` is floating-point, it may differ
                from the recomputed `scale_factor` due to rounding and precision issues.
                If `recompute_scale_factor` is ``False``, then `size` or `scale_factor` will
                be used directly for interpolation. Default: ``None``.
            antialias (bool, optional): flag to apply anti-aliasing. Default: ``False``. Using anti-alias
                option together with ``align_corners=False``, interpolation result would match Pillow
                result for downsampling operation. Supported modes: ``'bilinear'``, ``'bicubic'``.
    
        .. note::
            With ``mode='bicubic'``, it's possible to cause overshoot, in other words it can produce
            negative values or values greater than 255 for images.
            Explicitly call ``result.clamp(min=0, max=255)`` if you want to reduce the overshoot
            when displaying the image.
    
        .. note::
            Mode ``mode='nearest-exact'`` matches Scikit-Image and PIL nearest neighbours interpolation
            algorithms and fixes known issues with ``mode='nearest'``. This mode is introduced to keep
            backward compatibility.
            Mode ``mode='nearest'`` matches buggy OpenCV's ``INTER_NEAREST`` interpolation algorithm.
    
        .. note::
            The gradients for the dtype ``float16`` on CUDA may be inaccurate in the upsample operation
            when using modes ``['linear', 'bilinear', 'bicubic', 'trilinear', 'area']``.
            For more details, please refer to the discussion in
            `issue#104157 <https://github.com/pytorch/pytorch/issues/104157>`_.
    
        Note:
            {backward_reproducibility_note}
        """
        if has_torch_function_unary(input):
            return handle_torch_function(
                interpolate,
                (input,),
                input,
                size=size,
                scale_factor=scale_factor,
                mode=mode,
                align_corners=align_corners,
                recompute_scale_factor=recompute_scale_factor,
                antialias=antialias,
            )
    
        if mode in ("nearest", "area", "nearest-exact"):
            if align_corners is not None:
                raise ValueError(
                    "align_corners option can only be set with the "
                    "interpolating modes: linear | bilinear | bicubic | trilinear"
                )
        else:
            if align_corners is None:
                align_corners = False
    
        dim = input.dim() - 2  # Number of spatial dimensions.
    
        # Process size and scale_factor.  Validate that exactly one is set.
        # Validate its length if it is a list, or expand it if it is a scalar.
        # After this block, exactly one of output_size and scale_factors will
        # be non-None, and it will be a list (or tuple).
        if size is not None and scale_factor is not None:
            raise ValueError("only one of size or scale_factor should be defined")
        elif size is not None:
            assert scale_factor is None
            scale_factors = None
            if isinstance(size, (list, tuple)):
                if len(size) != dim:
                    raise ValueError(
                        "Input and output must have the same number of spatial dimensions, but got "
                        f"input with spatial dimensions of {list(input.shape[2:])} and output size of {size}. "
                        "Please provide input tensor in (N, C, d1, d2, ...,dK) format and "
                        "output size in (o1, o2, ...,oK) format."
                    )
                if not torch.jit.is_scripting():
                    if not all(_is_integer(x) for x in size):
                        raise TypeError(
                            "expected size to be one of int or Tuple[int] or Tuple[int, int] or "
                            f"Tuple[int, int, int], but got size with types {[type(x) for x in size]}"
                        )
                output_size = size
            else:
                output_size = [size for _ in range(dim)]
        elif scale_factor is not None:
            assert size is None
            output_size = None
            if isinstance(scale_factor, (list, tuple)):
                if len(scale_factor) != dim:
                    raise ValueError(
                        "Input and scale_factor must have the same number of spatial dimensions, but "
                        f"got input with spatial dimensions of {list(input.shape[2:])} and "
                        f"scale_factor of shape {scale_factor}. "
                        "Please provide input tensor in (N, C, d1, d2, ...,dK) format and "
                        "scale_factor in (s1, s2, ...,sK) format."
                    )
                scale_factors = scale_factor
            else:
                scale_factors = [scale_factor for _ in range(dim)]
        else:
            raise ValueError("either size or scale_factor should be defined")
    
        if (
            recompute_scale_factor is not None
            and recompute_scale_factor
            and size is not None
        ):
            raise ValueError(
                "recompute_scale_factor is not meaningful with an explicit size."
            )
    
        # "area" mode always requires an explicit size rather than scale factor.
        # Re-use the recompute_scale_factor code path.
        if mode == "area" and output_size is None:
            recompute_scale_factor = True
    
        if recompute_scale_factor is not None and recompute_scale_factor:
            # We compute output_size here, then un-set scale_factors.
            # The C++ code will recompute it based on the (integer) output size.
            assert scale_factors is not None
            if not torch.jit.is_scripting() and torch._C._get_tracing_state():
                # make scale_factor a tensor in tracing so constant doesn't get baked in
                output_size = [
                    (
                        torch.floor(
                            (
                                input.size(i + 2).float()
                                * torch.tensor(scale_factors[i], dtype=torch.float32)
                            ).float()
                        )
                    )
                    for i in range(dim)
                ]
            elif torch.jit.is_scripting():
                output_size = [
                    int(math.floor(float(input.size(i + 2)) * scale_factors[i]))
                    for i in range(dim)
                ]
            else:
                output_size = [
                    _sym_int(input.size(i + 2) * scale_factors[i]) for i in range(dim)
                ]
            scale_factors = None
    
        if antialias and not (mode in ("bilinear", "bicubic") and input.ndim == 4):
            raise ValueError(
                "Anti-alias option is restricted to bilinear and bicubic modes and requires a 4-D tensor as input"
            )
    
        if input.dim() == 3 and mode == "nearest":
            return torch._C._nn.upsample_nearest1d(input, output_size, scale_factors)
        if input.dim() == 4 and mode == "nearest":
            return torch._C._nn.upsample_nearest2d(input, output_size, scale_factors)
        if input.dim() == 5 and mode == "nearest":
            return torch._C._nn.upsample_nearest3d(input, output_size, scale_factors)
    
        if input.dim() == 3 and mode == "nearest-exact":
            return torch._C._nn._upsample_nearest_exact1d(input, output_size, scale_factors)
        if input.dim() == 4 and mode == "nearest-exact":
            return torch._C._nn._upsample_nearest_exact2d(input, output_size, scale_factors)
        if input.dim() == 5 and mode == "nearest-exact":
            return torch._C._nn._upsample_nearest_exact3d(input, output_size, scale_factors)
    
        if input.dim() == 3 and mode == "area":
            assert output_size is not None
            return adaptive_avg_pool1d(input, output_size)
        if input.dim() == 4 and mode == "area":
            assert output_size is not None
            return adaptive_avg_pool2d(input, output_size)
        if input.dim() == 5 and mode == "area":
            assert output_size is not None
            return adaptive_avg_pool3d(input, output_size)
    
        if input.dim() == 3 and mode == "linear":
            assert align_corners is not None
            return torch._C._nn.upsample_linear1d(
                input, output_size, align_corners, scale_factors
            )
        if input.dim() == 4 and mode == "bilinear":
            assert align_corners is not None
            if antialias:
                return torch._C._nn._upsample_bilinear2d_aa(
                    input, output_size, align_corners, scale_factors
                )
            # Two levels are necessary to prevent TorchScript from touching
            # are_deterministic_algorithms_enabled.
            if not torch.jit.is_scripting():
                if torch.are_deterministic_algorithms_enabled() and (
                    input.is_cuda or input.is_xpu
                ):
                    # Use slow decomp whose backward will be in terms of index_put
                    # importlib is required because the import cannot be top level
                    # (cycle) and cannot be nested (TS doesn't support)
                    return importlib.import_module(
                        "torch._decomp.decompositions"
                    )._upsample_linear_vec(input, output_size, align_corners, scale_factors)
>           return torch._C._nn.upsample_bilinear2d(
                input, output_size, align_corners, scale_factors
            )
E           RuntimeError: Input and output sizes should be greater than 0, but got input (H: 1, W: 1) output (H: 0, W: 0)

/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/functional.py:4580: RuntimeError
__________________ TestExtractPatchesPyr.test_gradcheck[cpu] ___________________

self = <test_laf.TestExtractPatchesPyr object at 0x7f07d93703d0>
device = device(type='cpu')

    def test_gradcheck(self, device):
        nlaf = torch.tensor([[0.1, 0.001, 0.5], [0, 0.1, 0.5]], device=device, dtype=torch.float64)
        nlaf = nlaf.view(1, 1, 2, 3)
        img = torch.rand(1, 3, 20, 30, device=device, dtype=torch.float64)
        PS = 11
>       self.gradcheck(
            kornia.feature.extract_patches_from_pyramid,
            (img, nlaf, PS, False),
            nondet_tol=1e-8,
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py:452: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2074: in _gradcheck_helper
    func_out = func(*tupled_inputs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/feature/laf.py:348: in extract_patches_from_pyramid
    return extract_patches_from_pyramid(img, laf, PS, normalize_lafs_before_extraction)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/feature/temp.py:38: in extract_patches_from_pyramid
    patch = extract_patch_from_level(pyramid[level][b], A, t, patch_size)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/feature/temp.py:56: in extract_patch_from_level
    grid = F.affine_grid(A.unsqueeze(0), [1, img.size(0), patch_size, patch_size], align_corners=False)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

theta = tensor([[[0.1000, 0.0010],
         [0.0000, 0.1000]]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)
size = [1, 3, 11, 11], align_corners = False

    def affine_grid(
        theta: Tensor,
        size: List[int],
        align_corners: Optional[bool] = None,
    ) -> Tensor:
        r"""Generate 2D or 3D flow field (sampling grid), given a batch of affine matrices :attr:`theta`.
    
        .. note::
            This function is often used in conjunction with :func:`grid_sample`
            to build `Spatial Transformer Networks`_ .
    
        Args:
            theta (Tensor): input batch of affine matrices with shape
                (:math:`N \times 2 \times 3`) for 2D or
                (:math:`N \times 3 \times 4`) for 3D
            size (torch.Size): the target output image size.
                (:math:`N \times C \times H \times W` for 2D or
                :math:`N \times C \times D \times H \times W` for 3D)
                Example: torch.Size((32, 3, 24, 24))
            align_corners (bool, optional): if ``True``, consider ``-1`` and ``1``
                to refer to the centers of the corner pixels rather than the image corners.
                Refer to :func:`grid_sample` for a more complete description.
                A grid generated by :func:`affine_grid` should be passed to :func:`grid_sample`
                with the same setting for this option.
                Default: ``False``
    
        Returns:
            output (Tensor): output Tensor of size (:math:`N \times H \times W \times 2`)
    
        .. _`Spatial Transformer Networks`:
            https://arxiv.org/abs/1506.02025
    
        .. warning::
            When ``align_corners = True``, the grid positions depend on the pixel
            size relative to the input image size, and so the locations sampled by
            :func:`grid_sample` will differ for the same input given at different
            resolutions (that is, after being upsampled or downsampled).
            The default behavior up to version 1.2.0 was ``align_corners = True``.
            Since then, the default behavior has been changed to ``align_corners = False``,
            in order to bring it in line with the default for :func:`interpolate`.
        .. warning::
            When ``align_corners = True``, 2D affine transforms on 1D data and
            3D affine transforms on 2D data (that is, when one of the spatial
            dimensions has unit size) are ill-defined, and not an intended use case.
            This is not a problem when ``align_corners = False``.
            Up to version 1.2.0, all grid points along a unit dimension were
            considered arbitrarily to be at ``-1``.
            From version 1.3.0, under ``align_corners = True`` all grid points
            along a unit dimension are considered to be at ``0``
            (the center of the input image).
        """
        if has_torch_function_unary(theta):
            return handle_torch_function(
                affine_grid, (theta,), theta, size, align_corners=align_corners
            )
        if align_corners is None:
            warnings.warn(
                "Default grid_sample and affine_grid behavior has changed "
                "to align_corners=False since 1.3.0. Please specify "
                "align_corners=True if the old behavior is desired. "
                "See the documentation of grid_sample for details."
            )
            align_corners = False
    
        # enforce floating point dtype on theta
        if not theta.is_floating_point():
            raise ValueError(
                f"Expected theta to have floating point type, but got {theta.dtype}"
            )
        # check that shapes and sizes match
        if len(size) == 4:
            if theta.dim() != 3 or theta.shape[-2] != 2 or theta.shape[-1] != 3:
>               raise ValueError(
                    f"Expected a batch of 2D affine matrices of shape Nx2x3 for size {size}. Got {theta.shape}."
                )
E               ValueError: Expected a batch of 2D affine matrices of shape Nx2x3 for size [1, 3, 11, 11]. Got torch.Size([1, 2, 2]).

/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/functional.py:4985: ValueError
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_shape[cpu]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_non_zero[cpu]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_odd[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_even[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_gradcheck[cpu]
============================== 5 failed in 0.69s ===============================


Final Test Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'inductor', 'onnxrt', 'tvm', 'openxla', 'cudagraphs', 'jit', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 5 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_shape[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_non_zero[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_odd[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_even[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_gradcheck[cpu] PASSED

============================== 5 passed in 0.14s ===============================


Initial Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'inductor', 'jit', 'openxla', 'tvm', 'cudagraphs', 'onnxrt', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 5 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_shape[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_non_zero[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_odd[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_same_even[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/feature/test_laf.py::TestExtractPatchesPyr::test_gradcheck[cpu] PASSED

============================== 5 passed in 0.25s ===============================
