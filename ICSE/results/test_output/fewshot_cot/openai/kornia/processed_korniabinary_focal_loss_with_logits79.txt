output file:
processed_korniabinary_focal_loss_with_logits79.json
function:
binary_focal_loss_with_logits
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] FAILED', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2]', '../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2]'}

All Test Cases On Generated code:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'tvm', 'jit', 'cudagraphs', 'onnxrt', 'openxla', 'inductor', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 59 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] FAILED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] FAILED

=================================== FAILURES ===================================
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32--100-none] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403a0e0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
ignore_index = -100

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9935, 0.2457],
         [0.2447, 0.0852],
         [0.3610, 0.4429]],

        [[0.2665, 0.9689],
         [0.2900, 0.4887],
         [0.8123, 0.1954]]])
target = tensor([[[0.3371, 0.5738],
         [0.6059, 0.9493],
         [0.4882, 0.7002]],

        [[0.3562, 0.1359],
         [0.4116, 0.9095],
         [0.1752, 0.5176]]])
alpha = None, gamma = 0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32--100-mean] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504039f00>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
ignore_index = -100

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6464, 0.8175],
         [0.3791, 0.8819],
         [0.0791, 0.6998]],

        [[0.4875, 0.8008],
         [0.5656, 0.6817],
         [0.3078, 0.5407]]])
target = tensor([[[0.3245, 0.8667],
         [0.1151, 0.8773],
         [0.5301, 0.3045]],

        [[0.4678, 0.3071],
         [0.2527, 0.8129],
         [0.1167, 0.2591]]])
alpha = None, gamma = 0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32--100-sum] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403a380>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
ignore_index = -100

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0973, 0.4653],
         [0.0445, 0.5386],
         [0.8817, 0.5755]],

        [[0.5148, 0.3829],
         [0.3802, 0.5372],
         [0.0987, 0.5584]]])
target = tensor([[[0.9308, 0.5826],
         [0.8279, 0.1308],
         [0.3607, 0.7176]],

        [[0.7359, 0.6166],
         [0.4417, 0.3829],
         [0.0675, 0.7645]]])
alpha = None, gamma = 0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32-None-none] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403a440>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
ignore_index = None

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6324, 0.8009],
         [0.0928, 0.1267],
         [0.4640, 0.8786]],

        [[0.2439, 0.8350],
         [0.5224, 0.9760],
         [0.7251, 0.7394]]])
target = tensor([[[0.0997, 0.4218],
         [0.2106, 0.2363],
         [0.7579, 0.3301]],

        [[0.1689, 0.9940],
         [0.3405, 0.0415],
         [0.8174, 0.2752]]])
alpha = None, gamma = 0, reduction = 'none', pos_weight = None, weight = None
ignore_index = None

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32-None-mean] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403a500>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
ignore_index = None

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4854, 0.8416],
         [0.8195, 0.3139],
         [0.4618, 0.8357]],

        [[0.6406, 0.0071],
         [0.0677, 0.1818],
         [0.0376, 0.3303]]])
target = tensor([[[0.1227, 0.1182],
         [0.2584, 0.2846],
         [0.8496, 0.9048]],

        [[0.0058, 0.6923],
         [0.1517, 0.9301],
         [0.4526, 0.5645]]])
alpha = None, gamma = 0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = None

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32-None-sum] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403a5c0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
ignore_index = None

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0557, 0.6939],
         [0.9163, 0.4951],
         [0.0561, 0.0578]],

        [[0.2022, 0.2795],
         [0.7069, 0.5039],
         [0.2485, 0.6437]]])
target = tensor([[[0.8636, 0.4349],
         [0.3674, 0.5015],
         [0.2208, 0.3859]],

        [[0.1756, 0.3635],
         [0.0360, 0.9283],
         [0.0621, 0.1705]]])
alpha = None, gamma = 0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = None

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403a980>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    def test_value_same_as_torch_bce_loss_pos_weight_weight(self, device, dtype, reduction):
        num_classes = 3
        logits = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
        labels = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
    
        pos_weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
        weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, pos_weight=pos_weight, weight=weight
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3854, 0.0157],
         [0.0259, 0.2552],
         [0.0906, 0.1982]],

        [[0.8727, 0.1469],
         [0.0888, 0.5305],
         [0.5151, 0.1743]]])
target = tensor([[[0.9562, 0.7034],
         [0.8942, 0.3551],
         [0.8329, 0.4936]],

        [[0.1028, 0.0438],
         [0.2560, 0.8075],
         [0.4668, 0.0724]]])
alpha = None, gamma = 0, reduction = 'none'
pos_weight = tensor([[0.5774],
        [0.0132],
        [0.0337]])
weight = tensor([[0.7090],
        [0.6713],
        [0.1466]])
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403a8c0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    def test_value_same_as_torch_bce_loss_pos_weight_weight(self, device, dtype, reduction):
        num_classes = 3
        logits = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
        labels = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
    
        pos_weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
        weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, pos_weight=pos_weight, weight=weight
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2915, 0.2541],
         [0.1461, 0.1396],
         [0.2073, 0.5031]],

        [[0.0890, 0.0548],
         [0.7320, 0.4091],
         [0.3434, 0.1462]]])
target = tensor([[[0.0167, 0.4417],
         [0.5708, 0.5462],
         [0.8903, 0.4593]],

        [[0.4877, 0.6604],
         [0.6984, 0.1573],
         [0.2466, 0.1707]]])
alpha = None, gamma = 0, reduction = 'mean'
pos_weight = tensor([[0.9197],
        [0.7679],
        [0.1492]])
weight = tensor([[0.7091],
        [0.4978],
        [0.3743]])
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403abc0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    def test_value_same_as_torch_bce_loss_pos_weight_weight(self, device, dtype, reduction):
        num_classes = 3
        logits = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
        labels = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
    
        pos_weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
        weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, pos_weight=pos_weight, weight=weight
        )

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8996, 0.1870],
         [0.0127, 0.4635],
         [0.5978, 0.0132]],

        [[0.8292, 0.5260],
         [0.0146, 0.4537],
         [0.5440, 0.7868]]])
target = tensor([[[0.0481, 0.5359],
         [0.8982, 0.3732],
         [0.2504, 0.0750]],

        [[0.3634, 0.1352],
         [0.2257, 0.2746],
         [0.8824, 0.3416]]])
alpha = None, gamma = 0, reduction = 'sum'
pos_weight = tensor([[8.2426e-01],
        [2.0576e-04],
        [4.8363e-01]])
weight = tensor([[0.0114],
        [0.8311],
        [0.3585]])
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403b2b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = None, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3496, 0.6676],
         [0.1939, 0.0657],
         [0.1309, 0.7991]],

        [[0.7484, 0.5042],
         [0.4636, 0.5044],
         [0.9303, 0.7271]]])
target = tensor([[[0.7731, 0.7818],
         [0.9428, 0.0723],
         [0.6965, 0.0647]],

        [[0.8463, 0.2058],
         [0.9078, 0.2529],
         [0.4321, 0.7518]]])
alpha = None, gamma = 0.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403b010>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = None, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9625, 0.7065],
         [0.3700, 0.4116],
         [0.7079, 0.8185]],

        [[0.2917, 0.6322],
         [0.8509, 0.7258],
         [0.1341, 0.9481]]])
target = tensor([[[0.8265, 0.5779],
         [0.5632, 0.1408],
         [0.6073, 0.4859]],

        [[0.3363, 0.7813],
         [0.7091, 0.3076],
         [0.7093, 0.5142]]])
alpha = None, gamma = 0.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403b0d0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = None, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5920, 0.6382],
         [0.7064, 0.0024],
         [0.2675, 0.7286]],

        [[0.9231, 0.8251],
         [0.3491, 0.4830],
         [0.2808, 0.2197]]])
target = tensor([[[0.2375, 0.1769],
         [0.3818, 0.7568],
         [0.9623, 0.5207]],

        [[0.9100, 0.5500],
         [0.5115, 0.5506],
         [0.2205, 0.4358]]])
alpha = None, gamma = 0.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403b190>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.2, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5555, 0.9722],
         [0.2539, 0.5593],
         [0.9044, 0.0691]],

        [[0.9348, 0.2496],
         [0.6727, 0.2989],
         [0.9475, 0.1877]]])
target = tensor([[[0.1714, 0.0171],
         [0.4197, 0.2826],
         [0.2234, 0.5731]],

        [[0.3169, 0.0198],
         [0.5045, 0.3624],
         [0.9123, 0.3254]]])
alpha = 0.2, gamma = 0.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403b250>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.2, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1970, 0.1880],
         [0.8331, 0.5666],
         [0.7202, 0.8218]],

        [[0.5105, 0.5034],
         [0.8441, 0.1030],
         [0.8923, 0.1669]]])
target = tensor([[[0.4435, 0.1409],
         [0.4909, 0.4218],
         [0.6960, 0.7417]],

        [[0.0763, 0.7650],
         [0.3803, 0.5101],
         [0.0970, 0.6828]]])
alpha = 0.2, gamma = 0.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403af50>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.2, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3619, 0.7462],
         [0.8093, 0.3244],
         [0.8444, 0.3709]],

        [[0.6220, 0.0726],
         [0.3877, 0.4796],
         [0.6437, 0.5615]]])
target = tensor([[[0.1654, 0.0279],
         [0.2275, 0.1342],
         [0.0571, 0.5596]],

        [[0.5658, 0.7795],
         [0.1301, 0.0967],
         [0.8057, 0.4777]]])
alpha = 0.2, gamma = 0.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403bd60>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.5, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5517, 0.7045],
         [0.1072, 0.2032],
         [0.1653, 0.2535]],

        [[0.7251, 0.8991],
         [0.8721, 0.9869],
         [0.8795, 0.4923]]])
target = tensor([[[0.1367, 0.9472],
         [0.2270, 0.5782],
         [0.3475, 0.6517]],

        [[0.7895, 0.8105],
         [0.8262, 0.8616],
         [0.3115, 0.2712]]])
alpha = 0.5, gamma = 0.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403be20>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.5, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3377, 0.2459],
         [0.9041, 0.3869],
         [0.2030, 0.9510]],

        [[0.7937, 0.9395],
         [0.9095, 0.5231],
         [0.3499, 0.8531]]])
target = tensor([[[0.3282, 0.5461],
         [0.6118, 0.8995],
         [0.2805, 0.0427]],

        [[0.6691, 0.7665],
         [0.8886, 0.4672],
         [0.6102, 0.8501]]])
alpha = 0.5, gamma = 0.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403bee0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.5, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9748, 0.8658],
         [0.9583, 0.5308],
         [0.8457, 0.8657]],

        [[0.8240, 0.8916],
         [0.9648, 0.2798],
         [0.4681, 0.1908]]])
target = tensor([[[0.8454, 0.0172],
         [0.8284, 0.0109],
         [0.3545, 0.8605]],

        [[0.0809, 0.3108],
         [0.3223, 0.5192],
         [0.1531, 0.8751]]])
alpha = 0.5, gamma = 0.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650403bfa0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = None, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1793, 0.3058],
         [0.4054, 0.1167],
         [0.6414, 0.9459]],

        [[0.6300, 0.7589],
         [0.9957, 0.6927],
         [0.1956, 0.1316]]])
target = tensor([[[0.8445, 0.1244],
         [0.1383, 0.4378],
         [0.3208, 0.1155]],

        [[0.6826, 0.7899],
         [0.7828, 0.8813],
         [0.3025, 0.7102]]])
alpha = None, gamma = 1.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f65040680a0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = None, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0671, 0.8783],
         [0.7363, 0.0472],
         [0.3889, 0.2910]],

        [[0.1691, 0.1805],
         [0.6900, 0.3612],
         [0.9821, 0.8451]]])
target = tensor([[[0.6838, 0.6043],
         [0.3352, 0.2047],
         [0.5055, 0.0190]],

        [[0.0507, 0.3964],
         [0.4400, 0.6578],
         [0.6242, 0.5020]]])
alpha = None, gamma = 1.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504068160>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = None, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4356, 0.7475],
         [0.5562, 0.7864],
         [0.0340, 0.7301]],

        [[0.3293, 0.3642],
         [0.9368, 0.1301],
         [0.7950, 0.8959]]])
target = tensor([[[0.3670, 0.2342],
         [0.7170, 0.9597],
         [0.1784, 0.3425]],

        [[0.3976, 0.3520],
         [0.3241, 0.4520],
         [0.7823, 0.7859]]])
alpha = None, gamma = 1.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504068220>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.2, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4274, 0.8141],
         [0.5342, 0.5279],
         [0.5451, 0.5147]],

        [[0.9226, 0.1304],
         [0.0838, 0.8412],
         [0.2868, 0.7610]]])
target = tensor([[[0.9028, 0.2075],
         [0.6276, 0.6399],
         [0.4926, 0.8518]],

        [[0.4913, 0.7260],
         [0.7512, 0.6553],
         [0.7434, 0.4805]]])
alpha = 0.2, gamma = 1.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f65040682e0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.2, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7708, 0.7914],
         [0.3038, 0.5062],
         [0.5713, 0.1093]],

        [[0.2376, 0.7986],
         [0.2626, 0.6289],
         [0.1126, 0.3741]]])
target = tensor([[[0.8559, 0.1013],
         [0.4167, 0.8765],
         [0.2223, 0.7496]],

        [[0.6200, 0.4850],
         [0.3177, 0.4593],
         [0.3086, 0.0617]]])
alpha = 0.2, gamma = 1.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f65040683a0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.2, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3034, 0.9064],
         [0.1941, 0.3489],
         [0.4455, 0.5895]],

        [[0.6609, 0.3477],
         [0.6547, 0.3096],
         [0.2933, 0.3100]]])
target = tensor([[[0.5159, 0.6135],
         [0.2203, 0.0438],
         [0.5177, 0.3710]],

        [[0.7639, 0.1766],
         [0.7191, 0.0135],
         [0.9086, 0.2695]]])
alpha = 0.2, gamma = 1.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504068460>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.5, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1984, 0.9179],
         [0.5647, 0.6404],
         [0.5774, 0.3703]],

        [[0.7399, 0.2834],
         [0.1648, 0.0777],
         [0.8293, 0.0959]]])
target = tensor([[[0.6360, 0.8755],
         [0.3973, 0.1062],
         [0.0888, 0.3405]],

        [[0.7328, 0.7734],
         [0.2595, 0.8357],
         [0.4697, 0.5530]]])
alpha = 0.5, gamma = 1.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504068520>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.5, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8828, 0.2764],
         [0.4546, 0.1710],
         [0.6501, 0.7629]],

        [[0.2822, 0.1743],
         [0.8609, 0.1920],
         [0.0650, 0.0107]]])
target = tensor([[[0.3127, 0.4610],
         [0.3329, 0.3002],
         [0.7346, 0.0647]],

        [[0.0773, 0.0813],
         [0.3572, 0.8352],
         [0.5275, 0.1247]]])
alpha = 0.5, gamma = 1.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f65040685e0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.5, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0208, 0.1359],
         [0.0104, 0.4488],
         [0.3144, 0.7484]],

        [[0.2523, 0.1258],
         [0.5133, 0.6763],
         [0.7514, 0.8908]]])
target = tensor([[[0.1102, 0.7708],
         [0.7702, 0.9475],
         [0.9345, 0.1313]],

        [[0.5056, 0.4611],
         [0.0713, 0.5020],
         [0.8023, 0.4016]]])
alpha = 0.5, gamma = 1.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f65040686a0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = None, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3961, 0.9398],
         [0.1742, 0.7223],
         [0.5089, 0.5074]],

        [[0.7766, 0.7326],
         [0.7195, 0.8405],
         [0.8557, 0.1501]]])
target = tensor([[[0.3183, 0.6253],
         [0.8877, 0.7424],
         [0.9879, 0.2819]],

        [[0.8781, 0.7869],
         [0.0969, 0.8177],
         [0.1518, 0.2822]]])
alpha = None, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504068760>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = None, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6871, 0.5624],
         [0.2942, 0.6300],
         [0.0968, 0.1077]],

        [[0.3462, 0.9980],
         [0.3386, 0.4179],
         [0.7533, 0.6026]]])
target = tensor([[[0.3838, 0.9251],
         [0.6738, 0.5711],
         [0.1246, 0.0013]],

        [[0.3062, 0.2951],
         [0.8073, 0.0122],
         [0.5334, 0.8241]]])
alpha = None, gamma = 2.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504068820>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = None, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8326, 0.8650],
         [0.4985, 0.4671],
         [0.4651, 0.7238]],

        [[0.7858, 0.5085],
         [0.9707, 0.8414],
         [0.0184, 0.3004]]])
target = tensor([[[0.3672, 0.3642],
         [0.8626, 0.7282],
         [0.6790, 0.6306]],

        [[0.4241, 0.4305],
         [0.4178, 0.5609],
         [0.5116, 0.4495]]])
alpha = None, gamma = 2.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f65040688e0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.2, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5554, 0.0619],
         [0.2629, 0.4953],
         [0.3540, 0.6223]],

        [[0.0355, 0.7356],
         [0.2209, 0.3416],
         [0.9409, 0.6083]]])
target = tensor([[[0.4057, 0.9232],
         [0.1020, 0.6487],
         [0.5386, 0.2744]],

        [[0.7130, 0.4631],
         [0.6091, 0.3477],
         [0.6496, 0.6266]]])
alpha = 0.2, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f65040689a0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.2, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7438, 0.3920],
         [0.5162, 0.8225],
         [0.1762, 0.8958]],

        [[0.6347, 0.1437],
         [0.1337, 0.1021],
         [0.0350, 0.3361]]])
target = tensor([[[0.9254, 0.6211],
         [0.1059, 0.8850],
         [0.9945, 0.4656]],

        [[0.4005, 0.0986],
         [0.9052, 0.8978],
         [0.5073, 0.8086]]])
alpha = 0.2, gamma = 2.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504068a60>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.2, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3578, 0.6615],
         [0.9719, 0.5691],
         [0.8608, 0.3394]],

        [[0.2890, 0.7234],
         [0.7654, 0.7790],
         [0.1758, 0.7983]]])
target = tensor([[[0.0969, 0.3916],
         [0.6475, 0.9955],
         [0.0856, 0.9078]],

        [[0.6771, 0.1597],
         [0.7203, 0.4133],
         [0.4037, 0.5353]]])
alpha = 0.2, gamma = 2.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504068b20>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.5, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2607, 0.2567],
         [0.7683, 0.0604],
         [0.3436, 0.2712]],

        [[0.2262, 0.4727],
         [0.8059, 0.5477],
         [0.1136, 0.5643]]])
target = tensor([[[0.3378, 0.6577],
         [0.0179, 0.8719],
         [0.1374, 0.9000]],

        [[0.5235, 0.8947],
         [0.7108, 0.6934],
         [0.6116, 0.9089]]])
alpha = 0.5, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504068be0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.5, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0534, 0.0914],
         [0.1284, 0.5586],
         [0.4829, 0.3640]],

        [[0.2794, 0.5848],
         [0.4570, 0.4763],
         [0.9060, 0.9553]]])
target = tensor([[[0.9838, 0.4179],
         [0.1442, 0.4420],
         [0.2448, 0.5101]],

        [[0.0565, 0.1232],
         [0.1013, 0.7682],
         [0.0893, 0.2458]]])
alpha = 0.5, gamma = 2.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504068ca0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.5, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0010, 0.8006],
         [0.8247, 0.0886],
         [0.7968, 0.5524]],

        [[0.2170, 0.1742],
         [0.5835, 0.5810],
         [0.0424, 0.3855]]])
target = tensor([[[0.9143, 0.6393],
         [0.7357, 0.9034],
         [0.0231, 0.4499]],

        [[0.8075, 0.4204],
         [0.7253, 0.4642],
         [0.5970, 0.0375]]])
alpha = 0.5, gamma = 2.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f65040692a0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = None, weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1311, 0.7058],
         [0.3486, 0.5465],
         [0.8094, 0.7206]],

        [[0.3000, 0.3276],
         [0.1507, 0.8507],
         [0.4171, 0.0013]]])
target = tensor([[[0.2154, 0.4797],
         [0.0976, 0.6750],
         [0.5075, 0.6678]],

        [[0.7007, 0.8205],
         [0.0574, 0.2996],
         [0.3304, 0.5768]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f65040691e0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = None, weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5378, 0.5052],
         [0.0417, 0.2493],
         [0.5742, 0.9034]],

        [[0.1825, 0.3324],
         [0.1907, 0.5321],
         [0.6205, 0.4544]]])
target = tensor([[[0.3216, 0.5324],
         [0.4769, 0.7474],
         [0.5325, 0.0894]],

        [[0.1454, 0.8521],
         [0.0709, 0.7634],
         [0.2248, 0.5663]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f65040690c0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = None, weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9409, 0.2959],
         [0.1666, 0.2528],
         [0.0768, 0.6562]],

        [[0.8893, 0.9556],
         [0.8879, 0.1540],
         [0.8416, 0.1363]]])
target = tensor([[[0.7445, 0.5891],
         [0.3972, 0.7554],
         [0.7572, 0.2868]],

        [[0.7902, 0.2741],
         [0.6075, 0.4104],
         [0.6679, 0.6872]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f65040697b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = tensor([1., 2., 5.]), weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4708, 0.8073],
         [0.5781, 0.0239],
         [0.6308, 0.0402]],

        [[0.9775, 0.9490],
         [0.9991, 0.0690],
         [0.3708, 0.0475]]])
target = tensor([[[0.8959, 0.3128],
         [0.5565, 0.6127],
         [0.3257, 0.1794]],

        [[0.5646, 0.2155],
         [0.9509, 0.1694],
         [0.9213, 0.8964]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = tensor([1., 2., 5.])
weight = None, ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504069870>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = tensor([1., 2., 5.]), weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5893, 0.6920],
         [0.3635, 0.9060],
         [0.1074, 0.0128]],

        [[0.4696, 0.6440],
         [0.5117, 0.5263],
         [0.7867, 0.6168]]])
target = tensor([[[0.8189, 0.1691],
         [0.2079, 0.1375],
         [0.9414, 0.8408]],

        [[0.7610, 0.9277],
         [0.5332, 0.2965],
         [0.5835, 0.4099]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = tensor([1., 2., 5.])
weight = None, ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504069930>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = tensor([1., 2., 5.]), weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7572, 0.3798],
         [0.7772, 0.6429],
         [0.6901, 0.6306]],

        [[0.8153, 0.4442],
         [0.7415, 0.7113],
         [0.4005, 0.0492]]])
target = tensor([[[0.4705, 0.3338],
         [0.0825, 0.8178],
         [0.0757, 0.4112]],

        [[0.2346, 0.5156],
         [0.7694, 0.0519],
         [0.8571, 0.4998]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = tensor([1., 2., 5.])
weight = None, ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f65040699f0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4891, 0.0611],
         [0.2961, 0.7896],
         [0.9606, 0.8121]],

        [[0.1098, 0.4822],
         [0.2509, 0.2934],
         [0.2975, 0.3685]]])
target = tensor([[[0.0941, 0.4881],
         [0.3554, 0.2932],
         [0.1646, 0.2684]],

        [[0.7687, 0.8172],
         [0.9164, 0.7598],
         [0.2346, 0.9193]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504069ab0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1488, 0.8467],
         [0.7850, 0.7370],
         [0.9941, 0.7301]],

        [[0.9219, 0.2474],
         [0.4730, 0.5829],
         [0.8035, 0.0725]]])
target = tensor([[[0.5869, 0.9290],
         [0.8350, 0.9427],
         [0.1668, 0.0932]],

        [[0.4826, 0.1817],
         [0.1679, 0.0285],
         [0.1604, 0.4988]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504069b70>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0284, 0.9870],
         [0.4507, 0.1479],
         [0.8255, 0.3346]],

        [[0.7732, 0.7007],
         [0.7220, 0.0163],
         [0.8169, 0.6149]]])
target = tensor([[[0.2642, 0.1779],
         [0.3100, 0.6591],
         [0.3670, 0.9186]],

        [[0.0814, 0.9181],
         [0.6656, 0.5693],
         [0.3712, 0.7007]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504069c30>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2580, 0.3213],
         [0.6158, 0.8460],
         [0.5420, 0.7839]],

        [[0.9161, 0.7050],
         [0.6520, 0.8249],
         [0.4638, 0.5314]]])
target = tensor([[[0.6662, 0.2362],
         [0.2292, 0.7351],
         [0.0532, 0.8829]],

        [[0.9451, 0.7091],
         [0.8958, 0.4185],
         [0.9206, 0.1727]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504069cf0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3871, 0.9334],
         [0.2981, 0.9699],
         [0.1126, 0.1989]],

        [[0.8928, 0.3599],
         [0.2370, 0.0568],
         [0.2764, 0.1111]]])
target = tensor([[[0.2328, 0.1141],
         [0.1482, 0.7476],
         [0.6721, 0.8939]],

        [[0.9320, 0.7983],
         [0.5409, 0.9247],
         [0.6094, 0.5409]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504069db0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4277, 0.4148],
         [0.1297, 0.1134],
         [0.3539, 0.7848]],

        [[0.5079, 0.2938],
         [0.8634, 0.0235],
         [0.5369, 0.9747]]])
target = tensor([[[0.1850, 0.5772],
         [0.4073, 0.6165],
         [0.7298, 0.6853]],

        [[0.2343, 0.9786],
         [0.0572, 0.3174],
         [0.5252, 0.5896]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32--100-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650406a230>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), ignore_index = -100

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9599, 0.4832],
         [0.6530, 0.8833],
         [0.4013, 0.1448]],

        [[0.7616, 0.6654],
         [0.6170, 0.1253],
         [0.2648, 0.9761]]])
target = tensor([[[ 1.3574e-01,  1.8535e-01],
         [ 6.9395e-01, -1.0000e+02],
         [ 2.5378e-01,  2.3018e-02]],

        [[ 6.6155e-02,  7.6165e-01],
         [ 1.5467e-02,  1.9603e-01],
         [ 8.9467e-02, -1.0000e+02]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650406a0e0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), ignore_index = -100

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4425, 0.7882],
         [0.9840, 0.5592],
         [0.4446, 0.1490]],

        [[0.0015, 0.4694],
         [0.6719, 0.4221],
         [0.1470, 0.4505]]])
target = tensor([[[   0.8676, -100.0000],
         [-100.0000,    0.9155],
         [   0.6203, -100.0000]],

        [[   0.8771,    0.9962],
         [   0.4659,    0.7762],
         [   0.9136, -100.0000]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650406a560>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), ignore_index = -100

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6062, 0.8127],
         [0.7221, 0.0783],
         [0.8053, 0.3853]],

        [[0.7410, 0.9619],
         [0.9110, 0.6191],
         [0.9182, 0.1957]]])
target = tensor([[[-100.0000, -100.0000],
         [   0.4782,    0.7921],
         [   0.1857, -100.0000]],

        [[   0.9867,    0.4890],
         [   0.2243,    0.8865],
         [   0.3548, -100.0000]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32-255-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650406a620>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), ignore_index = 255

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0914, 0.8766],
         [0.8464, 0.8209],
         [0.6078, 0.8721]],

        [[0.4946, 0.5510],
         [0.0635, 0.4521],
         [0.0643, 0.2148]]])
target = tensor([[[  0.8136,   0.5869],
         [255.0000,   0.5836],
         [255.0000,   0.6064]],

        [[  0.8073, 255.0000],
         [  0.3689, 255.0000],
         [  0.7516, 255.0000]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None, weight = None
ignore_index = 255

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650406a6e0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), ignore_index = 255

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2057, 0.6736],
         [0.0607, 0.2738],
         [0.2639, 0.8811]],

        [[0.2710, 0.5896],
         [0.3833, 0.6902],
         [0.5226, 0.8193]]])
target = tensor([[[255.0000,   0.4303],
         [  0.7091,   0.6656],
         [  0.2822,   0.8040]],

        [[255.0000,   0.2695],
         [255.0000,   0.8737],
         [255.0000,   0.7875]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None, weight = None
ignore_index = 255

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650406a7a0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), ignore_index = 255

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2522, 0.3597],
         [0.9851, 0.8555],
         [0.0147, 0.0618]],

        [[0.1294, 0.3811],
         [0.7435, 0.1914],
         [0.5367, 0.6602]]])
target = tensor([[[1.0554e-02, 2.5500e+02],
         [3.9101e-01, 2.4475e-01],
         [2.5500e+02, 4.4252e-01]],

        [[3.8366e-01, 2.2102e-01],
         [2.5500e+02, 6.9397e-01],
         [2.5500e+02, 8.4813e-01]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None, weight = None
ignore_index = 255

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_______ TestBinaryFocalLossWithLogits.test_dynamo[cpu-float32-inductor] ________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650406ab30>
device = device(type='cpu'), dtype = torch.float32
torch_optimizer = functools.partial(<function compile at 0x7f65cf4232e0>, backend='inductor')

    def test_dynamo(self, device, dtype, torch_optimizer):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        op = kornia.losses.binary_focal_loss_with_logits
        op_optimized = torch_optimizer(op)
    
        args = (0.25, 2.0)
>       actual = op_optimized(logits, labels, *args)

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:89: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:465: in _fn
    return fn(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3827, 0.6246],
         [0.0780, 0.2420],
         [0.0645, 0.9243]],

        [[0.0328, 0.0531],
         [0.0089, 0.3964],
         [0.0796, 0.8794]]])
target = tensor([[[0.7295, 0.9161],
         [0.7038, 0.2568],
         [0.9609, 0.7564]],

        [[0.1222, 0.8118],
         [0.4390, 0.6667],
         [0.7327, 0.8680]]])
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
______________ TestBinaryFocalLossWithLogits.test_gradcheck[cpu] _______________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650406add0>
device = device(type='cpu')

    def test_gradcheck(self, device):
        logits = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
        labels = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
    
        args = (0.25, 2.0)
        op = kornia.losses.binary_focal_loss_with_logits
>       self.gradcheck(op, (logits, labels, *args))

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:99: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2074: in _gradcheck_helper
    func_out = func(*tupled_inputs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3679, 0.5135],
         [0.0353, 0.8924],
         [0.2882, 0.9032]],

        [[0.5972, 0.4535],
         [0.7428, 0.9681],
         [0.4849, 0.2657]]], dtype=torch.float64, requires_grad=True)
target = tensor([[[0.4240, 0.0923],
         [0.9863, 0.9828],
         [0.6380, 0.8902]],

        [[0.1053, 0.2154],
         [0.2607, 0.2854],
         [0.5630, 0.2731]]], dtype=torch.float64, requires_grad=True)
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
________ TestBinaryFocalLossWithLogits.test_gradcheck_ignore_index[cpu] ________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650406b070>
device = device(type='cpu')

    def test_gradcheck_ignore_index(self, device):
        logits = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
        labels = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
        ignore = torch.rand(2, 3, 2, device=device) > 0.8
        labels[ignore] = -100
    
        args = (0.25, 2.0)
        op = kornia.losses.binary_focal_loss_with_logits
>       self.gradcheck(op, (logits, labels, *args), requires_grad=[True, False, False, False])

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2074: in _gradcheck_helper
    func_out = func(*tupled_inputs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9156, 0.7648],
         [0.5456, 0.9030],
         [0.6414, 0.7009]],

        [[0.4156, 0.9439],
         [0.9763, 0.6888],
         [0.1687, 0.1421]]], dtype=torch.float64, requires_grad=True)
target = tensor([[[ 8.4137e-02,  1.0468e-01],
         [ 6.5531e-01, -1.0000e+02],
         [ 6.3414e-01,  4.1795e-01]],

     ...121e-01,  2.9560e-01],
         [ 5.7999e-01,  3.4417e-01],
         [ 7.8363e-01,  6.3937e-01]]], dtype=torch.float64)
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
____________ TestBinaryFocalLossWithLogits.test_module[cpu-float32] ____________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f6504068ee0>
device = device(type='cpu'), dtype = torch.float32

    def test_module(self, device, dtype):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        args = (0.25, 2.0)
        op = kornia.losses.binary_focal_loss_with_logits
        op_module = kornia.losses.BinaryFocalLossWithLogits(*args)
>       self.assert_close(op_module(logits, labels), op(logits, labels, *args))

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:261: in forward
    return binary_focal_loss_with_logits(pred, target, self.alpha, self.gamma, self.reduction, self.pos_weight, self.weight, self.ignore_index)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3384, 0.1766],
         [0.9229, 0.6076],
         [0.2473, 0.9257]],

        [[0.2957, 0.7445],
         [0.1013, 0.6726],
         [0.0181, 0.8757]]])
target = tensor([[[0.9320, 0.5631],
         [0.3024, 0.1665],
         [0.4003, 0.2843]],

        [[0.4375, 0.7879],
         [0.3887, 0.5027],
         [0.6358, 0.0478]]])
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
______ TestBinaryFocalLossWithLogits.test_numeric_stability[cpu-float32] _______

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7f650406b460>
device = device(type='cpu'), dtype = torch.float32

    def test_numeric_stability(self, device, dtype):
        logits = torch.tensor([[100.0, -100]], dtype=dtype, device=device)
        labels = torch.tensor([[1.0, 0.0]], dtype=dtype, device=device)
    
        args = (0.25, 2.0)
>       actual = kornia.losses.binary_focal_loss_with_logits(logits, labels, *args)

/local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[ 100., -100.]]), target = tensor([[1., 0.]]), alpha = 0.25
gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

/local/data0/moved_data/publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32]
FAILED ../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32]
============================== 59 failed in 0.88s ==============================


Final Test Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'inductor', 'jit', 'openxla', 'onnxrt', 'cudagraphs', 'tvm', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 59 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] PASSED

============================== 59 passed in 2.12s ==============================


Initial Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'inductor', 'tvm', 'cudagraphs', 'jit', 'onnxrt', 'openxla', None}
model weights cached: []

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1, jaxtyping-0.2.38
collecting ... collected 59 items

../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] PASSED
../../../../../../local/data0/moved_data/publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] PASSED

============================== 59 passed in 2.12s ==============================
