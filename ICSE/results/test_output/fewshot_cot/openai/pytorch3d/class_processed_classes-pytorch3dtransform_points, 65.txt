output file:
processed_classes-pytorch3dtransform_points, 65.json
function:
transform_points
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_to FAILED [ 23%]', '../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_dtype_propagation FAILED [  4%]', 'FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_dtype_propagation', 'FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_to'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.8.5, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/pytorch3d/venv/bin/python3
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/pytorch3d
collecting ... collected 65 items

../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_clone PASSED [  1%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_compose_fail PASSED [  3%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_dtype_propagation FAILED [  4%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_get_item PASSED [  6%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_get_se3 PASSED [  7%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_init_with_custom_matrix PASSED [  9%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_init_with_custom_matrix_errors PASSED [ 10%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_inverse PASSED [ 12%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_axis_angle FAILED [ 13%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_off FAILED [ 15%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_on FAILED [ 16%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale FAILED [ 18%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale_translate FAILED [ 20%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_stack FAILED [ 21%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_to FAILED [ 23%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_eps FAILED [ 24%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_fail PASSED [ 26%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_translate FAILED [ 27%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_bad_broadcast PASSED [ 29%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_get_item PASSED [ 30%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_inverse PASSED [ 32%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_matrix PASSED [ 33%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_matrix_extra_args PASSED [ 35%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_broadcast PASSED [ 36%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_broadcast_grad PASSED [ 38%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_scalars PASSED [ 40%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_python_scalar PASSED [ 41%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_scalar PASSED [ 43%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_scalar_grads PASSED [ 44%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_vectors PASSED [ 46%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_vector_broadcast PASSED [ 47%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_get_item PASSED [ 49%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_inverse PASSED [ 50%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_matrix PASSED [ 52%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_python_scalar PASSED [ 53%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_torch_scalar PASSED [ 55%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_vector PASSED [ 56%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_mixed_broadcast_grad PASSED [ 58%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_mixed_scalar PASSED [ 60%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_python_scalar PASSED [ 61%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_torch_scalar PASSED [ 63%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_vector_broadcast PASSED [ 64%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose PASSED [ 66%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose_fail PASSED [ 67%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_normals PASSED [ 69%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_points FAILED [ 70%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_multiple_broadcast_compose PASSED [ 72%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_get_item PASSED [ 73%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_invalid_dimensions PASSED [ 75%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_inverse PASSED [ 76%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_single_matrix PASSED [ 78%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_axis_fail PASSED [ 80%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_lower_case_axis PASSED [ 81%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_angle_fail PASSED [ 83%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_angle_radians PASSED [ 84%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_compose_x_y_z PASSED [ 86%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_python_scalar FAILED [ 87%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_scalar FAILED [ 89%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_tensor PASSED [ 90%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_python_scalar FAILED [ 92%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_scalar FAILED [ 93%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_tensor PASSED [ 95%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_python_scalar FAILED [ 96%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_scalar FAILED [ 98%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_tensor PASSED [100%]

=================================== FAILURES ===================================
_____________________ TestTransform.test_dtype_propagation _____________________

self = <tests.test_transforms.TestTransform testMethod=test_dtype_propagation>

    def test_dtype_propagation(self):
        """
        Check that a given dtype is correctly passed along to child
        transformations.
        """
        # Use at least two dtypes so we avoid only testing on the
        # default dtype.
        for dtype in [torch.float32, torch.float64]:
            R = torch.tensor(
                [[0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0]],
                dtype=dtype,
            )
            tf = (
                Transform3d(dtype=dtype)
                .rotate(R)
                .rotate_axis_angle(
                    R[0],
                    "X",
                )
                .translate(3, 2, 1)
                .scale(0.5)
            )
    
            self.assertEqual(tf.dtype, dtype)
            for inner_tf in tf._transforms:
                self.assertEqual(inner_tf.dtype, dtype)
    
>           transformed = tf.transform_points(R)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:120: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x704891f3d940>
points = tensor([[[0., 1., 0.],
         [0., 0., 1.],
         [1., 0., 0.]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (Optional[float]): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() == 2:
            points = points.unsqueeze(0)
        elif points.dim() != 3 or points.size(-1) != 3:
            raise ValueError('Input points should have shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
>       transformed_homogeneous = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1))
E       RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [4, 1].

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:344: RuntimeError
_____________________ TestTransform.test_rotate_axis_angle _____________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_axis_angle>

    def test_rotate_axis_angle(self):
        t = Transform3d().rotate_axis_angle(90.0, axis="Z")
        points = torch.tensor([[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 1.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x704891db19d0>
points = tensor([[[0., 0., 0.],
         [0., 1., 0.],
         [0., 1., 1.]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (Optional[float]): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() == 2:
            points = points.unsqueeze(0)
        elif points.dim() != 3 or points.size(-1) != 3:
            raise ValueError('Input points should have shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
>       transformed_homogeneous = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1))
E       RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [4, 1].

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:344: RuntimeError
________________ TestTransform.test_rotate_check_rot_valid_off _________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_check_rot_valid_off>

    @mock.patch.dict(os.environ, {"PYTORCH3D_CHECK_ROTATION_MATRICES": "0"}, clear=True)
    def test_rotate_check_rot_valid_off(self):
        R = so3_exp_map(torch.randn((1, 3)))
        t = Transform3d().rotate(R)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x7049479a4880>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (Optional[float]): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() == 2:
            points = points.unsqueeze(0)
        elif points.dim() != 3 or points.size(-1) != 3:
            raise ValueError('Input points should have shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
>       transformed_homogeneous = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1))
E       RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [4, 1].

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:344: RuntimeError
_________________ TestTransform.test_rotate_check_rot_valid_on _________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_check_rot_valid_on>

    @mock.patch.dict(os.environ, {"PYTORCH3D_CHECK_ROTATION_MATRICES": "1"}, clear=True)
    def test_rotate_check_rot_valid_on(self):
        R = so3_exp_map(torch.randn((1, 3)))
        t = Transform3d().rotate(R)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:205: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x704891d10250>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (Optional[float]): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() == 2:
            points = points.unsqueeze(0)
        elif points.dim() != 3 or points.size(-1) != 3:
            raise ValueError('Input points should have shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
>       transformed_homogeneous = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1))
E       RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [4, 1].

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:344: RuntimeError
___________________________ TestTransform.test_scale ___________________________

self = <tests.test_transforms.TestTransform testMethod=test_scale>

    def test_scale(self):
        t = Transform3d().scale(2.0).scale(0.5, 0.25, 1.0)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:237: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x704946811970>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (Optional[float]): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() == 2:
            points = points.unsqueeze(0)
        elif points.dim() != 3 or points.size(-1) != 3:
            raise ValueError('Input points should have shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
>       transformed_homogeneous = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1))
E       RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [4, 1].

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:344: RuntimeError
______________________ TestTransform.test_scale_translate ______________________

self = <tests.test_transforms.TestTransform testMethod=test_scale_translate>

    def test_scale_translate(self):
        t = Transform3d().scale(2, 1, 3).translate(1, 2, 3)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x70494679d640>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (Optional[float]): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() == 2:
            points = points.unsqueeze(0)
        elif points.dim() != 3 or points.size(-1) != 3:
            raise ValueError('Input points should have shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
>       transformed_homogeneous = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1))
E       RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [4, 1].

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:344: RuntimeError
___________________________ TestTransform.test_stack ___________________________

self = <tests.test_transforms.TestTransform testMethod=test_stack>

    def test_stack(self):
        rotations = random_rotations(3)
        transform3 = Transform3d().rotate(rotations).translate(torch.full((3, 3), 0.3))
        transform1 = Scale(37)
        transform4 = transform1.stack(transform3)
        self.assertEqual(len(transform1), 1)
        self.assertEqual(len(transform3), 3)
        self.assertEqual(len(transform4), 4)
        self.assertClose(
            transform4.get_matrix(),
            torch.cat([transform1.get_matrix(), transform3.get_matrix()]),
        )
        points = torch.rand(4, 5, 3)
        new_points_expect = torch.cat(
            [
>               transform1.transform_points(points[:1]),
                transform3.transform_points(points[1:]),
            ]
        )

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Scale object at 0x7048999602b0>
points = tensor([[[0.1053, 0.2695, 0.3588],
         [0.1994, 0.5472, 0.0062],
         [0.9516, 0.0753, 0.8860],
         [0.5832, 0.3376, 0.8090],
         [0.5779, 0.9040, 0.5547]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (Optional[float]): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() == 2:
            points = points.unsqueeze(0)
        elif points.dim() != 3 or points.size(-1) != 3:
            raise ValueError('Input points should have shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
>       transformed_homogeneous = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1))
E       RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [4, 1].

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:344: RuntimeError
____________________________ TestTransform.test_to _____________________________

self = <tests.test_transforms.TestTransform testMethod=test_to>

    def test_to(self):
        tr = Translate(torch.FloatTensor([[1.0, 2.0, 3.0]]))
        R = torch.FloatTensor([[0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0]])
        R = Rotate(R)
        t = Transform3d().compose(R, tr)
    
        cpu_device = torch.device("cpu")
    
        cpu_t = t.to("cpu")
        self.assertEqual(cpu_device, cpu_t.device)
        self.assertEqual(cpu_device, t.device)
        self.assertEqual(torch.float32, cpu_t.dtype)
        self.assertEqual(torch.float32, t.dtype)
        self.assertIs(t, cpu_t)
    
        cpu_t = t.to(cpu_device)
        self.assertEqual(cpu_device, cpu_t.device)
        self.assertEqual(cpu_device, t.device)
        self.assertEqual(torch.float32, cpu_t.dtype)
        self.assertEqual(torch.float32, t.dtype)
        self.assertIs(t, cpu_t)
    
        cpu_t = t.to(dtype=torch.float64, device=cpu_device)
        self.assertEqual(cpu_device, cpu_t.device)
        self.assertEqual(cpu_device, t.device)
        self.assertEqual(torch.float64, cpu_t.dtype)
        self.assertEqual(torch.float32, t.dtype)
        self.assertIsNot(t, cpu_t)
    
        cuda_device = torch.device("cuda:0")
    
        cuda_t = t.to("cuda:0")
        self.assertEqual(cuda_device, cuda_t.device)
        self.assertEqual(cpu_device, t.device)
        self.assertEqual(torch.float32, cuda_t.dtype)
        self.assertEqual(torch.float32, t.dtype)
        self.assertIsNot(t, cuda_t)
    
        cuda_t = t.to(cuda_device)
        self.assertEqual(cuda_device, cuda_t.device)
        self.assertEqual(cpu_device, t.device)
        self.assertEqual(torch.float32, cuda_t.dtype)
        self.assertEqual(torch.float32, t.dtype)
        self.assertIsNot(t, cuda_t)
    
        cuda_t = t.to(dtype=torch.float64, device=cuda_device)
        self.assertEqual(cuda_device, cuda_t.device)
        self.assertEqual(cpu_device, t.device)
        self.assertEqual(torch.float64, cuda_t.dtype)
        self.assertEqual(torch.float32, t.dtype)
        self.assertIsNot(t, cuda_t)
    
        cpu_points = torch.rand(9, 3)
        cuda_points = cpu_points.cuda()
        for _ in range(3):
            t = t.cpu()
>           t.transform_points(cpu_points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x704891db1070>
points = tensor([[[0.8823, 0.9150, 0.3829],
         [0.9593, 0.3904, 0.6009],
         [0.2566, 0.7936, 0.9408],
         [0.1...54, 0.5739],
         [0.2666, 0.6274, 0.2696],
         [0.4414, 0.2969, 0.8317],
         [0.1053, 0.2695, 0.3588]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (Optional[float]): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() == 2:
            points = points.unsqueeze(0)
        elif points.dim() != 3 or points.size(-1) != 3:
            raise ValueError('Input points should have shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
>       transformed_homogeneous = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1))
E       RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [4, 1].

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:344: RuntimeError
___________________ TestTransform.test_transform_points_eps ____________________

self = <tests.test_transforms.TestTransform testMethod=test_transform_points_eps>

    def test_transform_points_eps(self):
        t1 = Transform3d()
        persp_proj = [
            [
                [1.0, 0.0, 0.0, 0.0],
                [0.0, 1.0, 0.0, 0.0],
                [0.0, 0.0, 0.0, 1.0],
                [0.0, 0.0, 1.0, 0.0],
            ]
        ]
        t1._matrix = torch.FloatTensor(persp_proj)
        points = torch.tensor(
            [[0.0, 1.0, 0.0], [0.0, 0.0, 1e-5], [-1.0, 0.0, 1e-5]]
        ).view(
            1, 3, 3
        )  # a set of points with z-coord very close to 0
    
>       proj = t1.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x7049467f6730>
points = tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  1.0000e-05],
         [-1.0000e+00,  0.0000e+00,  1.0000e-05]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (Optional[float]): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() == 2:
            points = points.unsqueeze(0)
        elif points.dim() != 3 or points.size(-1) != 3:
            raise ValueError('Input points should have shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
>       transformed_homogeneous = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1))
E       RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [4, 1].

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:344: RuntimeError
_________________________ TestTransform.test_translate _________________________

self = <tests.test_transforms.TestTransform testMethod=test_translate>

    def test_translate(self):
        t = Transform3d().translate(1, 2, 3)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x704891f3d520>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (Optional[float]): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() == 2:
            points = points.unsqueeze(0)
        elif points.dim() != 3 or points.size(-1) != 3:
            raise ValueError('Input points should have shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
>       transformed_homogeneous = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1))
E       RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [4, 1].

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:344: RuntimeError
____________ TestTransformBroadcast.test_broadcast_transform_points ____________

self = <tests.test_transforms.TestTransformBroadcast testMethod=test_broadcast_transform_points>

    def test_broadcast_transform_points(self):
        t1 = Scale(0.1, 0.1, 0.1)
        N = 10
        P = 7
        M = 20
        x = torch.tensor([0.2] * N)
        y = torch.tensor([0.3] * N)
        z = torch.tensor([0.4] * N)
        tN = Translate(x, y, z)
>       p1 = t1.transform_points(torch.randn(P, 3))

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:903: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Scale object at 0x70494680a460>
points = tensor([[[ 9.7715e-01, -1.4153e+00, -7.8205e-04],
         [ 9.2348e-01, -1.1860e+00,  3.6402e-01],
         [-2.8120e...01, -5.6820e-01],
         [-8.6795e-02, -8.4834e-01,  1.6489e+00],
         [ 1.6006e+00, -7.8589e-02,  4.3105e-01]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (Optional[float]): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() == 2:
            points = points.unsqueeze(0)
        elif points.dim() != 3 or points.size(-1) != 3:
            raise ValueError('Input points should have shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
>       transformed_homogeneous = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1))
E       RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [4, 1].

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:344: RuntimeError
_______________ TestRotateAxisAngle.test_rotate_x_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_x_python_scalar>

    def test_rotate_x_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="X")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [1.0,  0.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 1.0, 0.0],  # noqa: E241, E201
                    [0.0, -1.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([0.0, 1.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1034: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x704946797af0>
points = tensor([[[0., 1., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (Optional[float]): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() == 2:
            points = points.unsqueeze(0)
        elif points.dim() != 3 or points.size(-1) != 3:
            raise ValueError('Input points should have shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
>       transformed_homogeneous = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1))
E       RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [4, 1].

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:344: RuntimeError
________________ TestRotateAxisAngle.test_rotate_x_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_x_torch_scalar>

    def test_rotate_x_torch_scalar(self):
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="X")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [1.0,  0.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 1.0, 0.0],  # noqa: E241, E201
                    [0.0, -1.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([0.0, 1.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1058: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x704891630ac0>
points = tensor([[[0., 1., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (Optional[float]): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() == 2:
            points = points.unsqueeze(0)
        elif points.dim() != 3 or points.size(-1) != 3:
            raise ValueError('Input points should have shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
>       transformed_homogeneous = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1))
E       RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [4, 1].

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:344: RuntimeError
_______________ TestRotateAxisAngle.test_rotate_y_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_y_python_scalar>

    def test_rotate_y_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="Y")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [0.0, 0.0, -1.0, 0.0],  # noqa: E241, E201
                    [0.0, 1.0,  0.0, 0.0],  # noqa: E241, E201
                    [1.0, 0.0,  0.0, 0.0],  # noqa: E241, E201
                    [0.0, 0.0,  0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1116: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x704891d87cd0>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (Optional[float]): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() == 2:
            points = points.unsqueeze(0)
        elif points.dim() != 3 or points.size(-1) != 3:
            raise ValueError('Input points should have shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
>       transformed_homogeneous = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1))
E       RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [4, 1].

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:344: RuntimeError
________________ TestRotateAxisAngle.test_rotate_y_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_y_torch_scalar>

    def test_rotate_y_torch_scalar(self):
        """
        Test rotation about Y axis. With a right hand coordinate system this
        should result in a vector pointing along the x-axis being rotated to
        point along the negative z axis.
        """
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="Y")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [0.0, 0.0, -1.0, 0.0],  # noqa: E241, E201
                    [0.0, 1.0,  0.0, 0.0],  # noqa: E241, E201
                    [1.0, 0.0,  0.0, 0.0],  # noqa: E241, E201
                    [0.0, 0.0,  0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x704891e959d0>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (Optional[float]): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() == 2:
            points = points.unsqueeze(0)
        elif points.dim() != 3 or points.size(-1) != 3:
            raise ValueError('Input points should have shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
>       transformed_homogeneous = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1))
E       RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [4, 1].

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:344: RuntimeError
_______________ TestRotateAxisAngle.test_rotate_z_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_z_python_scalar>

    def test_rotate_z_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="Z")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [ 0.0, 1.0, 0.0, 0.0],  # noqa: E241, E201
                    [-1.0, 0.0, 0.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 1.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x704891f344c0>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (Optional[float]): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() == 2:
            points = points.unsqueeze(0)
        elif points.dim() != 3 or points.size(-1) != 3:
            raise ValueError('Input points should have shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
>       transformed_homogeneous = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1))
E       RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [4, 1].

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:344: RuntimeError
________________ TestRotateAxisAngle.test_rotate_z_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_z_torch_scalar>

    def test_rotate_z_torch_scalar(self):
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="Z")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [ 0.0, 1.0, 0.0, 0.0],  # noqa: E241, E201
                    [-1.0, 0.0, 0.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 1.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x704891e8a6a0>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (Optional[float]): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() == 2:
            points = points.unsqueeze(0)
        elif points.dim() != 3 or points.size(-1) != 3:
            raise ValueError('Input points should have shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
>       transformed_homogeneous = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1))
E       RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [4, 1].

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:344: RuntimeError
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_dtype_propagation
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_axis_angle
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_off
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_on
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale_translate
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_stack
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_to
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_eps
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_translate
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_points
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_scalar
======================== 17 failed, 48 passed in 1.86s =========================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.8.5, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/pytorch3d/venv/bin/python3
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/pytorch3d
collecting ... collected 65 items

../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_clone PASSED [  1%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_compose_fail PASSED [  3%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_dtype_propagation PASSED [  4%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_get_item PASSED [  6%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_get_se3 PASSED [  7%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_init_with_custom_matrix PASSED [  9%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_init_with_custom_matrix_errors PASSED [ 10%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_inverse PASSED [ 12%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_axis_angle FAILED [ 13%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_off FAILED [ 15%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_on FAILED [ 16%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale FAILED [ 18%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale_translate FAILED [ 20%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_stack FAILED [ 21%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_to PASSED [ 23%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_eps FAILED [ 24%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_fail PASSED [ 26%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_translate FAILED [ 27%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_bad_broadcast PASSED [ 29%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_get_item PASSED [ 30%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_inverse PASSED [ 32%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_matrix PASSED [ 33%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_matrix_extra_args PASSED [ 35%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_broadcast PASSED [ 36%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_broadcast_grad PASSED [ 38%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_scalars PASSED [ 40%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_python_scalar PASSED [ 41%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_scalar PASSED [ 43%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_scalar_grads PASSED [ 44%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_vectors PASSED [ 46%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_vector_broadcast PASSED [ 47%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_get_item PASSED [ 49%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_inverse PASSED [ 50%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_matrix PASSED [ 52%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_python_scalar PASSED [ 53%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_torch_scalar PASSED [ 55%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_vector PASSED [ 56%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_mixed_broadcast_grad PASSED [ 58%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_mixed_scalar PASSED [ 60%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_python_scalar PASSED [ 61%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_torch_scalar PASSED [ 63%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_vector_broadcast PASSED [ 64%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose PASSED [ 66%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose_fail PASSED [ 67%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_normals PASSED [ 69%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_points FAILED [ 70%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_multiple_broadcast_compose PASSED [ 72%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_get_item PASSED [ 73%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_invalid_dimensions PASSED [ 75%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_inverse PASSED [ 76%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_single_matrix PASSED [ 78%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_axis_fail PASSED [ 80%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_lower_case_axis PASSED [ 81%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_angle_fail PASSED [ 83%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_angle_radians PASSED [ 84%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_compose_x_y_z PASSED [ 86%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_python_scalar FAILED [ 87%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_scalar FAILED [ 89%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_tensor PASSED [ 90%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_python_scalar FAILED [ 92%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_scalar FAILED [ 93%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_tensor PASSED [ 95%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_python_scalar FAILED [ 96%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_scalar FAILED [ 98%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_tensor PASSED [100%]

=================================== FAILURES ===================================
_____________________ TestTransform.test_rotate_axis_angle _____________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_axis_angle>

    def test_rotate_axis_angle(self):
        t = Transform3d().rotate_axis_angle(90.0, axis="Z")
        points = torch.tensor([[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 1.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x76cb898c3df0>
points = tensor([[[0., 0., 0.],
         [0., 1., 0.],
         [0., 1., 1.]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
________________ TestTransform.test_rotate_check_rot_valid_off _________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_check_rot_valid_off>

    @mock.patch.dict(os.environ, {"PYTORCH3D_CHECK_ROTATION_MATRICES": "0"}, clear=True)
    def test_rotate_check_rot_valid_off(self):
        R = so3_exp_map(torch.randn((1, 3)))
        t = Transform3d().rotate(R)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x76cc3f310880>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
_________________ TestTransform.test_rotate_check_rot_valid_on _________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_check_rot_valid_on>

    @mock.patch.dict(os.environ, {"PYTORCH3D_CHECK_ROTATION_MATRICES": "1"}, clear=True)
    def test_rotate_check_rot_valid_on(self):
        R = so3_exp_map(torch.randn((1, 3)))
        t = Transform3d().rotate(R)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:205: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x76cc3f2fc700>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
___________________________ TestTransform.test_scale ___________________________

self = <tests.test_transforms.TestTransform testMethod=test_scale>

    def test_scale(self):
        t = Transform3d().scale(2.0).scale(0.5, 0.25, 1.0)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:237: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x76cc3e146eb0>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
______________________ TestTransform.test_scale_translate ______________________

self = <tests.test_transforms.TestTransform testMethod=test_scale_translate>

    def test_scale_translate(self):
        t = Transform3d().scale(2, 1, 3).translate(1, 2, 3)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x76cb898c3be0>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
___________________________ TestTransform.test_stack ___________________________

self = <tests.test_transforms.TestTransform testMethod=test_stack>

    def test_stack(self):
        rotations = random_rotations(3)
        transform3 = Transform3d().rotate(rotations).translate(torch.full((3, 3), 0.3))
        transform1 = Scale(37)
        transform4 = transform1.stack(transform3)
        self.assertEqual(len(transform1), 1)
        self.assertEqual(len(transform3), 3)
        self.assertEqual(len(transform4), 4)
        self.assertClose(
            transform4.get_matrix(),
            torch.cat([transform1.get_matrix(), transform3.get_matrix()]),
        )
        points = torch.rand(4, 5, 3)
        new_points_expect = torch.cat(
            [
>               transform1.transform_points(points[:1]),
                transform3.transform_points(points[1:]),
            ]
        )

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Scale object at 0x76cc3e0fce50>
points = tensor([[[0.1053, 0.2695, 0.3588],
         [0.1994, 0.5472, 0.0062],
         [0.9516, 0.0753, 0.8860],
         [0.5832, 0.3376, 0.8090],
         [0.5779, 0.9040, 0.5547]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
___________________ TestTransform.test_transform_points_eps ____________________

self = <tests.test_transforms.TestTransform testMethod=test_transform_points_eps>

    def test_transform_points_eps(self):
        t1 = Transform3d()
        persp_proj = [
            [
                [1.0, 0.0, 0.0, 0.0],
                [0.0, 1.0, 0.0, 0.0],
                [0.0, 0.0, 0.0, 1.0],
                [0.0, 0.0, 1.0, 0.0],
            ]
        ]
        t1._matrix = torch.FloatTensor(persp_proj)
        points = torch.tensor(
            [[0.0, 1.0, 0.0], [0.0, 0.0, 1e-5], [-1.0, 0.0, 1e-5]]
        ).view(
            1, 3, 3
        )  # a set of points with z-coord very close to 0
    
>       proj = t1.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x76cb88ba7040>
points = tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  1.0000e-05],
         [-1.0000e+00,  0.0000e+00,  1.0000e-05]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
_________________________ TestTransform.test_translate _________________________

self = <tests.test_transforms.TestTransform testMethod=test_translate>

    def test_translate(self):
        t = Transform3d().translate(1, 2, 3)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x76cb899182e0>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
____________ TestTransformBroadcast.test_broadcast_transform_points ____________

self = <tests.test_transforms.TestTransformBroadcast testMethod=test_broadcast_transform_points>

    def test_broadcast_transform_points(self):
        t1 = Scale(0.1, 0.1, 0.1)
        N = 10
        P = 7
        M = 20
        x = torch.tensor([0.2] * N)
        y = torch.tensor([0.3] * N)
        z = torch.tensor([0.4] * N)
        tN = Translate(x, y, z)
        p1 = t1.transform_points(torch.randn(P, 3))
>       self.assertTrue(p1.shape == (P, 3))
E       AssertionError: False is not true

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:904: AssertionError
_______________ TestRotateAxisAngle.test_rotate_x_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_x_python_scalar>

    def test_rotate_x_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="X")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [1.0,  0.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 1.0, 0.0],  # noqa: E241, E201
                    [0.0, -1.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([0.0, 1.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1034: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x76cb8970cc70>
points = tensor([[[0., 1., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
________________ TestRotateAxisAngle.test_rotate_x_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_x_torch_scalar>

    def test_rotate_x_torch_scalar(self):
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="X")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [1.0,  0.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 1.0, 0.0],  # noqa: E241, E201
                    [0.0, -1.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([0.0, 1.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1058: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x76cc3e157eb0>
points = tensor([[[0., 1., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
_______________ TestRotateAxisAngle.test_rotate_y_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_y_python_scalar>

    def test_rotate_y_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="Y")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [0.0, 0.0, -1.0, 0.0],  # noqa: E241, E201
                    [0.0, 1.0,  0.0, 0.0],  # noqa: E241, E201
                    [1.0, 0.0,  0.0, 0.0],  # noqa: E241, E201
                    [0.0, 0.0,  0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1116: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x76cb88ab0040>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
________________ TestRotateAxisAngle.test_rotate_y_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_y_torch_scalar>

    def test_rotate_y_torch_scalar(self):
        """
        Test rotation about Y axis. With a right hand coordinate system this
        should result in a vector pointing along the x-axis being rotated to
        point along the negative z axis.
        """
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="Y")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [0.0, 0.0, -1.0, 0.0],  # noqa: E241, E201
                    [0.0, 1.0,  0.0, 0.0],  # noqa: E241, E201
                    [1.0, 0.0,  0.0, 0.0],  # noqa: E241, E201
                    [0.0, 0.0,  0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x76cc3e1047f0>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
_______________ TestRotateAxisAngle.test_rotate_z_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_z_python_scalar>

    def test_rotate_z_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="Z")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [ 0.0, 1.0, 0.0, 0.0],  # noqa: E241, E201
                    [-1.0, 0.0, 0.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 1.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x76cb88f6ff10>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
________________ TestRotateAxisAngle.test_rotate_z_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_z_torch_scalar>

    def test_rotate_z_torch_scalar(self):
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="Z")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [ 0.0, 1.0, 0.0, 0.0],  # noqa: E241, E201
                    [-1.0, 0.0, 0.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 1.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x76cc3e174940>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
=============================== warnings summary ===============================
tests/test_transforms.py::TestTransform::test_dtype_propagation
  /local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:343: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3697.)
    transformed_points = points_homogeneous @ self._matrix.T

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_axis_angle
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_off
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_on
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale_translate
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_stack
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_eps
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_translate
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_points
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_scalar
=================== 15 failed, 50 passed, 1 warning in 1.71s ===================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.8.5, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/pytorch3d/venv/bin/python3
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/pytorch3d
collecting ... collected 65 items

../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_clone PASSED [  1%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_compose_fail PASSED [  3%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_dtype_propagation PASSED [  4%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_get_item PASSED [  6%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_get_se3 PASSED [  7%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_init_with_custom_matrix PASSED [  9%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_init_with_custom_matrix_errors PASSED [ 10%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_inverse PASSED [ 12%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_axis_angle FAILED [ 13%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_off FAILED [ 15%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_on FAILED [ 16%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale FAILED [ 18%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale_translate FAILED [ 20%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_stack FAILED [ 21%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_to PASSED [ 23%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_eps FAILED [ 24%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_fail PASSED [ 26%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_translate FAILED [ 27%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_bad_broadcast PASSED [ 29%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_get_item PASSED [ 30%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_inverse PASSED [ 32%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_matrix PASSED [ 33%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_matrix_extra_args PASSED [ 35%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_broadcast PASSED [ 36%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_broadcast_grad PASSED [ 38%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_mixed_scalars PASSED [ 40%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_python_scalar PASSED [ 41%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_scalar PASSED [ 43%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_scalar_grads PASSED [ 44%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_torch_vectors PASSED [ 46%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTranslate::test_vector_broadcast PASSED [ 47%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_get_item PASSED [ 49%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_inverse PASSED [ 50%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_matrix PASSED [ 52%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_python_scalar PASSED [ 53%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_torch_scalar PASSED [ 55%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_single_vector PASSED [ 56%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_mixed_broadcast_grad PASSED [ 58%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_mixed_scalar PASSED [ 60%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_python_scalar PASSED [ 61%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_torch_scalar PASSED [ 63%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestScale::test_three_vector_broadcast PASSED [ 64%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose PASSED [ 66%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_compose_fail PASSED [ 67%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_normals PASSED [ 69%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_points FAILED [ 70%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_multiple_broadcast_compose PASSED [ 72%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_get_item PASSED [ 73%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_invalid_dimensions PASSED [ 75%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_inverse PASSED [ 76%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotate::test_single_matrix PASSED [ 78%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_axis_fail PASSED [ 80%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_lower_case_axis PASSED [ 81%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_angle_fail PASSED [ 83%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_angle_radians PASSED [ 84%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_compose_x_y_z PASSED [ 86%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_python_scalar FAILED [ 87%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_scalar FAILED [ 89%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_tensor PASSED [ 90%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_python_scalar FAILED [ 92%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_scalar FAILED [ 93%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_tensor PASSED [ 95%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_python_scalar FAILED [ 96%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_scalar FAILED [ 98%]
../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_tensor PASSED [100%]

=================================== FAILURES ===================================
_____________________ TestTransform.test_rotate_axis_angle _____________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_axis_angle>

    def test_rotate_axis_angle(self):
        t = Transform3d().rotate_axis_angle(90.0, axis="Z")
        points = torch.tensor([[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 1.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x736b9b27c850>
points = tensor([[[0., 0., 0.],
         [0., 1., 0.],
         [0., 1., 1.]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
________________ TestTransform.test_rotate_check_rot_valid_off _________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_check_rot_valid_off>

    @mock.patch.dict(os.environ, {"PYTORCH3D_CHECK_ROTATION_MATRICES": "0"}, clear=True)
    def test_rotate_check_rot_valid_off(self):
        R = so3_exp_map(torch.randn((1, 3)))
        t = Transform3d().rotate(R)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x736c50cbd880>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
_________________ TestTransform.test_rotate_check_rot_valid_on _________________

self = <tests.test_transforms.TestTransform testMethod=test_rotate_check_rot_valid_on>

    @mock.patch.dict(os.environ, {"PYTORCH3D_CHECK_ROTATION_MATRICES": "1"}, clear=True)
    def test_rotate_check_rot_valid_on(self):
        R = so3_exp_map(torch.randn((1, 3)))
        t = Transform3d().rotate(R)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:205: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x736c50ca9700>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
___________________________ TestTransform.test_scale ___________________________

self = <tests.test_transforms.TestTransform testMethod=test_scale>

    def test_scale(self):
        t = Transform3d().scale(2.0).scale(0.5, 0.25, 1.0)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:237: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x736c4fb0c5e0>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
______________________ TestTransform.test_scale_translate ______________________

self = <tests.test_transforms.TestTransform testMethod=test_scale_translate>

    def test_scale_translate(self):
        t = Transform3d().scale(2, 1, 3).translate(1, 2, 3)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x736b9b0dc310>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
___________________________ TestTransform.test_stack ___________________________

self = <tests.test_transforms.TestTransform testMethod=test_stack>

    def test_stack(self):
        rotations = random_rotations(3)
        transform3 = Transform3d().rotate(rotations).translate(torch.full((3, 3), 0.3))
        transform1 = Scale(37)
        transform4 = transform1.stack(transform3)
        self.assertEqual(len(transform1), 1)
        self.assertEqual(len(transform3), 3)
        self.assertEqual(len(transform4), 4)
        self.assertClose(
            transform4.get_matrix(),
            torch.cat([transform1.get_matrix(), transform3.get_matrix()]),
        )
        points = torch.rand(4, 5, 3)
        new_points_expect = torch.cat(
            [
>               transform1.transform_points(points[:1]),
                transform3.transform_points(points[1:]),
            ]
        )

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Scale object at 0x736c4fab9820>
points = tensor([[[0.1053, 0.2695, 0.3588],
         [0.1994, 0.5472, 0.0062],
         [0.9516, 0.0753, 0.8860],
         [0.5832, 0.3376, 0.8090],
         [0.5779, 0.9040, 0.5547]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
___________________ TestTransform.test_transform_points_eps ____________________

self = <tests.test_transforms.TestTransform testMethod=test_transform_points_eps>

    def test_transform_points_eps(self):
        t1 = Transform3d()
        persp_proj = [
            [
                [1.0, 0.0, 0.0, 0.0],
                [0.0, 1.0, 0.0, 0.0],
                [0.0, 0.0, 0.0, 1.0],
                [0.0, 0.0, 1.0, 0.0],
            ]
        ]
        t1._matrix = torch.FloatTensor(persp_proj)
        points = torch.tensor(
            [[0.0, 1.0, 0.0], [0.0, 0.0, 1e-5], [-1.0, 0.0, 1e-5]]
        ).view(
            1, 3, 3
        )  # a set of points with z-coord very close to 0
    
>       proj = t1.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x736c50cbd850>
points = tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  1.0000e-05],
         [-1.0000e+00,  0.0000e+00,  1.0000e-05]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
_________________________ TestTransform.test_translate _________________________

self = <tests.test_transforms.TestTransform testMethod=test_translate>

    def test_translate(self):
        t = Transform3d().translate(1, 2, 3)
        points = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.5, 0.5, 0.0]]).view(
            1, 3, 3
        )
        normals = torch.tensor(
            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0]]
        ).view(1, 3, 3)
>       points_out = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.Transform3d object at 0x736c4fb274f0>
points = tensor([[[1.0000, 0.0000, 0.0000],
         [0.0000, 1.0000, 0.0000],
         [0.5000, 0.5000, 0.0000]]])
eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
____________ TestTransformBroadcast.test_broadcast_transform_points ____________

self = <tests.test_transforms.TestTransformBroadcast testMethod=test_broadcast_transform_points>

    def test_broadcast_transform_points(self):
        t1 = Scale(0.1, 0.1, 0.1)
        N = 10
        P = 7
        M = 20
        x = torch.tensor([0.2] * N)
        y = torch.tensor([0.3] * N)
        z = torch.tensor([0.4] * N)
        tN = Translate(x, y, z)
        p1 = t1.transform_points(torch.randn(P, 3))
>       self.assertTrue(p1.shape == (P, 3))
E       AssertionError: False is not true

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:904: AssertionError
_______________ TestRotateAxisAngle.test_rotate_x_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_x_python_scalar>

    def test_rotate_x_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="X")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [1.0,  0.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 1.0, 0.0],  # noqa: E241, E201
                    [0.0, -1.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([0.0, 1.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1034: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x736b9a9a6c40>
points = tensor([[[0., 1., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
________________ TestRotateAxisAngle.test_rotate_x_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_x_torch_scalar>

    def test_rotate_x_torch_scalar(self):
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="X")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [1.0,  0.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 1.0, 0.0],  # noqa: E241, E201
                    [0.0, -1.0, 0.0, 0.0],  # noqa: E241, E201
                    [0.0,  0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([0.0, 1.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1058: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x736c4fb20520>
points = tensor([[[0., 1., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
_______________ TestRotateAxisAngle.test_rotate_y_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_y_python_scalar>

    def test_rotate_y_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="Y")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [0.0, 0.0, -1.0, 0.0],  # noqa: E241, E201
                    [0.0, 1.0,  0.0, 0.0],  # noqa: E241, E201
                    [1.0, 0.0,  0.0, 0.0],  # noqa: E241, E201
                    [0.0, 0.0,  0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1116: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x736b9a5f6100>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
________________ TestRotateAxisAngle.test_rotate_y_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_y_torch_scalar>

    def test_rotate_y_torch_scalar(self):
        """
        Test rotation about Y axis. With a right hand coordinate system this
        should result in a vector pointing along the x-axis being rotated to
        point along the negative z axis.
        """
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="Y")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [0.0, 0.0, -1.0, 0.0],  # noqa: E241, E201
                    [0.0, 1.0,  0.0, 0.0],  # noqa: E241, E201
                    [1.0, 0.0,  0.0, 0.0],  # noqa: E241, E201
                    [0.0, 0.0,  0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x736b99b71400>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
_______________ TestRotateAxisAngle.test_rotate_z_python_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_z_python_scalar>

    def test_rotate_z_python_scalar(self):
        t = RotateAxisAngle(angle=90, axis="Z")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [ 0.0, 1.0, 0.0, 0.0],  # noqa: E241, E201
                    [-1.0, 0.0, 0.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 1.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x736b9b0c1d30>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
________________ TestRotateAxisAngle.test_rotate_z_torch_scalar ________________

self = <tests.test_transforms.TestRotateAxisAngle testMethod=test_rotate_z_torch_scalar>

    def test_rotate_z_torch_scalar(self):
        angle = torch.tensor(90.0)
        t = RotateAxisAngle(angle=angle, axis="Z")
        # fmt: off
        matrix = torch.tensor(
            [
                [
                    [ 0.0, 1.0, 0.0, 0.0],  # noqa: E241, E201
                    [-1.0, 0.0, 0.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 1.0, 0.0],  # noqa: E241, E201
                    [ 0.0, 0.0, 0.0, 1.0],  # noqa: E241, E201
                ]
            ],
            dtype=torch.float32,
        )
        # fmt: on
        points = torch.tensor([1.0, 0.0, 0.0])[None, None, :]  # (1, 1, 3)
>       transformed_points = t.transform_points(points)

/local/data0/moved_data/pytorch3d/tests/test_transforms.py:1224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <pytorch3d.transforms.transform3d.RotateAxisAngle object at 0x736b9a91d160>
points = tensor([[[1., 0., 0.]]]), eps = None

    def transform_points(self, points: torch.Tensor, eps: Optional[float]=None) -> torch.Tensor:
        """
        Transforms a set of 3D points using the transformation matrix.
    
        Args:
            points (torch.Tensor): Tensor of shape (P, 3) or (N, P, 3).
            eps (float, optional): Small value to clamp the homogeneous coordinate.
    
        Returns:
            torch.Tensor: Transformed points of the same shape as input.
        """
        if points.dim() not in {2, 3} or points.size(-1) != 3:
            raise ValueError('Points should be of shape (P, 3) or (N, P, 3).')
        ones = torch.ones(*points.shape[:-1], 1, dtype=points.dtype, device=points.device)
        points_homogeneous = torch.cat([points, ones], dim=-1)
        if points.dim() == 2:
            transformed_points = points_homogeneous @ self._matrix.T
        else:
>           transformed_points = torch.bmm(points_homogeneous, self._matrix.transpose(0, 1).expand(points.size(0), -1, -1))
E           RuntimeError: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, -1, -1].  Tensor sizes: [4, 1, 4]

/local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:345: RuntimeError
=============================== warnings summary ===============================
tests/test_transforms.py::TestTransform::test_dtype_propagation
  /local/data0/moved_data/pytorch3d/pytorch3d/transforms/transform3d.py:343: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3697.)
    transformed_points = points_homogeneous @ self._matrix.T

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_axis_angle
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_off
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_rotate_check_rot_valid_on
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_scale_translate
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_stack
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_transform_points_eps
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransform::test_translate
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestTransformBroadcast::test_broadcast_transform_points
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_x_torch_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_y_torch_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_python_scalar
FAILED ../../../../../../local/data0/moved_data/pytorch3d/tests/test_transforms.py::TestRotateAxisAngle::test_rotate_z_torch_scalar
=================== 15 failed, 50 passed, 1 warning in 1.71s ===================
