output file:
processed_GPflowgauss_kl44.json
function:
gauss_kl
Error Cases:
2025-02-13 20:28:29.559601: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1739496509.571022 1266281 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1739496509.574629 1266281 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-13 20:28:29.587217: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
I0000 00:00:1739496512.374131 1266281 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9345 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:06:00.0, compute capability: 8.6

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[False-1]', '../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[False-1] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[True-1]', '../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[True-0] FAILED', '../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[True-1] FAILED', '../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[False-0] FAILED', 'FAILED ../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[True-0]', 'FAILED ../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[False-0]'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/GPflow/GPflow/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/GPflow/GPflow
collecting ... collected 4 items

../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[True-0] FAILED
../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[True-1] FAILED
../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[False-0] FAILED
../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[False-1] FAILED

=================================== FAILURES ===================================
______________________________ test_oned[True-0] _______________________________

white = True, dim = 0

    @pytest.mark.parametrize("dim", [0, 1])
    @pytest.mark.parametrize("white", [True, False])
    def test_oned(white: bool, dim: bool) -> None:
        """
        Check that the KL divergence matches a 1D by-hand calculation.
        """
        mu1d = Datum.mu[dim, :][None, :]  # [1, N]
        s1d = Datum.sqrt[:, dim, dim][:, None, None]  # [N, 1, 1]
        K1d = Datum.K_batch[:, dim, dim][:, None, None]  # [N, 1, 1]
    
>       kl = gauss_kl(mu1d, s1d, K1d if not white else None)

/local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py:223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/GPflow/GPflow/gpflow/kullback_leiblers.py:24: in gauss_kl
    return gauss_kl(q_mu, q_sqrt, K)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

q_mu = array([[1.76405235, 0.40015721, 0.97873798, 2.2408932 ]])
q_sqrt = array([[[-0.4380743 ]],

       [[ 0.72909056]],

       [[ 0.70657317]],

       [[ 0.37642553]]])
K = None, K_cholesky = None

    def gauss_kl(q_mu, q_sqrt, K=None, K_cholesky=None):
        """
        Compute the KL divergence KL[q || p] for multiple independent Gaussian distributions.
    
        Args:
            q_mu (np.ndarray): Mean of q, shape [M, L].
            q_sqrt (np.ndarray): Square-root of the covariance of q.
                                 Shape can be [L, M, M] or [M, L].
            K (np.ndarray, optional): Covariance matrix of p, shape [M, M] or [L, M, M].
            K_cholesky (np.ndarray, optional): Cholesky factor of K, shape [M, M] or [L, M, M].
    
        Returns:
            float: The sum of KL divergences for all L distributions.
        """
        M, L = q_mu.shape
        if K is None and K_cholesky is None:
            K_inv = np.eye(M)
            log_det_K = 0.0
        else:
            if K is not None:
                if K.ndim == 2:
                    K_cholesky = np.linalg.cholesky(K)
                else:
                    K_cholesky = np.array([np.linalg.cholesky(K[i]) for i in range(L)])
            if K_cholesky.ndim == 2:
                K_inv = np.linalg.inv(K_cholesky).T @ np.linalg.inv(K_cholesky)
                log_det_K = 2 * np.sum(np.log(np.diag(K_cholesky)))
            else:
                K_inv = np.array([np.linalg.inv(K_cholesky[i]).T @ np.linalg.inv(K_cholesky[i]) for i in range(L)])
                log_det_K = 2 * np.sum([np.log(np.diag(K_cholesky[i])) for i in range(L)], axis=1)
        kl_sum = 0.0
        for l in range(L):
            q_mu_l = q_mu[:, l]
            if q_sqrt.ndim == 3:
                q_sqrt_l = q_sqrt[l]
                Sigma_q = q_sqrt_l @ q_sqrt_l.T
                log_det_Sigma_q = 2 * np.sum(np.log(np.diag(q_sqrt_l)))
            else:
                q_sqrt_l = np.diag(q_sqrt[:, l])
                Sigma_q = q_sqrt_l @ q_sqrt_l
                log_det_Sigma_q = 2 * np.sum(np.log(np.diag(q_sqrt_l)))
>           if K.ndim == 3:
E           AttributeError: 'NoneType' object has no attribute 'ndim'

/local/data0/moved_data/publishablew/GPflow/GPflow/gpflow/temp.py:53: AttributeError
______________________________ test_oned[True-1] _______________________________

white = True, dim = 1

    @pytest.mark.parametrize("dim", [0, 1])
    @pytest.mark.parametrize("white", [True, False])
    def test_oned(white: bool, dim: bool) -> None:
        """
        Check that the KL divergence matches a 1D by-hand calculation.
        """
        mu1d = Datum.mu[dim, :][None, :]  # [1, N]
        s1d = Datum.sqrt[:, dim, dim][:, None, None]  # [N, 1, 1]
        K1d = Datum.K_batch[:, dim, dim][:, None, None]  # [N, 1, 1]
    
>       kl = gauss_kl(mu1d, s1d, K1d if not white else None)

/local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py:223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/local/data0/moved_data/publishablew/GPflow/GPflow/gpflow/kullback_leiblers.py:24: in gauss_kl
    return gauss_kl(q_mu, q_sqrt, K)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

q_mu = array([[ 1.86755799, -0.97727788,  0.95008842, -0.15135721]])
q_sqrt = array([[[ 0.3869025 ]],

       [[-0.87079715]],

       [[-1.34775906]],

       [[-0.43515355]]])
K = None, K_cholesky = None

    def gauss_kl(q_mu, q_sqrt, K=None, K_cholesky=None):
        """
        Compute the KL divergence KL[q || p] for multiple independent Gaussian distributions.
    
        Args:
            q_mu (np.ndarray): Mean of q, shape [M, L].
            q_sqrt (np.ndarray): Square-root of the covariance of q.
                                 Shape can be [L, M, M] or [M, L].
            K (np.ndarray, optional): Covariance matrix of p, shape [M, M] or [L, M, M].
            K_cholesky (np.ndarray, optional): Cholesky factor of K, shape [M, M] or [L, M, M].
    
        Returns:
            float: The sum of KL divergences for all L distributions.
        """
        M, L = q_mu.shape
        if K is None and K_cholesky is None:
            K_inv = np.eye(M)
            log_det_K = 0.0
        else:
            if K is not None:
                if K.ndim == 2:
                    K_cholesky = np.linalg.cholesky(K)
                else:
                    K_cholesky = np.array([np.linalg.cholesky(K[i]) for i in range(L)])
            if K_cholesky.ndim == 2:
                K_inv = np.linalg.inv(K_cholesky).T @ np.linalg.inv(K_cholesky)
                log_det_K = 2 * np.sum(np.log(np.diag(K_cholesky)))
            else:
                K_inv = np.array([np.linalg.inv(K_cholesky[i]).T @ np.linalg.inv(K_cholesky[i]) for i in range(L)])
                log_det_K = 2 * np.sum([np.log(np.diag(K_cholesky[i])) for i in range(L)], axis=1)
        kl_sum = 0.0
        for l in range(L):
            q_mu_l = q_mu[:, l]
            if q_sqrt.ndim == 3:
                q_sqrt_l = q_sqrt[l]
                Sigma_q = q_sqrt_l @ q_sqrt_l.T
                log_det_Sigma_q = 2 * np.sum(np.log(np.diag(q_sqrt_l)))
            else:
                q_sqrt_l = np.diag(q_sqrt[:, l])
                Sigma_q = q_sqrt_l @ q_sqrt_l
                log_det_Sigma_q = 2 * np.sum(np.log(np.diag(q_sqrt_l)))
>           if K.ndim == 3:
E           AttributeError: 'NoneType' object has no attribute 'ndim'

/local/data0/moved_data/publishablew/GPflow/GPflow/gpflow/temp.py:53: AttributeError
______________________________ test_oned[False-0] ______________________________

white = False, dim = 0

    @pytest.mark.parametrize("dim", [0, 1])
    @pytest.mark.parametrize("white", [True, False])
    def test_oned(white: bool, dim: bool) -> None:
        """
        Check that the KL divergence matches a 1D by-hand calculation.
        """
        mu1d = Datum.mu[dim, :][None, :]  # [1, N]
        s1d = Datum.sqrt[:, dim, dim][:, None, None]  # [N, 1, 1]
        K1d = Datum.K_batch[:, dim, dim][:, None, None]  # [N, 1, 1]
    
        kl = gauss_kl(mu1d, s1d, K1d if not white else None)
        kl_1d = compute_kl_1d(
            tf.reshape(mu1d, (-1,)),  # N
            tf.reshape(s1d, (-1,)),  # N
            None if white else tf.reshape(K1d, (-1,)),
        )  # N
>       np.testing.assert_allclose(kl, kl_1d)

/local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py:229: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<function assert_allclose.<locals>.compare at 0x7994c03ddd00>, array(nan), array(5.91539092))
kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-07, atol=0', 'verbose': True}

    @wraps(func)
    def inner(*args, **kwds):
        with self._recreate_cm():
>           return func(*args, **kwds)
E           AssertionError: 
E           Not equal to tolerance rtol=1e-07, atol=0
E           
E           x and y nan location mismatch:
E            x: array(nan)
E            y: array(5.915391)

/usr/lib/python3.11/contextlib.py:81: AssertionError
______________________________ test_oned[False-1] ______________________________

white = False, dim = 1

    @pytest.mark.parametrize("dim", [0, 1])
    @pytest.mark.parametrize("white", [True, False])
    def test_oned(white: bool, dim: bool) -> None:
        """
        Check that the KL divergence matches a 1D by-hand calculation.
        """
        mu1d = Datum.mu[dim, :][None, :]  # [1, N]
        s1d = Datum.sqrt[:, dim, dim][:, None, None]  # [N, 1, 1]
        K1d = Datum.K_batch[:, dim, dim][:, None, None]  # [N, 1, 1]
    
        kl = gauss_kl(mu1d, s1d, K1d if not white else None)
        kl_1d = compute_kl_1d(
            tf.reshape(mu1d, (-1,)),  # N
            tf.reshape(s1d, (-1,)),  # N
            None if white else tf.reshape(K1d, (-1,)),
        )  # N
>       np.testing.assert_allclose(kl, kl_1d)

/local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py:229: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<function assert_allclose.<locals>.compare at 0x7994c03dd620>, array(nan), array(3.7908131))
kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-07, atol=0', 'verbose': True}

    @wraps(func)
    def inner(*args, **kwds):
        with self._recreate_cm():
>           return func(*args, **kwds)
E           AssertionError: 
E           Not equal to tolerance rtol=1e-07, atol=0
E           
E           x and y nan location mismatch:
E            x: array(nan)
E            y: array(3.790813)

/usr/lib/python3.11/contextlib.py:81: AssertionError
=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/venv/lib/python3.11/site-packages/tensorflow_probability/python/__init__.py:57
  /local/data0/moved_data/publishablew/GPflow/GPflow/venv/lib/python3.11/site-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if (distutils.version.LooseVersion(tf.__version__) <

../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/venv/lib/python3.11/site-packages/tensorflow_probability/python/__init__.py:58
  /local/data0/moved_data/publishablew/GPflow/GPflow/venv/lib/python3.11/site-packages/tensorflow_probability/python/__init__.py:58: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    distutils.version.LooseVersion(required_tensorflow_version)):

tests/gpflow/test_kullback_leiblers.py::test_oned[True-0]
tests/gpflow/test_kullback_leiblers.py::test_oned[False-0]
tests/gpflow/test_kullback_leiblers.py::test_oned[False-1]
  /local/data0/moved_data/publishablew/GPflow/GPflow/gpflow/temp.py:48: RuntimeWarning: invalid value encountered in log
    log_det_Sigma_q = 2 * np.sum(np.log(np.diag(q_sqrt_l)))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[True-0]
FAILED ../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[True-1]
FAILED ../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[False-0]
FAILED ../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[False-1]
======================== 4 failed, 5 warnings in 0.81s =========================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/GPflow/GPflow/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/GPflow/GPflow
collecting ... collected 4 items

../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[True-0] PASSED
../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[True-1] PASSED
../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[False-0] PASSED
../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[False-1] PASSED

=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/venv/lib/python3.11/site-packages/tensorflow_probability/python/__init__.py:57
  /local/data0/moved_data/publishablew/GPflow/GPflow/venv/lib/python3.11/site-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if (distutils.version.LooseVersion(tf.__version__) <

../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/venv/lib/python3.11/site-packages/tensorflow_probability/python/__init__.py:58
  /local/data0/moved_data/publishablew/GPflow/GPflow/venv/lib/python3.11/site-packages/tensorflow_probability/python/__init__.py:58: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    distutils.version.LooseVersion(required_tensorflow_version)):

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================== 4 passed, 2 warnings in 0.64s =========================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/GPflow/GPflow/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/GPflow/GPflow
collecting ... collected 4 items

../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[True-0] PASSED
../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[True-1] PASSED
../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[False-0] PASSED
../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/tests/gpflow/test_kullback_leiblers.py::test_oned[False-1] PASSED

=============================== warnings summary ===============================
../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/venv/lib/python3.11/site-packages/tensorflow_probability/python/__init__.py:57
  /local/data0/moved_data/publishablew/GPflow/GPflow/venv/lib/python3.11/site-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if (distutils.version.LooseVersion(tf.__version__) <

../../../../../../local/data0/moved_data/publishablew/GPflow/GPflow/venv/lib/python3.11/site-packages/tensorflow_probability/python/__init__.py:58
  /local/data0/moved_data/publishablew/GPflow/GPflow/venv/lib/python3.11/site-packages/tensorflow_probability/python/__init__.py:58: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    distutils.version.LooseVersion(required_tensorflow_version)):

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================== 4 passed, 2 warnings in 0.68s =========================
