stage: Evaluating&Metrics
task: Detection
data: Image

prompt:
Generate a Python function called _compute_label_quality_scores that takes in the following parameters:
- labels: a list of dictionaries containing any type of values
- predictions: a list of numpy arrays
- method: an optional string parameter with a default value of "objectlab"
- aggregation_weights: an optional dictionary with string keys and float values
- threshold: an optional float parameter
- overlapping_label_check: an optional boolean parameter with a default value of True
- verbose: a boolean parameter with a default value of True

The function prunes extra bounding boxes and computes label quality scores based on the specified method. If the method is "objectlab", it calculates the scores using specific parameters. Otherwise, it raises a ValueError.

The function returns a numpy array of computed scores.

 ground Truth:cleanlab/object_detection/rank.py

 repo:cleanlab

 function:_compute_label_quality_scores
 
 test_cases:tests/test_filter_count.py
